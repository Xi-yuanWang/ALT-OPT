[I 2023-06-12 00:12:20,373] A new study created in RDB with name: Cora_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9
lr:  0.00012232275962895215
weight_decay:  0.013549343621362717
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.40% Test: 77.90%
Split: 01, Run: 01
None time:  4.091839288827032
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  2.61629640404135
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.20% Test: 77.80%
Split: 01, Run: 03
None time:  2.9242656759452075
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.50
run time now: 9.659052848815918
total time:  11.421869406010956
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 1.81
  Final Train: 100.00 ± 0.00
   Final Test: 76.13 ± 2.63
[I 2023-06-12 00:12:32,513] Trial 0 finished with value: 76.4666748046875 and parameters: {'Fwd': 0.0004630683033693502, 'K': 4, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 9.317082933341654, 'loop': 0, 'loss': 'CE', 'lr': 0.00012232275962895215, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.013549343621362717, 'weightedloss': True}. Best is trial 0 with value: 76.4666748046875.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.003092740749658761
weight_decay:  1.688238925550729e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6223009719979018
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  0.7087849581148475
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.3502598439808935
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 80.00
run time now: 2.708580493927002
total time:  2.734836084069684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 7.37
  Final Train: 100.00 ± 0.00
   Final Test: 76.07 ± 6.90
[I 2023-06-12 00:12:35,748] Trial 1 finished with value: 74.46666717529297 and parameters: {'Fwd': 0.009152307866584372, 'K': 10, 'alpha': 0.75, 'dropout': 0.2, 'gnnepoch': 30, 'lambda1': 0.8, 'lambda2': 7.380078401353093, 'loop': 1, 'loss': 'MSE', 'lr': 0.003092740749658761, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.688238925550729e-05, 'weightedloss': False}. Best is trial 0 with value: 76.4666748046875.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.003604635405971627
weight_decay:  1.4394918328894921e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5570825659669936
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  1.6693870332092047
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.8809403420891613
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.182532787322998
total time:  5.259807097958401
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.36
[I 2023-06-12 00:12:41,568] Trial 2 finished with value: 81.13333129882812 and parameters: {'Fwd': 5.386962661377661e-05, 'K': 10, 'alpha': 0.8, 'dropout': 0.0, 'gnnepoch': 80, 'lambda1': 0.9500000000000001, 'lambda2': 5.498897740374612, 'loop': 1, 'loss': 'CE', 'lr': 0.003604635405971627, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4394918328894921e-06, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.004672834514484735
weight_decay:  0.0035076186825844925
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2960020878817886
None Run 01:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 59.90
Split: 01, Run: 02
None time:  0.25112279201857746
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 59.90
Split: 01, Run: 03
None time:  0.2556912589352578
None Run 03:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 59.90
run time now: 0.8443031311035156
total time:  0.872001247946173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 59.90 ± 0.00
[I 2023-06-12 00:12:42,882] Trial 3 finished with value: 55.80000305175781 and parameters: {'Fwd': 3.970731949200455e-06, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.6000000000000001, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 4.57087058166076, 'loop': 0, 'loss': 'CE', 'lr': 0.004672834514484735, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0035076186825844925, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.005174692552547639
weight_decay:  4.698475849641612e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8464688719250262
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.6546510618645698
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  0.970581651898101
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 73.80
run time now: 3.5033810138702393
total time:  3.5285235929768533
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 2.80
  Final Train: 100.00 ± 0.00
   Final Test: 72.93 ± 4.56
[I 2023-06-12 00:12:46,802] Trial 4 finished with value: 70.0 and parameters: {'Fwd': 0.00013665784497441733, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.55, 'lambda2': 2.5195967459313726, 'loop': 2, 'loss': 'MSE', 'lr': 0.005174692552547639, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.698475849641612e-05, 'weightedloss': True}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.00011455087238352235
weight_decay:  0.0003818141273596722
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.60% Test: 78.30%
Split: 01, Run: 01
None time:  3.0602853801101446
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.80% Test: 79.50%
Split: 01, Run: 02
None time:  2.41486925794743
None Run 02:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 77.50%
Split: 01, Run: 03
None time:  2.9010832391213626
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 8.47589898109436
total time:  8.495600850088522
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 1.07
[I 2023-06-12 00:12:55,656] Trial 5 finished with value: 77.53333282470703 and parameters: {'Fwd': 0.007558486812293682, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 1.0, 'lambda2': 8.747256975597614, 'loop': 0, 'loss': 'CE', 'lr': 0.00011455087238352235, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003818141273596722, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.007389090289465032
weight_decay:  0.0013172837306037251
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0258269261103123
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.1987555529922247
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.0532071099150926
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.70
run time now: 3.304774761199951
total time:  3.3291723600123078
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.80 ± 0.26
[I 2023-06-12 00:12:59,302] Trial 6 finished with value: 79.26666259765625 and parameters: {'Fwd': 0.0005347945180643822, 'K': 5, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 1.6892285820253272, 'loop': 1, 'loss': 'MSE', 'lr': 0.007389090289465032, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013172837306037251, 'weightedloss': True}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.7000000000000001
lr:  0.0006884544198537339
weight_decay:  0.0011577141080761424
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.356962257064879
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 74.80%
Split: 01, Run: 02
None time:  1.6518020830117166
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.80% Test: 79.20%
Split: 01, Run: 03
None time:  1.568806380033493
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.600735187530518
total time:  4.619212494930252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.93 ± 2.48
  Final Train: 100.00 ± 0.00
   Final Test: 76.20 ± 2.34
[I 2023-06-12 00:13:04,310] Trial 7 finished with value: 74.93333435058594 and parameters: {'Fwd': 1.1951029757431897e-05, 'K': 2, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.1, 'lambda2': 9.820204742227489, 'loop': 0, 'loss': 'MSE', 'lr': 0.0006884544198537339, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0011577141080761424, 'weightedloss': True}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.0001496302435544526
weight_decay:  0.04287170927649111
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8267612708732486
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.7903491561301053
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 76.40%
Split: 01, Run: 03
None time:  2.9499208831693977
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.40
run time now: 6.590437650680542
total time:  6.617058445932344
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.13 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 1.29
[I 2023-06-12 00:13:11,312] Trial 8 finished with value: 77.13333892822266 and parameters: {'Fwd': 1.879271965851804e-05, 'K': 5, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 7.938978085329172, 'loop': 0, 'loss': 'CE', 'lr': 0.0001496302435544526, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.04287170927649111, 'weightedloss': True}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.65
lr:  0.009724523504331948
weight_decay:  2.758018217983115e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4493079909589142
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.6128618530929089
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.4810637088958174
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.60
run time now: 4.567022085189819
total time:  4.586016905028373
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.61
[I 2023-06-12 00:13:16,379] Trial 9 finished with value: 78.46666717529297 and parameters: {'Fwd': 0.00016101245068211726, 'K': 1, 'alpha': 0.65, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 9.865391081330502, 'loop': 1, 'loss': 'MSE', 'lr': 0.009724523504331948, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.758018217983115e-06, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.0019112332758853784
weight_decay:  1.9592232858942062e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.187015544855967
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  1.5903796150814742
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  2.267460779985413
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
run time now: 6.072049856185913
total time:  6.098277952056378
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.57 ± 0.42
[I 2023-06-12 00:13:22,924] Trial 10 finished with value: 80.13333129882812 and parameters: {'Fwd': 2.4930504265513243e-06, 'K': 8, 'alpha': 1.0, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 5.8262974459416, 'loop': 2, 'loss': 'CE', 'lr': 0.0019112332758853784, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.9592232858942062e-06, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.0020089946088003297
weight_decay:  1.7082853260168328e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.956606307066977
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  2.071810560999438
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  2.063295266125351
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.80
run time now: 6.113403558731079
total time:  6.131281578913331
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 80.63 ± 0.47
[I 2023-06-12 00:13:29,555] Trial 11 finished with value: 80.20000457763672 and parameters: {'Fwd': 1.5522811441555893e-06, 'K': 8, 'alpha': 1.0, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 5.520728748523365, 'loop': 2, 'loss': 'CE', 'lr': 0.0020089946088003297, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7082853260168328e-06, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.001491782557070654
weight_decay:  1.2178311105885435e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7032675901427865
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  2.08220172021538
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  2.0088927869219333
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.8216352462768555
total time:  5.848305260995403
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 79.27 ± 0.67
[I 2023-06-12 00:13:35,853] Trial 12 finished with value: 79.33332824707031 and parameters: {'Fwd': 1.1219461849205419e-06, 'K': 8, 'alpha': 0.05, 'dropout': 0.0, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 4.904882645492617, 'loop': 2, 'loss': 'CE', 'lr': 0.001491782557070654, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2178311105885435e-06, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0025114662752695467
weight_decay:  1.8309766886505925e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.958475672872737
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.4807218790519983
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.430035786004737
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.70
run time now: 3.8951807022094727
total time:  3.920336670940742
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 79.63 ± 1.37
[I 2023-06-12 00:13:40,235] Trial 13 finished with value: 79.33333587646484 and parameters: {'Fwd': 2.631212574813878e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 50, 'lambda1': 0.35000000000000003, 'lambda2': 6.216853709206171, 'loop': 2, 'loss': 'CE', 'lr': 0.0025114662752695467, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8309766886505925e-05, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0009239603701166584
weight_decay:  5.891251456761136e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7569514759816229
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 02
None time:  0.5828700521960855
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.5525739470031112
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 73.40
run time now: 1.9220528602600098
total time:  1.9419924921821803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 2.39
  Final Train: 100.00 ± 0.00
   Final Test: 73.00 ± 3.22
[I 2023-06-12 00:13:42,600] Trial 14 finished with value: 72.26667022705078 and parameters: {'Fwd': 1.3529777088668495e-06, 'K': 7, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 0, 'lambda1': 0.25, 'lambda2': 3.3027569921542868, 'loop': 1, 'loss': 'CE', 'lr': 0.0009239603701166584, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.891251456761136e-06, 'weightedloss': False}. Best is trial 2 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.004019053281786702
weight_decay:  7.783772874865377e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0614801589399576
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7627069128211588
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.9182846180628985
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.7675158977508545
total time:  5.792948170797899
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.65
[I 2023-06-12 00:13:48,815] Trial 15 finished with value: 81.5999984741211 and parameters: {'Fwd': 7.781968150311958e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.060556131128363, 'loop': 1, 'loss': 'CE', 'lr': 0.004019053281786702, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.783772874865377e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0038276131399213667
weight_decay:  0.00011335635956275616
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.862262493930757
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.1626363210380077
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.066780747147277
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.120781183242798
total time:  6.136990495026112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.87
[I 2023-06-12 00:13:55,381] Trial 16 finished with value: 80.86666870117188 and parameters: {'Fwd': 4.748989913731255e-05, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.8524168703635775, 'loop': 1, 'loss': 'CE', 'lr': 0.0038276131399213667, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011335635956275616, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0063322498709398965
weight_decay:  0.00012081274915994276
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.752400501864031
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.713598886039108
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.9105487049091607
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 80.70
run time now: 5.407263994216919
total time:  5.430308724055067
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.12
  Final Train: 99.52 ± 0.41
   Final Test: 81.10 ± 0.69
[I 2023-06-12 00:14:01,223] Trial 17 finished with value: 81.06666564941406 and parameters: {'Fwd': 1.1445456110534968e-05, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 1.3279890658661375, 'loop': 1, 'loss': 'CE', 'lr': 0.0063322498709398965, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012081274915994276, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0038159643265797683
weight_decay:  8.709349972558167e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1102794588077813
None Run 01:
Highest Train: 99.29
Highest Valid: 80.80
  Final Train: 97.86
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5799728920683265
None Run 02:
Highest Train: 99.29
Highest Valid: 80.00
  Final Train: 95.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.6640139110386372
None Run 03:
Highest Train: 99.29
Highest Valid: 80.00
  Final Train: 97.14
   Final Test: 80.20
run time now: 4.3834145069122314
total time:  4.439204246038571
None All runs:
Highest Train: 99.29 ± 0.00
Highest Valid: 80.27 ± 0.46
  Final Train: 96.67 ± 1.49
   Final Test: 80.73 ± 1.01
[I 2023-06-12 00:14:06,106] Trial 18 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.09337938705587334, 'K': 7, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 0.010062295991724923, 'loop': 1, 'loss': 'CE', 'lr': 0.0038159643265797683, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.709349972558167e-06, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.008385653408231093
weight_decay:  3.9526141947482225e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7152258090209216
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  1.862745309015736
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.8413360281847417
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.4401397705078125
total time:  5.458354793023318
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 79.73 ± 0.21
[I 2023-06-12 00:14:12,122] Trial 19 finished with value: 80.79999542236328 and parameters: {'Fwd': 6.0922250786184487e-05, 'K': 9, 'alpha': 0.8, 'dropout': 0.1, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 6.807285757688826, 'loop': 1, 'loss': 'CE', 'lr': 0.008385653408231093, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.9526141947482225e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.0013224258549449485
weight_decay:  5.491226277289014e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9544566350523382
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  2.0368987179826945
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  2.169305684044957
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.30
run time now: 6.1829071044921875
total time:  6.257255767006427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 80.13 ± 0.85
[I 2023-06-12 00:14:18,940] Trial 20 finished with value: 80.0 and parameters: {'Fwd': 6.778225873971787e-06, 'K': 6, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 4.026403020464412, 'loop': 1, 'loss': 'CE', 'lr': 0.0013224258549449485, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.491226277289014e-06, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0048025602890800195
weight_decay:  0.0001253943594761959
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0329737099818885
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9099739489611238
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.0182268309872597
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.998088836669922
total time:  6.016443229978904
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.68
[I 2023-06-12 00:14:25,367] Trial 21 finished with value: 81.4000015258789 and parameters: {'Fwd': 6.477888438086828e-06, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 5.059024803138761, 'loop': 1, 'loss': 'CE', 'lr': 0.0048025602890800195, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001253943594761959, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0059290828806477305
weight_decay:  0.00021469485298846575
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5070381921250373
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  1.8856396940536797
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.7044164801482111
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.20
run time now: 5.119880437850952
total time:  5.150830191094428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.73 ± 0.61
[I 2023-06-12 00:14:31,046] Trial 22 finished with value: 80.80000305175781 and parameters: {'Fwd': 6.293737975322332e-06, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 5.0772100835125356, 'loop': 1, 'loss': 'CE', 'lr': 0.0059290828806477305, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021469485298846575, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.0035076047361376583
weight_decay:  3.5285413029349625e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0120844091288745
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.254325133981183
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.9800187651999295
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.272672891616821
total time:  6.294152640970424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.35
[I 2023-06-12 00:14:37,758] Trial 23 finished with value: 81.33333587646484 and parameters: {'Fwd': 4.259830332322054e-06, 'K': 10, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 6.316166525424285, 'loop': 1, 'loss': 'CE', 'lr': 0.0035076047361376583, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.5285413029349625e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0028425865632601827
weight_decay:  3.1955811597709246e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9558978469576687
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9329902259632945
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.185987996868789
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.099217891693115
total time:  6.122918592998758
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.40
[I 2023-06-12 00:14:44,399] Trial 24 finished with value: 81.0666732788086 and parameters: {'Fwd': 3.1727720488385814e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 6.563311941593625, 'loop': 1, 'loss': 'CE', 'lr': 0.0028425865632601827, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.1955811597709246e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.009772875014128676
weight_decay:  7.923644973575599e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.35281851910986
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 02
None time:  2.285192067967728
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.1943448800593615
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.90
run time now: 6.8549964427948
total time:  6.872716224985197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 1.02
[I 2023-06-12 00:14:51,779] Trial 25 finished with value: 80.33333587646484 and parameters: {'Fwd': 4.581771733877071e-06, 'K': 7, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 4.511373312500678, 'loop': 1, 'loss': 'CE', 'lr': 0.009772875014128676, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.923644973575599e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.004888064156256283
weight_decay:  0.0003807390955370936
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.085094843991101
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.9522471569944173
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 03
None time:  2.1380468520801514
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 6.204545974731445
total time:  6.233657923992723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 0.57
[I 2023-06-12 00:14:58,459] Trial 26 finished with value: 80.5999984741211 and parameters: {'Fwd': 1.0221266288302988e-05, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 6.059926058010255, 'loop': 0, 'loss': 'CE', 'lr': 0.004888064156256283, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003807390955370936, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0060375240009237375
weight_decay:  6.52291274373935e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4609131028410047
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  1.3360531420912594
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.4487353728618473
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 79.50
run time now: 4.275414228439331
total time:  4.293309507891536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 79.47 ± 0.45
[I 2023-06-12 00:15:03,306] Trial 27 finished with value: 77.66666412353516 and parameters: {'Fwd': 2.2399802172376273e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 7.409877337039221, 'loop': 2, 'loss': 'MSE', 'lr': 0.0060375240009237375, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.52291274373935e-05, 'weightedloss': True}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0025494642776794463
weight_decay:  1.8772232772280562e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.379910381976515
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.5603157291188836
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.766779461875558
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.80
run time now: 4.727126359939575
total time:  4.754366104025394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 79.63 ± 0.85
[I 2023-06-12 00:15:08,565] Trial 28 finished with value: 79.13333129882812 and parameters: {'Fwd': 1.704179823940801e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 3.47028184162032, 'loop': 1, 'loss': 'CE', 'lr': 0.0025494642776794463, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8772232772280562e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.004284231168472972
weight_decay:  0.00021170001819102916
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9209432289935648
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.7758768468629569
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  2.0559436378534883
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.7763566970825195
total time:  5.799609411042184
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 81.97 ± 0.40
[I 2023-06-12 00:15:14,841] Trial 29 finished with value: 80.9333267211914 and parameters: {'Fwd': 5.293234883355798e-06, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 5.299587162641023, 'loop': 0, 'loss': 'CE', 'lr': 0.004284231168472972, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00021170001819102916, 'weightedloss': True}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.0056920759525874234
weight_decay:  0.00013882239825224963
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.715157259022817
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.9090843650046736
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.7872258010320365
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.433799982070923
total time:  5.4584732530638576
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.32
[I 2023-06-12 00:15:20,876] Trial 30 finished with value: 81.0 and parameters: {'Fwd': 1.3222723187541113e-06, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 4.6160161898229, 'loop': 1, 'loss': 'CE', 'lr': 0.0056920759525874234, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013882239825224963, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.0034976185552249533
weight_decay:  3.945035204988658e-06
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8507434430066496
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.4333184878341854
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.9899530839174986
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.303328990936279
total time:  5.322503884090111
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 0.25
[I 2023-06-12 00:15:26,628] Trial 31 finished with value: 80.5999984741211 and parameters: {'Fwd': 3.205268415584062e-05, 'K': 10, 'alpha': 0.8, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.9500000000000001, 'lambda2': 5.676525183033032, 'loop': 1, 'loss': 'CE', 'lr': 0.0034976185552249533, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.945035204988658e-06, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0035127466126449376
weight_decay:  8.463427356460056e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.016295918961987
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.8296310231089592
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.7047742779832333
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.80
run time now: 5.626920700073242
total time:  5.6579201319254935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.70
[I 2023-06-12 00:15:32,711] Trial 32 finished with value: 80.46666717529297 and parameters: {'Fwd': 8.897197041715568e-06, 'K': 9, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 5.44483471042044, 'loop': 1, 'loss': 'CE', 'lr': 0.0035127466126449376, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.463427356460056e-06, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.00732477005001656
weight_decay:  1.0686147928202901e-06
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3021063751075417
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  2.1567611929494888
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  2.2025278171058744
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.60
run time now: 6.688502788543701
total time:  6.715098888147622
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 79.73 ± 0.51
[I 2023-06-12 00:15:39,855] Trial 33 finished with value: 80.60000610351562 and parameters: {'Fwd': 3.593959682431723e-06, 'K': 10, 'alpha': 0.75, 'dropout': 0.1, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 6.5971892494953925, 'loop': 1, 'loss': 'CE', 'lr': 0.00732477005001656, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0686147928202901e-06, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.004660774670155984
weight_decay:  4.3473499143856065e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0617718528956175
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.3355478108860552
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.304753497010097
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 79.40
run time now: 4.728442430496216
total time:  4.7450430791359395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 79.37 ± 0.06
[I 2023-06-12 00:15:45,036] Trial 34 finished with value: 78.73332977294922 and parameters: {'Fwd': 3.185254683791207e-05, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.236450251591271, 'loop': 1, 'loss': 'MSE', 'lr': 0.004660774670155984, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.3473499143856065e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0031975864538139934
weight_decay:  1.4770375932850033e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.720827020937577
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  1.6737151979468763
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.740836851997301
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.40
run time now: 5.163758754730225
total time:  5.190466854954138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.73 ± 0.29
[I 2023-06-12 00:15:50,643] Trial 35 finished with value: 79.73332977294922 and parameters: {'Fwd': 1.282301359202076e-05, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 4.971983077162228, 'loop': 1, 'loss': 'CE', 'lr': 0.0031975864538139934, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4770375932850033e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.007348186513909657
weight_decay:  2.282165459123299e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.609089493053034
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.6243843489792198
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.7109537478536367
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 1.9706673622131348
total time:  1.9900640149135143
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.93 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.69
[I 2023-06-12 00:15:53,064] Trial 36 finished with value: 68.93333435058594 and parameters: {'Fwd': 3.02166638071476e-06, 'K': 8, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 5.935150195723363, 'loop': 0, 'loss': 'CE', 'lr': 0.007348186513909657, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.282165459123299e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.004648446275882239
weight_decay:  6.0997253382578034e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7387554158922285
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.8569583459757268
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.4004213018342853
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.30
run time now: 5.025805234909058
total time:  5.053498370107263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 1.04
[I 2023-06-12 00:15:58,552] Trial 37 finished with value: 79.79999542236328 and parameters: {'Fwd': 6.944031081118621e-05, 'K': 10, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 20, 'lambda1': 0.8, 'lambda2': 4.473670153063111, 'loop': 2, 'loss': 'MSE', 'lr': 0.004648446275882239, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.0997253382578034e-05, 'weightedloss': True}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.0027116980721983005
weight_decay:  0.0006457889278903174
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9247101249638945
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.3073898130096495
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.3355182621162385
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.588578701019287
total time:  3.6166772509459406
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.00
[I 2023-06-12 00:16:02,706] Trial 38 finished with value: 68.80000305175781 and parameters: {'Fwd': 2.013632729214251e-05, 'K': 10, 'alpha': 0.1, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 7.073300489621424, 'loop': 1, 'loss': 'CE', 'lr': 0.0027116980721983005, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006457889278903174, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.75
lr:  0.002104497050746483
weight_decay:  3.451903345287574e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.00% Test: 80.30%
Split: 01, Run: 01
None time:  2.7896049038972706
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.20% Test: 81.20%
Split: 01, Run: 02
None time:  3.064222862944007
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.00% Test: 80.90%
Split: 01, Run: 03
None time:  2.430909108137712
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 8.309810876846313
total time:  8.330839289119467
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.46
[I 2023-06-12 00:16:11,529] Trial 39 finished with value: 79.06666564941406 and parameters: {'Fwd': 6.426315574807419e-06, 'K': 4, 'alpha': 0.75, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.9500000000000001, 'lambda2': 7.736752030625617, 'loop': 0, 'loss': 'MSE', 'lr': 0.002104497050746483, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.451903345287574e-06, 'weightedloss': True}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.004212087500898654
weight_decay:  1.0240503514329916e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8976007120218128
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9459136549849063
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.9700322519056499
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.8408923149108887
total time:  2.8664255389012396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.00
[I 2023-06-12 00:16:14,879] Trial 40 finished with value: 68.80000305175781 and parameters: {'Fwd': 0.00013879481218728672, 'K': 9, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.35066488417824, 'loop': 1, 'loss': 'CE', 'lr': 0.004212087500898654, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0240503514329916e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0028185870779421957
weight_decay:  3.2513244763788304e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0309219320770353
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.9248648260254413
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.1980812968686223
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.195959806442261
total time:  6.210566772148013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.40
[I 2023-06-12 00:16:21,612] Trial 41 finished with value: 81.0666732788086 and parameters: {'Fwd': 2.7628609863780545e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 6.791142312912018, 'loop': 1, 'loss': 'CE', 'lr': 0.0028185870779421957, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.2513244763788304e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0029696300058671223
weight_decay:  3.3367390124165524e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9376970671582967
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.115217911079526
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.9137166431173682
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
run time now: 5.989753723144531
total time:  6.017473476938903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.17
[I 2023-06-12 00:16:28,022] Trial 42 finished with value: 81.0 and parameters: {'Fwd': 4.177704115180287e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 8.313691541705367, 'loop': 1, 'loss': 'CE', 'lr': 0.0029696300058671223, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.3367390124165524e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8500000000000001
lr:  0.005248641496762981
weight_decay:  6.416001144136662e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7190985409542918
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.9134090507868677
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.8926153969950974
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.551333904266357
total time:  5.566942652920261
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.72
[I 2023-06-12 00:16:34,056] Trial 43 finished with value: 81.0 and parameters: {'Fwd': 1.8697275574381343e-06, 'K': 3, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 6.243609691304984, 'loop': 1, 'loss': 'CE', 'lr': 0.005248641496762981, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.416001144136662e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.003421239625426891
weight_decay:  2.106688971923096e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3698970139957964
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.7375743601005524
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.8209601340349764
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.953685998916626
total time:  4.966418719151989
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.72
[I 2023-06-12 00:16:39,501] Trial 44 finished with value: 80.19998931884766 and parameters: {'Fwd': 1.5041518018383131e-05, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 5.417011227503561, 'loop': 1, 'loss': 'CE', 'lr': 0.003421239625426891, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.106688971923096e-06, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0019378128011612655
weight_decay:  0.00022829517169035236
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1472952489275485
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  2.4273796200286597
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.296010226942599
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.80
run time now: 6.898165464401245
total time:  6.916934340028092
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 0.47
[I 2023-06-12 00:16:46,954] Trial 45 finished with value: 80.20000457763672 and parameters: {'Fwd': 8.471553247950725e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 7.086760799249976, 'loop': 1, 'loss': 'CE', 'lr': 0.0019378128011612655, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00022829517169035236, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.004323055449415154
weight_decay:  2.8200861166413727e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.044579708017409
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9882909648586065
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.915175996022299
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.9698402881622314
total time:  5.982616723980755
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.80 ± 0.30
[I 2023-06-12 00:16:53,528] Trial 46 finished with value: 81.46666717529297 and parameters: {'Fwd': 2.6293074671902924e-06, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.828469251709075, 'loop': 1, 'loss': 'CE', 'lr': 0.004323055449415154, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.8200861166413727e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.007706662769290961
weight_decay:  1.21770153781792e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4637962030246854
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.629022784065455
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.994695619912818
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
run time now: 7.1199469566345215
total time:  7.142292869044468
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.84
[I 2023-06-12 00:17:01,104] Trial 47 finished with value: 80.66666412353516 and parameters: {'Fwd': 1.0970631536173273e-06, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 4.993840735360872, 'loop': 1, 'loss': 'CE', 'lr': 0.007706662769290961, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.21770153781792e-05, 'weightedloss': True}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.2
lr:  0.003999872495750778
weight_decay:  2.3900911820923902e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1310, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 01
None time:  7.18290781811811
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.1268, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 02
None time:  6.6959672649390996
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.1196, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 03
None time:  6.373973271111026
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
run time now: 20.28110647201538
total time:  20.30742348311469
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 73.20 ± 0.00
[I 2023-06-12 00:17:22,153] Trial 48 finished with value: 72.5999984741211 and parameters: {'Fwd': 1.8528685917177865e-06, 'K': 7, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.0, 'lambda2': 5.627482222968248, 'loop': 2, 'loss': 'MSE', 'lr': 0.003999872495750778, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3900911820923902e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.002298262390836825
weight_decay:  0.0005381887069592486
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.98057532007806
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.771077728131786
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.9252650230191648
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 5.703024387359619
total time:  5.721466870047152
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.78
[I 2023-06-12 00:17:28,459] Trial 49 finished with value: 80.39999389648438 and parameters: {'Fwd': 2.0805162411661354e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 5.99825023107013, 'loop': 1, 'loss': 'CE', 'lr': 0.002298262390836825, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005381887069592486, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0016135854006846452
weight_decay:  0.00010004100577682368
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1113644042052329
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.5401840989943594
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.4616345660760999
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 4.140562057495117
total time:  4.166459909873083
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 79.47 ± 1.01
[I 2023-06-12 00:17:33,130] Trial 50 finished with value: 78.73332977294922 and parameters: {'Fwd': 0.00030800632127969945, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 3.7420733467687715, 'loop': 1, 'loss': 'CE', 'lr': 0.0016135854006846452, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010004100577682368, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.003198919448296599
weight_decay:  4.138618264138888e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1320042200386524
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.9776611428242177
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.20245677488856
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.338082313537598
total time:  6.358125287108123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.40
[I 2023-06-12 00:17:39,993] Trial 51 finished with value: 80.93333435058594 and parameters: {'Fwd': 3.7871735242523227e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 6.602642034034507, 'loop': 1, 'loss': 'CE', 'lr': 0.003198919448296599, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.138618264138888e-05, 'weightedloss': False}. Best is trial 15 with value: 81.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.005220016048575065
weight_decay:  2.6159982979930876e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0155895189382136
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2128036031499505
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.9784690539818257
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.70
run time now: 6.229489088058472
total time:  6.2534161088988185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.25
[I 2023-06-12 00:17:46,731] Trial 52 finished with value: 81.73333740234375 and parameters: {'Fwd': 2.3580282032885736e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.779725587577481, 'loop': 1, 'loss': 'CE', 'lr': 0.005220016048575065, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6159982979930876e-05, 'weightedloss': False}. Best is trial 52 with value: 81.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.005185525680942401
weight_decay:  5.543844599475541e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9896739479154348
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1087485030293465
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.857501442078501
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.0137786865234375
total time:  6.045734131941572
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.91
[I 2023-06-12 00:17:53,303] Trial 53 finished with value: 81.26666259765625 and parameters: {'Fwd': 7.232734152602405e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 4.821905216301075, 'loop': 1, 'loss': 'CE', 'lr': 0.005185525680942401, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.543844599475541e-06, 'weightedloss': False}. Best is trial 52 with value: 81.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.006427794991791317
weight_decay:  1.345782295384835e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.231216765008867
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  2.4546827741432935
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.332168139051646
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.10
run time now: 7.057059288024902
total time:  7.091174144065008
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 80.70 ± 0.72
[I 2023-06-12 00:18:00,944] Trial 54 finished with value: 80.79999542236328 and parameters: {'Fwd': 1.0693134045545294e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 4.8876720659329465, 'loop': 1, 'loss': 'CE', 'lr': 0.006427794991791317, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.345782295384835e-05, 'weightedloss': False}. Best is trial 52 with value: 81.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.0053157120744399666
weight_decay:  2.4315571657545116e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1131508010439575
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.0874755759723485
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.9050516339484602
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.131724834442139
total time:  6.1465326440520585
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.92
[I 2023-06-12 00:18:07,560] Trial 55 finished with value: 80.46666717529297 and parameters: {'Fwd': 2.155518979651702e-06, 'K': 8, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 4.2297036145396145, 'loop': 1, 'loss': 'CE', 'lr': 0.0053157120744399666, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.4315571657545116e-05, 'weightedloss': False}. Best is trial 52 with value: 81.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0087248730469738
weight_decay:  6.537630938078175e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3629170660860837
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  2.3703924510627985
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.9669283819384873
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.20
run time now: 6.726960897445679
total time:  6.746998718008399
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 80.10 ± 0.82
[I 2023-06-12 00:18:14,963] Trial 56 finished with value: 80.66666412353516 and parameters: {'Fwd': 6.144865059579775e-06, 'K': 9, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.8187008045703985, 'loop': 1, 'loss': 'CE', 'lr': 0.0087248730469738, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.537630938078175e-06, 'weightedloss': False}. Best is trial 52 with value: 81.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.006620158953620357
weight_decay:  5.702297508419528e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.203691925154999
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.011203096015379
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.212028735084459
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.452815055847168
total time:  6.470773039152846
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.98
[I 2023-06-12 00:18:21,942] Trial 57 finished with value: 81.0 and parameters: {'Fwd': 8.255448308178139e-06, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 3.0454088116455456, 'loop': 1, 'loss': 'CE', 'lr': 0.006620158953620357, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.702297508419528e-05, 'weightedloss': False}. Best is trial 52 with value: 81.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.005192044307938228
weight_decay:  9.49091860955623e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1844249279238284
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0486104148440063
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.2207897850312293
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
run time now: 6.482443332672119
total time:  6.5093129391316324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.62
[I 2023-06-12 00:18:28,929] Trial 58 finished with value: 80.79999542236328 and parameters: {'Fwd': 4.693689864311303e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 5.107724620483193, 'loop': 1, 'loss': 'CE', 'lr': 0.005192044307938228, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.49091860955623e-05, 'weightedloss': False}. Best is trial 52 with value: 81.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004234905323363422
weight_decay:  1.4723260307570959e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.154907519929111
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.954841883154586
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.93203540192917
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.068269491195679
total time:  6.095271498896182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.64
[I 2023-06-12 00:18:35,576] Trial 59 finished with value: 81.80001068115234 and parameters: {'Fwd': 1.6085814936617253e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.678927680523105, 'loop': 1, 'loss': 'CE', 'lr': 0.004234905323363422, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4723260307570959e-05, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.05
lr:  0.00444194127109101
weight_decay:  1.6850310769959147e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2537306069862098
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.368770875968039
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.15103960596025
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.00
run time now: 3.8010382652282715
total time:  3.819005215074867
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 3.14
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 2.57
[I 2023-06-12 00:18:39,868] Trial 60 finished with value: 68.86666107177734 and parameters: {'Fwd': 1.645957515845431e-06, 'K': 6, 'alpha': 0.05, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 5.3979481156484646, 'loop': 0, 'loss': 'CE', 'lr': 0.00444194127109101, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6850310769959147e-05, 'weightedloss': True}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.004125760771195594
weight_decay:  9.355577666504779e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.075019677169621
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.2153567490167916
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.799360224045813
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.129083156585693
total time:  6.153071118053049
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.55
[I 2023-06-12 00:18:46,558] Trial 61 finished with value: 81.73333740234375 and parameters: {'Fwd': 2.196327069051906e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.744047373293356, 'loop': 1, 'loss': 'CE', 'lr': 0.004125760771195594, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.355577666504779e-06, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0036606645191477167
weight_decay:  4.288782541520406e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.184149453882128
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.1928825778886676
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.649611313128844
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.0556230545043945
total time:  6.082210729131475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.60
[I 2023-06-12 00:18:53,187] Trial 62 finished with value: 81.46666717529297 and parameters: {'Fwd': 2.067524884525405e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.423374246722416, 'loop': 1, 'loss': 'CE', 'lr': 0.0036606645191477167, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.288782541520406e-05, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.004150150709736637
weight_decay:  0.00015012012631617747
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1794453780166805
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.4802562450058758
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.10894311289303
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.798363447189331
total time:  5.8195874048396945
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.64
[I 2023-06-12 00:18:59,477] Trial 63 finished with value: 81.80001068115234 and parameters: {'Fwd': 2.501111761331826e-06, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.154883146446903, 'loop': 1, 'loss': 'CE', 'lr': 0.004150150709736637, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015012012631617747, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.004053589692397175
weight_decay:  9.734748008883444e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.19071386102587
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.5581620400771499
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.9507713918574154
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.726360559463501
total time:  5.745857696980238
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.55
[I 2023-06-12 00:19:05,704] Trial 64 finished with value: 81.5999984741211 and parameters: {'Fwd': 2.5943970589962384e-06, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.0675500744457285, 'loop': 1, 'loss': 'CE', 'lr': 0.004053589692397175, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.734748008883444e-06, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.004115043284879447
weight_decay:  1.0988151202136546e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.485540598165244
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.0113614639267325
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.4452989290002733
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.969905853271484
total time:  6.991791390813887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 80.90 ± 0.96
[I 2023-06-12 00:19:13,166] Trial 65 finished with value: 80.79999542236328 and parameters: {'Fwd': 3.0057657322311704e-06, 'K': 8, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.650142334076583, 'loop': 1, 'loss': 'CE', 'lr': 0.004115043284879447, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0988151202136546e-05, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.2
lr:  0.006556142548588811
weight_decay:  7.656162548552593e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2649381160736084
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 02
None time:  2.1005188580602407
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  2.1767562420573086
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 6.578222990036011
total time:  6.614895112114027
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 80.37 ± 0.87
[I 2023-06-12 00:19:20,351] Trial 66 finished with value: 81.0666732788086 and parameters: {'Fwd': 1.0063352460156112e-06, 'K': 7, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.166822462128243, 'loop': 1, 'loss': 'CE', 'lr': 0.006556142548588811, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.656162548552593e-06, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0023237844516095932
weight_decay:  2.204695754915916e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2605933020822704
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.0501661591697484
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2156317948829383
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.555531740188599
total time:  6.569001897936687
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.40
[I 2023-06-12 00:19:27,385] Trial 67 finished with value: 81.0666732788086 and parameters: {'Fwd': 1.437878702130309e-06, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 3.926954515550081, 'loop': 1, 'loss': 'CE', 'lr': 0.0023237844516095932, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.204695754915916e-05, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.15000000000000002
lr:  0.0038687809764438867
weight_decay:  1.7091715656284663e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9025160209275782
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  2.369376097805798
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.861812189919874
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.70
run time now: 6.156196355819702
total time:  6.201352671021596
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 0.35
[I 2023-06-12 00:19:34,182] Trial 68 finished with value: 79.33333587646484 and parameters: {'Fwd': 2.536747120999525e-06, 'K': 7, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.688639579996757, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038687809764438867, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7091715656284663e-05, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0057252637150876735
weight_decay:  9.445475107659166e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2591433408670127
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.9405772630125284
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.9841532008722425
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.212045669555664
total time:  6.231500533176586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 0.59
[I 2023-06-12 00:19:40,875] Trial 69 finished with value: 80.66666412353516 and parameters: {'Fwd': 1.4919133399822682e-06, 'K': 8, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 3.1071816444782647, 'loop': 1, 'loss': 'CE', 'lr': 0.0057252637150876735, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.445475107659166e-06, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0031016360809081856
weight_decay:  4.280386790936135e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5583893090952188
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 02
None time:  0.7673605198506266
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.5307476629968733
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 1.8875575065612793
total time:  1.9064857000485063
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 2.09
  Final Train: 100.00 ± 0.00
   Final Test: 71.30 ± 2.23
[I 2023-06-12 00:19:43,260] Trial 70 finished with value: 70.4000015258789 and parameters: {'Fwd': 2.879906035603189e-06, 'K': 8, 'alpha': 0.25, 'dropout': 0.4, 'gnnepoch': 0, 'lambda1': 0.65, 'lambda2': 3.9377979921203314, 'loop': 1, 'loss': 'CE', 'lr': 0.0031016360809081856, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.280386790936135e-06, 'weightedloss': False}. Best is trial 59 with value: 81.80001068115234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004365124114750151
weight_decay:  3.0192800618880286e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3037956419866532
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.206098346039653
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.1295085318852216
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.667638540267944
total time:  5.694519297918305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:19:49,523] Trial 71 finished with value: 82.0 and parameters: {'Fwd': 2.1024841957616666e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.390892049492704, 'loop': 1, 'loss': 'CE', 'lr': 0.004365124114750151, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.0192800618880286e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.004642526822923637
weight_decay:  2.5799269452448894e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.981246290029958
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.341642967890948
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.237780410097912
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.583991289138794
total time:  6.612069009104744
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.85
[I 2023-06-12 00:19:56,592] Trial 72 finished with value: 80.73333740234375 and parameters: {'Fwd': 2.0400786407026585e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 4.3852476085073935, 'loop': 1, 'loss': 'CE', 'lr': 0.004642526822923637, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.5799269452448894e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.00394789356470303
weight_decay:  7.425658563730309e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9707501721568406
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.1928466060198843
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.075786306988448
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.265605926513672
total time:  6.287958963075653
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.25
[I 2023-06-12 00:20:03,381] Trial 73 finished with value: 81.46666717529297 and parameters: {'Fwd': 4.908407086669857e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 4.732074905317898, 'loop': 1, 'loss': 'CE', 'lr': 0.00394789356470303, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.425658563730309e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0026614332862287923
weight_decay:  1.3443321363438564e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.241229873849079
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.1921715908683836
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.2385949671734124
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.80
run time now: 6.69196343421936
total time:  6.708074531983584
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.50
[I 2023-06-12 00:20:10,731] Trial 74 finished with value: 81.0666732788086 and parameters: {'Fwd': 1.4957970947328006e-06, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 5.215397541071331, 'loop': 1, 'loss': 'CE', 'lr': 0.0026614332862287923, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3443321363438564e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.004469916633573477
weight_decay:  4.675139207695633e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.627488506026566
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  1.893748288974166
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.64148836908862
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 5.1899168491363525
total time:  5.218893728218973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.62
[I 2023-06-12 00:20:16,454] Trial 75 finished with value: 80.73332977294922 and parameters: {'Fwd': 3.7869984486995893e-06, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 3.4783117905368592, 'loop': 1, 'loss': 'CE', 'lr': 0.004469916633573477, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.675139207695633e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.005920253955065115
weight_decay:  2.8604086286904985e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.106089983135462
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.2095579700544477
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.9485249789431691
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.295677423477173
total time:  6.313682938925922
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.81
[I 2023-06-12 00:20:23,234] Trial 76 finished with value: 81.66667175292969 and parameters: {'Fwd': 2.6905200411291294e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.7022553339498305, 'loop': 1, 'loss': 'CE', 'lr': 0.005920253955065115, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.8604086286904985e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.008820888762754971
weight_decay:  7.143435694730614e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.210194684099406
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.2179477689787745
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.2450936599634588
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.7025673389434814
total time:  3.7243037580046803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.00
[I 2023-06-12 00:20:27,478] Trial 77 finished with value: 68.80000305175781 and parameters: {'Fwd': 1.0315450090830546e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 4.221639390748272, 'loop': 1, 'loss': 'CE', 'lr': 0.008820888762754971, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.143435694730614e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.005688295893961108
weight_decay:  0.00015228707642264046
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.431805893080309
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.0972976610064507
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.0751908130478114
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.62670636177063
total time:  5.643203810090199
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.87
[I 2023-06-12 00:20:33,620] Trial 78 finished with value: 80.80000305175781 and parameters: {'Fwd': 1.1332881515298786e-05, 'K': 10, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.670991548146016, 'loop': 1, 'loss': 'CE', 'lr': 0.005688295893961108, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00015228707642264046, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.007296667056176434
weight_decay:  1.7500033400147267e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.564475225051865
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  1.452037338865921
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.3855063288938254
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.422950506210327
total time:  4.444135880097747
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 1.07
[I 2023-06-12 00:20:38,599] Trial 79 finished with value: 79.33333587646484 and parameters: {'Fwd': 5.017676999045758e-06, 'K': 10, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 30, 'lambda1': 0.8, 'lambda2': 3.9783266479643986, 'loop': 1, 'loss': 'MSE', 'lr': 0.007296667056176434, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7500033400147267e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0034428625880535985
weight_decay:  5.265992085962303e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1569193399045616
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.347501417156309
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.439338186988607
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.96913480758667
total time:  6.989344461122528
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.92
[I 2023-06-12 00:20:46,124] Trial 80 finished with value: 80.73332977294922 and parameters: {'Fwd': 1.6821481852249475e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 5.208545960286839, 'loop': 1, 'loss': 'CE', 'lr': 0.0034428625880535985, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.265992085962303e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.005088628291592617
weight_decay:  2.6521088394891574e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.97080258699134
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.079692194936797
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.1657183528877795
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.240439176559448
total time:  6.266610898077488
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.47
[I 2023-06-12 00:20:53,002] Trial 81 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.182142271480197e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.467502883989177, 'loop': 1, 'loss': 'CE', 'lr': 0.005088628291592617, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6521088394891574e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0049058303294636256
weight_decay:  3.3687976715409924e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1450227820314467
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.2372597428038716
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.0589719768613577
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.5096869468688965
total time:  6.528513693017885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.55
[I 2023-06-12 00:21:00,184] Trial 82 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.490519929882577e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.536975425328596, 'loop': 1, 'loss': 'CE', 'lr': 0.0049058303294636256, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.3687976715409924e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.004997995266686254
weight_decay:  3.401322549399568e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.224760093027726
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.3342457509133965
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.3219322690274566
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.904404640197754
total time:  6.923240010859445
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.51
[I 2023-06-12 00:21:07,630] Trial 83 finished with value: 81.46666717529297 and parameters: {'Fwd': 3.785902582726672e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 4.624335901776773, 'loop': 1, 'loss': 'CE', 'lr': 0.004997995266686254, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.401322549399568e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.00590299732004472
weight_decay:  9.369209887902729e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4295718970242888
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9185639969073236
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.3254501218907535
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.701069593429565
total time:  6.72749102814123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.90
[I 2023-06-12 00:21:14,866] Trial 84 finished with value: 80.5999984741211 and parameters: {'Fwd': 3.2251607600946564e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 4.453831638756277, 'loop': 1, 'loss': 'CE', 'lr': 0.00590299732004472, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.369209887902729e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.0030107970692055323
weight_decay:  8.012342034354393e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9194001599680632
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.0803576682228595
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.8420253228396177
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.872263193130493
total time:  5.9048642420675606
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.49
[I 2023-06-12 00:21:21,320] Trial 85 finished with value: 80.73333740234375 and parameters: {'Fwd': 6.048592856091693e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 4.887423775815188, 'loop': 1, 'loss': 'CE', 'lr': 0.0030107970692055323, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.012342034354393e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.006799620653800148
weight_decay:  3.0848949609452954e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0857244110666215
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.217042025877163
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.8969855499453843
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 6.223667144775391
total time:  6.253819603007287
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.81
[I 2023-06-12 00:21:28,168] Trial 86 finished with value: 81.46666717529297 and parameters: {'Fwd': 1.3613211087691467e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 5.547548620078782, 'loop': 1, 'loss': 'CE', 'lr': 0.006799620653800148, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.0848949609452954e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.004874297045676903
weight_decay:  1.9437451170236344e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.259695657994598
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.3508489809464663
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.132335517089814
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.769718170166016
total time:  6.794800884090364
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.81
[I 2023-06-12 00:21:35,503] Trial 87 finished with value: 80.79999542236328 and parameters: {'Fwd': 2.227071819101386e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 4.335557460051116, 'loop': 1, 'loss': 'CE', 'lr': 0.004874297045676903, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.9437451170236344e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.005787064253693472
weight_decay:  4.810126012551327e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.003557969117537
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.8298384160734713
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.9963294041808695
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.8525190353393555
total time:  5.886435298947617
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.00 ± 0.53
[I 2023-06-12 00:21:41,947] Trial 88 finished with value: 81.06666564941406 and parameters: {'Fwd': 8.00203340285991e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 3.7079826969866683, 'loop': 1, 'loss': 'CE', 'lr': 0.005787064253693472, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.810126012551327e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.007859404318257707
weight_decay:  1.2700309451841613e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.43182898312807083
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.2852858048863709
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.40552367409691215
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 1.1528897285461426
total time:  1.1799768980126828
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.00
[I 2023-06-12 00:21:43,615] Trial 89 finished with value: 68.80000305175781 and parameters: {'Fwd': 3.804490887336276e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.30000000000000004, 'gnnepoch': 10, 'lambda1': 0.75, 'lambda2': 5.09742301611607, 'loop': 1, 'loss': 'CE', 'lr': 0.007859404318257707, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2700309451841613e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.0036807201143166557
weight_decay:  5.938473957471838e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0469475251156837
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.201156029012054
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.996776983141899
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.273137092590332
total time:  6.301851797150448
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.80 ± 0.44
[I 2023-06-12 00:21:50,487] Trial 90 finished with value: 81.0 and parameters: {'Fwd': 1.0756820257041905e-05, 'K': 10, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.748458996994905, 'loop': 1, 'loss': 'CE', 'lr': 0.0036807201143166557, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.938473957471838e-05, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004250469554532593
weight_decay:  2.709576035445763e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2450193418189883
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9782572048716247
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.890131447929889
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.139757394790649
total time:  6.158025456825271
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.67
[I 2023-06-12 00:21:57,117] Trial 91 finished with value: 81.80001068115234 and parameters: {'Fwd': 2.3758193359314323e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.017192430755959, 'loop': 1, 'loss': 'CE', 'lr': 0.004250469554532593, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.709576035445763e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.00539092882562265
weight_decay:  3.703366650302956e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.003830371890217
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1861221010331064
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.9483034799341112
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.16288948059082
total time:  6.1918823139276356
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.67
[I 2023-06-12 00:22:03,767] Trial 92 finished with value: 80.66666412353516 and parameters: {'Fwd': 1.9290682489103435e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.149540424581742, 'loop': 1, 'loss': 'CE', 'lr': 0.00539092882562265, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.703366650302956e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004719894551291479
weight_decay:  1.9942134285981182e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0841466961428523
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.9741668929345906
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.9046724089421332
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.019880294799805
total time:  6.050233465153724
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.40
[I 2023-06-12 00:22:10,360] Trial 93 finished with value: 81.86666870117188 and parameters: {'Fwd': 4.811536105454536e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.431706566632372, 'loop': 1, 'loss': 'CE', 'lr': 0.004719894551291479, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.9942134285981182e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.006201345174646868
weight_decay:  2.5967921155869827e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.150050695054233
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 02
None time:  2.172192401951179
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.2141711919102818
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.588450193405151
total time:  6.62268790602684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.50
[I 2023-06-12 00:22:17,432] Trial 94 finished with value: 81.0 and parameters: {'Fwd': 1.284991000789324e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.583029104394113, 'loop': 1, 'loss': 'CE', 'lr': 0.006201345174646868, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.5967921155869827e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004579216228528988
weight_decay:  2.0016117322763778e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.90032521286048
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.5609373978804797
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.9392411760054529
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.435019254684448
total time:  5.451981857186183
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.70
[I 2023-06-12 00:22:23,390] Trial 95 finished with value: 81.0 and parameters: {'Fwd': 5.0920521444239476e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 4.933310128895131, 'loop': 1, 'loss': 'CE', 'lr': 0.004579216228528988, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.0016117322763778e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.005082048721491397
weight_decay:  1.7427404731121902e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9328102488070726
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9783869930543005
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.2296849181875587
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.170088052749634
total time:  6.1970695508643985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.31
[I 2023-06-12 00:22:30,059] Trial 96 finished with value: 81.66666412353516 and parameters: {'Fwd': 2.6853006793318793e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.350103428392547, 'loop': 1, 'loss': 'CE', 'lr': 0.005082048721491397, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7427404731121902e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0033137684945857226
weight_decay:  1.2809214984675428e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.128636596957222
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 02
None time:  2.1749829780310392
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  2.3824580339714885
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.10
run time now: 8.712768316268921
total time:  8.73604017100297
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 79.23 ± 0.23
[I 2023-06-12 00:22:39,297] Trial 97 finished with value: 79.33333587646484 and parameters: {'Fwd': 1.7365291675756345e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 4.455475158243514, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033137684945857226, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2809214984675428e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.003691146411308762
weight_decay:  2.921184842603287e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8076566448435187
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.8826740400400013
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  2.050820149946958
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.765952825546265
total time:  5.783571995096281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.30
[I 2023-06-12 00:22:45,599] Trial 98 finished with value: 80.73332977294922 and parameters: {'Fwd': 3.3007779537295137e-06, 'K': 8, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 4.320667266130094, 'loop': 1, 'loss': 'CE', 'lr': 0.003691146411308762, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.921184842603287e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.0042883493629727095
weight_decay:  8.773974885168288e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7129937820136547
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.164837633026764
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.0723258599173278
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.971673250198364
total time:  5.997137961909175
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.23
[I 2023-06-12 00:22:52,202] Trial 99 finished with value: 81.26666259765625 and parameters: {'Fwd': 2.343028350489526e-06, 'K': 5, 'alpha': 0.25, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 5.1800315673274415, 'loop': 1, 'loss': 'CE', 'lr': 0.0042883493629727095, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.773974885168288e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.006920800087401056
weight_decay:  3.706860693698488e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9288553609512746
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  2.3286913610063493
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.2495722400490195
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.534685373306274
total time:  6.551999490940943
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 80.77 ± 0.67
[I 2023-06-12 00:22:59,318] Trial 100 finished with value: 81.13333892822266 and parameters: {'Fwd': 5.594096941734191e-06, 'K': 8, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 3.844097626311954, 'loop': 1, 'loss': 'CE', 'lr': 0.006920800087401056, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.706860693698488e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0049107635285461125
weight_decay:  1.4792619033527014e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3069798019714653
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2661223909817636
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.6704496298916638
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.272119998931885
total time:  6.290500417817384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.38
[I 2023-06-12 00:23:06,146] Trial 101 finished with value: 81.66666412353516 and parameters: {'Fwd': 2.6245980444043756e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.3874067722463055, 'loop': 1, 'loss': 'CE', 'lr': 0.0049107635285461125, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4792619033527014e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.005432355416793787
weight_decay:  2.168111860169905e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9214369698893279
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.7734726059716195
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.6674715399276465
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
run time now: 5.3947649002075195
total time:  5.408320108894259
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.61
[I 2023-06-12 00:23:12,044] Trial 102 finished with value: 81.20000457763672 and parameters: {'Fwd': 1.3029955152179992e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 5.665462432396138, 'loop': 1, 'loss': 'CE', 'lr': 0.005432355416793787, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.168111860169905e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.006033181999083487
weight_decay:  1.5640243552621965e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9878368608187884
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1079037371091545
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.061562251066789
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.183967351913452
total time:  6.211654391139746
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.45
[I 2023-06-12 00:23:18,734] Trial 103 finished with value: 81.66666412353516 and parameters: {'Fwd': 4.1636994943152815e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.85217520699357, 'loop': 1, 'loss': 'CE', 'lr': 0.006033181999083487, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5640243552621965e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.004898447296764975
weight_decay:  1.1469494729730113e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1703874971717596
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.1701549149584025
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.626060505863279
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.991778373718262
total time:  6.00425642891787
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.60
[I 2023-06-12 00:23:25,313] Trial 104 finished with value: 81.66666412353516 and parameters: {'Fwd': 1.857705255772939e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 5.326609724090305, 'loop': 1, 'loss': 'CE', 'lr': 0.004898447296764975, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1469494729730113e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004192617002609369
weight_decay:  1.8745325302838294e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.489487105049193
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.370656224898994
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.096804897999391
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.986527681350708
total time:  7.006136037874967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.57
[I 2023-06-12 00:23:32,793] Trial 105 finished with value: 80.73333740234375 and parameters: {'Fwd': 3.1231183494852078e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 4.127763183347422, 'loop': 1, 'loss': 'CE', 'lr': 0.004192617002609369, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8745325302838294e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0032309300689018217
weight_decay:  3.0231211259548076e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.191816793056205
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.12104619294405
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.611571720102802
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.9511120319366455
total time:  5.977755817817524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.40
[I 2023-06-12 00:23:39,266] Trial 106 finished with value: 81.26666259765625 and parameters: {'Fwd': 2.2884170814665267e-06, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.701860837117636, 'loop': 1, 'loss': 'CE', 'lr': 0.0032309300689018217, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.0231211259548076e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.006186138727843164
weight_decay:  2.428379217141587e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8945039210375398
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  1.783359545050189
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.7257386401761323
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.430723428726196
total time:  5.447075513191521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.53
[I 2023-06-12 00:23:45,165] Trial 107 finished with value: 80.4000015258789 and parameters: {'Fwd': 1.2505323869684222e-06, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.45664162466103, 'loop': 1, 'loss': 'CE', 'lr': 0.006186138727843164, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.428379217141587e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.003753023122638701
weight_decay:  3.9625778169806744e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3193530719727278
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.3149526820052415
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1144367409870028
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.7776336669921875
total time:  3.7984763169661164
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.00
[I 2023-06-12 00:23:49,478] Trial 108 finished with value: 68.80000305175781 and parameters: {'Fwd': 4.378310980599725e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 4.972786746664995, 'loop': 1, 'loss': 'CE', 'lr': 0.003753023122638701, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.9625778169806744e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.005451327031819547
weight_decay:  5.3357005570821234e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1928170979954302
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  2.003201365005225
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.9236518279649317
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 82.20
run time now: 6.148956775665283
total time:  6.168734253849834
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 0.50
[I 2023-06-12 00:23:56,094] Trial 109 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.168509418057657e-06, 'K': 8, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 3.5910198356492677, 'loop': 1, 'loss': 'CE', 'lr': 0.005451327031819547, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.3357005570821234e-05, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.004646844041254448
weight_decay:  7.661195076902938e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.34996803291142
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.7946266171056777
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.2209391659125686
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.80
run time now: 6.391957759857178
total time:  6.419146925909445
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.81
[I 2023-06-12 00:24:02,960] Trial 110 finished with value: 80.53333282470703 and parameters: {'Fwd': 1.6614709428479197e-06, 'K': 10, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 4.01018344049709, 'loop': 1, 'loss': 'CE', 'lr': 0.004646844041254448, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.661195076902938e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.004989135712766329
weight_decay:  1.543273084285166e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2445213480386883
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6151448010932654
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.1979155400767922
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 6.085238218307495
total time:  6.103968137875199
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.23
[I 2023-06-12 00:24:09,642] Trial 111 finished with value: 81.73332977294922 and parameters: {'Fwd': 2.570458034934255e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.464131894510943, 'loop': 1, 'loss': 'CE', 'lr': 0.004989135712766329, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.543273084285166e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004232411863447072
weight_decay:  1.547491409285442e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1228916910476983
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.9370551479514688
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.0806567850522697
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 6.1679441928863525
total time:  6.1946513468865305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.40
[I 2023-06-12 00:24:16,380] Trial 112 finished with value: 81.5999984741211 and parameters: {'Fwd': 2.3255390729390155e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.71447336060947, 'loop': 1, 'loss': 'CE', 'lr': 0.004232411863447072, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.547491409285442e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.005032399477376592
weight_decay:  1.052114585302849e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.92995196999982
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.7236982251051813
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.9583850118797272
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.6398608684539795
total time:  5.66653569182381
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.72
[I 2023-06-12 00:24:22,489] Trial 113 finished with value: 81.0666732788086 and parameters: {'Fwd': 6.433047628444895e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 5.460169055833838, 'loop': 1, 'loss': 'CE', 'lr': 0.005032399477376592, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.052114585302849e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0028566558030506794
weight_decay:  2.2360263044888445e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8666106378659606
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.8584749908186495
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.9001896639820188
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.651663064956665
total time:  5.667926073074341
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.70
[I 2023-06-12 00:24:28,602] Trial 114 finished with value: 80.73333740234375 and parameters: {'Fwd': 1.0005992322618784e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 5.079174481846761, 'loop': 1, 'loss': 'CE', 'lr': 0.0028566558030506794, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.2360263044888445e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.006522450298355563
weight_decay:  6.171148531119561e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0641260049305856
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9143080639187247
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.0680781949777156
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.073953628540039
total time:  6.099998597986996
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.50
[I 2023-06-12 00:24:35,155] Trial 115 finished with value: 81.79999542236328 and parameters: {'Fwd': 2.822206693166127e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.28651313613219, 'loop': 1, 'loss': 'CE', 'lr': 0.006522450298355563, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.171148531119561e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.006897971000933032
weight_decay:  5.343307528795761e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3046125951223075
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  2.0182246689219028
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.9800727351102978
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.331491708755493
total time:  6.350816549966112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.35
[I 2023-06-12 00:24:41,943] Trial 116 finished with value: 78.13333892822266 and parameters: {'Fwd': 3.5687919020440416e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.3148892849025735, 'loop': 1, 'loss': 'MSE', 'lr': 0.006897971000933032, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.343307528795761e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.007994908191818957
weight_decay:  6.338552755870821e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.352260240819305
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 02
None time:  2.3036307729780674
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 98.57
   Final Test: 79.90
Split: 01, Run: 03
None time:  2.3372519679833204
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.10
run time now: 7.020128488540649
total time:  7.04640965606086
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 99.52 ± 0.82
   Final Test: 80.07 ± 0.15
[I 2023-06-12 00:24:49,431] Trial 117 finished with value: 80.66666412353516 and parameters: {'Fwd': 1.9031114954614675e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.8370392955500585, 'loop': 1, 'loss': 'CE', 'lr': 0.007994908191818957, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.338552755870821e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.006532525146754736
weight_decay:  9.153884183210836e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6845685029402375
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.8739724538754672
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.0702757919207215
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
run time now: 5.656343221664429
total time:  5.679388968041167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.83 ± 0.87
[I 2023-06-12 00:24:55,576] Trial 118 finished with value: 80.53333282470703 and parameters: {'Fwd': 1.4279713747016555e-06, 'K': 8, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.564225710069279, 'loop': 1, 'loss': 'CE', 'lr': 0.006532525146754736, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.153884183210836e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.005560123376739702
weight_decay:  3.023592461055788e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.987325028050691
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.8591412799432874
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.250497060827911
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.124837398529053
total time:  6.152787272119895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.50
[I 2023-06-12 00:25:02,243] Trial 119 finished with value: 81.5999984741211 and parameters: {'Fwd': 4.701385095791713e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.064731898554688, 'loop': 1, 'loss': 'CE', 'lr': 0.005560123376739702, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.023592461055788e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.003935222131304687
weight_decay:  4.511717072955491e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0057416069321334
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.224531547166407
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.0606419160030782
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.321086168289185
total time:  6.339622722938657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.80
[I 2023-06-12 00:25:09,014] Trial 120 finished with value: 81.5999984741211 and parameters: {'Fwd': 7.029659274066491e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.854939792380804, 'loop': 1, 'loss': 'CE', 'lr': 0.003935222131304687, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.511717072955491e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004522006403310579
weight_decay:  1.7086991563863825e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2762005110271275
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.2736953359562904
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.272323683137074
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.850616693496704
total time:  6.880345741985366
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.46
[I 2023-06-12 00:25:16,343] Trial 121 finished with value: 81.5999984741211 and parameters: {'Fwd': 2.8168625919602266e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.710726148406581, 'loop': 1, 'loss': 'CE', 'lr': 0.004522006403310579, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7086991563863825e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0073515080105379296
weight_decay:  1.2604815768267907e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.201950496993959
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.113093031104654
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.9869943209923804
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.37998628616333
total time:  6.407291475916281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.85
[I 2023-06-12 00:25:23,300] Trial 122 finished with value: 81.73332977294922 and parameters: {'Fwd': 2.693587193142816e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.285881899548787, 'loop': 1, 'loss': 'CE', 'lr': 0.0073515080105379296, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2604815768267907e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.007359787707088378
weight_decay:  1.1885012767363195e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9744516790378839
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.824990649940446
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.8203438099008054
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.647697687149048
total time:  5.669787376886234
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 0.89
[I 2023-06-12 00:25:29,404] Trial 123 finished with value: 80.9333267211914 and parameters: {'Fwd': 2.086305321470194e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 4.318283166646601, 'loop': 1, 'loss': 'CE', 'lr': 0.007359787707088378, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1885012767363195e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.008459909847947433
weight_decay:  4.705105744487774e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4080559068825096
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 02
None time:  1.992964189965278
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.3955897300038487
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.825893402099609
total time:  6.842690302990377
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.83 ± 0.38
[I 2023-06-12 00:25:36,686] Trial 124 finished with value: 80.4000015258789 and parameters: {'Fwd': 3.61880090538766e-06, 'K': 8, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 6.086480615748315, 'loop': 1, 'loss': 'CE', 'lr': 0.008459909847947433, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.705105744487774e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.006141610791187189
weight_decay:  8.062547049257976e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.065979246981442
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.0662482399493456
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.200827552936971
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.360328435897827
total time:  6.382194831036031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.69
[I 2023-06-12 00:25:43,518] Trial 125 finished with value: 81.53333282470703 and parameters: {'Fwd': 1.5981100727106015e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 5.148185294982229, 'loop': 1, 'loss': 'CE', 'lr': 0.006141610791187189, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.062547049257976e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.008769946882211553
weight_decay:  3.164601775542522e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.08563208184205
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  2.0633907930459827
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.2529219680000097
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.00
run time now: 6.43130087852478
total time:  6.461124383145943
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 80.27 ± 1.10
[I 2023-06-12 00:25:50,535] Trial 126 finished with value: 80.79999542236328 and parameters: {'Fwd': 5.2227596639089994e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.536037539807384, 'loop': 1, 'loss': 'CE', 'lr': 0.008769946882211553, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.164601775542522e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.007040787467576361
weight_decay:  2.3144590439108945e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.135831712046638
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  2.409073376096785
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.2170449199620634
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.787558078765869
total time:  6.811984353931621
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.59
[I 2023-06-12 00:25:57,875] Trial 127 finished with value: 80.53333282470703 and parameters: {'Fwd': 2.6230444505935933e-06, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.440173156928858, 'loop': 1, 'loss': 'CE', 'lr': 0.007040787467576361, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.3144590439108945e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.009604028329718566
weight_decay:  6.562204456617341e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0790822540875524
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  1.1700156149454415
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0925624708179384
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.369485855102539
total time:  3.3875957059208304
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.20 ± 1.39
[I 2023-06-12 00:26:01,714] Trial 128 finished with value: 69.13333892822266 and parameters: {'Fwd': 4.141826712127756e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 5.863743170569293, 'loop': 1, 'loss': 'CE', 'lr': 0.009604028329718566, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.562204456617341e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.003472777365900512
weight_decay:  1.4534025991793333e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0830000101123005
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.7950654728338122
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.9070706439670175
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.810933351516724
total time:  5.833867527078837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.26
[I 2023-06-12 00:26:08,103] Trial 129 finished with value: 80.73333740234375 and parameters: {'Fwd': 2.0020563020134153e-06, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.55, 'lambda2': 4.1959272958855065, 'loop': 1, 'loss': 'CE', 'lr': 0.003472777365900512, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4534025991793333e-05, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.005692160506296826
weight_decay:  2.7394933182201667e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3047836790792644
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.0356512758880854
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 03
None time:  2.1457666670903563
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 6.512365102767944
total time:  6.533920424990356
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 82.00 ± 0.36
[I 2023-06-12 00:26:15,148] Trial 130 finished with value: 80.66666412353516 and parameters: {'Fwd': 1.2793453941099837e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.820266481485658, 'loop': 1, 'loss': 'CE', 'lr': 0.005692160506296826, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.7394933182201667e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.005082073441378891
weight_decay:  1.9317317852667192e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9804390049539506
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2449356119614094
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.853521293029189
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.107406139373779
total time:  6.138057179981843
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.31
[I 2023-06-12 00:26:21,875] Trial 131 finished with value: 81.73333740234375 and parameters: {'Fwd': 2.7174125397296514e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.291244302439319, 'loop': 1, 'loss': 'CE', 'lr': 0.005082073441378891, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.9317317852667192e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0043752861330834105
weight_decay:  1.0706739095158472e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2006355051416904
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.2533637080341578
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6152542119380087
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 6.097930908203125
total time:  6.122104240115732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.83 ± 0.32
[I 2023-06-12 00:26:28,485] Trial 132 finished with value: 81.66667175292969 and parameters: {'Fwd': 3.177372100727199e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.587205045909863, 'loop': 1, 'loss': 'CE', 'lr': 0.0043752861330834105, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0706739095158472e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.004398974904135538
weight_decay:  1.0565829457041174e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.399805597960949
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.316602698992938
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.9665154819376767
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.708934307098389
total time:  6.727530906908214
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.45
[I 2023-06-12 00:26:35,718] Trial 133 finished with value: 81.06666564941406 and parameters: {'Fwd': 2.6960257895253446e-06, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 5.548542468672375, 'loop': 1, 'loss': 'CE', 'lr': 0.004398974904135538, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0565829457041174e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.003963769093214761
weight_decay:  6.508098223234928e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.09331913292408
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.8872946221381426
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.7866692380048335
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.60
run time now: 5.798938751220703
total time:  5.825693286955357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.31
[I 2023-06-12 00:26:42,029] Trial 134 finished with value: 81.0 and parameters: {'Fwd': 1.673634635762241e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 5.299239751406234, 'loop': 1, 'loss': 'CE', 'lr': 0.003963769093214761, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.508098223234928e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.006372888939332768
weight_decay:  1.2637416144424653e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1036943159997463
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.9536871679592878
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.0613594551105052
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.1488518714904785
total time:  6.174464347073808
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.80 ± 0.56
[I 2023-06-12 00:26:48,726] Trial 135 finished with value: 81.73332977294922 and parameters: {'Fwd': 8.388436093851838e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 5.0121153994439975, 'loop': 1, 'loss': 'CE', 'lr': 0.006372888939332768, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2637416144424653e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.007606058387557337
weight_decay:  5.150722588303388e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1786131160333753
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.8088674149475992
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.0585959821473807
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.60
run time now: 6.070723295211792
total time:  6.0971173900179565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 1.42
[I 2023-06-12 00:26:55,293] Trial 136 finished with value: 81.0666732788086 and parameters: {'Fwd': 8.866121255854752e-06, 'K': 5, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 5.655385440358922, 'loop': 1, 'loss': 'CE', 'lr': 0.007606058387557337, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.150722588303388e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.006271973946709499
weight_decay:  1.3051740751155103e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4344639941118658
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.265639921184629
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  2.3471063810866326
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 7.078284978866577
total time:  7.1044604810886085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 0.84
[I 2023-06-12 00:27:02,986] Trial 137 finished with value: 78.46666717529297 and parameters: {'Fwd': 5.628870395312371e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 5.044142651942799, 'loop': 1, 'loss': 'MSE', 'lr': 0.006271973946709499, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3051740751155103e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.005470415050184301
weight_decay:  8.846416254905537e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2643358879722655
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  1.0943175319116563
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.3682451671920717
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 3.75667667388916
total time:  3.7868255330249667
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 80.73 ± 0.59
[I 2023-06-12 00:27:07,240] Trial 138 finished with value: 79.79999542236328 and parameters: {'Fwd': 2.380085018066506e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 40, 'lambda1': 0.9500000000000001, 'lambda2': 6.0433955247775035, 'loop': 1, 'loss': 'CE', 'lr': 0.005470415050184301, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.846416254905537e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.2
lr:  0.00462593362151777
weight_decay:  3.6822038802581013e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.34633161383681
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.328696154989302
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.359945449978113
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 7.064507484436035
total time:  7.086106332018971
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.75
[I 2023-06-12 00:27:14,756] Trial 139 finished with value: 81.66666412353516 and parameters: {'Fwd': 1.2936931453963421e-05, 'K': 10, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 5.771881514019954, 'loop': 1, 'loss': 'CE', 'lr': 0.00462593362151777, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.6822038802581013e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.006337236905529246
weight_decay:  6.560905878992711e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.252988177817315
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.89744667802006
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.1879421030171216
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.362648248672485
total time:  6.389668536838144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.64
[I 2023-06-12 00:27:21,704] Trial 140 finished with value: 81.66666412353516 and parameters: {'Fwd': 4.531048760378099e-06, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.503074061200696, 'loop': 1, 'loss': 'CE', 'lr': 0.006337236905529246, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.560905878992711e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0052918831662918196
weight_decay:  2.0143436367505986e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.00665375799872
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.979109298903495
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.237555213039741
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.70
run time now: 6.249924898147583
total time:  6.271932179108262
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.30
[I 2023-06-12 00:27:28,451] Trial 141 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.2119833134439103e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.206835103347963, 'loop': 1, 'loss': 'CE', 'lr': 0.0052918831662918196, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.0143436367505986e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.004993982262508745
weight_decay:  1.4337036754890527e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6275074610020965
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.030378725146875
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.065140137914568
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.751089572906494
total time:  5.768465348985046
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.87
[I 2023-06-12 00:27:34,728] Trial 142 finished with value: 81.13333129882812 and parameters: {'Fwd': 2.1683632688166897e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 4.993342834807998, 'loop': 1, 'loss': 'CE', 'lr': 0.004993982262508745, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4337036754890527e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0041462215195234515
weight_decay:  1.0094351253442228e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8112953039817512
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.1597155740018934
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.024945725919679
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.021874666213989
total time:  6.036850308068097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.55
[I 2023-06-12 00:27:41,248] Trial 143 finished with value: 81.73333740234375 and parameters: {'Fwd': 3.0710282959087886e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.816600057417351, 'loop': 1, 'loss': 'CE', 'lr': 0.0041462215195234515, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0094351253442228e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.003669684552346285
weight_decay:  1.028435934654541e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.967350177001208
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2000452999491245
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.9983897518832237
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.2075090408325195
total time:  6.226663301000372
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.35
[I 2023-06-12 00:27:48,072] Trial 144 finished with value: 81.39999389648438 and parameters: {'Fwd': 1.6199317999870212e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.854671381637052, 'loop': 1, 'loss': 'CE', 'lr': 0.003669684552346285, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.028435934654541e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.004297357991571724
weight_decay:  1.7746037451393636e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.96621735394001
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.173121972940862
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.9930535869207233
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.165104627609253
total time:  6.190697499085218
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.61
[I 2023-06-12 00:27:54,739] Trial 145 finished with value: 81.9333267211914 and parameters: {'Fwd': 3.988712384190945e-06, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.667549031215161, 'loop': 1, 'loss': 'CE', 'lr': 0.004297357991571724, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7746037451393636e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.0029968039612931208
weight_decay:  1.8778733143784823e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.357610219158232
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0293320699129254
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.125532080885023
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
run time now: 6.538996696472168
total time:  6.562857398064807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.55
[I 2023-06-12 00:28:01,811] Trial 146 finished with value: 81.19999694824219 and parameters: {'Fwd': 6.6477404600980954e-06, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 4.635210583048051, 'loop': 1, 'loss': 'CE', 'lr': 0.0029968039612931208, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8778733143784823e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.004038792343372877
weight_decay:  1.4532592822480588e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0110947978682816
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.842867902945727
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.765211737016216
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.646618604660034
total time:  5.665997460018843
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.32
[I 2023-06-12 00:28:07,965] Trial 147 finished with value: 80.86666870117188 and parameters: {'Fwd': 4.117179378656569e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.250675508794675, 'loop': 1, 'loss': 'CE', 'lr': 0.004038792343372877, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4532592822480588e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.0033198361970881245
weight_decay:  7.966367773309826e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.236681885784492
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.8112815651111305
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.0596982780843973
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.159239768981934
total time:  6.224162471946329
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.25
[I 2023-06-12 00:28:14,762] Trial 148 finished with value: 81.20000457763672 and parameters: {'Fwd': 2.4911088005940466e-06, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.773176502186729, 'loop': 1, 'loss': 'CE', 'lr': 0.0033198361970881245, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.966367773309826e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.005785887179100891
weight_decay:  2.1071886079299925e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2389514870010316
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.012434164993465
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  2.2181754829362035
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.495715856552124
total time:  6.518478256184608
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.83
[I 2023-06-12 00:28:21,754] Trial 149 finished with value: 81.53333282470703 and parameters: {'Fwd': 1.1824718077749399e-06, 'K': 9, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 5.253387529652311, 'loop': 1, 'loss': 'CE', 'lr': 0.005785887179100891, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.1071886079299925e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.2
lr:  0.0070102467078742015
weight_decay:  4.231540816902953e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3274161929730326
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 02
None time:  0.9459575118962675
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  1.4002978729549795
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 72.50
run time now: 3.7042691707611084
total time:  3.728920228779316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 72.13 ± 0.40
[I 2023-06-12 00:28:25,901] Trial 150 finished with value: 70.73333740234375 and parameters: {'Fwd': 1.9259632232293913e-06, 'K': 10, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.8911911824886674, 'loop': 1, 'loss': 'CE', 'lr': 0.0070102467078742015, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.231540816902953e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.00441036994992851
weight_decay:  1.126862853805379e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.199427681043744
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.7022382190916687
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.0902304500341415
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.015625238418579
total time:  6.039501186925918
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.40
[I 2023-06-12 00:28:32,423] Trial 151 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.1287909755119814e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.02213267693881, 'loop': 1, 'loss': 'CE', 'lr': 0.00441036994992851, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.126862853805379e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.00396444612343467
weight_decay:  1.773348240884883e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0889778251294047
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.206873239018023
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.5433368298690766
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.866614818572998
total time:  5.886477281106636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.90 ± 0.36
[I 2023-06-12 00:28:38,853] Trial 152 finished with value: 81.53333282470703 and parameters: {'Fwd': 3.737879872506138e-06, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 5.4177605196405265, 'loop': 1, 'loss': 'CE', 'lr': 0.00396444612343467, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.773348240884883e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.00471433947765575
weight_decay:  1.1809346785131803e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1603664190042764
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.2162225442007184
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.5874063451774418
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.9907145500183105
total time:  6.0163540539797395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.46
[I 2023-06-12 00:28:45,424] Trial 153 finished with value: 81.93334197998047 and parameters: {'Fwd': 4.998928381510529e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.627287408366995, 'loop': 1, 'loss': 'CE', 'lr': 0.00471433947765575, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1809346785131803e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0048645673427039765
weight_decay:  3.788988434512537e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.178285425994545
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0129529910627753
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.656956238904968
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.874548673629761
total time:  5.892970961984247
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.51
[I 2023-06-12 00:28:51,861] Trial 154 finished with value: 81.79999542236328 and parameters: {'Fwd': 8.68998781853636e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.42828659960322, 'loop': 1, 'loss': 'CE', 'lr': 0.0048645673427039765, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.788988434512537e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004823937912184044
weight_decay:  3.750185054812301e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0561283989809453
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.8486089129000902
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.8959964129608124
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
run time now: 5.830484867095947
total time:  5.856271948199719
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.74
[I 2023-06-12 00:28:58,190] Trial 155 finished with value: 81.0 and parameters: {'Fwd': 9.617658205008236e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 4.396056394169544, 'loop': 1, 'loss': 'CE', 'lr': 0.004823937912184044, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.750185054812301e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.003622552976240304
weight_decay:  1.2369369991402233e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.173116949154064
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.083598540863022
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.065213645109907
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.401720285415649
total time:  6.4387302310206
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.56
[I 2023-06-12 00:29:05,169] Trial 156 finished with value: 81.46666717529297 and parameters: {'Fwd': 7.96882257641918e-06, 'K': 9, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.053681188185278, 'loop': 1, 'loss': 'CE', 'lr': 0.003622552976240304, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2369369991402233e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.004268556654419003
weight_decay:  7.366815498690893e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.34955567214638
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.2203428060747683
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.09223441593349
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.688190937042236
total time:  6.708988281199709
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.72
[I 2023-06-12 00:29:12,407] Trial 157 finished with value: 81.9333267211914 and parameters: {'Fwd': 1.4424266635090622e-05, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.537326056291989, 'loop': 1, 'loss': 'CE', 'lr': 0.004268556654419003, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.366815498690893e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0042405696135413605
weight_decay:  5.9053635869602415e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2229500240646303
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.2436571549624205
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  2.3240379048511386
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.60
run time now: 6.81914210319519
total time:  6.8661146278027445
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 82.07 ± 0.42
[I 2023-06-12 00:29:19,774] Trial 158 finished with value: 80.53333282470703 and parameters: {'Fwd': 5.935078735705722e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 4.515324983321949, 'loop': 1, 'loss': 'CE', 'lr': 0.0042405696135413605, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.9053635869602415e-06, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.003417614482472227
weight_decay:  7.896312638906275e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9932663149666041
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  2.071797720855102
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  2.0618517510592937
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.00
run time now: 6.15612006187439
total time:  6.177456667879596
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 0.26
[I 2023-06-12 00:29:26,476] Trial 159 finished with value: 79.20000457763672 and parameters: {'Fwd': 5.065702162576818e-06, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.239948664438129, 'loop': 1, 'loss': 'MSE', 'lr': 0.003417614482472227, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.896312638906275e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.003806342897061466
weight_decay:  2.4415778671567708e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9250763941090554
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.9119317280128598
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.4839295072015375
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.348891496658325
total time:  5.374470640905201
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.40
[I 2023-06-12 00:29:32,341] Trial 160 finished with value: 80.93333435058594 and parameters: {'Fwd': 1.3394407420088554e-05, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.7059322387393556, 'loop': 1, 'loss': 'CE', 'lr': 0.003806342897061466, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.4415778671567708e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.005343580344850621
weight_decay:  1.6745968564027362e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1170087710488588
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1482565789483488
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.8560573610011488
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.152466535568237
total time:  6.178770455066115
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.64
[I 2023-06-12 00:29:39,006] Trial 161 finished with value: 81.46666717529297 and parameters: {'Fwd': 7.49552521711699e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.6923836219045985, 'loop': 1, 'loss': 'CE', 'lr': 0.005343580344850621, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.6745968564027362e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.00473424961578879
weight_decay:  1.4810617037242258e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2068225289694965
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.215625808108598
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4855833780020475
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.937763214111328
total time:  5.9591402870137244
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.46
[I 2023-06-12 00:29:45,406] Trial 162 finished with value: 81.86666870117188 and parameters: {'Fwd': 4.602762447316368e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.970646688736755, 'loop': 1, 'loss': 'CE', 'lr': 0.00473424961578879, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4810617037242258e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.004768363597717882
weight_decay:  9.036841845143158e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1928192069754004
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2011551540344954
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.5521650479640812
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.993084907531738
total time:  6.022789295064285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.45
[I 2023-06-12 00:29:52,031] Trial 163 finished with value: 81.86666870117188 and parameters: {'Fwd': 4.152043852511973e-06, 'K': 9, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.465383153769558, 'loop': 1, 'loss': 'CE', 'lr': 0.004768363597717882, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.036841845143158e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0048302355177657795
weight_decay:  9.48942087801986e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.151501035084948
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.0506131039001048
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.8997416067868471
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.131194353103638
total time:  6.161501660011709
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.50
[I 2023-06-12 00:29:58,742] Trial 164 finished with value: 81.86666870117188 and parameters: {'Fwd': 4.149263435102873e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.376412981555579, 'loop': 1, 'loss': 'CE', 'lr': 0.0048302355177657795, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.48942087801986e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004586588235417742
weight_decay:  9.400279811701937e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1406064978800714
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.2438545399345458
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.6044644450303167
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.016336917877197
total time:  6.036619957070798
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.35
[I 2023-06-12 00:30:05,257] Trial 165 finished with value: 82.0 and parameters: {'Fwd': 4.5756106081778915e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.454333719218382, 'loop': 1, 'loss': 'CE', 'lr': 0.004586588235417742, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.400279811701937e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004730931767016366
weight_decay:  6.946349383518851e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2706923889927566
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.0780446701683104
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.262608715100214
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.645191192626953
total time:  6.662310682004318
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.83
[I 2023-06-12 00:30:12,389] Trial 166 finished with value: 80.73333740234375 and parameters: {'Fwd': 4.822156607588711e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 4.107729809161435, 'loop': 1, 'loss': 'CE', 'lr': 0.004730931767016366, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.946349383518851e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0045497459633530414
weight_decay:  5.69661223308171e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.825226800981909
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.594444442074746
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.030949441017583
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.477855205535889
total time:  5.49832931603305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.66
[I 2023-06-12 00:30:18,407] Trial 167 finished with value: 81.0666732788086 and parameters: {'Fwd': 1.6543113335567586e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 4.380031584064232, 'loop': 1, 'loss': 'CE', 'lr': 0.0045497459633530414, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.69661223308171e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.00523340732294172
weight_decay:  2.4412438398093623e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.243395092897117
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.1718762659002095
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.8687980810645968
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.311807870864868
total time:  6.342159525025636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.49
[I 2023-06-12 00:30:25,317] Trial 168 finished with value: 81.46666717529297 and parameters: {'Fwd': 6.140211594108576e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.575663609201729, 'loop': 1, 'loss': 'CE', 'lr': 0.00523340732294172, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.4412438398093623e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.004208127342411404
weight_decay:  4.872608107931148e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1475546918809414
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.9319002630654722
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.9443280978593975
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.052698612213135
total time:  6.073790366994217
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.30
[I 2023-06-12 00:30:31,908] Trial 169 finished with value: 81.46666717529297 and parameters: {'Fwd': 1.0918187913044862e-05, 'K': 8, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.032036017626405, 'loop': 1, 'loss': 'CE', 'lr': 0.004208127342411404, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.872608107931148e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0037636730533392683
weight_decay:  8.701069327426223e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3954311141278595
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.1465423421468586
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.2747921920381486
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.8440234661102295
total time:  6.871709555154666
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.87
[I 2023-06-12 00:30:39,230] Trial 170 finished with value: 80.79999542236328 and parameters: {'Fwd': 3.866214221587444e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 4.333589441404691, 'loop': 1, 'loss': 'CE', 'lr': 0.0037636730533392683, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.701069327426223e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.00413165141858022
weight_decay:  9.482611683530992e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.850072907982394
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7593941381201148
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.2116803200915456
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.84905481338501
total time:  5.876595678040758
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.55
[I 2023-06-12 00:30:45,649] Trial 171 finished with value: 81.73333740234375 and parameters: {'Fwd': 5.364422055668589e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.5860888088619225, 'loop': 1, 'loss': 'CE', 'lr': 0.00413165141858022, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.482611683530992e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004689873748505532
weight_decay:  0.00015356891118309735
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9725679990369827
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.858606685884297
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.1234195339493454
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.980915784835815
total time:  5.9974278879817575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.40
[I 2023-06-12 00:30:52,155] Trial 172 finished with value: 81.93334197998047 and parameters: {'Fwd': 4.531590691417608e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.808842459448295, 'loop': 1, 'loss': 'CE', 'lr': 0.004689873748505532, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015356891118309735, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0047007795621095295
weight_decay:  0.00011917233265612498
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.754772897111252
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.2123702759854496
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.1705917299259454
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.161912202835083
total time:  6.18031343515031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.40
[I 2023-06-12 00:30:58,831] Trial 173 finished with value: 81.93334197998047 and parameters: {'Fwd': 4.203572203788964e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.860951097691066, 'loop': 1, 'loss': 'CE', 'lr': 0.0047007795621095295, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011917233265612498, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004628337804152823
weight_decay:  0.00013697272143924538
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.863668237812817
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.182035454083234
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.1643944319803268
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.2398247718811035
total time:  6.2610587971284986
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.71
[I 2023-06-12 00:31:05,604] Trial 174 finished with value: 81.0 and parameters: {'Fwd': 4.427173254893314e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.8272638769741993, 'loop': 1, 'loss': 'CE', 'lr': 0.004628337804152823, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013697272143924538, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004629826117738448
weight_decay:  8.500651265302251e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1254771780222654
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.3103386589791626
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.309488101163879
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.775645732879639
total time:  6.7950526820495725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.35
[I 2023-06-12 00:31:12,882] Trial 175 finished with value: 81.93334197998047 and parameters: {'Fwd': 7.086275041973107e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.230192596671605, 'loop': 1, 'loss': 'CE', 'lr': 0.004629826117738448, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.500651265302251e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.15000000000000002
lr:  0.0045937500895998325
weight_decay:  0.0001583333022407956
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7634333889000118
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.8123320939484984
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.1891016468871385
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.796068906784058
total time:  5.820781684946269
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.51
[I 2023-06-12 00:31:19,222] Trial 176 finished with value: 81.06666564941406 and parameters: {'Fwd': 7.043755385120666e-06, 'K': 6, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.133786689520098, 'loop': 1, 'loss': 'CE', 'lr': 0.0045937500895998325, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001583333022407956, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.005683866467511627
weight_decay:  0.00010194387458674349
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5806459828745574
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  0.9425416730809957
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.549570756033063
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.1283276081085205
total time:  4.152677275007591
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.20
[I 2023-06-12 00:31:23,964] Trial 177 finished with value: 81.20000457763672 and parameters: {'Fwd': 9.566105754213307e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 3.9082047971159426, 'loop': 1, 'loss': 'CE', 'lr': 0.005683866467511627, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010194387458674349, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.003191685935250008
weight_decay:  0.00022545642879418158
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1342892749235034
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9555582830216736
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.8881582340691239
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.008792877197266
total time:  6.029898935928941
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.42
[I 2023-06-12 00:31:30,438] Trial 178 finished with value: 81.4000015258789 and parameters: {'Fwd': 5.969614151029485e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.288550288315831, 'loop': 1, 'loss': 'CE', 'lr': 0.003191685935250008, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00022545642879418158, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004817616480359754
weight_decay:  7.69399819975146e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3629233159590513
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.2374111290555447
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.255829544039443
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.10
run time now: 6.883417129516602
total time:  6.903356284135953
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.83
[I 2023-06-12 00:31:37,789] Trial 179 finished with value: 80.73333740234375 and parameters: {'Fwd': 4.251409430887216e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 4.401749324200517, 'loop': 1, 'loss': 'CE', 'lr': 0.004817616480359754, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.69399819975146e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.00537533273724229
weight_decay:  0.00028719207241397865
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.250846307957545
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 98.57
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.2522390040103346
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.2174306809902191
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 99.29
   Final Test: 78.50
run time now: 3.7513251304626465
total time:  3.7749584051780403
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.87 ± 1.29
  Final Train: 99.29 ± 0.71
   Final Test: 78.47 ± 1.35
[I 2023-06-12 00:31:42,037] Trial 180 finished with value: 77.86666870117188 and parameters: {'Fwd': 4.761083156042627e-05, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.4903684259320764, 'loop': 1, 'loss': 'CE', 'lr': 0.00537533273724229, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00028719207241397865, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.003779818181285503
weight_decay:  0.0001788285066670504
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.16163579095155
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.8361936819273978
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.860204285942018
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.883341550827026
total time:  5.901248273206875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.65
[I 2023-06-12 00:31:48,524] Trial 181 finished with value: 81.46666717529297 and parameters: {'Fwd': 3.822951136526617e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.553500255648919, 'loop': 1, 'loss': 'CE', 'lr': 0.003779818181285503, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001788285066670504, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004342474178796623
weight_decay:  0.00011579198045764029
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.252387773944065
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7128052900079638
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.01028087711893
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.0038206577301025
total time:  6.024700166890398
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:31:55,119] Trial 182 finished with value: 82.0 and parameters: {'Fwd': 5.170918037641968e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.14625232853465, 'loop': 1, 'loss': 'CE', 'lr': 0.004342474178796623, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011579198045764029, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00436737459213623
weight_decay:  0.00013773370351607481
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.220606294926256
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.168504565022886
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6766388488467783
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.092331171035767
total time:  6.105224407976493
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:32:01,843] Trial 183 finished with value: 82.0 and parameters: {'Fwd': 5.370845807475558e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.7214838672046042, 'loop': 1, 'loss': 'CE', 'lr': 0.00436737459213623, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013773370351607481, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004371683215516223
weight_decay:  0.00012609156106529676
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1861398180481046
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.078160848002881
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6774670630693436
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.9683897495269775
total time:  5.990649695042521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:32:08,304] Trial 184 finished with value: 82.0 and parameters: {'Fwd': 7.629343268301388e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.629848035002791, 'loop': 1, 'loss': 'CE', 'lr': 0.004371683215516223, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012609156106529676, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0043772222416193236
weight_decay:  0.00010827389397447391
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1908175530843437
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.133031344972551
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.8912836730014533
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.240527391433716
total time:  6.261128454003483
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.61
[I 2023-06-12 00:32:15,038] Trial 185 finished with value: 81.9333267211914 and parameters: {'Fwd': 6.664447519976531e-06, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.5969870129184662, 'loop': 1, 'loss': 'CE', 'lr': 0.0043772222416193236, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010827389397447391, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.00432117131238572
weight_decay:  9.72349038047909e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9717515790835023
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.2340459669940174
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.7822109088301659
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.01256799697876
total time:  6.0304167659487575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 1.01
[I 2023-06-12 00:32:21,600] Trial 186 finished with value: 81.0666732788086 and parameters: {'Fwd': 6.9247040444685784e-06, 'K': 7, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.7302144214517967, 'loop': 1, 'loss': 'CE', 'lr': 0.00432117131238572, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.72349038047909e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0035579571760068307
weight_decay:  0.0001716695233093025
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.041040268028155
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.029201307101175
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.7755346710328013
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.875617742538452
total time:  5.895398437045515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.26
[I 2023-06-12 00:32:27,984] Trial 187 finished with value: 80.73333740234375 and parameters: {'Fwd': 1.1888307588520933e-05, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.3677178749480916, 'loop': 1, 'loss': 'CE', 'lr': 0.0035579571760068307, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001716695233093025, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.003968698000940711
weight_decay:  0.00012127536472436072
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.235210594953969
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.296328319935128
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.149391224840656
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.70
run time now: 6.7082014083862305
total time:  6.723124293144792
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.93
[I 2023-06-12 00:32:35,150] Trial 188 finished with value: 80.86666870117188 and parameters: {'Fwd': 5.172255034124681e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.5831648817512987, 'loop': 2, 'loss': 'CE', 'lr': 0.003968698000940711, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00012127536472436072, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0044809984387056325
weight_decay:  0.00012218433004328367
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1783499591983855
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.930506037082523
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.0863690429832786
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.220271587371826
total time:  6.269075543154031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.51
[I 2023-06-12 00:32:42,001] Trial 189 finished with value: 82.0 and parameters: {'Fwd': 7.179910443216282e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.734572659516421, 'loop': 1, 'loss': 'CE', 'lr': 0.0044809984387056325, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012218433004328367, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.004485063698347118
weight_decay:  0.00013446394060400064
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1822639550082386
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.9038587368559092
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.646543958922848
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.757661819458008
total time:  5.779639228014275
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.50
[I 2023-06-12 00:32:48,266] Trial 190 finished with value: 81.60000610351562 and parameters: {'Fwd': 1.0058574284988454e-05, 'K': 8, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.26583048199723, 'loop': 1, 'loss': 'CE', 'lr': 0.004485063698347118, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013446394060400064, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004359735024620775
weight_decay:  0.00012624980361066506
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9806049829348922
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.8544402641709894
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.1976789929904044
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.062883377075195
total time:  6.110213402891532
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.42
[I 2023-06-12 00:32:54,877] Trial 191 finished with value: 82.0 and parameters: {'Fwd': 6.918684919815597e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6327615313949044, 'loop': 1, 'loss': 'CE', 'lr': 0.004359735024620775, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012624980361066506, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00388126234094623
weight_decay:  0.00012777332294853778
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6465200770180672
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.2441268160473555
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.1882654828950763
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.107373237609863
total time:  6.131664999993518
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.75
[I 2023-06-12 00:33:01,493] Trial 192 finished with value: 81.5999984741211 and parameters: {'Fwd': 6.062079773605107e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.628484499903519, 'loop': 1, 'loss': 'CE', 'lr': 0.00388126234094623, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012777332294853778, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.004607976127742221
weight_decay:  0.00010615232126516464
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5939273070544004
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.179756835103035
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  2.1588887290563434
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.95555567741394
total time:  5.983324836008251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 1.08
[I 2023-06-12 00:33:07,989] Trial 193 finished with value: 80.86666870117188 and parameters: {'Fwd': 7.945929826384282e-06, 'K': 3, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.8508151544417064, 'loop': 1, 'loss': 'CE', 'lr': 0.004607976127742221, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010615232126516464, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.003519316330002649
weight_decay:  0.0001974204215951164
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7138568861410022
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.2752176059875637
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.236220811959356
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.244607925415039
total time:  6.2979862270876765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.46
[I 2023-06-12 00:33:14,777] Trial 194 finished with value: 81.4000015258789 and parameters: {'Fwd': 7.292592929640178e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.745126863404129, 'loop': 1, 'loss': 'CE', 'lr': 0.003519316330002649, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001974204215951164, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004292230720005981
weight_decay:  9.121607086214351e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0056076808832586
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.2012421258259565
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.8937190768774599
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.153346300125122
total time:  6.170337704010308
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.61
[I 2023-06-12 00:33:21,571] Trial 195 finished with value: 81.9333267211914 and parameters: {'Fwd': 1.9778681686899457e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.084689340178196, 'loop': 1, 'loss': 'CE', 'lr': 0.004292230720005981, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.121607086214351e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004883638104704746
weight_decay:  8.53736397132353e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.157935183029622
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.201962189981714
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.0153559809550643
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.405473470687866
total time:  6.432054275879636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.50
[I 2023-06-12 00:33:28,526] Trial 196 finished with value: 81.66666412353516 and parameters: {'Fwd': 1.6636115275698856e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.254665926217008, 'loop': 1, 'loss': 'CE', 'lr': 0.004883638104704746, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.53736397132353e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004350253111669539
weight_decay:  0.0001256479952626532
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.183267430868
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.2563006840646267
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.323255182011053
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.792503356933594
total time:  6.8120285999029875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.76
[I 2023-06-12 00:33:35,830] Trial 197 finished with value: 80.66666412353516 and parameters: {'Fwd': 2.0510638442733087e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 2.858228593848856, 'loop': 1, 'loss': 'CE', 'lr': 0.004350253111669539, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001256479952626532, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0008583789817432359
weight_decay:  7.421388278545933e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0354, Train: 100.00%, Valid: 79.20% Test: 80.50%
Split: 01, Run: 01
None time:  5.687888267915696
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 02
None time:  2.1098079578951
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0332, Train: 100.00%, Valid: 79.20% Test: 80.10%
Split: 01, Run: 03
None time:  5.484908055048436
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.00
run time now: 13.308331489562988
total time:  13.325782920932397
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 80.03 ± 0.55
[I 2023-06-12 00:33:49,729] Trial 198 finished with value: 79.19999694824219 and parameters: {'Fwd': 1.4454295771979558e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.479442053842296, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008583789817432359, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.421388278545933e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.005100062036754747
weight_decay:  9.967802509309713e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9940425590611994
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9778124748263508
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.5756794139742851
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.573339223861694
total time:  5.5945664551109076
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.84
[I 2023-06-12 00:33:55,826] Trial 199 finished with value: 81.06666564941406 and parameters: {'Fwd': 9.560689699975007e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.174229872275778, 'loop': 1, 'loss': 'CE', 'lr': 0.005100062036754747, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.967802509309713e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004017132104497938
weight_decay:  0.00016800349432075846
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2858951741363853
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.01246968889609
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.415380819933489
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 99.29
   Final Test: 80.30
run time now: 6.752839803695679
total time:  6.775327287847176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 99.76 ± 0.41
   Final Test: 81.33 ± 0.90
[I 2023-06-12 00:34:03,135] Trial 200 finished with value: 80.93334197998047 and parameters: {'Fwd': 5.475545677789078e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.0261262279435157, 'loop': 1, 'loss': 'CE', 'lr': 0.004017132104497938, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016800349432075846, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004360494817769421
weight_decay:  0.00013881728256917288
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9084278619848192
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9667777980212122
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.196420499822125
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.099022626876831
total time:  6.118075134931132
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:34:09,726] Trial 201 finished with value: 82.0 and parameters: {'Fwd': 4.686449632998204e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.984067838409563, 'loop': 1, 'loss': 'CE', 'lr': 0.004360494817769421, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013881728256917288, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004504844817732689
weight_decay:  0.0001404911029062555
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9619399760849774
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.040647584013641
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2014889360871166
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.231642484664917
total time:  6.245576906017959
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.51
[I 2023-06-12 00:34:16,497] Trial 202 finished with value: 82.0 and parameters: {'Fwd': 4.921593153414218e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.8936886338642056, 'loop': 1, 'loss': 'CE', 'lr': 0.004504844817732689, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001404911029062555, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004576492923125384
weight_decay:  0.00022962424386672908
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7994725750759244
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.0417123541701585
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.190783182159066
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.056105852127075
total time:  6.068961815908551
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.44
[I 2023-06-12 00:34:23,030] Trial 203 finished with value: 82.0 and parameters: {'Fwd': 4.5960443801063545e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.641835232822559, 'loop': 1, 'loss': 'CE', 'lr': 0.004576492923125384, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00022962424386672908, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004404018174452747
weight_decay:  0.00024280461540140906
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.583234132034704
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.1746286479756236
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2132135699503124
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.998086929321289
total time:  6.016352911945432
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.46
[I 2023-06-12 00:34:29,549] Trial 204 finished with value: 82.0 and parameters: {'Fwd': 6.6666624335183135e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.566375216017615, 'loop': 1, 'loss': 'CE', 'lr': 0.004404018174452747, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00024280461540140906, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0039065692139142825
weight_decay:  0.00030525930978983723
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.625015005003661
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.8589086548890918
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.1643526849802583
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.677754163742065
total time:  5.6983619020320475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.75
[I 2023-06-12 00:34:35,700] Trial 205 finished with value: 81.5999984741211 and parameters: {'Fwd': 6.639889422108436e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6708873689169694, 'loop': 1, 'loss': 'CE', 'lr': 0.0039065692139142825, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00030525930978983723, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004306469173279229
weight_decay:  0.0001881741589449519
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1703297728672624
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.4859344600699842
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.188283591065556
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.874344348907471
total time:  5.892323883017525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.50
[I 2023-06-12 00:34:42,062] Trial 206 finished with value: 81.9333267211914 and parameters: {'Fwd': 5.374721726331916e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.5253176631775993, 'loop': 1, 'loss': 'CE', 'lr': 0.004306469173279229, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001881741589449519, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.003161241884805879
weight_decay:  0.0002484619376030511
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.161218540975824
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.4243422849103808
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.2058816119097173
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.820472717285156
total time:  5.8402762790210545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.32
[I 2023-06-12 00:34:48,358] Trial 207 finished with value: 81.26666259765625 and parameters: {'Fwd': 1.1027726680503318e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.5595849227582224, 'loop': 1, 'loss': 'CE', 'lr': 0.003161241884805879, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002484619376030511, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0035427794898279692
weight_decay:  0.00019034371892793795
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.122402491979301
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9208427348639816
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.163986497092992
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.2340803146362305
total time:  6.257335486123338
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.46
[I 2023-06-12 00:34:55,084] Trial 208 finished with value: 81.46666717529297 and parameters: {'Fwd': 8.731849910539341e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.3574979909949834, 'loop': 1, 'loss': 'CE', 'lr': 0.0035427794898279692, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00019034371892793795, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004324039256175516
weight_decay:  0.0001393033569293007
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3016050960868597
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  1.8716530189849436
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  2.2970626200549304
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 6.498961925506592
total time:  6.515176417073235
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 80.20 ± 0.61
[I 2023-06-12 00:35:02,061] Trial 209 finished with value: 80.06666564941406 and parameters: {'Fwd': 2.635858639926974e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.05, 'lambda2': 3.973764193561052, 'loop': 1, 'loss': 'CE', 'lr': 0.004324039256175516, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001393033569293007, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0013668603939141434
weight_decay:  0.00020272800405609842
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6229931840207428
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.5692802348639816
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 03
None time:  1.8530937221366912
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.076569080352783
total time:  5.097670309944078
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.63 ± 2.54
[I 2023-06-12 00:35:07,596] Trial 210 finished with value: 78.5999984741211 and parameters: {'Fwd': 7.158742452980439e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.7848596362208053, 'loop': 1, 'loss': 'CE', 'lr': 0.0013668603939141434, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020272800405609842, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00434250040487999
weight_decay:  0.00010710331820799501
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8341353349387646
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0399276490788907
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2382553059142083
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.139410972595215
total time:  6.161375681869686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.42
[I 2023-06-12 00:35:14,218] Trial 211 finished with value: 82.0 and parameters: {'Fwd': 5.606908317951323e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6405776834242634, 'loop': 1, 'loss': 'CE', 'lr': 0.00434250040487999, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010710331820799501, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004296999291594761
weight_decay:  0.00011422580498158192
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7220181319862604
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.1525560149457306
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.189519050065428
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.090220212936401
total time:  6.109765988076106
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.56
[I 2023-06-12 00:35:20,787] Trial 212 finished with value: 81.9333267211914 and parameters: {'Fwd': 5.741091830143196e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.4571322529434387, 'loop': 1, 'loss': 'CE', 'lr': 0.004296999291594761, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011422580498158192, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0025037632932484255
weight_decay:  0.00011172791192144375
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.136055670911446
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2711267170961946
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.006895605009049
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.435633420944214
total time:  6.452466829912737
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.51
[I 2023-06-12 00:35:27,837] Trial 213 finished with value: 81.06666564941406 and parameters: {'Fwd': 5.509425824581599e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.4071944067836117, 'loop': 1, 'loss': 'CE', 'lr': 0.0025037632932484255, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011172791192144375, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0041887838519242895
weight_decay:  0.00015665847164046874
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0056428010575473
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.343414963921532
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.017144810175523
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.396222829818726
total time:  6.415685313055292
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.56
[I 2023-06-12 00:35:34,718] Trial 214 finished with value: 81.73333740234375 and parameters: {'Fwd': 6.533886411765411e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.59113705637829, 'loop': 1, 'loss': 'CE', 'lr': 0.0041887838519242895, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015665847164046874, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0037756206224333205
weight_decay:  0.0002485853445555435
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.267539430875331
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.3391760089434683
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.2941150600090623
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.92901611328125
total time:  6.943229032913223
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.70
[I 2023-06-12 00:35:42,127] Trial 215 finished with value: 81.60000610351562 and parameters: {'Fwd': 7.805076966500899e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.2514532047731546, 'loop': 1, 'loss': 'CE', 'lr': 0.0037756206224333205, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002485853445555435, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004354092345964561
weight_decay:  8.48374237813413e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7742432050872594
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.241637749830261
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2093706789892167
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.249370336532593
total time:  6.267050605034456
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:35:49,005] Trial 216 finished with value: 81.9333267211914 and parameters: {'Fwd': 5.464233118403308e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.4656539514693856, 'loop': 1, 'loss': 'CE', 'lr': 0.004354092345964561, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.48374237813413e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00048142637160136765
weight_decay:  0.00012349898863975637
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9244168158620596
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02
None time:  2.0040272371843457
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.0260948021896183
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.977650165557861
total time:  5.995037369895726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.40 ± 5.94
  Final Train: 100.00 ± 0.00
   Final Test: 75.83 ± 5.16
[I 2023-06-12 00:35:55,636] Trial 217 finished with value: 75.4000015258789 and parameters: {'Fwd': 1.3259498950970773e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.989274325486161, 'loop': 1, 'loss': 'CE', 'lr': 0.00048142637160136765, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012349898863975637, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.005340646809605868
weight_decay:  0.00016328809486445918
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0597321880050004
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.2135938860010356
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.9182217819616199
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.213997840881348
total time:  6.227199832908809
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.67
[I 2023-06-12 00:36:02,473] Trial 218 finished with value: 81.53333282470703 and parameters: {'Fwd': 9.849594417314198e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.8541773725516713, 'loop': 1, 'loss': 'CE', 'lr': 0.005340646809605868, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016328809486445918, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.003989586646384129
weight_decay:  0.00010446943826690385
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1665332519914955
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.8679245570674539
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.186598737956956
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.245347023010254
total time:  6.259248102083802
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.65
[I 2023-06-12 00:36:09,274] Trial 219 finished with value: 81.66667175292969 and parameters: {'Fwd': 5.243844757940097e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6506204132248175, 'loop': 1, 'loss': 'CE', 'lr': 0.003989586646384129, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010446943826690385, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004417868396914538
weight_decay:  6.515240489044855e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3574628250207752
None Run 01:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  1.1124908227939159
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.29
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.130154653917998
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.626523494720459
total time:  3.64081680518575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 2.90
  Final Train: 99.76 ± 0.41
   Final Test: 70.00 ± 1.25
[I 2023-06-12 00:36:13,405] Trial 220 finished with value: 71.53333282470703 and parameters: {'Fwd': 6.687436749127329e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.3523200070631893, 'loop': 1, 'loss': 'CE', 'lr': 0.004417868396914538, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.515240489044855e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004404150824891309
weight_decay:  9.425459726198645e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1740799758117646
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.9587880240287632
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.209372712066397
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.369144916534424
total time:  6.381627139169723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.46
[I 2023-06-12 00:36:20,289] Trial 221 finished with value: 82.0 and parameters: {'Fwd': 5.124295182133205e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.4499155995725506, 'loop': 1, 'loss': 'CE', 'lr': 0.004404150824891309, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.425459726198645e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005160229950376371
weight_decay:  9.193331081349083e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.14659910206683
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.952591931913048
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.0162146571092308
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.141744136810303
total time:  6.160309724044055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.53
[I 2023-06-12 00:36:27,030] Trial 222 finished with value: 81.66666412353516 and parameters: {'Fwd': 5.092067691971467e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.934284509775283, 'loop': 1, 'loss': 'CE', 'lr': 0.005160229950376371, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.193331081349083e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004576027986217847
weight_decay:  0.00012252299245915773
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1861577418167144
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0191714090760797
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.166421949164942
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.400561571121216
total time:  6.417401537997648
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.38
[I 2023-06-12 00:36:34,027] Trial 223 finished with value: 82.0 and parameters: {'Fwd': 8.793564838137814e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.578517875422735, 'loop': 1, 'loss': 'CE', 'lr': 0.004576027986217847, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012252299245915773, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004602468312308857
weight_decay:  0.0001453955743358457
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.150059777777642
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.108543158043176
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.0151466289535165
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.299163579940796
total time:  6.315368112875149
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.35
[I 2023-06-12 00:36:40,967] Trial 224 finished with value: 81.93334197998047 and parameters: {'Fwd': 0.00011323904440843025, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6827775916606016, 'loop': 1, 'loss': 'CE', 'lr': 0.004602468312308857, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001453955743358457, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004795301810977439
weight_decay:  0.00012605284198908886
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0051938369870186
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.231574645033106
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.864933667005971
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.128454923629761
total time:  6.143213401082903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.45
[I 2023-06-12 00:36:47,748] Trial 225 finished with value: 81.86666870117188 and parameters: {'Fwd': 8.197904161664639e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.7705304126549692, 'loop': 1, 'loss': 'CE', 'lr': 0.004795301810977439, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012605284198908886, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005626500000439392
weight_decay:  7.630993105088559e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2403952600434422
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 02
None time:  2.3756415869574994
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.6323877358809114
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.275697708129883
total time:  6.288020970998332
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 80.90 ± 0.62
[I 2023-06-12 00:36:54,482] Trial 226 finished with value: 80.79999542236328 and parameters: {'Fwd': 3.517217641131807e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 4.032974901683787, 'loop': 1, 'loss': 'CE', 'lr': 0.005626500000439392, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.630993105088559e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.003635811122157553
weight_decay:  0.0001582386128267248
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2327190511859953
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.2087666511069983
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4420451079495251
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.9096081256866455
total time:  5.927285237936303
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.35
[I 2023-06-12 00:37:00,849] Trial 227 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.00020261076231672557, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.200827365906116, 'loop': 1, 'loss': 'CE', 'lr': 0.003635811122157553, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001582386128267248, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00511533937894633
weight_decay:  0.00022464314206485812
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1022292780689895
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.093353387899697
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.7193806418217719
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.941261529922485
total time:  5.956016563111916
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.70
[I 2023-06-12 00:37:07,288] Trial 228 finished with value: 81.0666732788086 and parameters: {'Fwd': 1.14997295121672e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.658744861132392, 'loop': 1, 'loss': 'CE', 'lr': 0.00511533937894633, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00022464314206485812, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004541767757350892
weight_decay:  0.0001447063240369932
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7299694619141519
None Run 01:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  0.7399471360258758
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 03
None time:  0.577638158807531
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.90
run time now: 2.076160192489624
total time:  2.090577549068257
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.60 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 76.30 ± 0.66
[I 2023-06-12 00:37:09,944] Trial 229 finished with value: 76.60000610351562 and parameters: {'Fwd': 0.000881011404665974, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 10, 'lambda1': 1.0, 'lambda2': 3.8650742553395903, 'loop': 1, 'loss': 'CE', 'lr': 0.004541767757350892, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001447063240369932, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.15000000000000002
lr:  0.00396454891857101
weight_decay:  8.972716939558727e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1585731259547174
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.236202819040045
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.0983215579763055
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.516868591308594
total time:  6.531896959990263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.55
[I 2023-06-12 00:37:17,091] Trial 230 finished with value: 81.53333282470703 and parameters: {'Fwd': 7.5499947252609445e-06, 'K': 10, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.114628732857524, 'loop': 1, 'loss': 'CE', 'lr': 0.00396454891857101, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.972716939558727e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004526145034911552
weight_decay:  0.00017639526863244494
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2071287110447884
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.308408420998603
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2001996701583266
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.743704080581665
total time:  6.756179000949487
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:37:24,473] Trial 231 finished with value: 82.0 and parameters: {'Fwd': 8.593525470685912e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.556766016873885, 'loop': 1, 'loss': 'CE', 'lr': 0.004526145034911552, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017639526863244494, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004726032665670633
weight_decay:  0.00039457674522692704
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1053303389344364
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.1647812291048467
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.9198651199694723
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.217633008956909
total time:  6.237332848133519
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.40
[I 2023-06-12 00:37:31,267] Trial 232 finished with value: 81.79999542236328 and parameters: {'Fwd': 9.454215045962948e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6896442717443327, 'loop': 1, 'loss': 'CE', 'lr': 0.004726032665670633, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00039457674522692704, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0018354355277743445
weight_decay:  0.00011647082172740811
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1511840829625726
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.9586784639395773
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.983314991928637
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.1323487758636475
total time:  6.15093562216498
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 80.90 ± 0.30
[I 2023-06-12 00:37:38,045] Trial 233 finished with value: 80.33332824707031 and parameters: {'Fwd': 1.4678424606217119e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 2.8226610258734857, 'loop': 1, 'loss': 'CE', 'lr': 0.0018354355277743445, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011647082172740811, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.003995685079096993
weight_decay:  0.00014848480152067516
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2400313639082015
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0467351181432605
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.967186362016946
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.283372402191162
total time:  6.297093185130507
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.55
[I 2023-06-12 00:37:44,806] Trial 234 finished with value: 81.53333282470703 and parameters: {'Fwd': 8.829206224800382e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 3.2798323579061592, 'loop': 1, 'loss': 'CE', 'lr': 0.003995685079096993, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014848480152067516, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0044942188944635635
weight_decay:  0.00020060584911770827
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2246735498774797
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.896257929969579
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.8848246671259403
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.032247304916382
total time:  6.044979413971305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.51
[I 2023-06-12 00:37:51,391] Trial 235 finished with value: 82.0 and parameters: {'Fwd': 1.8571227547737735e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.568462811619727, 'loop': 1, 'loss': 'CE', 'lr': 0.0044942188944635635, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020060584911770827, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005450261620910569
weight_decay:  0.00020423830925218054
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.130993277998641
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.0773811109829694
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.899240316124633
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.137452602386475
total time:  6.157279115868732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.46
[I 2023-06-12 00:37:58,140] Trial 236 finished with value: 81.53333282470703 and parameters: {'Fwd': 4.154479339803233e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 3.94542865395669, 'loop': 1, 'loss': 'CE', 'lr': 0.005450261620910569, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020423830925218054, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004697104231822144
weight_decay:  0.00026998847008149676
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0920930919237435
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  2.4094446229282767
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  2.062284955987707
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.70
run time now: 6.587732791900635
total time:  6.60891068005003
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 0.32
[I 2023-06-12 00:38:05,346] Trial 237 finished with value: 79.0666732788086 and parameters: {'Fwd': 6.8489672694040836e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6570322406364193, 'loop': 1, 'loss': 'MSE', 'lr': 0.004697104231822144, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00026998847008149676, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005161816330213892
weight_decay:  0.0001832141227817823
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4246706489939243
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  2.3184452650602907
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.1344245690852404
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.899785757064819
total time:  6.914453587960452
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 0.64
[I 2023-06-12 00:38:12,800] Trial 238 finished with value: 80.5999984741211 and parameters: {'Fwd': 3.6156688099432705e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.500268033748892, 'loop': 1, 'loss': 'CE', 'lr': 0.005161816330213892, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001832141227817823, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004541048701442232
weight_decay:  0.00013734336140614498
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1544589051045477
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.1843924259301275
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.8609854478854686
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.224524736404419
total time:  6.236551767913625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:38:19,594] Trial 239 finished with value: 82.0 and parameters: {'Fwd': 8.554448051007044e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.8190292317778476, 'loop': 1, 'loss': 'CE', 'lr': 0.004541048701442232, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013734336140614498, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0058112252054175785
weight_decay:  0.00022279376784581869
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.102575207129121
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.6302921120077372
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.8365441591013223
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.5970094203948975
total time:  5.613061740063131
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.49
[I 2023-06-12 00:38:25,747] Trial 240 finished with value: 81.06666564941406 and parameters: {'Fwd': 1.0443020703480512e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.113351623920457, 'loop': 1, 'loss': 'CE', 'lr': 0.0058112252054175785, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00022279376784581869, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004359316484861375
weight_decay:  0.00012928491814715788
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.113309634849429
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.0513066919520497
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.8569572910200804
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.051012754440308
total time:  6.066310545895249
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:38:32,299] Trial 241 finished with value: 82.0 and parameters: {'Fwd': 8.413796976461614e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.821269785217787, 'loop': 1, 'loss': 'CE', 'lr': 0.004359316484861375, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012928491814715788, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004570049985019048
weight_decay:  0.00015226830199958316
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.240306616993621
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.0424694509711117
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.9672996141016483
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.277603387832642
total time:  6.292337823892012
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.42
[I 2023-06-12 00:38:39,093] Trial 242 finished with value: 82.0 and parameters: {'Fwd': 7.925947993881166e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.822511286842121, 'loop': 1, 'loss': 'CE', 'lr': 0.004570049985019048, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015226830199958316, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004912828425248752
weight_decay:  0.0001497656593505932
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0851032650098205
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.832894298946485
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.8679577130824327
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.808669328689575
total time:  5.8204515050165355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.55
[I 2023-06-12 00:38:45,450] Trial 243 finished with value: 81.66666412353516 and parameters: {'Fwd': 8.106150684654646e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.835827301602711, 'loop': 1, 'loss': 'CE', 'lr': 0.004912828425248752, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001497656593505932, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004484321629249326
weight_decay:  0.00013484222385226082
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1758406499866396
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9196322890929878
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.906961278989911
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.031746864318848
total time:  6.050489437999204
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.51
[I 2023-06-12 00:38:52,003] Trial 244 finished with value: 82.0 and parameters: {'Fwd': 4.5538741023238935e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.8780013962888376, 'loop': 1, 'loss': 'CE', 'lr': 0.004484321629249326, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013484222385226082, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004573364313235312
weight_decay:  0.00014112786585612075
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1771787849720567
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6451677880249918
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.159882049076259
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.009090185165405
total time:  6.024468931835145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.40
[I 2023-06-12 00:38:58,524] Trial 245 finished with value: 82.0 and parameters: {'Fwd': 7.997306472248216e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.8623378689944934, 'loop': 1, 'loss': 'CE', 'lr': 0.004573364313235312, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014112786585612075, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0038644788723461022
weight_decay:  0.00012952216041127755
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.195319138932973
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.7396499759051949
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.824045272078365
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.78482985496521
total time:  5.800211034016684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.75
[I 2023-06-12 00:39:04,842] Trial 246 finished with value: 81.5999984741211 and parameters: {'Fwd': 8.27857243618142e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.9465691730311594, 'loop': 1, 'loss': 'CE', 'lr': 0.0038644788723461022, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012952216041127755, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00496964907917713
weight_decay:  0.00018475168014307105
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.181840327102691
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.181943106930703
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.897478548111394
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.287551164627075
total time:  6.3028348970692605
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.50
[I 2023-06-12 00:39:11,594] Trial 247 finished with value: 81.66666412353516 and parameters: {'Fwd': 6.001746048676001e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.769604727143367, 'loop': 1, 'loss': 'CE', 'lr': 0.00496964907917713, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018475168014307105, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004528819264154842
weight_decay:  0.00011763384562356808
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1134268390014768
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9464079712051898
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.287398654036224
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.370903015136719
total time:  6.384331134147942
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:39:18,551] Trial 248 finished with value: 82.0 and parameters: {'Fwd': 1.2005124397817615e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.062116797711617, 'loop': 1, 'loss': 'CE', 'lr': 0.004528819264154842, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011763384562356808, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.003393000792094255
weight_decay:  0.000323808269267102
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.28977898391895
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0620635969098657
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.1375551209785044
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.516828536987305
total time:  6.551750256912783
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.31
[I 2023-06-12 00:39:25,686] Trial 249 finished with value: 81.26666259765625 and parameters: {'Fwd': 1.0561805637850293e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.948052475366215, 'loop': 1, 'loss': 'CE', 'lr': 0.003393000792094255, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000323808269267102, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00403918860600571
weight_decay:  0.00012248317803088252
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.072685888968408
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 02
None time:  1.114231170155108
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.38159573613666
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.00
run time now: 3.5955121517181396
total time:  3.6120497449301183
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 80.03 ± 0.75
[I 2023-06-12 00:39:29,760] Trial 250 finished with value: 79.53333282470703 and parameters: {'Fwd': 5.0809510926773e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.1, 'gnnepoch': 40, 'lambda1': 0.9500000000000001, 'lambda2': 3.4009055241437802, 'loop': 1, 'loss': 'CE', 'lr': 0.00403918860600571, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012248317803088252, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00988798753785971
weight_decay:  0.00017439925611351947
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.274589039152488
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.596717185107991
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  2.2008486229460686
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.90
run time now: 6.099924564361572
total time:  6.112124068895355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 79.90 ± 0.87
[I 2023-06-12 00:39:36,312] Trial 251 finished with value: 80.86666870117188 and parameters: {'Fwd': 1.1720200537518028e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.7827310494632753, 'loop': 1, 'loss': 'CE', 'lr': 0.00988798753785971, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017439925611351947, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005214325945463764
weight_decay:  0.00024017839662501234
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.928620083956048
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9110209189821035
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.1823865950573236
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.0515968799591064
total time:  6.069297139067203
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.52
[I 2023-06-12 00:39:42,885] Trial 252 finished with value: 81.53333282470703 and parameters: {'Fwd': 8.688887123949825e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.086747500220293, 'loop': 1, 'loss': 'CE', 'lr': 0.005214325945463764, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00024017839662501234, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0045335867474928055
weight_decay:  0.0001044801067985707
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1411032369360328
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.8800544398836792
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.050004383083433
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.0993287563323975
total time:  6.115201331907883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.51
[I 2023-06-12 00:39:49,467] Trial 253 finished with value: 82.0 and parameters: {'Fwd': 4.419296279338016e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.5753498322215007, 'loop': 1, 'loss': 'CE', 'lr': 0.0045335867474928055, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001044801067985707, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0036265332391060908
weight_decay:  6.964035702338457e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2040370458271354
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0037872020620853
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.9425381398759782
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.1756484508514404
total time:  3.1915334051009268
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.00
[I 2023-06-12 00:39:53,110] Trial 254 finished with value: 68.5999984741211 and parameters: {'Fwd': 6.214445897700441e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.5202692993573392, 'loop': 1, 'loss': 'CE', 'lr': 0.0036265332391060908, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.964035702338457e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004106155553022189
weight_decay:  0.00010886714063376718
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2542080311104655
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.8891713090706617
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.0796170660760254
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.248266696929932
total time:  6.272843364160508
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.71
[I 2023-06-12 00:39:59,953] Trial 255 finished with value: 81.66667175292969 and parameters: {'Fwd': 4.497977566525355e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.3766237394057246, 'loop': 1, 'loss': 'CE', 'lr': 0.004106155553022189, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010886714063376718, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004565068781960483
weight_decay:  0.00016171771675323814
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3417519871145487
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.9836874038446695
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.220575165003538
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.573908567428589
total time:  6.586109299911186
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.78
[I 2023-06-12 00:40:06,989] Trial 256 finished with value: 80.73333740234375 and parameters: {'Fwd': 1.3337372541418343e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 3.7633742537276, 'loop': 1, 'loss': 'CE', 'lr': 0.004565068781960483, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016171771675323814, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.005429893581875305
weight_decay:  0.00020468243138308743
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.18500891700387
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 83.00
Split: 01, Run: 02
None time:  2.1631299580913037
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.1392551991157234
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
run time now: 6.512964725494385
total time:  6.528833772055805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 82.17 ± 0.80
[I 2023-06-12 00:40:13,985] Trial 257 finished with value: 81.4000015258789 and parameters: {'Fwd': 8.554579480845632e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.548064641964538, 'loop': 1, 'loss': 'CE', 'lr': 0.005429893581875305, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020468243138308743, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004033387962592653
weight_decay:  5.965395262797977e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3384293508715928
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.7011555039789528
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.0445721060968935
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.10996150970459
total time:  6.1300303468015045
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.81
[I 2023-06-12 00:40:20,623] Trial 258 finished with value: 80.93334197998047 and parameters: {'Fwd': 7.1093649690326035e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 4.044924947031893, 'loop': 1, 'loss': 'CE', 'lr': 0.004033387962592653, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.965395262797977e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004965052848977533
weight_decay:  0.00014043616534179098
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9824845709372312
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.055854468140751
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.052360199857503
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.90
run time now: 6.150431156158447
total time:  6.168639591895044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 82.03 ± 0.32
[I 2023-06-12 00:40:27,342] Trial 259 finished with value: 81.4000015258789 and parameters: {'Fwd': 4.791431177854521e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.6106617325053305, 'loop': 1, 'loss': 'CE', 'lr': 0.004965052848977533, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00014043616534179098, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0036878291527467754
weight_decay:  0.00010179872252300236
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1808836760465056
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9107030460145324
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.203188994899392
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.319607496261597
total time:  6.335277508944273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.51
[I 2023-06-12 00:40:34,278] Trial 260 finished with value: 81.53333282470703 and parameters: {'Fwd': 1.1371770576271505e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.191810900545569, 'loop': 1, 'loss': 'CE', 'lr': 0.0036878291527467754, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010179872252300236, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004504826828359486
weight_decay:  8.571661959993777e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.74539779801853
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.739451311994344
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  2.3760014879517257
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.886017322540283
total time:  5.89984570001252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.59
[I 2023-06-12 00:40:40,685] Trial 261 finished with value: 79.46666717529297 and parameters: {'Fwd': 5.533792200329309e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.15867256722613, 'loop': 1, 'loss': 'MSE', 'lr': 0.004504826828359486, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.571661959993777e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0027480920575738803
weight_decay:  0.0002642116054832031
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7297132120002061
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.8932338189333677
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 99.29
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.02996398601681
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.694358587265015
total time:  5.711264430079609
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.46
  Final Train: 99.76 ± 0.41
   Final Test: 81.37 ± 0.71
[I 2023-06-12 00:40:46,860] Trial 262 finished with value: 80.46666717529297 and parameters: {'Fwd': 3.4918927803525923e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.9095967652093053, 'loop': 1, 'loss': 'CE', 'lr': 0.0027480920575738803, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002642116054832031, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005851675977045939
weight_decay:  0.00017400038647450182
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9771666079759598
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.9724396020174026
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  2.006404618965462
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.983219861984253
total time:  6.002608156995848
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.87
[I 2023-06-12 00:40:53,342] Trial 263 finished with value: 81.5999984741211 and parameters: {'Fwd': 7.88386376889161e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.413055942539104, 'loop': 1, 'loss': 'CE', 'lr': 0.005851675977045939, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017400038647450182, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004350630412998217
weight_decay:  0.00013295522778425614
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.153392992913723
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.612954513169825
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.1508412121329457
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.946655035018921
total time:  5.966201242059469
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:40:59,730] Trial 264 finished with value: 82.0 and parameters: {'Fwd': 1.6951870052057196e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.84271829653519, 'loop': 1, 'loss': 'CE', 'lr': 0.004350630412998217, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013295522778425614, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0033069074049355504
weight_decay:  0.00010569515847388855
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9665014939382672
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.906066669151187
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.9568205601535738
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.859198570251465
total time:  5.87704548612237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.36
[I 2023-06-12 00:41:06,080] Trial 265 finished with value: 81.33333587646484 and parameters: {'Fwd': 1.7564791915821682e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.7272977653463477, 'loop': 1, 'loss': 'CE', 'lr': 0.0033069074049355504, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010569515847388855, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.00427032782641353
weight_decay:  0.00013076836983342172
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1727566309273243
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.7706030290573835
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.1866166689433157
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.214963436126709
total time:  6.234873319976032
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.47
[I 2023-06-12 00:41:12,873] Trial 266 finished with value: 81.80001068115234 and parameters: {'Fwd': 1.6395341235952826e-05, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.9587499998577003, 'loop': 1, 'loss': 'CE', 'lr': 0.00427032782641353, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013076836983342172, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00380068080025991
weight_decay:  0.00020411981600425806
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2052346172276884
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.0614717099815607
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.9293581540696323
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.224541902542114
total time:  6.242782328044996
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.75
[I 2023-06-12 00:41:19,595] Trial 267 finished with value: 81.53333282470703 and parameters: {'Fwd': 1.3182938531871498e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6106053589114935, 'loop': 1, 'loss': 'CE', 'lr': 0.00380068080025991, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020411981600425806, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005078287603633952
weight_decay:  7.416060977733162e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1670772419311106
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.080658850958571
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.9864335709717125
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.70
run time now: 6.328904628753662
total time:  6.350558463018388
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.78
[I 2023-06-12 00:41:26,453] Trial 268 finished with value: 81.06666564941406 and parameters: {'Fwd': 2.1762918923337403e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.167450052719477, 'loop': 1, 'loss': 'CE', 'lr': 0.005078287603633952, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.416060977733162e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004210270916844307
weight_decay:  0.00012973776675520465
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2533403439447284
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.2023470371495932
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.3762514491099864
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.860904932022095
total time:  6.8786831989418715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.67
[I 2023-06-12 00:41:33,828] Trial 269 finished with value: 80.86666870117188 and parameters: {'Fwd': 1.1108449961235068e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 3.837827190742587, 'loop': 1, 'loss': 'CE', 'lr': 0.004210270916844307, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012973776675520465, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004525164657840534
weight_decay:  5.1270096134175296e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9483115738257766
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  2.2295664809644222
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  2.0672436540480703
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.272705554962158
total time:  6.288240449968725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.63 ± 0.49
[I 2023-06-12 00:41:40,592] Trial 270 finished with value: 80.79999542236328 and parameters: {'Fwd': 6.415967178559738e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.3156161686832295, 'loop': 1, 'loss': 'CE', 'lr': 0.004525164657840534, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.1270096134175296e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0038585772524053477
weight_decay:  0.00033515622061748335
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.094827759778127
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.231066838139668
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.1057762659620494
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.45889687538147
total time:  6.471584348008037
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.70
[I 2023-06-12 00:41:47,521] Trial 271 finished with value: 80.86666870117188 and parameters: {'Fwd': 9.083059517443272e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 3.5629548491332685, 'loop': 1, 'loss': 'CE', 'lr': 0.0038585772524053477, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00033515622061748335, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005058856175683763
weight_decay:  9.739997864658179e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.262844004901126
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.681712046964094
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.0656438199803233
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.035914421081543
total time:  6.050632672850043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.46
[I 2023-06-12 00:41:54,100] Trial 272 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.532939704164886e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.9687948157460524, 'loop': 1, 'loss': 'CE', 'lr': 0.005058856175683763, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.739997864658179e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.0057520567391303136
weight_decay:  0.00023516787760192887
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2095951240044087
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.1901897699572146
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  0.7220502849668264
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.70
run time now: 3.150563955307007
total time:  3.168766171904281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 79.97 ± 0.23
[I 2023-06-12 00:41:57,846] Trial 273 finished with value: 79.39999389648438 and parameters: {'Fwd': 5.993276009721453e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 3.757005475172206, 'loop': 1, 'loss': 'CE', 'lr': 0.0057520567391303136, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00023516787760192887, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.001171499909301824
weight_decay:  0.00040335558389082484
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2476013938430697
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.208123676944524
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.236898418981582
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.7183375358581543
total time:  3.73184190900065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.00
[I 2023-06-12 00:42:02,115] Trial 274 finished with value: 68.80000305175781 and parameters: {'Fwd': 9.388305341150299e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.195935194270245, 'loop': 1, 'loss': 'CE', 'lr': 0.001171499909301824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00040335558389082484, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.003070223616703702
weight_decay:  0.0001452433435309955
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0534354159608483
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  0.9550486300140619
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.3787377090193331
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 3.414034366607666
total time:  3.42845819494687
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 0.25
[I 2023-06-12 00:42:06,014] Trial 275 finished with value: 80.26666259765625 and parameters: {'Fwd': 7.691560842480301e-06, 'K': 8, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 3.113706184941323, 'loop': 1, 'loss': 'CE', 'lr': 0.003070223616703702, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001452433435309955, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0044249174142612395
weight_decay:  0.00011045726541684576
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2327312058769166
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.7697029141709208
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 99.29
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.0981901600025594
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 99.29
   Final Test: 81.00
run time now: 6.128602981567383
total time:  6.142618508078158
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 99.52 ± 0.41
   Final Test: 81.43 ± 0.45
[I 2023-06-12 00:42:12,651] Trial 276 finished with value: 82.0 and parameters: {'Fwd': 4.772263803870081e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 1.6442283589792739, 'loop': 1, 'loss': 'CE', 'lr': 0.0044249174142612395, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011045726541684576, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0034819661021569088
weight_decay:  8.382358995614097e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.268629183061421
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6778424179647118
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.0354557749815285
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.011971712112427
total time:  6.030801641987637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.31
[I 2023-06-12 00:42:19,257] Trial 277 finished with value: 81.26667022705078 and parameters: {'Fwd': 2.2809061004071808e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.3950566238747024, 'loop': 1, 'loss': 'CE', 'lr': 0.0034819661021569088, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.382358995614097e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.05
lr:  0.004138565128996909
weight_decay:  0.00011118750608170292
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.922991338884458
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.811657686950639
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.3009382281452417
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
run time now: 5.06082558631897
total time:  5.075665048090741
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 1.04
[I 2023-06-12 00:42:24,796] Trial 278 finished with value: 80.86666870117188 and parameters: {'Fwd': 1.564270481018945e-05, 'K': 5, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 2.849096450704953, 'loop': 0, 'loss': 'CE', 'lr': 0.004138565128996909, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011118750608170292, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.004398672159539438
weight_decay:  0.00018081824022788128
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.807702240999788
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.9638172590639442
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 99.29
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.9460187940858305
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 81.10
run time now: 5.742209434509277
total time:  5.761308339890093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.90
  Final Train: 99.52 ± 0.41
   Final Test: 81.37 ± 0.93
[I 2023-06-12 00:42:31,037] Trial 279 finished with value: 81.13333129882812 and parameters: {'Fwd': 6.701161119669855e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 1.9108051617573167, 'loop': 1, 'loss': 'CE', 'lr': 0.004398672159539438, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018081824022788128, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0037754859520656553
weight_decay:  6.0841670219186054e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.208719339920208
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.8950763568282127
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.1905601990874857
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 80.90
run time now: 6.320706844329834
total time:  6.338698612060398
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.20
  Final Train: 99.29 ± 0.00
   Final Test: 81.43 ± 0.47
[I 2023-06-12 00:42:37,995] Trial 280 finished with value: 81.19999694824219 and parameters: {'Fwd': 4.272300783517251e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 0.608757619620812, 'loop': 1, 'loss': 'CE', 'lr': 0.0037754859520656553, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.0841670219186054e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004485484640150151
weight_decay:  0.00011793708916935252
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8817821110133082
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  2.5135574031155556
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  2.6318174079060555
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.90
run time now: 7.0535972118377686
total time:  7.077595395967364
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.53
[I 2023-06-12 00:42:45,581] Trial 281 finished with value: 78.46666717529297 and parameters: {'Fwd': 1.2201550605691323e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 4.0061731661716244, 'loop': 1, 'loss': 'MSE', 'lr': 0.004485484640150151, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011793708916935252, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.05
lr:  0.005353603924427979
weight_decay:  0.00015302023392931938
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0004172790795565
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9884207299910486
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.7607750068418682
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.40
run time now: 5.769251823425293
total time:  5.783001176081598
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 99.76 ± 0.41
   Final Test: 81.30 ± 0.85
[I 2023-06-12 00:42:51,914] Trial 282 finished with value: 81.33333587646484 and parameters: {'Fwd': 3.3342937580901383e-06, 'K': 4, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.578652215414554, 'loop': 1, 'loss': 'CE', 'lr': 0.005353603924427979, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015302023392931938, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.002398306105616239
weight_decay:  8.79272708611814e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.235633481061086
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9943735690321773
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.9691161001101136
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.222832441329956
total time:  6.239804447861388
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.64
[I 2023-06-12 00:42:58,642] Trial 283 finished with value: 81.0 and parameters: {'Fwd': 9.743480074100586e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.615161215563942, 'loop': 1, 'loss': 'CE', 'lr': 0.002398306105616239, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.79272708611814e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004077351103975763
weight_decay:  0.0002598427097291371
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0173448610585183
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.8150952560827136
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.7000546888448298
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.40
run time now: 5.565493822097778
total time:  5.587029535090551
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.12
  Final Train: 99.29 ± 0.00
   Final Test: 81.27 ± 0.42
[I 2023-06-12 00:43:04,814] Trial 284 finished with value: 81.06666564941406 and parameters: {'Fwd': 5.227744795115946e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.381942915195648, 'loop': 1, 'loss': 'CE', 'lr': 0.004077351103975763, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002598427097291371, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0005046705361075003
weight_decay:  0.00018696090915837273
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2412319120485336
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.57
   Final Test: 79.20
Split: 01, Run: 02
None time:  2.112752455053851
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 98.57
   Final Test: 78.60
Split: 01, Run: 03
None time:  2.1773301288485527
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 97.14
   Final Test: 75.80
run time now: 6.559359788894653
total time:  6.581888349959627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 1.91
  Final Train: 98.10 ± 0.82
   Final Test: 77.87 ± 1.81
[I 2023-06-12 00:43:11,867] Trial 285 finished with value: 78.4000015258789 and parameters: {'Fwd': 6.981797899286644e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 0.14430753393218998, 'loop': 1, 'loss': 'CE', 'lr': 0.0005046705361075003, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018696090915837273, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.004891811996976719
weight_decay:  1.2982486394398336e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2573405541479588
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.3218234728556126
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.1112936371937394
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.7146828174591064
total time:  6.727562624961138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.75
[I 2023-06-12 00:43:19,072] Trial 286 finished with value: 81.20000457763672 and parameters: {'Fwd': 4.311969629578387e-06, 'K': 6, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.1399075106229803, 'loop': 1, 'loss': 'CE', 'lr': 0.004891811996976719, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2982486394398336e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.003393252475019266
weight_decay:  6.795736277087714e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0525677278637886
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.2019935629796237
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.974580456968397
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.20
run time now: 6.260312080383301
total time:  6.274075577966869
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.00
  Final Train: 99.29 ± 0.00
   Final Test: 81.50 ± 0.26
[I 2023-06-12 00:43:25,836] Trial 287 finished with value: 81.4000015258789 and parameters: {'Fwd': 5.852203929232604e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 1.3387598614075324, 'loop': 1, 'loss': 'CE', 'lr': 0.003393252475019266, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.795736277087714e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004523706576794229
weight_decay:  0.0001308838364458218
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.987626593094319
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9330141439568251
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2174322379287332
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.165420055389404
total time:  6.178556213853881
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:43:32,445] Trial 288 finished with value: 82.0 and parameters: {'Fwd': 0.0007843540653739664, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.798777527808403, 'loop': 1, 'loss': 'CE', 'lr': 0.004523706576794229, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001308838364458218, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0028675087901411105
weight_decay:  0.00010177600871657653
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.038065518019721
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.090424627996981
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 99.29
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.3470350259449333
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.10
run time now: 6.503541707992554
total time:  6.523140524979681
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.50
  Final Train: 99.29 ± 0.00
   Final Test: 81.43 ± 0.42
[I 2023-06-12 00:43:39,503] Trial 289 finished with value: 80.93333435058594 and parameters: {'Fwd': 6.0119437172704916e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 2.07794318483532, 'loop': 1, 'loss': 'CE', 'lr': 0.0028675087901411105, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010177600871657653, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.003968007696937798
weight_decay:  0.00015572485377617214
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8011728290002793
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.1397165190428495
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.0913175670430064
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.091598987579346
total time:  6.106778741115704
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.75
[I 2023-06-12 00:43:46,081] Trial 290 finished with value: 81.66667175292969 and parameters: {'Fwd': 9.032760262544787e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.4469893669490443, 'loop': 1, 'loss': 'CE', 'lr': 0.003968007696937798, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015572485377617214, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.005503188971083628
weight_decay:  0.00023440459629699013
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.997301439056173
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.111817433964461
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.1623768811114132
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.299223184585571
total time:  6.316788916941732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.74
[I 2023-06-12 00:43:52,894] Trial 291 finished with value: 81.5999984741211 and parameters: {'Fwd': 1.2921086965809722e-05, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 4.251045471593436, 'loop': 1, 'loss': 'CE', 'lr': 0.005503188971083628, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00023440459629699013, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00489941512277301
weight_decay:  0.0001120515611426468
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7640737660694867
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.004523932002485
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.033770719077438
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.90650749206543
total time:  5.9818767830729485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.00 ± 0.78
[I 2023-06-12 00:43:59,498] Trial 292 finished with value: 81.20000457763672 and parameters: {'Fwd': 3.4112296716953202e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 4.009678282066999, 'loop': 1, 'loss': 'CE', 'lr': 0.00489941512277301, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001120515611426468, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0015905317484536095
weight_decay:  0.00019601154041257982
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3347653199452907
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0671805699821562
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.9954995180014521
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.4273037910461426
total time:  3.446975986007601
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.00
[I 2023-06-12 00:44:03,413] Trial 293 finished with value: 68.5999984741211 and parameters: {'Fwd': 2.486139385452448e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 1.345489577820054, 'loop': 1, 'loss': 'CE', 'lr': 0.0015905317484536095, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019601154041257982, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.003596410209086943
weight_decay:  8.329656143585307e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1551511539146304
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.2150772591121495
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.6014959961175919
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.003822088241577
total time:  6.022173567907885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.51
[I 2023-06-12 00:44:09,868] Trial 294 finished with value: 81.46666717529297 and parameters: {'Fwd': 2.837388514091499e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.2922794863648135, 'loop': 1, 'loss': 'CE', 'lr': 0.003596410209086943, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.329656143585307e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0061421760145359
weight_decay:  0.0003090090015678132
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2504631190095097
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.1699257369618863
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.416619444033131
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.867046594619751
total time:  5.887434492819011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.72
[I 2023-06-12 00:44:16,227] Trial 295 finished with value: 81.5999984741211 and parameters: {'Fwd': 1.7774690389225534e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.7110474483119247, 'loop': 1, 'loss': 'CE', 'lr': 0.0061421760145359, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003090090015678132, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.002194493181997713
weight_decay:  5.051427846386769e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2886865481268615
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9484710958786309
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.9619890579488128
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.232545852661133
total time:  6.2466043988242745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.70
[I 2023-06-12 00:44:22,948] Trial 296 finished with value: 80.66666412353516 and parameters: {'Fwd': 4.0531172384762805e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.985274166717729, 'loop': 1, 'loss': 'CE', 'lr': 0.002194493181997713, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.051427846386769e-05, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004423318946229723
weight_decay:  0.0001366958153605422
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.223793857032433
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 02
None time:  1.998536627041176
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.179592481115833
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.60
run time now: 6.429687976837158
total time:  6.444825584068894
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 82.07 ± 0.57
[I 2023-06-12 00:44:29,915] Trial 297 finished with value: 81.33333587646484 and parameters: {'Fwd': 7.615513055886206e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 9.178131382761315, 'loop': 1, 'loss': 'CE', 'lr': 0.004423318946229723, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001366958153605422, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00017966052153975715
weight_decay:  0.04726571260288294
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2218437700066715
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.035658024949953
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.7998514561913908
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.30
run time now: 6.081444501876831
total time:  6.096219192957506
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.87 ± 3.52
  Final Train: 100.00 ± 0.00
   Final Test: 76.90 ± 3.31
[I 2023-06-12 00:44:36,575] Trial 298 finished with value: 76.86666107177734 and parameters: {'Fwd': 5.053161678322426e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.5409543440939273, 'loop': 1, 'loss': 'CE', 'lr': 0.00017966052153975715, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04726571260288294, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.00253668245658911
weight_decay:  0.0001662113194959792
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.072100284975022
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.3504829690791667
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.240422783885151
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.690773963928223
total time:  5.709446717984974
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.57
[I 2023-06-12 00:44:42,882] Trial 299 finished with value: 80.93333435058594 and parameters: {'Fwd': 6.1526810873351905e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.8593146550980073, 'loop': 1, 'loss': 'CE', 'lr': 0.00253668245658911, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001662113194959792, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.004095073680968531
weight_decay:  0.00010186418706764135
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.715483329957351
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  2.008836707100272
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  2.2208676158916205
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.976490020751953
total time:  6.991522000171244
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 80.50 ± 0.62
[I 2023-06-12 00:44:50,360] Trial 300 finished with value: 79.5999984741211 and parameters: {'Fwd': 1.045054829724538e-05, 'K': 8, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 4.138162249707983, 'loop': 1, 'loss': 'MSE', 'lr': 0.004095073680968531, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010186418706764135, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005102882169794758
weight_decay:  7.78338520065755e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9707053999882191
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.074972649803385
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.9536344250664115
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 6.027159214019775
total time:  6.044391417177394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.45
[I 2023-06-12 00:44:56,875] Trial 301 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.035940956635909384, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.6405219695576263, 'loop': 1, 'loss': 'CE', 'lr': 0.005102882169794758, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.78338520065755e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004681472488860679
weight_decay:  0.0001292146325300998
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0587841260712594
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.1077001010999084
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.5996834309771657
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.793262004852295
total time:  5.80802632891573
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.76
[I 2023-06-12 00:45:03,176] Trial 302 finished with value: 81.0 and parameters: {'Fwd': 4.124108722997894e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.289619178573625, 'loop': 1, 'loss': 'CE', 'lr': 0.004681472488860679, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001292146325300998, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0038622602136488527
weight_decay:  0.005131145048738548
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2491686230059713
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 99.29
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.0034894968848675
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.9230127660557628
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 99.29
   Final Test: 80.80
run time now: 6.207693576812744
total time:  6.22610413399525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 99.29 ± 0.00
   Final Test: 81.63 ± 0.76
[I 2023-06-12 00:45:09,960] Trial 303 finished with value: 81.5999984741211 and parameters: {'Fwd': 7.763310204933787e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 1.4954899470584169, 'loop': 1, 'loss': 'CE', 'lr': 0.0038622602136488527, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.005131145048738548, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004210585172115282
weight_decay:  0.00021042637631005077
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3425344401039183
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.9569448621477932
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.9028376031201333
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.232003211975098
total time:  6.251253579044715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.78
[I 2023-06-12 00:45:16,736] Trial 304 finished with value: 80.93334197998047 and parameters: {'Fwd': 3.306707628503117e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.9012014992231143, 'loop': 1, 'loss': 'CE', 'lr': 0.004210585172115282, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021042637631005077, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005395848409508425
weight_decay:  0.00016900949724116498
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.365721947979182
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.300724101951346
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6960786511190236
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.406167268753052
total time:  6.426163369091228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.49
[I 2023-06-12 00:45:23,806] Trial 305 finished with value: 81.46666717529297 and parameters: {'Fwd': 4.790340948716046e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 4.203701416908766, 'loop': 1, 'loss': 'CE', 'lr': 0.005395848409508425, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016900949724116498, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0020256508941718285
weight_decay:  6.50875696744263e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4272753871046007
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.7522059709299356
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  2.04183531482704
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.246960163116455
total time:  6.260351798031479
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 0.67
[I 2023-06-12 00:45:30,545] Trial 306 finished with value: 80.66666412353516 and parameters: {'Fwd': 5.879536779975083e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 2.6379322752806464, 'loop': 1, 'loss': 'CE', 'lr': 0.0020256508941718285, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.50875696744263e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.004707792571284588
weight_decay:  1.8187750167425051e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.175744857173413
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.8791606731247157
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.1728708951268345
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.257158041000366
total time:  6.27626054501161
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.55
[I 2023-06-12 00:45:37,281] Trial 307 finished with value: 81.66666412353516 and parameters: {'Fwd': 1.052395629311225e-05, 'K': 8, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.5274409775861044, 'loop': 1, 'loss': 'CE', 'lr': 0.004707792571284588, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8187750167425051e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004287684220630362
weight_decay:  9.898283056411485e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.742300204001367
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.8719007829204202
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.2223665239289403
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.866455793380737
total time:  5.886883004102856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.67
[I 2023-06-12 00:45:43,702] Trial 308 finished with value: 81.9333267211914 and parameters: {'Fwd': 7.961734412435687e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.777934241325685, 'loop': 1, 'loss': 'CE', 'lr': 0.004287684220630362, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.898283056411485e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.0037101190491121484
weight_decay:  0.0004582058255435356
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9414636511355639
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.845899268053472
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.0804557469673455
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.889887809753418
total time:  5.904036934953183
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.35
[I 2023-06-12 00:45:50,136] Trial 309 finished with value: 80.73333740234375 and parameters: {'Fwd': 1.4504385835476311e-05, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.025859757663913, 'loop': 1, 'loss': 'CE', 'lr': 0.0037101190491121484, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004582058255435356, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004911528319926795
weight_decay:  0.0002830322120632083
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2490509680937976
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  2.2061707840766758
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  2.4771754890680313
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 99.29
   Final Test: 79.80
run time now: 6.9606852531433105
total time:  6.974471925990656
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.64
  Final Train: 99.76 ± 0.41
   Final Test: 80.40 ± 0.72
[I 2023-06-12 00:45:57,620] Trial 310 finished with value: 80.86666870117188 and parameters: {'Fwd': 6.6105349967397155e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.29746357547774, 'loop': 2, 'loss': 'CE', 'lr': 0.004911528319926795, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002830322120632083, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0032002459934570436
weight_decay:  0.00012712265141592169
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.451764508150518
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02
None time:  1.4101269890088588
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.5523410078603774
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.80
run time now: 4.45557427406311
total time:  4.503221440128982
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 80.57 ± 0.75
[I 2023-06-12 00:46:02,773] Trial 311 finished with value: 79.79999542236328 and parameters: {'Fwd': 7.791325355600891e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 2.7445243856161237, 'loop': 1, 'loss': 'CE', 'lr': 0.0032002459934570436, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012712265141592169, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.006128301633477697
weight_decay:  0.00015405685954375975
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4117716609034687
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 98.57
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.173020396148786
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 99.29
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.3034938019700348
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 3.916706085205078
total time:  3.9320377111434937
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.53 ± 0.50
  Final Train: 99.29 ± 0.71
   Final Test: 78.43 ± 0.71
[I 2023-06-12 00:46:07,182] Trial 312 finished with value: 77.53333282470703 and parameters: {'Fwd': 4.495654311669777e-06, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.096440958120386, 'loop': 1, 'loss': 'CE', 'lr': 0.006128301633477697, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015405685954375975, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.1
lr:  0.00809072983592289
weight_decay:  1.0350235731529344e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1961982960347086
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 99.29
   Final Test: 80.50
Split: 01, Run: 02
None time:  2.252397747943178
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.102033474948257
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.10
run time now: 6.572284698486328
total time:  6.586105759022757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 99.76 ± 0.41
   Final Test: 80.40 ± 0.26
[I 2023-06-12 00:46:14,305] Trial 313 finished with value: 81.0 and parameters: {'Fwd': 1.9886882840422806e-05, 'K': 3, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 1.6706916519312778, 'loop': 1, 'loss': 'CE', 'lr': 0.00809072983592289, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0350235731529344e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0043877662733677065
weight_decay:  0.0001171783679863311
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0714177479967475
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.0727046590764076
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.9961434740107507
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.164804458618164
total time:  6.177293285960332
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.42
[I 2023-06-12 00:46:21,008] Trial 314 finished with value: 82.0 and parameters: {'Fwd': 2.9020195070741685e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.373215207760812, 'loop': 1, 'loss': 'CE', 'lr': 0.0043877662733677065, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001171783679863311, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.002214718284219322
weight_decay:  0.00022373807139921306
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6274210270494223
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 99.29
   Final Test: 81.10
Split: 01, Run: 02
None time:  1.8237125878222287
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 98.57
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.580978370970115
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 99.29
   Final Test: 80.70
run time now: 5.063219308853149
total time:  5.135129363974556
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.60
  Final Train: 99.05 ± 0.41
   Final Test: 80.67 ± 0.45
[I 2023-06-12 00:46:26,702] Trial 315 finished with value: 80.0 and parameters: {'Fwd': 2.8713079842361414e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 0.8378341783793184, 'loop': 0, 'loss': 'CE', 'lr': 0.002214718284219322, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00022373807139921306, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.005488306160925549
weight_decay:  8.663065673426146e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9776191550772637
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.1580372268799692
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.6143587010446936
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.770886659622192
total time:  5.78380329394713
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.78
[I 2023-06-12 00:46:32,988] Trial 316 finished with value: 81.46666717529297 and parameters: {'Fwd': 8.319893487041175e-06, 'K': 8, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.295896041504095, 'loop': 1, 'loss': 'CE', 'lr': 0.005488306160925549, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.663065673426146e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.003932952534724603
weight_decay:  0.00018172954473445253
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2288331710733473
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.141376679064706
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.5300411737989634
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.928210258483887
total time:  5.9481614760588855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.50
[I 2023-06-12 00:46:39,418] Trial 317 finished with value: 81.33333587646484 and parameters: {'Fwd': 5.694756178256065e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 6.374471394908877, 'loop': 1, 'loss': 'CE', 'lr': 0.003932952534724603, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00018172954473445253, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.003569670974330228
weight_decay:  0.00033122930694988407
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1927689800504595
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.966320201056078
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.1625400779303163
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.351208925247192
total time:  6.365305030951276
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.46
[I 2023-06-12 00:46:46,290] Trial 318 finished with value: 81.46666717529297 and parameters: {'Fwd': 1.1332583038729332e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.796587515229418, 'loop': 1, 'loss': 'CE', 'lr': 0.003569670974330228, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00033122930694988407, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.008932719828956269
weight_decay:  4.942236332555999e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.85145487007685
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  2.110852555837482
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.2188922138884664
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.00
run time now: 6.2099385261535645
total time:  6.235612046904862
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.93 ± 0.95
[I 2023-06-12 00:46:53,006] Trial 319 finished with value: 80.73332977294922 and parameters: {'Fwd': 3.986353681048452e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 3.58452546278284, 'loop': 1, 'loss': 'CE', 'lr': 0.008932719828956269, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.942236332555999e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004969271802005969
weight_decay:  2.6142683060053017e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2293817489407957
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  2.275417765136808
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  2.0576810820493847
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.00
run time now: 6.5868847370147705
total time:  6.598421101924032
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 1.04
[I 2023-06-12 00:47:00,192] Trial 320 finished with value: 78.9333267211914 and parameters: {'Fwd': 3.526960061269938e-05, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.044366003631353, 'loop': 1, 'loss': 'MSE', 'lr': 0.004969271802005969, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6142683060053017e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0045406924884873094
weight_decay:  0.0848696515171133
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9850103210192174
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.3229081330355257
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.10592773091048
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.440573215484619
total time:  6.453116688178852
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.46
[I 2023-06-12 00:47:07,185] Trial 321 finished with value: 82.0 and parameters: {'Fwd': 5.07073344668693e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.86451889172132, 'loop': 1, 'loss': 'CE', 'lr': 0.0045406924884873094, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0848696515171133, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.004174397755740929
weight_decay:  0.00013746299165643186
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3285498570185155
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.2982444858644158
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.912459708051756
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.580338478088379
total time:  6.600207913899794
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.50
[I 2023-06-12 00:47:14,466] Trial 322 finished with value: 81.66666412353516 and parameters: {'Fwd': 5.145347519084932e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.2725099010812926, 'loop': 1, 'loss': 'CE', 'lr': 0.004174397755740929, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013746299165643186, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005237992822397361
weight_decay:  9.64553782565453e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.070835951017216
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.9823173461481929
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.7240739781409502
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.807397127151489
total time:  5.82640862907283
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.61
[I 2023-06-12 00:47:20,894] Trial 323 finished with value: 81.06666564941406 and parameters: {'Fwd': 9.318470530571306e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.717755666335565, 'loop': 1, 'loss': 'CE', 'lr': 0.005237992822397361, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.64553782565453e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004579763348933993
weight_decay:  0.0002398597530290817
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9722445481456816
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.0668074812274426
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.9945922479964793
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.061940908432007
total time:  6.079925694968551
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.36
[I 2023-06-12 00:47:27,457] Trial 324 finished with value: 81.73333740234375 and parameters: {'Fwd': 6.6007187308128045e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 3.9075130853072935, 'loop': 1, 'loss': 'CE', 'lr': 0.004579763348933993, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002398597530290817, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0039215887101655845
weight_decay:  7.001394643485708e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8987731721717864
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.080155969131738
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.1087660151533782
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.113775014877319
total time:  6.128104639006779
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.50
[I 2023-06-12 00:47:34,061] Trial 325 finished with value: 81.4000015258789 and parameters: {'Fwd': 1.3395438628488761e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 1.924744789541452, 'loop': 1, 'loss': 'CE', 'lr': 0.0039215887101655845, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.001394643485708e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0033470769724863155
weight_decay:  0.00011365346229795627
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.325003266101703
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6861885169055313
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.3392994010355324
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.380551338195801
total time:  6.400186174083501
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.46
[I 2023-06-12 00:47:40,938] Trial 326 finished with value: 81.13333129882812 and parameters: {'Fwd': 3.3943793047133186e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.025064020900283, 'loop': 1, 'loss': 'CE', 'lr': 0.0033470769724863155, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011365346229795627, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.002982845860385478
weight_decay:  0.0005629710601760684
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7911564349196851
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.1112749280873686
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.1839812491089106
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.1137120723724365
total time:  6.127154061105102
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.36
[I 2023-06-12 00:47:47,643] Trial 327 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.003488223083309692, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.512861650589151, 'loop': 1, 'loss': 'CE', 'lr': 0.002982845860385478, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005629710601760684, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.005821662533422023
weight_decay:  0.00015375022644233637
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7996107980143279
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  2.169072057818994
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.9925284630153328
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.986485004425049
total time:  6.005807152017951
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.35
[I 2023-06-12 00:47:54,227] Trial 328 finished with value: 81.66666412353516 and parameters: {'Fwd': 7.505646145770557e-06, 'K': 8, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 7.510420588459583, 'loop': 1, 'loss': 'CE', 'lr': 0.005821662533422023, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015375022644233637, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004768940016704334
weight_decay:  0.00018948831413336968
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0905345601495355
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9410364888608456
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 99.29
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.1781252678483725
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 99.29
   Final Test: 80.90
run time now: 6.237712860107422
total time:  6.251727350987494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 99.29 ± 0.00
   Final Test: 81.47 ± 0.55
[I 2023-06-12 00:48:00,943] Trial 329 finished with value: 81.66666412353516 and parameters: {'Fwd': 5.0307555096969205e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 1.0114755233177206, 'loop': 1, 'loss': 'CE', 'lr': 0.004768940016704334, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018948831413336968, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0017847482945261665
weight_decay:  0.0001141010100339557
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4550029928795993
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.6500657328870147
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.7074491658713669
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.20
run time now: 4.840697765350342
total time:  4.858484925003722
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 79.67 ± 0.84
[I 2023-06-12 00:48:06,254] Trial 330 finished with value: 79.13333129882812 and parameters: {'Fwd': 1.6208788531295186e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 2.4034589807560343, 'loop': 1, 'loss': 'CE', 'lr': 0.0017847482945261665, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001141010100339557, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.006724903089075649
weight_decay:  8.048940000341316e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1982304118573666
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7758751621004194
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  2.1416606940329075
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 6.141762018203735
total time:  6.157787438016385
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.75
[I 2023-06-12 00:48:12,937] Trial 331 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.00011824189487311941, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.21853146904907, 'loop': 1, 'loss': 'CE', 'lr': 0.006724903089075649, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.048940000341316e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.004283970281140541
weight_decay:  0.00014535021880601693
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9277990949340165
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02
None time:  1.5902015520259738
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.3526749599259347
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.897688865661621
total time:  4.912492986069992
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 0.31
[I 2023-06-12 00:48:18,446] Trial 332 finished with value: 80.73333740234375 and parameters: {'Fwd': 3.8714518630703136e-06, 'K': 10, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 3.6701456564697716, 'loop': 1, 'loss': 'CE', 'lr': 0.004283970281140541, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014535021880601693, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0051147462898505445
weight_decay:  5.787769938908516e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.290794714121148
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.2889871539082378
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.9302635728381574
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.541335105895996
total time:  3.556410585064441
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.00
[I 2023-06-12 00:48:22,600] Trial 333 finished with value: 68.80000305175781 and parameters: {'Fwd': 9.892478221961701e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.005130094944469, 'loop': 1, 'loss': 'CE', 'lr': 0.0051147462898505445, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.787769938908516e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.0037417257277887195
weight_decay:  0.00027663262131144805
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0677818299736828
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.043901107972488
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.805697362869978
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 5.946141719818115
total time:  5.962289047893137
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.17
[I 2023-06-12 00:48:29,128] Trial 334 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.00017248059038570785, 'K': 8, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.3996811740540354, 'loop': 1, 'loss': 'CE', 'lr': 0.0037417257277887195, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00027663262131144805, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004056783873830689
weight_decay:  0.00019585170377025052
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3296153389383107
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.3336095160339028
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.8860067860223353
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.574635028839111
total time:  6.590099983848631
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.79
[I 2023-06-12 00:48:36,296] Trial 335 finished with value: 80.93334197998047 and parameters: {'Fwd': 6.245120597331364e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.7739089804083816, 'loop': 1, 'loss': 'CE', 'lr': 0.004056783873830689, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00019585170377025052, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004549035681560929
weight_decay:  0.00010201519265922639
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.15318492683582
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  2.1049819241743535
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 03
None time:  2.0128048309125006
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.50
run time now: 6.2983598709106445
total time:  6.3116042371839285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 82.07 ± 0.55
[I 2023-06-12 00:48:43,121] Trial 336 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.0002939894396172637, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.2106142828828936, 'loop': 1, 'loss': 'CE', 'lr': 0.004549035681560929, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010201519265922639, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.005620276765046664
weight_decay:  0.0001381469238087717
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9418399690184742
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  2.178603939944878
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.214067972963676
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.3600172996521
total time:  6.37846646993421
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.45
[I 2023-06-12 00:48:50,022] Trial 337 finished with value: 81.66666412353516 and parameters: {'Fwd': 2.908701498702609e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.341636053179985, 'loop': 1, 'loss': 'CE', 'lr': 0.005620276765046664, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001381469238087717, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004894741652734828
weight_decay:  0.0003714277807715491
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9322292059659958
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9823586239945143
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.1682549309916794
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.108634948730469
total time:  6.128297894960269
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.50
[I 2023-06-12 00:48:56,692] Trial 338 finished with value: 81.73332977294922 and parameters: {'Fwd': 8.017092995197236e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.150219635262331, 'loop': 1, 'loss': 'CE', 'lr': 0.004894741652734828, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003714277807715491, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0035712016459094344
weight_decay:  3.9880397254937344e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2242567690555006
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.037855579983443
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.9173662341199815
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.225866794586182
total time:  6.2438590889796615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.66
[I 2023-06-12 00:49:03,525] Trial 339 finished with value: 81.33333587646484 and parameters: {'Fwd': 4.710608405762571e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 9.883296655006585, 'loop': 1, 'loss': 'CE', 'lr': 0.0035712016459094344, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.9880397254937344e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004232499894480556
weight_decay:  0.00017333300751805951
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2032161159440875
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02
None time:  2.2715674419887364
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  2.1576654731761664
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.50
run time now: 6.663228273391724
total time:  6.676802264060825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 0.20
[I 2023-06-12 00:49:10,765] Trial 340 finished with value: 79.26666259765625 and parameters: {'Fwd': 1.0688508136811755e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.471210077887666, 'loop': 1, 'loss': 'MSE', 'lr': 0.004232499894480556, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017333300751805951, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.0012617145839429727
weight_decay:  7.283568127339375e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.226096573052928
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 02
None time:  2.564459891989827
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  2.0975129690486938
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.918395757675171
total time:  6.937292193993926
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 79.87 ± 1.01
[I 2023-06-12 00:49:18,224] Trial 341 finished with value: 79.73332977294922 and parameters: {'Fwd': 1.2711007422596775e-05, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.9125211277759755, 'loop': 1, 'loss': 'CE', 'lr': 0.0012617145839429727, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.283568127339375e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.15000000000000002
lr:  0.0008797703836793992
weight_decay:  9.679206403021949e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0579122949857265
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  2.2319074070546776
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.10
Split: 01, Run: 03
None time:  1.9692629028577358
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.2942469120025635
total time:  6.31425982597284
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.40 ± 3.47
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 3.49
[I 2023-06-12 00:49:25,131] Trial 342 finished with value: 77.4000015258789 and parameters: {'Fwd': 6.48423725228856e-06, 'K': 7, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.1376939785256965, 'loop': 1, 'loss': 'CE', 'lr': 0.0008797703836793992, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.679206403021949e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004526792548442794
weight_decay:  0.00012022347267951412
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.907184542156756
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.1735941430088133
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.9491883718874305
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.069327116012573
total time:  6.0931260720826685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:49:31,816] Trial 343 finished with value: 82.0 and parameters: {'Fwd': 2.0870458486876e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.503372611590995, 'loop': 1, 'loss': 'CE', 'lr': 0.004526792548442794, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012022347267951412, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.001954048175116122
weight_decay:  0.0002188458691097026
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0013461059425026
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.9971991360653192
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.2054383610375226
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.23045539855957
total time:  6.250797382090241
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.61
[I 2023-06-12 00:49:38,549] Trial 344 finished with value: 80.46666717529297 and parameters: {'Fwd': 9.315470641636098e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 6.902865963961311, 'loop': 1, 'loss': 'CE', 'lr': 0.001954048175116122, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002188458691097026, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0016864188661829358
weight_decay:  0.00015518257167657234
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8306868190411478
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 02
None time:  1.9503969338256866
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  2.049635913223028
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.70
run time now: 5.859753608703613
total time:  5.890917513985187
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 0.47
[I 2023-06-12 00:49:44,996] Trial 345 finished with value: 79.46666717529297 and parameters: {'Fwd': 2.2509980116227664e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 8.463748400598764, 'loop': 1, 'loss': 'CE', 'lr': 0.0016864188661829358, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015518257167657234, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0014408055945235938
weight_decay:  0.0002669825463924723
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.995296877110377
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02
None time:  2.5176726470235735
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  2.41383044491522
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.40
run time now: 6.948342323303223
total time:  6.961644814815372
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 80.13 ± 1.02
[I 2023-06-12 00:49:52,479] Trial 346 finished with value: 80.06665802001953 and parameters: {'Fwd': 3.7250427372917654e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.644045806870899, 'loop': 1, 'loss': 'CE', 'lr': 0.0014408055945235938, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002669825463924723, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005219412746202562
weight_decay:  0.0007687026156804938
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.057560937013477
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.3044917499646544
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.089305530069396
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.4819934368133545
total time:  6.4963695800397545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.49
[I 2023-06-12 00:49:59,553] Trial 347 finished with value: 81.53333282470703 and parameters: {'Fwd': 5.60071000716577e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.852051057502235, 'loop': 1, 'loss': 'CE', 'lr': 0.005219412746202562, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0007687026156804938, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.002689803303117813
weight_decay:  8.672518606490156e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9082019820343703
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 99.29
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.2590455759782344
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.9449773218948394
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.20
run time now: 6.1415770053863525
total time:  6.161874159006402
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.35
  Final Train: 99.29 ± 0.00
   Final Test: 81.30 ± 0.36
[I 2023-06-12 00:50:06,266] Trial 348 finished with value: 81.20000457763672 and parameters: {'Fwd': 7.382599685601584e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.5993588331919657, 'loop': 1, 'loss': 'CE', 'lr': 0.002689803303117813, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.672518606490156e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.002378225457931781
weight_decay:  0.00012475128707416624
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.02634997991845
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.1647821839433163
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.230653460836038
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.450727701187134
total time:  6.4676386618521065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.71
[I 2023-06-12 00:50:13,239] Trial 349 finished with value: 80.86666870117188 and parameters: {'Fwd': 4.762279784182317e-06, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.385984318432356, 'loop': 1, 'loss': 'CE', 'lr': 0.002378225457931781, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012475128707416624, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.003839248529494939
weight_decay:  4.165419881063512e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8741940180771053
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.2131105549633503
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.9933711460325867
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.101430177688599
total time:  6.115270424168557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.75
[I 2023-06-12 00:50:19,889] Trial 350 finished with value: 81.5999984741211 and parameters: {'Fwd': 1.1645562879747486e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.028210628048453, 'loop': 1, 'loss': 'CE', 'lr': 0.003839248529494939, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.165419881063512e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.00415102998649997
weight_decay:  0.00018333743123069308
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8098626320715994
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  2.0602890900336206
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.819397192914039
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.71594762802124
total time:  5.741326035931706
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.35
[I 2023-06-12 00:50:26,258] Trial 351 finished with value: 81.06666564941406 and parameters: {'Fwd': 3.0272008924288043e-06, 'K': 9, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.4058379010376356, 'loop': 1, 'loss': 'CE', 'lr': 0.00415102998649997, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018333743123069308, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.00480435438867662
weight_decay:  2.20788597096472e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.33084860118106
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.3575253139715642
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  1.4089315379969776
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 4.1247875690460205
total time:  4.138070336077362
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.60 ± 1.61
[I 2023-06-12 00:50:30,868] Trial 352 finished with value: 71.79999542236328 and parameters: {'Fwd': 1.6505959491611104e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.134164315563776, 'loop': 1, 'loss': 'CE', 'lr': 0.00480435438867662, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.20788597096472e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0033731043864958293
weight_decay:  0.0001453299181805904
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9493709050584584
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.0331947901286185
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.2295660900417715
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.243224859237671
total time:  6.261649295920506
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.25
[I 2023-06-12 00:50:37,594] Trial 353 finished with value: 81.26667022705078 and parameters: {'Fwd': 9.014621023890353e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.7364697225765786, 'loop': 1, 'loss': 'CE', 'lr': 0.0033731043864958293, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001453299181805904, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004272880278271844
weight_decay:  0.00010406503851811368
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6159607598092407
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.194881852949038
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.244245450012386
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.081998109817505
total time:  6.10273068305105
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.47
[I 2023-06-12 00:50:44,186] Trial 354 finished with value: 81.46666717529297 and parameters: {'Fwd': 7.965765872850889e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 4.177298611545837, 'loop': 1, 'loss': 'CE', 'lr': 0.004272880278271844, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010406503851811368, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.006082284437661201
weight_decay:  6.028814490150121e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9373534189071506
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.041798129910603
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.0517028050962836
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.1242876052856445
total time:  6.143125368980691
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.38
[I 2023-06-12 00:50:50,958] Trial 355 finished with value: 81.66666412353516 and parameters: {'Fwd': 4.4905403085416944e-05, 'K': 10, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 1.7447871826748114, 'loop': 1, 'loss': 'CE', 'lr': 0.006082284437661201, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.028814490150121e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0052663523913420605
weight_decay:  1.5773910913999053e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3300848710350692
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.0768240878824145
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.1661540139466524
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.600743293762207
total time:  6.616065114969388
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.35
[I 2023-06-12 00:50:58,129] Trial 356 finished with value: 80.5999984741211 and parameters: {'Fwd': 6.07511614373687e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 3.4912379616674025, 'loop': 1, 'loss': 'CE', 'lr': 0.0052663523913420605, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5773910913999053e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0037449651686360576
weight_decay:  4.40431281078525e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0128777788486332
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  0.9966639159247279
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  0.9070731750689447
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
run time now: 2.9455134868621826
total time:  2.964153442066163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 2.16
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 1.90
[I 2023-06-12 00:51:01,593] Trial 357 finished with value: 78.20000457763672 and parameters: {'Fwd': 1.7526571988954698e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 3.9022597453607064, 'loop': 1, 'loss': 'CE', 'lr': 0.0037449651686360576, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.40431281078525e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004689190618724117
weight_decay:  7.804623809535218e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.987115205032751
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  1.9958318741992116
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.675118433078751
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.70
run time now: 6.688351631164551
total time:  6.706769631942734
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 80.33 ± 0.55
[I 2023-06-12 00:51:08,807] Trial 358 finished with value: 79.86666870117188 and parameters: {'Fwd': 3.873168428931056e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 2.8724615911957523, 'loop': 1, 'loss': 'MSE', 'lr': 0.004689190618724117, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.804623809535218e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.0010540362431295345
weight_decay:  3.4327798202740576e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.984695444116369
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 02
None time:  2.331968357786536
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  2.409584883134812
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.752303600311279
total time:  6.7666624849662185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 0.23
[I 2023-06-12 00:51:16,105] Trial 359 finished with value: 79.9333267211914 and parameters: {'Fwd': 2.4822840865868583e-05, 'K': 10, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.6299376085935697, 'loop': 1, 'loss': 'CE', 'lr': 0.0010540362431295345, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.4327798202740576e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.0016270013777549598
weight_decay:  0.00021623669264366434
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9148839579429477
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 02
None time:  2.1423313240520656
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  2.1706397489178926
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.255596876144409
total time:  6.274013255955651
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 80.43 ± 0.15
[I 2023-06-12 00:51:22,848] Trial 360 finished with value: 79.9333267211914 and parameters: {'Fwd': 1.3519654137851927e-06, 'K': 8, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.315422500789603, 'loop': 1, 'loss': 'CE', 'lr': 0.0016270013777549598, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021623669264366434, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.007366301463059124
weight_decay:  0.00012457873014442027
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.567980238934979
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02
None time:  3.2145393409300596
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03
None time:  3.1995461331680417
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
run time now: 9.010758876800537
total time:  9.023932915180922
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 73.20 ± 0.00
[I 2023-06-12 00:51:32,354] Trial 361 finished with value: 72.5999984741211 and parameters: {'Fwd': 3.354439581937876e-05, 'K': 9, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 4.0634360418343, 'loop': 1, 'loss': 'CE', 'lr': 0.007366301463059124, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012457873014442027, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004046554902063751
weight_decay:  0.00017111544610404376
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1910742791369557
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.3789549032226205
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.138428743928671
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.73987340927124
total time:  6.760849365033209
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.79
[I 2023-06-12 00:51:39,613] Trial 362 finished with value: 80.93334197998047 and parameters: {'Fwd': 4.666509988901325e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.781424305330843, 'loop': 1, 'loss': 'CE', 'lr': 0.004046554902063751, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017111544610404376, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004431556204127901
weight_decay:  0.00027407955348594744
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.011168352793902
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6166364760138094
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.091892051976174
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.744438409805298
total time:  5.756778219947591
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.65
[I 2023-06-12 00:51:45,870] Trial 363 finished with value: 81.13333129882812 and parameters: {'Fwd': 7.282609037556557e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 4.358254142052283, 'loop': 1, 'loss': 'CE', 'lr': 0.004431556204127901, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00027407955348594744, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005473263868658583
weight_decay:  9.486664769293688e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.005335367983207
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9229309021029621
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.2760237772017717
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.234561443328857
total time:  6.254570716992021
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.62
[I 2023-06-12 00:51:52,636] Trial 364 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.00044821558994890555, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.5803916482836464, 'loop': 1, 'loss': 'CE', 'lr': 0.005473263868658583, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.486664769293688e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004785264123103773
weight_decay:  0.00014238521192232886
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9632647491525859
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.9102948040235788
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.143310772953555
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.044543743133545
total time:  6.059353124117479
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.36
[I 2023-06-12 00:51:59,206] Trial 365 finished with value: 81.79999542236328 and parameters: {'Fwd': 9.844874422277451e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 2.1171150252684914, 'loop': 1, 'loss': 'CE', 'lr': 0.004785264123103773, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014238521192232886, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0036113057423892993
weight_decay:  0.00011556000017641555
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0333403451368213
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 97.86
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.9738890221342444
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 97.86
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.1409125339705497
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 97.86
   Final Test: 81.20
run time now: 6.17409348487854
total time:  6.188766136998311
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.12
  Final Train: 97.86 ± 0.00
   Final Test: 81.47 ± 0.23
[I 2023-06-12 00:52:05,896] Trial 366 finished with value: 81.26667022705078 and parameters: {'Fwd': 5.709412852151382e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 0.11143778342702726, 'loop': 1, 'loss': 'CE', 'lr': 0.0036113057423892993, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011556000017641555, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.003145337379624067
weight_decay:  3.159979272510053e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0049839369021356
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.254937883000821
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.026932548964396
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.314121246337891
total time:  6.326325216097757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.40
[I 2023-06-12 00:52:12,696] Trial 367 finished with value: 81.26667022705078 and parameters: {'Fwd': 2.4072868004368193e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.1229110295946683, 'loop': 1, 'loss': 'CE', 'lr': 0.003145337379624067, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.159979272510053e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004042849510033415
weight_decay:  0.00021397308913988051
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2687339591793716
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02
None time:  2.162859743926674
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.5506053608842194
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 7.009894132614136
total time:  7.024924706900492
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 80.87 ± 0.51
[I 2023-06-12 00:52:20,234] Trial 368 finished with value: 80.66666412353516 and parameters: {'Fwd': 8.369313999195188e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 7.81604806917846, 'loop': 2, 'loss': 'CE', 'lr': 0.004042849510033415, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021397308913988051, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004430649739867911
weight_decay:  0.00033721300925329805
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2451663848478347
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.9801135528832674
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.51248149597086
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 99.29
   Final Test: 80.30
run time now: 6.764253616333008
total time:  6.78254547691904
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 99.76 ± 0.41
   Final Test: 81.27 ± 0.84
[I 2023-06-12 00:52:27,511] Trial 369 finished with value: 80.73333740234375 and parameters: {'Fwd': 1.3305329399681111e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 2.7280191335141217, 'loop': 1, 'loss': 'CE', 'lr': 0.004430649739867911, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00033721300925329805, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.00660889226962615
weight_decay:  6.796526960678865e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.253423613961786
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0486098958645016
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0429419598076493
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.376343250274658
total time:  3.396857731975615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.00
[I 2023-06-12 00:52:31,421] Trial 370 finished with value: 68.5999984741211 and parameters: {'Fwd': 3.6059407391570405e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.9131426923553407, 'loop': 1, 'loss': 'CE', 'lr': 0.00660889226962615, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.796526960678865e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.009189045950459981
weight_decay:  0.0017830091098109343
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.310342923970893
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  2.1882174930069596
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.9438642119057477
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.10
run time now: 6.472474575042725
total time:  6.494209771975875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 80.27 ± 1.01
[I 2023-06-12 00:52:38,389] Trial 371 finished with value: 80.73332977294922 and parameters: {'Fwd': 4.561391650997834e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.147144693435362, 'loop': 1, 'loss': 'CE', 'lr': 0.009189045950459981, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0017830091098109343, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.005047952391697902
weight_decay:  0.00016260349706474742
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.17814424703829
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.9209124520421028
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  2.0338301837909967
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.15876841545105
total time:  6.173434665892273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.69
[I 2023-06-12 00:52:45,159] Trial 372 finished with value: 81.53333282470703 and parameters: {'Fwd': 7.092912892783591e-06, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.4300218376736944, 'loop': 1, 'loss': 'CE', 'lr': 0.005047952391697902, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016260349706474742, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.003876308246654387
weight_decay:  9.55523027366974e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2685417979955673
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.5993717059027404
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.2534256901126355
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
run time now: 6.147928476333618
total time:  6.163269951939583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.47
[I 2023-06-12 00:52:51,963] Trial 373 finished with value: 81.20000457763672 and parameters: {'Fwd': 6.007708715485628e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.7590505546068584, 'loop': 1, 'loss': 'CE', 'lr': 0.003876308246654387, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.55523027366974e-05, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004905361667534318
weight_decay:  0.00012915499524297793
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9330490108113736
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9094208218157291
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.7786202589049935
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 5.649499893188477
total time:  5.668552531860769
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.55
[I 2023-06-12 00:52:58,154] Trial 374 finished with value: 80.93333435058594 and parameters: {'Fwd': 1.1201116524950576e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 4.471911593924719, 'loop': 1, 'loss': 'CE', 'lr': 0.004905361667534318, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00012915499524297793, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.001975572108932297
weight_decay:  0.00019341234061246327
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0109048769809306
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 97.86
   Final Test: 81.40
Split: 01, Run: 02
None time:  2.255494642071426
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.57
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.5351200618315488
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 97.86
   Final Test: 80.70
run time now: 5.829593181610107
total time:  5.848534421995282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.31
  Final Train: 98.10 ± 0.41
   Final Test: 80.90 ± 0.44
[I 2023-06-12 00:53:04,577] Trial 375 finished with value: 80.46666717529297 and parameters: {'Fwd': 3.1867379126542527e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 0.45349849084085747, 'loop': 1, 'loss': 'CE', 'lr': 0.001975572108932297, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00019341234061246327, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005772982952814671
weight_decay:  7.903893956556524e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1882297131232917
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.2026701827999204
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.5245767561718822
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.946942329406738
total time:  5.964601771906018
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.93
[I 2023-06-12 00:53:11,051] Trial 376 finished with value: 81.5999984741211 and parameters: {'Fwd': 1.666586755285856e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.009064570865815, 'loop': 1, 'loss': 'CE', 'lr': 0.005772982952814671, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.903893956556524e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.009550467595748159
weight_decay:  5.24533723255027e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2753206870984286
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  2.0847891450393945
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.182523796102032
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 99.29
   Final Test: 79.00
run time now: 6.571873188018799
total time:  6.59167644707486
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.61
  Final Train: 99.76 ± 0.41
   Final Test: 80.47 ± 1.31
[I 2023-06-12 00:53:18,147] Trial 377 finished with value: 80.86666107177734 and parameters: {'Fwd': 5.136017217796821e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 2.9897481765228897, 'loop': 1, 'loss': 'CE', 'lr': 0.009550467595748159, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.24533723255027e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.007728794951967414
weight_decay:  0.0001136631016907326
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7497811638750136
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  3.669709203997627
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  1.7621340220794082
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 7.205780506134033
total time:  7.222429669927806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 77.70 ± 0.72
[I 2023-06-12 00:53:25,975] Trial 378 finished with value: 78.66666412353516 and parameters: {'Fwd': 8.075467917434091e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 0.96840503176408, 'loop': 1, 'loss': 'MSE', 'lr': 0.007728794951967414, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001136631016907326, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.004438399538735469
weight_decay:  0.013001386504534312
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.035954968072474
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7826576009392738
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  2.2674016039818525
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.110133647918701
total time:  6.122600367991254
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.90
[I 2023-06-12 00:53:32,678] Trial 379 finished with value: 80.73333740234375 and parameters: {'Fwd': 5.223568312789315e-05, 'K': 8, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 7.126200940510985, 'loop': 1, 'loss': 'CE', 'lr': 0.004438399538735469, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013001386504534312, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.003431518460892404
weight_decay:  0.00015509079987922983
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3304118800442666
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.297441069036722
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.851466075051576
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.505757808685303
total time:  6.518837214913219
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.31
[I 2023-06-12 00:53:39,860] Trial 380 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.0001070473496929393, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.599925023115523, 'loop': 1, 'loss': 'CE', 'lr': 0.003431518460892404, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015509079987922983, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.004090669979253491
weight_decay:  0.00024889865707741884
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.101361735025421
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.1683141868561506
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.6993402391672134
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.80
run time now: 5.988813161849976
total time:  6.002016872167587
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.40
[I 2023-06-12 00:53:46,468] Trial 381 finished with value: 81.0666732788086 and parameters: {'Fwd': 4.171491221367796e-06, 'K': 6, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.2897085252941816, 'loop': 1, 'loss': 'CE', 'lr': 0.004090669979253491, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00024889865707741884, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.005282005916207792
weight_decay:  0.0004451442170260723
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.411515037994832
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.3866856780368835
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.7531923931092024
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.80
run time now: 6.578307390213013
total time:  6.594467733986676
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 80.87 ± 1.01
[I 2023-06-12 00:53:53,663] Trial 382 finished with value: 80.79999542236328 and parameters: {'Fwd': 2.0586867479341246e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 4.246479314401194, 'loop': 1, 'loss': 'CE', 'lr': 0.005282005916207792, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004451442170260723, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.004677730304711696
weight_decay:  9.653487490404612e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3208888869266957
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.020595721900463
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.9687335821799934
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.338895797729492
total time:  6.352474004030228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.42
[I 2023-06-12 00:54:00,481] Trial 383 finished with value: 81.93333435058594 and parameters: {'Fwd': 1.0312997862713493e-05, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.8346416339002114, 'loop': 1, 'loss': 'CE', 'lr': 0.004677730304711696, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.653487490404612e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0008318445585689383
weight_decay:  0.00013721776876733066
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0084451360162348
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02
None time:  1.8555226679891348
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.888179702917114
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.781028985977173
total time:  5.8007274710107595
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 0.98
[I 2023-06-12 00:54:06,855] Trial 384 finished with value: 79.19998931884766 and parameters: {'Fwd': 6.450773577722846e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 1.7045009017908632, 'loop': 1, 'loss': 'CE', 'lr': 0.0008318445585689383, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013721776876733066, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004339523722471394
weight_decay:  0.00017819108453704112
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4215866678860039
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  1.224523191107437
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.4615143300034106
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
run time now: 4.133565664291382
total time:  4.1516937299165875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.50 ± 0.89
[I 2023-06-12 00:54:11,599] Trial 385 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0988331316684497, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 1.0, 'lambda2': 3.6079756098148, 'loop': 1, 'loss': 'CE', 'lr': 0.004339523722471394, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017819108453704112, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.00848646071529327
weight_decay:  0.000227084444585243
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6953147409949452
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  2.14323684386909
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.2524235108867288
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 6.12058424949646
total time:  6.143274842062965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 80.43 ± 0.98
[I 2023-06-12 00:54:18,328] Trial 386 finished with value: 80.73332977294922 and parameters: {'Fwd': 1.3267398651520149e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.082354093843095, 'loop': 1, 'loss': 'CE', 'lr': 0.00848646071529327, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000227084444585243, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0037947242441378304
weight_decay:  0.00011430050084861895
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6453262460418046
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.9852715320885181
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.2189811191055924
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.878322601318359
total time:  5.897762086009607
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.75
[I 2023-06-12 00:54:24,741] Trial 387 finished with value: 81.53333282470703 and parameters: {'Fwd': 2.864426828693144e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.7367533067123966, 'loop': 1, 'loss': 'CE', 'lr': 0.0037947242441378304, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011430050084861895, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.002899182370662617
weight_decay:  6.328102658431013e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.033889495069161
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  0.9188260869123042
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.2161481098737568
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.70
run time now: 3.1962950229644775
total time:  3.212325513828546
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.10
[I 2023-06-12 00:54:28,453] Trial 388 finished with value: 78.9333267211914 and parameters: {'Fwd': 5.212490580640528e-06, 'K': 8, 'alpha': 0.0, 'dropout': 0.1, 'gnnepoch': 40, 'lambda1': 1.0, 'lambda2': 3.445590357369685, 'loop': 1, 'loss': 'CE', 'lr': 0.002899182370662617, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.328102658431013e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005009894913127988
weight_decay:  3.765351331645678e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4186944160610437
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.43
   Final Test: 73.90
Split: 01, Run: 02
None time:  1.3020054250955582
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.172726312885061
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.20
run time now: 3.9243719577789307
total time:  3.944625749019906
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.53 ± 3.29
  Final Train: 98.81 ± 2.06
   Final Test: 76.10 ± 2.15
[I 2023-06-12 00:54:32,957] Trial 389 finished with value: 75.53333282470703 and parameters: {'Fwd': 2.1301091225974516e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 6.279622276378425, 'loop': 1, 'loss': 'CE', 'lr': 0.005009894913127988, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.765351331645678e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.005996015074280051
weight_decay:  0.00033775676293744546
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0674388529732823
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.225102768978104
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.9311271118931472
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.247395992279053
total time:  6.26172744599171
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.89
[I 2023-06-12 00:54:39,777] Trial 390 finished with value: 81.66666412353516 and parameters: {'Fwd': 7.653960842257862e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.3953836634210277, 'loop': 1, 'loss': 'CE', 'lr': 0.005996015074280051, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00033775676293744546, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0025156189436000447
weight_decay:  8.662073257414808e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1029358939267695
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 99.29
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.2645525669213384
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 99.29
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.9034937741234899
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 99.29
   Final Test: 81.10
run time now: 6.2939112186431885
total time:  6.308126248884946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 99.29 ± 0.00
   Final Test: 81.33 ± 0.49
[I 2023-06-12 00:54:46,648] Trial 391 finished with value: 81.0 and parameters: {'Fwd': 4.119229528227114e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 1.1313414669748787, 'loop': 1, 'loss': 'CE', 'lr': 0.0025156189436000447, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.662073257414808e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.004189707207484505
weight_decay:  0.00015218513435900214
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.201877485960722
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 99.29
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.0886745101306587
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 82.10
Split: 01, Run: 03
None time:  2.1092236491385847
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 99.29
   Final Test: 81.40
run time now: 6.450922250747681
total time:  6.46560039720498
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.42
  Final Train: 99.29 ± 0.00
   Final Test: 82.00 ± 0.56
[I 2023-06-12 00:54:53,722] Trial 392 finished with value: 81.73333740234375 and parameters: {'Fwd': 9.832754979158731e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 1.4026564641129848, 'loop': 1, 'loss': 'CE', 'lr': 0.004189707207484505, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015218513435900214, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005495147453755105
weight_decay:  0.0001296786991885885
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.300681204069406
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 99.29
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1002355930395424
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.9180010659620166
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 99.29
   Final Test: 80.70
run time now: 6.346416234970093
total time:  6.360542583046481
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.23
  Final Train: 99.52 ± 0.41
   Final Test: 81.63 ± 0.81
[I 2023-06-12 00:55:00,666] Trial 393 finished with value: 80.26667022705078 and parameters: {'Fwd': 5.9160619743869385e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 0.5357420411993226, 'loop': 1, 'loss': 'CE', 'lr': 0.005495147453755105, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001296786991885885, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0021713583395587296
weight_decay:  2.5921321918804443e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0551380021497607
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  2.0027663519140333
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.6328799838665873
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.742850065231323
total time:  5.790617809165269
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.53
[I 2023-06-12 00:55:07,015] Trial 394 finished with value: 80.06665802001953 and parameters: {'Fwd': 7.3581812360097555e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 3.9524390711335053, 'loop': 1, 'loss': 'CE', 'lr': 0.0021713583395587296, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.5921321918804443e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00457601749677994
weight_decay:  0.0001906218156567957
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9547952781431377
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.145389292156324
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.197767901001498
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.3283538818359375
total time:  6.34444146999158
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 1.01
[I 2023-06-12 00:55:13,922] Trial 395 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.07320177336783887, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.1899470283550406, 'loop': 1, 'loss': 'CE', 'lr': 0.00457601749677994, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001906218156567957, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.003593928644757346
weight_decay:  0.0002902967397305537
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8309327620081604
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02
None time:  2.2147637580055743
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  2.457668164977804
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 6.528408050537109
total time:  6.541538920952007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 79.47 ± 0.12
[I 2023-06-12 00:55:21,066] Trial 396 finished with value: 79.26666259765625 and parameters: {'Fwd': 2.697277774417167e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.522951120593552, 'loop': 1, 'loss': 'MSE', 'lr': 0.003593928644757346, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002902967397305537, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.004915797868967844
weight_decay:  0.00010536394036480762
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.33600009419024
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1759114649612457
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  2.288931675022468
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.828433275222778
total time:  6.84889142611064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.57
[I 2023-06-12 00:55:28,436] Trial 397 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.355546156716811e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 4.252176041775741, 'loop': 1, 'loss': 'CE', 'lr': 0.004915797868967844, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010536394036480762, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0015394414367697728
weight_decay:  7.697618741808278e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.157226324779913
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02
None time:  2.3080303841270506
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  2.1606597409117967
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.80
run time now: 6.652495384216309
total time:  6.6740832310169935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.43 ± 0.78
[I 2023-06-12 00:55:35,671] Trial 398 finished with value: 80.0666732788086 and parameters: {'Fwd': 0.00402216244400122, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.6781158079871106, 'loop': 1, 'loss': 'CE', 'lr': 0.0015394414367697728, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.697618741808278e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.003950062285196976
weight_decay:  4.972901370688123e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8758464648853987
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  2.024685255018994
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  2.0161858450155705
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.948611259460449
total time:  5.966781068127602
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.83 ± 0.59
[I 2023-06-12 00:55:42,156] Trial 399 finished with value: 81.46666717529297 and parameters: {'Fwd': 1.6796856938272472e-06, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 2.614564835509537, 'loop': 1, 'loss': 'CE', 'lr': 0.003950062285196976, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.972901370688123e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004438751315643178
weight_decay:  3.1948905735670057e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9717677000444382
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.8329073071945459
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.767162614967674
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.597884178161621
total time:  5.61096571595408
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.65
[I 2023-06-12 00:55:48,295] Trial 400 finished with value: 81.13333129882812 and parameters: {'Fwd': 4.86334585881894e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.421035616723099, 'loop': 1, 'loss': 'CE', 'lr': 0.004438751315643178, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.1948905735670057e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.00318698531286436
weight_decay:  0.00015611708716962945
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0257571949623525
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6814578890334815
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.1429353940766305
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.876862525939941
total time:  5.896847507916391
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.42
[I 2023-06-12 00:55:54,772] Trial 401 finished with value: 81.33333587646484 and parameters: {'Fwd': 1.1119447206831628e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.8871942717867145, 'loop': 1, 'loss': 'CE', 'lr': 0.00318698531286436, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015611708716962945, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005191321458837956
weight_decay:  1.3497022146137795e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.138282753061503
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.015629085013643
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 99.29
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.2464802358299494
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 99.29
   Final Test: 80.30
run time now: 6.427612781524658
total time:  6.441036443226039
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.31
  Final Train: 99.29 ± 0.00
   Final Test: 81.00 ± 0.75
[I 2023-06-12 00:56:01,692] Trial 402 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.00124318008334007, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 0.2672230103714637, 'loop': 1, 'loss': 'CE', 'lr': 0.005191321458837956, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3497022146137795e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.000505708967480044
weight_decay:  0.0002107808671123526
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.599425934953615
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 99.29
   Final Test: 79.50
Split: 01, Run: 02
None time:  2.06002417486161
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 03
None time:  2.129804829135537
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.30
run time now: 5.821568012237549
total time:  5.856581564061344
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.20 ± 3.60
  Final Train: 99.76 ± 0.41
   Final Test: 76.50 ± 3.10
[I 2023-06-12 00:56:07,986] Trial 403 finished with value: 76.20000457763672 and parameters: {'Fwd': 0.0003009390795953377, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 0.8708208698487985, 'loop': 1, 'loss': 'CE', 'lr': 0.000505708967480044, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002107808671123526, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004083329725738185
weight_decay:  2.4806650751062628e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6045572410803288
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 02
None time:  0.5406812150031328
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 03
None time:  0.5088159430306405
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 71.60
run time now: 1.6795861721038818
total time:  1.7125859819352627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 72.27 ± 0.70
[I 2023-06-12 00:56:10,231] Trial 404 finished with value: 69.93333435058594 and parameters: {'Fwd': 1.488566235880099e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 0, 'lambda1': 0.9500000000000001, 'lambda2': 2.9725026256346148, 'loop': 1, 'loss': 'CE', 'lr': 0.004083329725738185, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.4806650751062628e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0099719111024086
weight_decay:  0.00012031727340992317
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4320885641500354
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  2.130511075956747
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  2.2512926650233567
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.890055179595947
total time:  6.98690690100193
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 79.77 ± 0.95
[I 2023-06-12 00:56:17,831] Trial 405 finished with value: 80.73333740234375 and parameters: {'Fwd': 8.808950874915635e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 7.948572500261265, 'loop': 1, 'loss': 'CE', 'lr': 0.0099719111024086, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012031727340992317, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.0012585246205923898
weight_decay:  9.042849261073409e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.249448226997629
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 99.29
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.9966219400521368
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 99.29
   Final Test: 79.90
Split: 01, Run: 03
None time:  2.2859649921301752
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 99.29
   Final Test: 79.10
run time now: 6.563560962677002
total time:  6.58803721005097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.64
  Final Train: 99.29 ± 0.00
   Final Test: 79.70 ± 0.53
[I 2023-06-12 00:56:24,946] Trial 406 finished with value: 79.5333251953125 and parameters: {'Fwd': 2.425815673302105e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 0.6762957300000849, 'loop': 1, 'loss': 'CE', 'lr': 0.0012585246205923898, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.042849261073409e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.006622242086755205
weight_decay:  5.463978013087087e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2513025200460106
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.0999654929619282
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.0402071429416537
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.474077463150024
total time:  6.4894850379787385
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.59
[I 2023-06-12 00:56:32,046] Trial 407 finished with value: 82.0 and parameters: {'Fwd': 6.392806446047584e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 1.6195837441614656, 'loop': 1, 'loss': 'CE', 'lr': 0.006622242086755205, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.463978013087087e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0018316631727860026
weight_decay:  0.00016786934931336086
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0869295799639076
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.9200192529242486
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 99.29
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.8896825050469488
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.920140743255615
total time:  5.936819175025448
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.20
  Final Train: 99.76 ± 0.41
   Final Test: 80.10 ± 0.36
[I 2023-06-12 00:56:38,663] Trial 408 finished with value: 80.0 and parameters: {'Fwd': 4.226335688002314e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.050120075770825, 'loop': 1, 'loss': 'CE', 'lr': 0.0018316631727860026, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016786934931336086, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.004669801362784149
weight_decay:  0.00012923429344514328
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3798657250590622
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 02
None time:  1.2515943280886859
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.29
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1406671160366386
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.798769474029541
total time:  3.8129553359467536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 2.55
  Final Train: 99.76 ± 0.41
   Final Test: 71.17 ± 1.93
[I 2023-06-12 00:56:43,015] Trial 409 finished with value: 70.46666717529297 and parameters: {'Fwd': 1.3205316682418467e-06, 'K': 9, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 0.37499760326355425, 'loop': 1, 'loss': 'CE', 'lr': 0.004669801362784149, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012923429344514328, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.0035400468768842525
weight_decay:  0.00024414223313248
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9041847239714116
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 82.10
Split: 01, Run: 02
None time:  2.1147138180676848
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.1075124808121473
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.70
run time now: 6.155664443969727
total time:  6.175755819072947
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 99.29 ± 0.00
   Final Test: 81.83 ± 0.23
[I 2023-06-12 00:56:49,713] Trial 410 finished with value: 81.26666259765625 and parameters: {'Fwd': 0.00019897843683498812, 'K': 8, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 1.5043190865837295, 'loop': 1, 'loss': 'CE', 'lr': 0.0035400468768842525, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00024414223313248, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004285901769252224
weight_decay:  7.110598380586444e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.905744574032724
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.09671302116476
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  2.389373186044395
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 6.4191460609436035
total time:  6.436266083968803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.81
[I 2023-06-12 00:56:56,663] Trial 411 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.0001358170935996542, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 6.543839421579054, 'loop': 1, 'loss': 'CE', 'lr': 0.004285901769252224, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.110598380586444e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00014085235740360388
weight_decay:  0.00010015491001693086
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7773293950594962
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.1491788390558213
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 03
None time:  2.4078896038699895
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.360612392425537
total time:  6.381180684780702
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.27 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 77.37 ± 0.93
[I 2023-06-12 00:57:03,660] Trial 412 finished with value: 78.26667022705078 and parameters: {'Fwd': 9.817177103571981e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 2.2389259417761016, 'loop': 1, 'loss': 'CE', 'lr': 0.00014085235740360388, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010015491001693086, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00549993753021479
weight_decay:  1.8630211150022311e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8387926190625876
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.289696400053799
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.380407055839896
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.538177013397217
total time:  6.556452801916748
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.62
[I 2023-06-12 00:57:10,780] Trial 413 finished with value: 81.46666717529297 and parameters: {'Fwd': 5.557871813233547e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 5.999384085977155, 'loop': 1, 'loss': 'CE', 'lr': 0.00549993753021479, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8630211150022311e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.004772066149017448
weight_decay:  0.00016787643791557394
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.210550226038322
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.2827335838228464
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.353194492869079
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 6.8757483959198
total time:  6.89811090589501
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.46
[I 2023-06-12 00:57:18,184] Trial 414 finished with value: 81.93333435058594 and parameters: {'Fwd': 8.197865079957092e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.06401949602332, 'loop': 1, 'loss': 'CE', 'lr': 0.004772066149017448, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016787643791557394, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.15000000000000002
lr:  0.0007017318695975942
weight_decay:  0.0001364478413885865
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1765112201683223
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 02
None time:  2.498924992978573
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0331, Train: 100.00%, Valid: 77.00% Test: 78.90%
Split: 01, Run: 03
None time:  4.897125194082037
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 78.60
run time now: 10.596744537353516
total time:  10.614818749018013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 1.40
[I 2023-06-12 00:57:29,344] Trial 415 finished with value: 78.0 and parameters: {'Fwd': 3.534700582919893e-06, 'K': 5, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.5924181932613375, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007017318695975942, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001364478413885865, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0037675328876734314
weight_decay:  5.915171995176149e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.980340925976634
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2238498099613935
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.8000378229189664
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.03242564201355
total time:  6.053732373053208
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.36
[I 2023-06-12 00:57:35,936] Trial 416 finished with value: 81.53333282470703 and parameters: {'Fwd': 1.8523385609811513e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.317103200261359, 'loop': 1, 'loss': 'CE', 'lr': 0.0037675328876734314, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.915171995176149e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0003441539252677152
weight_decay:  0.00020100373920602785
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9534265268594027
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.0927001039963216
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  2.0967038029339164
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 76.30
run time now: 6.170492172241211
total time:  6.188927857903764
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.40 ± 5.01
  Final Train: 100.00 ± 0.00
   Final Test: 75.33 ± 3.84
[I 2023-06-12 00:57:42,684] Trial 417 finished with value: 74.4000015258789 and parameters: {'Fwd': 6.758651665108024e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.2342512642138344, 'loop': 1, 'loss': 'CE', 'lr': 0.0003441539252677152, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020100373920602785, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0015102939605415974
weight_decay:  0.00010367717374663973
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9038970049005002
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  1.8855063719674945
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  2.1307687270455062
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.949212312698364
total time:  5.970294329803437
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 80.00 ± 0.36
[I 2023-06-12 00:57:49,122] Trial 418 finished with value: 79.73332977294922 and parameters: {'Fwd': 3.4190306993131135e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.8139911426177484, 'loop': 1, 'loss': 'CE', 'lr': 0.0015102939605415974, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010367717374663973, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.0010257134236573218
weight_decay:  3.406251737680945e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1613530518952757
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.9871919159777462
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.9275393069256097
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 76.00
run time now: 6.145638704299927
total time:  6.237259105080739
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.07 ± 2.08
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 2.32
[I 2023-06-12 00:57:55,983] Trial 419 finished with value: 77.0666732788086 and parameters: {'Fwd': 1.129968427699669e-05, 'K': 2, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 3.4839104893381183, 'loop': 1, 'loss': 'CE', 'lr': 0.0010257134236573218, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.406251737680945e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.005852553689497768
weight_decay:  0.0004939393128248629
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3569786970037967
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1744306180626154
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  2.455646727932617
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.00
run time now: 7.015986204147339
total time:  7.033750782953575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 1.14
[I 2023-06-12 00:58:03,489] Trial 420 finished with value: 80.66666412353516 and parameters: {'Fwd': 4.934273047393393e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 4.606836045371483, 'loop': 1, 'loss': 'CE', 'lr': 0.005852553689497768, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004939393128248629, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0043059807391243755
weight_decay:  8.519052578675877e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0843954221345484
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.018806542037055
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.3248691391199827
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 6.454355001449585
total time:  6.469023850047961
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.56
[I 2023-06-12 00:58:10,438] Trial 421 finished with value: 81.9333267211914 and parameters: {'Fwd': 9.027905758602085e-06, 'K': 9, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.015348535042742, 'loop': 1, 'loss': 'CE', 'lr': 0.0043059807391243755, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.519052578675877e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004999302049247017
weight_decay:  0.0002967274673351956
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.237298985943198
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5678658029064536
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.0490717960055918
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.884592056274414
total time:  5.906716377008706
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.45
[I 2023-06-12 00:58:16,853] Trial 422 finished with value: 81.66666412353516 and parameters: {'Fwd': 2.7618761187415407e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.754177085819531, 'loop': 1, 'loss': 'CE', 'lr': 0.004999302049247017, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002967274673351956, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0038982522853127275
weight_decay:  0.00014432806683154623
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8836246179416776
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 99.29
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.1735271778889
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.1952022339683026
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 99.29
   Final Test: 81.10
run time now: 6.274154424667358
total time:  6.289955044863746
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 99.29 ± 0.00
   Final Test: 81.67 ± 0.55
[I 2023-06-12 00:58:23,737] Trial 423 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.01900155363126507, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 0.677412919581107, 'loop': 1, 'loss': 'CE', 'lr': 0.0038982522853127275, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014432806683154623, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.004535531038138004
weight_decay:  0.00010818237147699596
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8124531949870288
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9258762618992478
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.1510916370898485
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.920466184616089
total time:  5.9342978009954095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.45
[I 2023-06-12 00:58:30,207] Trial 424 finished with value: 80.5999984741211 and parameters: {'Fwd': 1.3326264597758972e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 4.214115790677909, 'loop': 0, 'loss': 'CE', 'lr': 0.004535531038138004, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010818237147699596, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0033807705228209315
weight_decay:  0.000878333236417091
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0666438001208007
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.60
Split: 01, Run: 02
None time:  2.229417265858501
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.8146315990015864
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.20
run time now: 6.135762453079224
total time:  6.156883751042187
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.12
  Final Train: 99.29 ± 0.00
   Final Test: 81.47 ± 0.23
[I 2023-06-12 00:58:36,888] Trial 425 finished with value: 81.33333587646484 and parameters: {'Fwd': 5.899479283884324e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 1.8278960034417708, 'loop': 1, 'loss': 'CE', 'lr': 0.0033807705228209315, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000878333236417091, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.005114305721640187
weight_decay:  2.8555646729210834e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6141369179822505
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6302392890211195
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.4971691858954728
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.762171983718872
total time:  4.775373276788741
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.64
[I 2023-06-12 00:58:42,164] Trial 426 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.0001574851368803188, 'K': 4, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 3.3268022039113165, 'loop': 1, 'loss': 'CE', 'lr': 0.005114305721640187, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.8555646729210834e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004180815358362275
weight_decay:  0.00022615085968146493
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3630425860174
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 98.57
   Final Test: 71.80
Split: 01, Run: 02
None time:  1.2225575849879533
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.3077628931496292
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.916391372680664
total time:  3.9436758779920638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 2.77
  Final Train: 99.52 ± 0.82
   Final Test: 70.53 ± 1.10
[I 2023-06-12 00:58:46,712] Trial 427 finished with value: 70.4000015258789 and parameters: {'Fwd': 4.3600703429242104e-05, 'K': 9, 'alpha': 0.1, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.941328988471368, 'loop': 1, 'loss': 'CE', 'lr': 0.004180815358362275, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00022615085968146493, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.0027381921942487087
weight_decay:  0.00038084208248590927
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1465510139241815
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.9080416169017553
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.9423845538403839
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
run time now: 6.022451400756836
total time:  6.035579115152359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.40
[I 2023-06-12 00:58:53,307] Trial 428 finished with value: 81.46666717529297 and parameters: {'Fwd': 4.35018177349746e-06, 'K': 7, 'alpha': 0.05, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.772525341737388, 'loop': 1, 'loss': 'CE', 'lr': 0.0027381921942487087, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00038084208248590927, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.004685703732214771
weight_decay:  4.409190798025671e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.065166319021955
None Run 01:
Highest Train: 99.29
Highest Valid: 80.60
  Final Train: 95.71
   Final Test: 81.00
Split: 01, Run: 02
None time:  1.7449548370204866
None Run 02:
Highest Train: 99.29
Highest Valid: 80.60
  Final Train: 97.86
   Final Test: 81.10
Split: 01, Run: 03
None time:  2.0269475399982184
None Run 03:
Highest Train: 99.29
Highest Valid: 80.80
  Final Train: 97.86
   Final Test: 80.80
run time now: 5.8615734577178955
total time:  5.879718896001577
None All runs:
Highest Train: 99.29 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 97.14 ± 1.24
   Final Test: 80.97 ± 0.15
[I 2023-06-12 00:58:59,658] Trial 429 finished with value: 80.66666412353516 and parameters: {'Fwd': 9.343938583959271e-05, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 0.013750559006311835, 'loop': 1, 'loss': 'CE', 'lr': 0.004685703732214771, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.409190798025671e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.0030459997656344835
weight_decay:  0.0001675774113075409
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.108194410102442
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  2.257591102970764
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.88221400603652
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.2692952156066895
total time:  6.292204453842714
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.26
[I 2023-06-12 00:59:06,528] Trial 430 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.00023329066997143893, 'K': 10, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.6569251485742607, 'loop': 1, 'loss': 'CE', 'lr': 0.0030459997656344835, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001675774113075409, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0013915925942596878
weight_decay:  0.0001111910913798663
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0368792770896107
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  0.7909289561212063
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.9923487959895283
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 79.30
run time now: 2.8487653732299805
total time:  2.867452282924205
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.00 ± 3.75
  Final Train: 100.00 ± 0.00
   Final Test: 76.27 ± 3.95
[I 2023-06-12 00:59:09,868] Trial 431 finished with value: 75.0 and parameters: {'Fwd': 7.4903728071489275e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 10, 'lambda1': 0.5, 'lambda2': 1.8735917561158089, 'loop': 1, 'loss': 'CE', 'lr': 0.0013915925942596878, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001111910913798663, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0039261983987656
weight_decay:  7.39738076308385e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9236284319777042
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.955415594857186
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  2.1572664969135076
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.063220500946045
total time:  6.095965165877715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.00 ± 0.60
[I 2023-06-12 00:59:16,436] Trial 432 finished with value: 81.46666717529297 and parameters: {'Fwd': 1.0768487088350666e-06, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 5.801927690025671, 'loop': 1, 'loss': 'CE', 'lr': 0.0039261983987656, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.39738076308385e-05, 'weightedloss': True}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0017012123396953774
weight_decay:  0.00013363223288465726
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0720124570652843
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  2.082077844068408
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  2.3238587640225887
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.507592439651489
total time:  6.5275085950270295
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.63 ± 0.75
[I 2023-06-12 00:59:23,456] Trial 433 finished with value: 80.20000457763672 and parameters: {'Fwd': 3.573493968312606e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.531436795051236, 'loop': 1, 'loss': 'CE', 'lr': 0.0017012123396953774, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013363223288465726, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0055219116705650445
weight_decay:  6.989542131279753e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9322316569741815
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  2.165328174130991
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.9640285409986973
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.0852203369140625
total time:  6.102764566196129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.64
[I 2023-06-12 00:59:30,140] Trial 434 finished with value: 81.46666717529297 and parameters: {'Fwd': 1.0057626113782113e-05, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.443505664310616, 'loop': 1, 'loss': 'CE', 'lr': 0.0055219116705650445, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.989542131279753e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00441866633694345
weight_decay:  0.00017746541976323263
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9453727349173278
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  2.2267274151090533
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  2.087632192997262
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.2857489585876465
total time:  6.299977645045146
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.72
[I 2023-06-12 00:59:36,916] Trial 435 finished with value: 78.99999237060547 and parameters: {'Fwd': 5.529843320720756e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.8369493071155083, 'loop': 1, 'loss': 'MSE', 'lr': 0.00441866633694345, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017746541976323263, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.006169297018025391
weight_decay:  5.014985186014442e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5839459621347487
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.889669283060357
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.8509442249778658
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.20
run time now: 5.350264310836792
total time:  5.366867962060496
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.72
[I 2023-06-12 00:59:42,722] Trial 436 finished with value: 81.00000762939453 and parameters: {'Fwd': 2.0925105629730938e-06, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 4.135534526851432, 'loop': 1, 'loss': 'CE', 'lr': 0.006169297018025391, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.014985186014442e-06, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.00489752174324564
weight_decay:  0.00023331530603905965
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9772893420886248
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.5356165829580277
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  2.1272648808080703
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.670510292053223
total time:  5.688977323938161
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.55
[I 2023-06-12 00:59:48,884] Trial 437 finished with value: 81.53333282470703 and parameters: {'Fwd': 6.636870309288246e-06, 'K': 8, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 8.784986077015144, 'loop': 1, 'loss': 'CE', 'lr': 0.00489752174324564, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00023331530603905965, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0011618423549662163
weight_decay:  0.00012667141493026595
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1144404641818255
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 02
None time:  2.235336605925113
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.080045487964526
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.461257457733154
total time:  6.476789582055062
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 79.73 ± 1.42
[I 2023-06-12 00:59:55,865] Trial 438 finished with value: 79.79999542236328 and parameters: {'Fwd': 1.661864406478248e-05, 'K': 9, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 2.6952977466600587, 'loop': 1, 'loss': 'CE', 'lr': 0.0011618423549662163, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012667141493026595, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004106506986324449
weight_decay:  8.6919370084673e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.123681527096778
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.4502892009913921
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  2.112377723911777
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.711368799209595
total time:  5.722633506171405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.71
[I 2023-06-12 01:00:02,051] Trial 439 finished with value: 81.66667175292969 and parameters: {'Fwd': 0.0005316084671333936, 'K': 9, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.1816771500900596, 'loop': 1, 'loss': 'CE', 'lr': 0.004106506986324449, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.6919370084673e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.003594734358385106
weight_decay:  5.956692630453461e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9714586108457297
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.363577082986012
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.9961765729822218
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.357637166976929
total time:  5.374788323882967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.31
[I 2023-06-12 01:00:07,914] Trial 440 finished with value: 80.79999542236328 and parameters: {'Fwd': 4.63178709816713e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.6960753885810838, 'loop': 1, 'loss': 'CE', 'lr': 0.003594734358385106, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.956692630453461e-05, 'weightedloss': False}. Best is trial 71 with value: 82.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0022231708920573087
weight_decay:  3.974545832342346e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
