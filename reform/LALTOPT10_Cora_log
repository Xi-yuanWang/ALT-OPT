[I 2023-06-12 00:12:20,346] A new study created in RDB with name: Cora_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0009425452197366458
weight_decay:  0.0001249819669131737
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6719952821731567
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.00
Split: 01, Run: 02
None time:  0.8567685461603105
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.00
Split: 01, Run: 03
None time:  0.8775025571230799
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.00
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8601055301260203
None Run 04:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 58.90
Split: 02, Run: 02
None time:  0.8342894080560654
None Run 05:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 58.90
Split: 02, Run: 03
None time:  0.8320057878736407
None Run 06:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 58.90
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8291852530092001
None Run 07:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 55.10
Split: 03, Run: 02
None time:  0.8433644229080528
None Run 08:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 55.10
Split: 03, Run: 03
None time:  0.8788652950897813
None Run 09:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 55.10
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8586199509445578
None Run 10:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
Split: 04, Run: 02
None time:  0.8408093131147325
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
Split: 04, Run: 03
None time:  0.8516744419466704
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8634727501776069
None Run 13:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.10
Split: 05, Run: 02
None time:  0.8870960611384362
None Run 14:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.10
Split: 05, Run: 03
None time:  0.8728613029234111
None Run 15:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8405325240455568
None Run 16:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.70
Split: 06, Run: 02
None time:  0.6366401468403637
None Run 17:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.70
Split: 06, Run: 03
None time:  0.8291378850117326
None Run 18:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.70
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8310549829620868
None Run 19:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.50
Split: 07, Run: 02
None time:  0.8841595090925694
None Run 20:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.50
Split: 07, Run: 03
None time:  0.8518344468902797
None Run 21:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0147, Train: 100.00%, Valid: 69.20% Test: 63.50%
Split: 08, Run: 01
None time:  4.2265068790875375
None Run 22:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 63.50
Split: 08, Run: 02
None time:  0.7808329490944743
None Run 23:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.70
Split: 08, Run: 03
None time:  0.7735009610187262
None Run 24:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.70
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7685503039974719
None Run 25:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.90
Split: 09, Run: 02
None time:  0.7699924698099494
None Run 26:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.90
Split: 09, Run: 03
None time:  0.7646903649438173
None Run 27:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7532192161306739
None Run 28:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.80
Split: 10, Run: 02
None time:  0.7681769670452923
None Run 29:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.80
Split: 10, Run: 03
None time:  0.7858836881350726
None Run 30:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.80
run time now: 2.335423469543457
total time:  31.2556324491743
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.36 ± 4.13
  Final Train: 100.00 ± 0.00
   Final Test: 60.04 ± 3.44
best run test_acc: 60.3599967956543
[I 2023-06-12 00:12:52,371] Trial 0 finished with value: 61.36000061035156 and parameters: {'Fwd': 0.0031822876485675055, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 20, 'lambda1': 0.9500000000000001, 'lambda2': 0.9352991863373172, 'loop': 1, 'loss': 'MSE', 'lr': 0.0009425452197366458, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001249819669131737, 'weightedloss': False}. Best is trial 0 with value: 61.36000061035156.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.00034574937822327183
weight_decay:  4.997376182715062e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0491509209387004
None Run 01:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 40.70
Split: 01, Run: 02
None time:  0.8494126768782735
None Run 02:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 35.60
Split: 01, Run: 03
None time:  0.8165545568335801
None Run 03:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 36.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3071295260451734
None Run 04:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 41.40
Split: 02, Run: 02
None time:  1.9215886800084263
None Run 05:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 44.20
Split: 02, Run: 03
None time:  0.8961951150558889
None Run 06:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 43.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7437937948852777
None Run 07:
Highest Train: 100.00
Highest Valid: 21.40
  Final Train: 100.00
   Final Test: 17.80
Split: 03, Run: 02
None time:  1.4759437050670385
None Run 08:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 44.80
Split: 03, Run: 03
None time:  1.363759861793369
None Run 09:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 48.30
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7615960719995201
None Run 10:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 36.10
Split: 04, Run: 02
None time:  1.0699566861148924
None Run 11:
Highest Train: 100.00
Highest Valid: 24.40
  Final Train: 100.00
   Final Test: 26.70
Split: 04, Run: 03
None time:  0.9266430588904768
None Run 12:
Highest Train: 100.00
Highest Valid: 29.00
  Final Train: 100.00
   Final Test: 30.60
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7199525751639158
None Run 13:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 35.30
Split: 05, Run: 02
None time:  1.3729448488447815
None Run 14:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 45.00
Split: 05, Run: 03
None time:  1.0245468390639871
None Run 15:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 46.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2118856681045145
None Run 16:
Highest Train: 100.00
Highest Valid: 29.80
  Final Train: 100.00
   Final Test: 28.10
Split: 06, Run: 02
None time:  1.2129778498783708
None Run 17:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 31.10
Split: 06, Run: 03
None time:  1.479883709922433
None Run 18:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 32.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4406883029732853
None Run 19:
Highest Train: 100.00
Highest Valid: 30.60
  Final Train: 100.00
   Final Test: 29.10
Split: 07, Run: 02
None time:  1.1411600450519472
None Run 20:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 38.10
Split: 07, Run: 03
None time:  0.9693513521924615
None Run 21:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 42.80
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8445384381338954
None Run 22:
Highest Train: 100.00
Highest Valid: 36.40
  Final Train: 100.00
   Final Test: 35.80
Split: 08, Run: 02
None time:  1.7494502540212125
None Run 23:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 44.90
Split: 08, Run: 03
None time:  1.1176595408469439
None Run 24:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 49.00
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2793256118893623
None Run 25:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 41.90
Split: 09, Run: 02
None time:  0.8642857410013676
None Run 26:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 44.10
Split: 09, Run: 03
None time:  0.814735742053017
None Run 27:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 45.20
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.801582818152383
None Run 28:
Highest Train: 100.00
Highest Valid: 21.60
  Final Train: 100.00
   Final Test: 25.60
Split: 10, Run: 02
None time:  1.2173194959759712
None Run 29:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 29.90
Split: 10, Run: 03
None time:  0.9633725481107831
None Run 30:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 33.90
run time now: 3.0047950744628906
total time:  34.91072708996944
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 38.53 ± 8.18
  Final Train: 100.00 ± 0.00
   Final Test: 37.49 ± 7.78
best run test_acc: 41.89999771118164
[I 2023-06-12 00:13:27,799] Trial 1 finished with value: 38.53333282470703 and parameters: {'Fwd': 4.808226912447442e-05, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 1.9459478823789311, 'loop': 1, 'loss': 'MSE', 'lr': 0.00034574937822327183, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.997376182715062e-06, 'weightedloss': False}. Best is trial 0 with value: 61.36000061035156.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.0006456743637928239
weight_decay:  5.702976203746492e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.069200382102281
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  2.283339451998472
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  2.254885279107839
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.80
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.2924452940933406
None Run 04:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.40
Split: 02, Run: 02
None time:  2.200439581880346
None Run 05:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 71.00
Split: 02, Run: 03
None time:  2.1887131489347667
None Run 06:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.5523981261067092
None Run 07:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 72.30
Split: 03, Run: 02
None time:  2.2361269330140203
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.80
Split: 03, Run: 03
None time:  2.213734103133902
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.30
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.3528384999372065
None Run 10:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.80
Split: 04, Run: 02
None time:  2.3196888838429004
None Run 11:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.50
Split: 04, Run: 03
None time:  2.6991519001312554
None Run 12:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.60
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.954414392122999
None Run 13:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 76.00
Split: 05, Run: 02
None time:  2.215350043028593
None Run 14:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.00
Split: 05, Run: 03
None time:  2.5890885940752923
None Run 15:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.00
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.249673570971936
None Run 16:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 64.90
Split: 06, Run: 02
None time:  2.312539584003389
None Run 17:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 69.40
Split: 06, Run: 03
None time:  2.2710938409436494
None Run 18:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 72.40
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.2844081178773195
None Run 19:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
Split: 07, Run: 02
None time:  2.6168516939505935
None Run 20:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.80
Split: 07, Run: 03
None time:  2.9344501530285925
None Run 21:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.70
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.445247279945761
None Run 22:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.20
Split: 08, Run: 02
None time:  2.198639656882733
None Run 23:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 73.20
Split: 08, Run: 03
None time:  2.2721106000244617
None Run 24:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.30
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.2939346849452704
None Run 25:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.50
Split: 09, Run: 02
None time:  2.20960880885832
None Run 26:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.60
Split: 09, Run: 03
None time:  2.260234047891572
None Run 27:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.20
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.2850166221614927
None Run 28:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.80
Split: 10, Run: 02
None time:  2.126343009993434
None Run 29:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
Split: 10, Run: 03
None time:  2.2812391810584813
None Run 30:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.80
run time now: 6.71909761428833
total time:  70.9707881489303
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.83 ± 4.13
  Final Train: 100.00 ± 0.00
   Final Test: 73.04 ± 3.61
best run test_acc: 75.1500015258789
[I 2023-06-12 00:14:39,207] Trial 2 finished with value: 73.83333587646484 and parameters: {'Fwd': 0.00026668086971103636, 'K': 6, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.8675834935965305, 'loop': 0, 'loss': 'CE', 'lr': 0.0006456743637928239, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.702976203746492e-06, 'weightedloss': False}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.2
lr:  0.00029584301262118183
weight_decay:  3.520479969449342e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7305058329366148
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.60
Split: 01, Run: 02
None time:  0.7323715989477932
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.60
Split: 01, Run: 03
None time:  0.7161901311483234
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.60
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7079149808268994
None Run 04:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.60
Split: 02, Run: 02
None time:  0.6953007529955357
None Run 05:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.60
Split: 02, Run: 03
None time:  0.6605735549237579
None Run 06:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7193651078268886
None Run 07:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 54.60
Split: 03, Run: 02
None time:  0.6705390107817948
None Run 08:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 54.60
Split: 03, Run: 03
None time:  0.7278749351389706
None Run 09:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 54.60
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7020024619996548
None Run 10:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 62.70
Split: 04, Run: 02
None time:  0.7339421561919153
None Run 11:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 62.70
Split: 04, Run: 03
None time:  0.7241141488775611
None Run 12:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 62.70
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6871539119165391
None Run 13:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.30
Split: 05, Run: 02
None time:  0.6632728781551123
None Run 14:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.30
Split: 05, Run: 03
None time:  0.6880319858901203
None Run 15:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7090855238493532
None Run 16:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.50
Split: 06, Run: 02
None time:  0.7065508130472153
None Run 17:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.50
Split: 06, Run: 03
None time:  0.73797338292934
None Run 18:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6883851590100676
None Run 19:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.00
Split: 07, Run: 02
None time:  0.7505160691216588
None Run 20:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.00
Split: 07, Run: 03
None time:  0.7071602849755436
None Run 21:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.00
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7288030639756471
None Run 22:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.20
Split: 08, Run: 02
None time:  0.7206501769833267
None Run 23:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.20
Split: 08, Run: 03
None time:  0.7190880510024726
None Run 24:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7290638820268214
None Run 25:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.10
Split: 09, Run: 02
None time:  0.7427033339627087
None Run 26:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.10
Split: 09, Run: 03
None time:  0.6898587408941239
None Run 27:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.10
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6905670419801027
None Run 28:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 60.10
Split: 10, Run: 02
None time:  0.6995577579364181
None Run 29:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 60.10
Split: 10, Run: 03
None time:  0.705005964031443
None Run 30:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 60.10
run time now: 2.1329445838928223
total time:  21.840535830007866
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.26 ± 3.58
  Final Train: 100.00 ± 0.00
   Final Test: 59.17 ± 3.12
best run test_acc: 59.17000198364258
[I 2023-06-12 00:15:01,389] Trial 3 finished with value: 60.26000213623047 and parameters: {'Fwd': 0.0006632312075483128, 'K': 6, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 3.4292520360443124, 'loop': 0, 'loss': 'MSE', 'lr': 0.00029584301262118183, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.520479969449342e-06, 'weightedloss': False}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0001868816133737871
weight_decay:  6.926652509040315e-06
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.655739659909159
None Run 01:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 97.14
   Final Test: 74.60
Split: 01, Run: 02
None time:  1.1733025959692895
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  1.2661577221006155
None Run 03:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.90
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6030755979008973
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.57
   Final Test: 64.50
Split: 02, Run: 02
None time:  1.132149696117267
None Run 05:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.90
Split: 02, Run: 03
None time:  1.2100549840833992
None Run 06:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.57
   Final Test: 72.20
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.078646024223417
None Run 07:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.40
Split: 03, Run: 02
None time:  1.117267024004832
None Run 08:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 63.30
Split: 03, Run: 03
None time:  1.1620248898398131
None Run 09:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 66.10
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0781900309957564
None Run 10:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.20
Split: 04, Run: 02
None time:  1.258844163035974
None Run 11:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 98.57
   Final Test: 77.00
Split: 04, Run: 03
None time:  1.3887972941156477
None Run 12:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 97.14
   Final Test: 77.60
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0408012031111866
None Run 13:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.50
Split: 05, Run: 02
None time:  1.2514886390417814
None Run 14:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.80
Split: 05, Run: 03
None time:  1.1071669831871986
None Run 15:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1197575971018523
None Run 16:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 57.30
Split: 06, Run: 02
None time:  1.1990315031725913
None Run 17:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 58.30
Split: 06, Run: 03
None time:  1.1315945240203291
None Run 18:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0291688540019095
None Run 19:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.40
Split: 07, Run: 02
None time:  1.0842758459039032
None Run 20:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.40
Split: 07, Run: 03
None time:  1.1715087338816375
None Run 21:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1681305300444365
None Run 22:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 65.90
Split: 08, Run: 02
None time:  1.237399814184755
None Run 23:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 75.80
Split: 08, Run: 03
None time:  1.2178567859809846
None Run 24:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.57
   Final Test: 75.40
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0961947808973491
None Run 25:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.10
Split: 09, Run: 02
None time:  1.1699078669771552
None Run 26:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.10
Split: 09, Run: 03
None time:  1.3367404688615352
None Run 27:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.60
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.11269332584925
None Run 28:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 02
None time:  0.9571102929767221
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 72.40
Split: 10, Run: 03
None time:  1.1585668588522822
None Run 30:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.20
run time now: 3.2539706230163574
total time:  36.48748199408874
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 6.52
  Final Train: 99.62 ± 0.83
   Final Test: 68.37 ± 6.37
best run test_acc: 71.46000671386719
[I 2023-06-12 00:15:38,243] Trial 4 finished with value: 69.13333129882812 and parameters: {'Fwd': 1.4443621224063145e-05, 'K': 9, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 1.8123080780164247, 'loop': 2, 'loss': 'CE', 'lr': 0.0001868816133737871, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.926652509040315e-06, 'weightedloss': True}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0001568057356057339
weight_decay:  9.599467973446208e-06
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 63.20%
Split: 01, Run: 01
None time:  3.014504491118714
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.20% Test: 64.90%
Split: 01, Run: 02
None time:  3.044292783131823
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 03
None time:  1.3883162538986653
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.00
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.40% Test: 60.70%
Split: 02, Run: 01
None time:  2.970077995210886
None Run 04:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.60
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 63.40% Test: 65.70%
Split: 02, Run: 02
None time:  3.057078446028754
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.70
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 63.00% Test: 65.40%
Split: 02, Run: 03
None time:  2.96938830986619
None Run 06:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.40
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3699767810758203
None Run 07:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 55.00
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.80% Test: 60.80%
Split: 03, Run: 02
None time:  2.974470918998122
None Run 08:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.60
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 63.20% Test: 63.70%
Split: 03, Run: 03
None time:  3.0115711740218103
None Run 09:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 63.70
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2676274878904223
None Run 10:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
Split: 04, Run: 02
None time:  1.251994689926505
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
Split: 04, Run: 03
None time:  1.3334604990668595
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3439514499623328
None Run 13:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.50
Split: 05, Run: 02
None time:  1.4423199300654233
None Run 14:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.50
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.80% Test: 63.10%
Split: 05, Run: 03
None time:  3.1271540061570704
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 63.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3288747891783714
None Run 16:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 54.90
Split: 06, Run: 02
None time:  1.3585806998889893
None Run 17:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 54.90
Split: 06, Run: 03
None time:  1.2981533219572157
None Run 18:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 54.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3623582848813385
None Run 19:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.50
Split: 07, Run: 02
None time:  1.2524693550076336
None Run 20:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.50
Split: 07, Run: 03
None time:  1.2525298239197582
None Run 21:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2166278650984168
None Run 22:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 59.00
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.60% Test: 64.40%
Split: 08, Run: 02
None time:  2.9617961088661104
None Run 23:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 64.30
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 66.20%
Split: 08, Run: 03
None time:  3.0893228477798402
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.20% Test: 62.80%
Split: 09, Run: 01
None time:  2.9331821359228343
None Run 25:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.80
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 66.70%
Split: 09, Run: 02
None time:  2.989074978046119
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.70
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 65.60%
Split: 09, Run: 03
None time:  3.0321476380340755
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.60
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3589408670086414
None Run 28:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.00
Split: 10, Run: 02
None time:  1.2955289238598198
None Run 29:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.00
Split: 10, Run: 03
None time:  1.257172997109592
None Run 30:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.00
run time now: 3.940702199935913
total time:  62.084983746055514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.15 ± 3.85
  Final Train: 100.00 ± 0.00
   Final Test: 62.11 ± 3.53
best run test_acc: 63.47999954223633
[I 2023-06-12 00:16:40,769] Trial 5 finished with value: 63.1533317565918 and parameters: {'Fwd': 9.257274696296488e-06, 'K': 9, 'alpha': 0.75, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.8707029160388124, 'loop': 0, 'loss': 'MSE', 'lr': 0.0001568057356057339, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.599467973446208e-06, 'weightedloss': True}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8500000000000001
lr:  0.0005325620315799111
weight_decay:  0.0914807080677487
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3008017670363188
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02
None time:  0.9628126500174403
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 03
None time:  1.4075222969986498
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2414257021155208
None Run 04:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 62.80
Split: 02, Run: 02
None time:  1.2036833998281509
None Run 05:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 60.10
Split: 02, Run: 03
None time:  1.1886506339069456
None Run 06:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 56.90
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7052011720370501
None Run 07:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.50
Split: 03, Run: 02
None time:  1.4592371608596295
None Run 08:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 56.30
Split: 03, Run: 03
None time:  1.8902330929413438
None Run 09:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.80
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3238525171764195
None Run 10:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.30
Split: 04, Run: 02
None time:  0.9865673531312495
None Run 11:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 59.00
Split: 04, Run: 03
None time:  1.3050295528955758
None Run 12:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 69.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.403099691029638
None Run 13:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 57.90
Split: 05, Run: 02
None time:  1.9996555959805846
None Run 14:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.00
Split: 05, Run: 03
None time:  1.3907958921045065
None Run 15:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 58.70
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2013501739129424
None Run 16:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 49.40
Split: 06, Run: 02
None time:  1.1109606549143791
None Run 17:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 49.10
Split: 06, Run: 03
None time:  0.8735979939810932
None Run 18:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 45.70
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9352786398958415
None Run 19:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 54.90
Split: 07, Run: 02
None time:  1.084307889919728
None Run 20:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 52.50
Split: 07, Run: 03
None time:  1.0177886749152094
None Run 21:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 56.70
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.228884523967281
None Run 22:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.20
Split: 08, Run: 02
None time:  1.3542777651455253
None Run 23:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.40
Split: 08, Run: 03
None time:  1.5161182689480484
None Run 24:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.10
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8619063801597804
None Run 25:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 74.00
Split: 09, Run: 02
None time:  1.859364164993167
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.60
Split: 09, Run: 03
None time:  1.3607281588483602
None Run 27:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4132711980491877
None Run 28:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.50
Split: 10, Run: 02
None time:  1.2792627490125597
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.50
Split: 10, Run: 03
None time:  1.64759650407359
None Run 30:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.60
run time now: 4.365008354187012
total time:  41.07354279886931
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.96 ± 7.19
  Final Train: 100.00 ± 0.00
   Final Test: 62.13 ± 7.90
best run test_acc: 66.06000518798828
[I 2023-06-12 00:17:22,228] Trial 6 finished with value: 62.959999084472656 and parameters: {'Fwd': 0.003322585093288179, 'K': 1, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 0, 'lambda1': 0.25, 'lambda2': 5.831144163208545, 'loop': 2, 'loss': 'CE', 'lr': 0.0005325620315799111, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0914807080677487, 'weightedloss': True}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.65
lr:  0.0004678084226172172
weight_decay:  0.001486619680193441
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.44150757417082787
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 02
None time:  0.430668342160061
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 03
None time:  1.1928770220838487
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.4229886778630316
None Run 04:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.30
Split: 02, Run: 02
None time:  0.415823234943673
None Run 05:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.30
Split: 02, Run: 03
None time:  1.283136504003778
None Run 06:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 73.80
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.42325772414915264
None Run 07:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.40
Split: 03, Run: 02
None time:  0.4365372199099511
None Run 08:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.40
Split: 03, Run: 03
None time:  0.4395721568726003
None Run 09:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5300975770223886
None Run 10:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.50
Split: 04, Run: 02
None time:  0.4761596128810197
None Run 11:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.10
Split: 04, Run: 03
None time:  0.8634317168034613
None Run 12:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.30
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.440412632888183
None Run 13:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.60
Split: 05, Run: 02
None time:  0.4091722429729998
None Run 14:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.60
Split: 05, Run: 03
None time:  0.43146762903779745
None Run 15:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.60
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.43182639800943434
None Run 16:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.90
Split: 06, Run: 02
None time:  0.4582461891695857
None Run 17:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.90
Split: 06, Run: 03
None time:  0.43542121001519263
None Run 18:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.4559572380967438
None Run 19:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.60
Split: 07, Run: 02
None time:  0.4147882980760187
None Run 20:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.60
Split: 07, Run: 03
None time:  0.449734274065122
None Run 21:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.60
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5432018390856683
None Run 22:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 62.80
Split: 08, Run: 02
None time:  1.6859876241069287
None Run 23:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 72.00
Split: 08, Run: 03
None time:  0.6463051559403539
None Run 24:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 72.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.1996847349219024
None Run 25:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.00
Split: 09, Run: 02
None time:  0.5776993532199413
None Run 26:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.30
Split: 09, Run: 03
None time:  0.6325604901649058
None Run 27:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.4158959840424359
None Run 28:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 61.50
Split: 10, Run: 02
None time:  0.42324671894311905
None Run 29:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 61.50
Split: 10, Run: 03
None time:  1.67456368310377
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 75.30
run time now: 2.5451972484588623
total time:  20.760995518183336
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.21 ± 7.02
  Final Train: 100.00 ± 0.00
   Final Test: 64.26 ± 6.89
best run test_acc: 67.83999633789062
[I 2023-06-12 00:17:43,416] Trial 7 finished with value: 65.21333312988281 and parameters: {'Fwd': 0.07109744068896327, 'K': 6, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 0, 'lambda1': 0.05, 'lambda2': 8.759204740099523, 'loop': 2, 'loss': 'CE', 'lr': 0.0004678084226172172, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001486619680193441, 'weightedloss': True}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0004721420116767202
weight_decay:  3.037112208611805e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5143252999987453
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 02
None time:  0.44668465992435813
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  0.4785871950443834
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.3854976010043174
None Run 04:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.20
Split: 02, Run: 02
None time:  0.4498320559505373
None Run 05:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.20
Split: 02, Run: 03
None time:  0.525182694895193
None Run 06:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.20
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4994118979666382
None Run 07:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.90
Split: 03, Run: 02
None time:  0.4791899509727955
None Run 08:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.90
Split: 03, Run: 03
None time:  0.4907565920148045
None Run 09:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5039659400936216
None Run 10:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.60
Split: 04, Run: 02
None time:  0.46575613995082676
None Run 11:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.60
Split: 04, Run: 03
None time:  0.47641886002384126
None Run 12:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.60
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.44436608301475644
None Run 13:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.00
Split: 05, Run: 02
None time:  0.48656240897253156
None Run 14:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.00
Split: 05, Run: 03
None time:  0.5110797509551048
None Run 15:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.00
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.4925004409160465
None Run 16:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 56.30
Split: 06, Run: 02
None time:  0.5051592239178717
None Run 17:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 56.30
Split: 06, Run: 03
None time:  0.4622330688871443
None Run 18:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 56.30
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.4675285890698433
None Run 19:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 65.90
Split: 07, Run: 02
None time:  0.4978794241324067
None Run 20:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 65.90
Split: 07, Run: 03
None time:  0.48901796084828675
None Run 21:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 65.90
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4630265971645713
None Run 22:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.40
Split: 08, Run: 02
None time:  0.4871723079122603
None Run 23:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.40
Split: 08, Run: 03
None time:  0.5014958828687668
None Run 24:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.40
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.4921389939263463
None Run 25:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.40
Split: 09, Run: 02
None time:  0.4753994799684733
None Run 26:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.40
Split: 09, Run: 03
None time:  0.4985837561544031
None Run 27:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 60.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5184594350866973
None Run 28:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 62.10
Split: 10, Run: 02
None time:  0.4805983540136367
None Run 29:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 62.10
Split: 10, Run: 03
None time:  0.49436900997534394
None Run 30:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 62.10
run time now: 1.5261147022247314
total time:  15.00335577595979
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.86 ± 3.91
  Final Train: 100.00 ± 0.00
   Final Test: 61.22 ± 3.45
best run test_acc: 61.25000762939453
[I 2023-06-12 00:17:58,818] Trial 8 finished with value: 61.86000061035156 and parameters: {'Fwd': 0.0040220176756114, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.15000000000000002, 'lambda2': 3.9126470861354576, 'loop': 0, 'loss': 'MSE', 'lr': 0.0004721420116767202, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.037112208611805e-06, 'weightedloss': True}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.2
lr:  0.002268809560794309
weight_decay:  1.6375792695235518e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8051778459921479
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 02
None time:  0.8038718921598047
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 03
None time:  0.8171853590756655
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8094575931318104
None Run 04:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 59.10
Split: 02, Run: 02
None time:  0.8431198350153863
None Run 05:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 61.40
Split: 02, Run: 03
None time:  0.8323314478620887
None Run 06:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.20
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7892594439908862
None Run 07:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.00
Split: 03, Run: 02
None time:  0.7844428869429976
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.50
Split: 03, Run: 03
None time:  0.8737278969492763
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 67.00
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9440708449110389
None Run 10:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.90
Split: 04, Run: 02
None time:  0.8301153620705009
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.70
Split: 04, Run: 03
None time:  0.8364430409856141
None Run 12:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.761763061163947
None Run 13:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 57.30
Split: 05, Run: 02
None time:  0.9167839239817113
None Run 14:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 05, Run: 03
None time:  0.9163621210027486
None Run 15:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8133437868673354
None Run 16:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 54.90
Split: 06, Run: 02
None time:  0.7370821118820459
None Run 17:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 54.90
Split: 06, Run: 03
None time:  0.7970879839267582
None Run 18:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 54.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.76267792400904
None Run 19:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.40
Split: 07, Run: 02
None time:  0.9090599229093641
None Run 20:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.20
Split: 07, Run: 03
None time:  0.8959228950552642
None Run 21:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7937746359966695
None Run 22:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.80
Split: 08, Run: 02
None time:  0.7837759391404688
None Run 23:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.80
Split: 08, Run: 03
None time:  0.7196311578154564
None Run 24:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 58.80
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8498154771514237
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 61.50
Split: 09, Run: 02
None time:  0.8031014450825751
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.80
Split: 09, Run: 03
None time:  0.8050818499177694
None Run 27:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8025070209987462
None Run 28:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 59.50
Split: 10, Run: 02
None time:  0.8364725389983505
None Run 29:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 75.70
Split: 10, Run: 03
None time:  0.890944124897942
None Run 30:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 75.40
run time now: 2.55438232421875
total time:  25.370365486945957
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.51 ± 6.16
  Final Train: 100.00 ± 0.00
   Final Test: 64.78 ± 6.85
best run test_acc: 68.87000274658203
[I 2023-06-12 00:18:24,649] Trial 9 finished with value: 65.50666809082031 and parameters: {'Fwd': 3.398226885728508e-06, 'K': 5, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 5.7626580241220084, 'loop': 1, 'loss': 'CE', 'lr': 0.002268809560794309, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.6375792695235518e-06, 'weightedloss': True}. Best is trial 2 with value: 73.83333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.008938948407786824
weight_decay:  6.728041829013162e-05
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1946244470309466
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  2.1199688429478556
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  2.189090284984559
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3943215841427445
None Run 04:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 75.30
Split: 02, Run: 02
None time:  2.2430022940970957
None Run 05:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.80
Split: 02, Run: 03
None time:  2.3452471429482102
None Run 06:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.974938780069351
None Run 07:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.90
Split: 03, Run: 02
None time:  2.459882813040167
None Run 08:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.40
Split: 03, Run: 03
None time:  2.725260714069009
None Run 09:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.388880031881854
None Run 10:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.50
Split: 04, Run: 02
None time:  2.2734640000853688
None Run 11:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 77.80
Split: 04, Run: 03
None time:  2.5195010660681874
None Run 12:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.30
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.3747267827857286
None Run 13:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.20
Split: 05, Run: 02
None time:  2.2447295328602195
None Run 14:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.00
Split: 05, Run: 03
None time:  2.0484666009433568
None Run 15:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.40
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.372295469045639
None Run 16:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 71.70
Split: 06, Run: 02
None time:  2.524899438023567
None Run 17:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 72.00
Split: 06, Run: 03
None time:  2.2943557060789317
None Run 18:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.3286277782171965
None Run 19:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.20
Split: 07, Run: 02
None time:  2.4646006419789046
None Run 20:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 03
None time:  2.420659305062145
None Run 21:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.60
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.308113422943279
None Run 22:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.40
Split: 08, Run: 02
None time:  2.1306859040632844
None Run 23:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.80
Split: 08, Run: 03
None time:  2.157702217809856
None Run 24:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.90
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.0001987118739635
None Run 25:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.70
Split: 09, Run: 02
None time:  2.186107270885259
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.10
Split: 09, Run: 03
None time:  2.2612766770180315
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.2831937801092863
None Run 28:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.30
Split: 10, Run: 02
None time:  2.1878774110227823
None Run 29:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.20
Split: 10, Run: 03
None time:  2.2290435230825096
None Run 30:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.10
run time now: 6.7302491664886475
total time:  70.13636386091821
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.89 ± 2.55
  Final Train: 100.00 ± 0.00
   Final Test: 73.58 ± 2.27
best run test_acc: 74.45999908447266
[I 2023-06-12 00:19:35,325] Trial 10 finished with value: 73.88667297363281 and parameters: {'Fwd': 8.585928514010522e-05, 'K': 4, 'alpha': 0.0, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 8.346351512067411, 'loop': 0, 'loss': 'CE', 'lr': 0.008938948407786824, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.728041829013162e-05, 'weightedloss': False}. Best is trial 10 with value: 73.88667297363281.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.009120035747227702
weight_decay:  6.554242842515399e-05
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.192001999123022
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 02
None time:  2.125788139179349
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  2.0799361360259354
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1769837189931422
None Run 04:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.90
Split: 02, Run: 02
None time:  2.4025345710106194
None Run 05:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 73.60
Split: 02, Run: 03
None time:  2.292591009987518
None Run 06:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.50
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.4874153018463403
None Run 07:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.90
Split: 03, Run: 02
None time:  2.1668432450387627
None Run 08:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.40
Split: 03, Run: 03
None time:  2.420322722988203
None Run 09:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.2111227728892118
None Run 10:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.80
Split: 04, Run: 02
None time:  2.3737521700095385
None Run 11:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.70
Split: 04, Run: 03
None time:  2.3084417518693954
None Run 12:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 76.80
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.7043472570367157
None Run 13:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.80
Split: 05, Run: 02
None time:  2.439337054034695
None Run 14:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.10
Split: 05, Run: 03
None time:  2.428396173985675
None Run 15:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.388439178932458
None Run 16:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 71.00
Split: 06, Run: 02
None time:  2.3205003801267594
None Run 17:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.40
Split: 06, Run: 03
None time:  2.5793975878041238
None Run 18:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 70.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7375589720904827
None Run 19:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.20
Split: 07, Run: 02
None time:  2.182129400083795
None Run 20:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.50
Split: 07, Run: 03
None time:  2.7014135411009192
None Run 21:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.3300933740101755
None Run 22:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.40
Split: 08, Run: 02
None time:  2.111623315140605
None Run 23:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.80
Split: 08, Run: 03
None time:  2.2784452789928764
None Run 24:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.60
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.306342590833083
None Run 25:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.40
Split: 09, Run: 02
None time:  2.298688628943637
None Run 26:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.00
Split: 09, Run: 03
None time:  2.155786591814831
None Run 27:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.159601296065375
None Run 28:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.80
Split: 10, Run: 02
None time:  2.1211600778624415
None Run 29:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.80
Split: 10, Run: 03
None time:  2.089909164002165
None Run 30:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.40
run time now: 6.39474892616272
total time:  70.13372356491163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.31 ± 2.54
  Final Train: 100.00 ± 0.00
   Final Test: 73.49 ± 2.30
best run test_acc: 74.5999984741211
[I 2023-06-12 00:20:45,922] Trial 11 finished with value: 74.30667114257812 and parameters: {'Fwd': 0.0002118996211598298, 'K': 4, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 8.599818618719352, 'loop': 0, 'loss': 'CE', 'lr': 0.009120035747227702, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.554242842515399e-05, 'weightedloss': False}. Best is trial 11 with value: 74.30667114257812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.008982755958433727
weight_decay:  0.00010322751193824075
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7039739878382534
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 02
None time:  1.5825951281003654
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.5850504599511623
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6639987719245255
None Run 04:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 73.10
Split: 02, Run: 02
None time:  1.8420066419057548
None Run 05:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.00
Split: 02, Run: 03
None time:  1.8690159539692104
None Run 06:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7004512089770287
None Run 07:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 03, Run: 02
None time:  1.5633346631657332
None Run 08:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
Split: 03, Run: 03
None time:  2.114955062046647
None Run 09:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.10
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.9096406800672412
None Run 10:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.80
Split: 04, Run: 02
None time:  2.027411671122536
None Run 11:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.00
Split: 04, Run: 03
None time:  1.9414144400507212
None Run 12:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.70
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.2282328179571778
None Run 13:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 79.00
Split: 05, Run: 02
None time:  2.064495185157284
None Run 14:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.90
Split: 05, Run: 03
None time:  2.055939423153177
None Run 15:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8230826519429684
None Run 16:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 71.60
Split: 06, Run: 02
None time:  2.031786080915481
None Run 17:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.40
Split: 06, Run: 03
None time:  1.9746035081334412
None Run 18:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 70.70
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8722417501267046
None Run 19:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.00
Split: 07, Run: 02
None time:  1.9288573460653424
None Run 20:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.50
Split: 07, Run: 03
None time:  1.8737348460126668
None Run 21:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.70
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9939652690663934
None Run 22:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.20
Split: 08, Run: 02
None time:  1.9593940740451217
None Run 23:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.50
Split: 08, Run: 03
None time:  1.9007073459215462
None Run 24:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.40
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.982963099842891
None Run 25:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.50
Split: 09, Run: 02
None time:  2.094822445884347
None Run 26:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.30
Split: 09, Run: 03
None time:  1.8507069640327245
None Run 27:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.00
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8389170609880239
None Run 28:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.80
Split: 10, Run: 02
None time:  1.9602298268582672
None Run 29:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.90
Split: 10, Run: 03
None time:  1.812558498000726
None Run 30:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.40
run time now: 5.636129140853882
total time:  57.28552752896212
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 2.44
  Final Train: 100.00 ± 0.00
   Final Test: 73.32 ± 2.34
best run test_acc: 74.5
[I 2023-06-12 00:21:43,744] Trial 12 finished with value: 74.26667022705078 and parameters: {'Fwd': 1.3094138374815313e-06, 'K': 3, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 9.965885680851787, 'loop': 0, 'loss': 'CE', 'lr': 0.008982755958433727, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010322751193824075, 'weightedloss': False}. Best is trial 11 with value: 74.30667114257812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.008786329169312844
weight_decay:  0.0006458160140132892
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6934674300719053
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  1.6560001119505614
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.6125881988555193
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.760897328844294
None Run 04:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 73.50
Split: 02, Run: 02
None time:  1.9610025151632726
None Run 05:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 74.20
Split: 02, Run: 03
None time:  1.8477811620105058
None Run 06:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.982155165169388
None Run 07:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.90
Split: 03, Run: 02
None time:  1.7325560019817203
None Run 08:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 03, Run: 03
None time:  2.0247097148094326
None Run 09:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.00
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5545937600545585
None Run 10:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.80
Split: 04, Run: 02
None time:  1.8580656310077757
None Run 11:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.30
Split: 04, Run: 03
None time:  1.811614244012162
None Run 12:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.60
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8569272549357265
None Run 13:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.60
Split: 05, Run: 02
None time:  1.7877969790715724
None Run 14:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.90
Split: 05, Run: 03
None time:  1.9155453231651336
None Run 15:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.70
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8408022900111973
None Run 16:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 70.60
Split: 06, Run: 02
None time:  1.9295721959788352
None Run 17:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.70
Split: 06, Run: 03
None time:  1.8111353260464966
None Run 18:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 70.70
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.080360348103568
None Run 19:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.20
Split: 07, Run: 02
None time:  1.8953573829494417
None Run 20:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.50
Split: 07, Run: 03
None time:  1.79407122801058
None Run 21:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.00
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7233640179038048
None Run 22:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.30
Split: 08, Run: 02
None time:  1.600856659002602
None Run 23:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.40
Split: 08, Run: 03
None time:  1.6057563351932913
None Run 24:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.70
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7277067380491644
None Run 25:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.40
Split: 09, Run: 02
None time:  1.7806848550681025
None Run 26:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.50
Split: 09, Run: 03
None time:  1.5256838370114565
None Run 27:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.658172121969983
None Run 28:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.00
Split: 10, Run: 02
None time:  1.7008822879288346
None Run 29:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.90
Split: 10, Run: 03
None time:  1.5638741420116276
None Run 30:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.50
run time now: 4.945816278457642
total time:  53.82044786307961
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.31 ± 2.49
  Final Train: 100.00 ± 0.00
   Final Test: 73.41 ± 2.37
best run test_acc: 74.52000427246094
[I 2023-06-12 00:22:38,110] Trial 13 finished with value: 74.3066635131836 and parameters: {'Fwd': 1.0273807863726637e-06, 'K': 3, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 9.934776389532727, 'loop': 0, 'loss': 'CE', 'lr': 0.008786329169312844, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006458160140132892, 'weightedloss': False}. Best is trial 11 with value: 74.30667114257812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.004033459759026901
weight_decay:  0.0009246419365497598
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8089017861057073
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 02
None time:  1.8184576970525086
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.5953767849132419
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.845209962921217
None Run 04:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 76.70
Split: 02, Run: 02
None time:  1.9276536211837083
None Run 05:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 79.50
Split: 02, Run: 03
None time:  1.813294016988948
None Run 06:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 75.00
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8426708760671318
None Run 07:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.40
Split: 03, Run: 02
None time:  1.935352786211297
None Run 08:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 03, Run: 03
None time:  1.844358418136835
None Run 09:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.80
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7640545079484582
None Run 10:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.40
Split: 04, Run: 02
None time:  1.8161220860201865
None Run 11:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.60
Split: 04, Run: 03
None time:  1.793136873980984
None Run 12:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.50
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8600543150678277
None Run 13:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.90
Split: 05, Run: 02
None time:  1.923100900836289
None Run 14:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.60
Split: 05, Run: 03
None time:  1.8832804679404944
None Run 15:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.60
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8430102879647166
None Run 16:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 72.40
Split: 06, Run: 02
None time:  1.754538487875834
None Run 17:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.80
Split: 06, Run: 03
None time:  1.816023017046973
None Run 18:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9035827410407364
None Run 19:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.50
Split: 07, Run: 02
None time:  1.934732145164162
None Run 20:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 03
None time:  1.7352260069455951
None Run 21:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.60
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.762130782008171
None Run 22:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.90
Split: 08, Run: 02
None time:  1.8402649250347167
None Run 23:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 74.90
Split: 08, Run: 03
None time:  1.7572643449530005
None Run 24:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.30
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8795796169433743
None Run 25:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.00
Split: 09, Run: 02
None time:  1.7614335329271853
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.70
Split: 09, Run: 03
None time:  1.7532671401277184
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8863366979639977
None Run 28:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 75.20
Split: 10, Run: 02
None time:  1.797255591955036
None Run 29:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.30
Split: 10, Run: 03
None time:  1.9513438849244267
None Run 30:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.60
run time now: 5.6661927700042725
total time:  55.420863235136494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.23 ± 2.92
  Final Train: 100.00 ± 0.00
   Final Test: 73.69 ± 2.75
best run test_acc: 75.05000305175781
[I 2023-06-12 00:23:34,103] Trial 14 finished with value: 74.23332977294922 and parameters: {'Fwd': 1.2838906603358567e-06, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 7.53568389680172, 'loop': 1, 'loss': 'CE', 'lr': 0.004033459759026901, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009246419365497598, 'weightedloss': False}. Best is trial 11 with value: 74.30667114257812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.004473462815418164
weight_decay:  0.0006905816033208258
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.717148591997102
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.7483655461110175
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  1.7616714560426772
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.945941437035799
None Run 04:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 77.20
Split: 02, Run: 02
None time:  1.8001327910460532
None Run 05:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 75.50
Split: 02, Run: 03
None time:  2.013505573151633
None Run 06:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 78.20
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8099495079368353
None Run 07:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 73.00
Split: 03, Run: 02
None time:  1.93143548280932
None Run 08:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.00
Split: 03, Run: 03
None time:  2.196027158992365
None Run 09:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.60
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7323244328144938
None Run 10:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.00
Split: 04, Run: 02
None time:  1.840120234992355
None Run 11:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 78.00
Split: 04, Run: 03
None time:  1.901886855950579
None Run 12:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.50
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.044516579946503
None Run 13:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 76.80
Split: 05, Run: 02
None time:  1.7945356639102101
None Run 14:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.00
Split: 05, Run: 03
None time:  1.76052367198281
None Run 15:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.80
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.1405586150940508
None Run 16:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 70.90
Split: 06, Run: 02
None time:  1.8854704720433801
None Run 17:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.30
Split: 06, Run: 03
None time:  2.048848479986191
None Run 18:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 70.30
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7798211660701782
None Run 19:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.40
Split: 07, Run: 02
None time:  1.9062917470000684
None Run 20:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 03
None time:  1.8324506669305265
None Run 21:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.90
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7694186931475997
None Run 22:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.70
Split: 08, Run: 02
None time:  1.697495664935559
None Run 23:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.20
Split: 08, Run: 03
None time:  1.8784041590988636
None Run 24:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.70
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8104814309626818
None Run 25:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.40
Split: 09, Run: 02
None time:  1.741102801868692
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.50
Split: 09, Run: 03
None time:  1.7468421410303563
None Run 27:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.10
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8138694779481739
None Run 28:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.50
Split: 10, Run: 02
None time:  1.8078656389843673
None Run 29:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 74.20
Split: 10, Run: 03
None time:  1.7738269409164786
None Run 30:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.50
run time now: 5.420905590057373
total time:  56.206536415964365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.46 ± 2.32
  Final Train: 100.00 ± 0.00
   Final Test: 74.06 ± 2.48
best run test_acc: 74.91000366210938
[I 2023-06-12 00:24:30,755] Trial 15 finished with value: 74.45999908447266 and parameters: {'Fwd': 9.846063679086786e-06, 'K': 3, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 9.96022452436573, 'loop': 0, 'loss': 'CE', 'lr': 0.004473462815418164, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006905816033208258, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0035105874898471658
weight_decay:  0.0038693927823565785
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.88990788301453
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 02
None time:  1.9221940748393536
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.9139680690132082
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9926113989204168
None Run 04:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 77.40
Split: 02, Run: 02
None time:  1.9919819259084761
None Run 05:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 76.30
Split: 02, Run: 03
None time:  2.1453848050441593
None Run 06:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 76.40
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.1651040168944746
None Run 07:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 79.00
Split: 03, Run: 02
None time:  1.9968225108459592
None Run 08:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.50
Split: 03, Run: 03
None time:  1.983854993013665
None Run 09:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.9810394051019102
None Run 10:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.90
Split: 04, Run: 02
None time:  1.9815124459564686
None Run 11:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 75.80
Split: 04, Run: 03
None time:  2.051843484165147
None Run 12:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 76.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.019572677090764
None Run 13:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.40
Split: 05, Run: 02
None time:  2.1767773078754544
None Run 14:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.40
Split: 05, Run: 03
None time:  2.0427047279663384
None Run 15:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.40
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.0010400770697743
None Run 16:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 73.00
Split: 06, Run: 02
None time:  2.0208436709363014
None Run 17:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 72.20
Split: 06, Run: 03
None time:  2.014776469906792
None Run 18:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.064775316976011
None Run 19:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.70
Split: 07, Run: 02
None time:  2.0048045099247247
None Run 20:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.60
Split: 07, Run: 03
None time:  1.9046394932083786
None Run 21:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7136400418821722
None Run 22:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 72.80
Split: 08, Run: 02
None time:  1.914175587007776
None Run 23:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 73.20
Split: 08, Run: 03
None time:  2.041808829177171
None Run 24:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 73.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9712756290100515
None Run 25:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.50
Split: 09, Run: 02
None time:  1.9128918659407645
None Run 26:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.90
Split: 09, Run: 03
None time:  2.0973794269375503
None Run 27:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9338001220021397
None Run 28:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.20
Split: 10, Run: 02
None time:  1.9381008280906826
None Run 29:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.30
Split: 10, Run: 03
None time:  1.954704737989232
None Run 30:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.50
run time now: 5.849221706390381
total time:  60.293441938003525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.32 ± 3.03
  Final Train: 100.00 ± 0.00
   Final Test: 73.62 ± 2.63
best run test_acc: 75.30999755859375
[I 2023-06-12 00:25:31,669] Trial 16 finished with value: 74.31999969482422 and parameters: {'Fwd': 1.9904362681401595e-05, 'K': 2, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 7.312219032057492, 'loop': 1, 'loss': 'CE', 'lr': 0.0035105874898471658, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0038693927823565785, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0020079371108232915
weight_decay:  0.0033730310102338466
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.668126706033945
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.6742918081581593
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.7945253811776638
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5643608539830893
None Run 04:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 74.40
Split: 02, Run: 02
None time:  1.8451098080258816
None Run 05:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 77.60
Split: 02, Run: 03
None time:  1.6862150900997221
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 73.10
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8246029689908028
None Run 07:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.40
Split: 03, Run: 02
None time:  1.7607074459083378
None Run 08:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.40
Split: 03, Run: 03
None time:  1.752709622029215
None Run 09:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8276050228159875
None Run 10:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.50
Split: 04, Run: 02
None time:  1.7536721578799188
None Run 11:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.10
Split: 04, Run: 03
None time:  1.8124068931210786
None Run 12:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7103481399826705
None Run 13:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.20
Split: 05, Run: 02
None time:  1.8874419771600515
None Run 14:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.90
Split: 05, Run: 03
None time:  1.8760216049849987
None Run 15:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.00
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8005619191098958
None Run 16:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.40
Split: 06, Run: 02
None time:  1.8096206879708916
None Run 17:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.00
Split: 06, Run: 03
None time:  1.7378666838631034
None Run 18:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 66.80
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8846135509666055
None Run 19:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.20
Split: 07, Run: 02
None time:  1.8718608929775655
None Run 20:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 76.20
Split: 07, Run: 03
None time:  1.7309301199857146
None Run 21:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.60
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8258010239806026
None Run 22:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 75.10
Split: 08, Run: 02
None time:  1.8183049308136106
None Run 23:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 75.30
Split: 08, Run: 03
None time:  1.7657006250228733
None Run 24:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 76.60
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8598009508568794
None Run 25:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.30
Split: 09, Run: 02
None time:  1.909466507146135
None Run 26:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.20
Split: 09, Run: 03
None time:  1.6088187268469483
None Run 27:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.70
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.764296661829576
None Run 28:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.60
Split: 10, Run: 02
None time:  1.871349950088188
None Run 29:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 74.20
Split: 10, Run: 03
None time:  1.806652813917026
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 5.46643328666687
total time:  54.22329784720205
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.95 ± 3.81
  Final Train: 100.00 ± 0.00
   Final Test: 73.04 ± 3.18
best run test_acc: 74.69999694824219
[I 2023-06-12 00:26:26,404] Trial 17 finished with value: 73.95333862304688 and parameters: {'Fwd': 1.009433742571571e-05, 'K': 2, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 6.736974920335992, 'loop': 1, 'loss': 'CE', 'lr': 0.0020079371108232915, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0033730310102338466, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004000898281372252
weight_decay:  0.0033799855055982975
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1582911079749465
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  2.0428542571607977
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  2.057362965075299
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.90
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.2270168270915747
None Run 04:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 74.70
Split: 02, Run: 02
None time:  2.226221919991076
None Run 05:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 76.40
Split: 02, Run: 03
None time:  2.2350696241483092
None Run 06:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 75.70
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.216537162195891
None Run 07:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 72.50
Split: 03, Run: 02
None time:  2.1652308420743793
None Run 08:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.10
Split: 03, Run: 03
None time:  2.053910286864266
None Run 09:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1973295961506665
None Run 10:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.50
Split: 04, Run: 02
None time:  2.2192378060426563
None Run 11:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.40
Split: 04, Run: 03
None time:  2.1759159648790956
None Run 12:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.150394615950063
None Run 13:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.90
Split: 05, Run: 02
None time:  2.256162067176774
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.30
Split: 05, Run: 03
None time:  2.2640933378133923
None Run 15:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.2975609321147203
None Run 16:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.30
Split: 06, Run: 02
None time:  2.1793147320859134
None Run 17:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.10
Split: 06, Run: 03
None time:  2.2455234441440552
None Run 18:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.30
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.2598225618712604
None Run 19:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 72.80
Split: 07, Run: 02
None time:  2.288602865068242
None Run 20:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.40
Split: 07, Run: 03
None time:  2.2796551438514143
None Run 21:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9701836579479277
None Run 22:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.90
Split: 08, Run: 02
None time:  2.3380623678676784
None Run 23:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 73.60
Split: 08, Run: 03
None time:  2.372792860958725
None Run 24:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.30
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.3509510681033134
None Run 25:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 71.80
Split: 09, Run: 02
None time:  2.3027975419536233
None Run 26:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 09, Run: 03
None time:  2.30200967611745
None Run 27:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.272573227994144
None Run 28:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.30
Split: 10, Run: 02
None time:  2.25301114609465
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.40
Split: 10, Run: 03
None time:  2.3013863030355424
None Run 30:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.40
run time now: 6.850535869598389
total time:  67.16272002086043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.45 ± 2.30
  Final Train: 100.00 ± 0.00
   Final Test: 72.57 ± 1.92
best run test_acc: 73.39999389648438
[I 2023-06-12 00:27:34,011] Trial 18 finished with value: 73.45333099365234 and parameters: {'Fwd': 3.276159269609339e-05, 'K': 2, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 6.740483008607055, 'loop': 2, 'loss': 'CE', 'lr': 0.004000898281372252, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0033799855055982975, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0017473262995605777
weight_decay:  0.015190886443745114
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1954227769747376
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.20665924414061
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  1.2441718569025397
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2033001719973981
None Run 04:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 66.50
Split: 02, Run: 02
None time:  1.2516282328870147
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 67.40
Split: 02, Run: 03
None time:  1.322163678938523
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 75.30
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1086789739783853
None Run 07:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.20
Split: 03, Run: 02
None time:  1.474972714902833
None Run 08:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.00
Split: 03, Run: 03
None time:  1.2764628240838647
None Run 09:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 59.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2216784988995641
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 70.10
Split: 04, Run: 02
None time:  1.1972346550319344
None Run 11:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.90
Split: 04, Run: 03
None time:  1.2328295621555299
None Run 12:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.20
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2113745489623398
None Run 13:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.70
Split: 05, Run: 02
None time:  1.3377722220029682
None Run 14:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.30
Split: 05, Run: 03
None time:  1.2846189490519464
None Run 15:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.214547511190176
None Run 16:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.00
Split: 06, Run: 02
None time:  1.2351879959460348
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 63.90
Split: 06, Run: 03
None time:  1.2222795018460602
None Run 18:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 58.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2677374801132828
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
Split: 07, Run: 02
None time:  1.2521491260267794
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.80
Split: 07, Run: 03
None time:  1.2800864658784121
None Run 21:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.80
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2326729770284146
None Run 22:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.50
Split: 08, Run: 02
None time:  1.2416870649904013
None Run 23:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.80
Split: 08, Run: 03
None time:  1.345929613802582
None Run 24:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.10
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1835461638402194
None Run 25:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.20
Split: 09, Run: 02
None time:  1.320585445035249
None Run 26:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.40
Split: 09, Run: 03
None time:  1.292241919087246
None Run 27:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 76.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3402805919758976
None Run 28:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 76.00
Split: 10, Run: 02
None time:  1.2396821910515428
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 71.10
Split: 10, Run: 03
None time:  1.326094799907878
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.932450294494629
total time:  38.25615229201503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.76 ± 5.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 5.51
best run test_acc: 73.69000244140625
[I 2023-06-12 00:28:12,722] Trial 19 finished with value: 69.76000213623047 and parameters: {'Fwd': 3.572315912976417e-06, 'K': 2, 'alpha': 0.9, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 7.788411317481767, 'loop': 1, 'loss': 'CE', 'lr': 0.0017473262995605777, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.015190886443745114, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.0046864560208897685
weight_decay:  0.00027828821536077665
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9072307171300054
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 02
None time:  2.040586539078504
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  2.0452016540803015
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.50
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.177935068961233
None Run 04:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 78.40
Split: 02, Run: 02
None time:  2.1571765411645174
None Run 05:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 76.50
Split: 02, Run: 03
None time:  2.1793127530254424
None Run 06:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.195201403927058
None Run 07:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.70
Split: 03, Run: 02
None time:  1.9763474648352712
None Run 08:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.60
Split: 03, Run: 03
None time:  2.204512253869325
None Run 09:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1306156169157475
None Run 10:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 76.50
Split: 04, Run: 02
None time:  2.1406732958275825
None Run 11:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.50
Split: 04, Run: 03
None time:  2.169188669184223
None Run 12:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.0271525499410927
None Run 13:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 05, Run: 02
None time:  1.9517348951194435
None Run 14:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 76.40
Split: 05, Run: 03
None time:  2.044415049953386
None Run 15:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.109760187799111
None Run 16:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 73.90
Split: 06, Run: 02
None time:  2.050987723050639
None Run 17:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.00
Split: 06, Run: 03
None time:  2.0508462260477245
None Run 18:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 71.40
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.105045098112896
None Run 19:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.90
Split: 07, Run: 02
None time:  1.9654424630571157
None Run 20:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.00
Split: 07, Run: 03
None time:  2.1727956829126924
None Run 21:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.70
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9875466208904982
None Run 22:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.00
Split: 08, Run: 02
None time:  1.9751660600304604
None Run 23:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.80
Split: 08, Run: 03
None time:  1.9340068099554628
None Run 24:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.1510577050503343
None Run 25:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.80
Split: 09, Run: 02
None time:  2.0798679031431675
None Run 26:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.50
Split: 09, Run: 03
None time:  2.090662528993562
None Run 27:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8995753698982298
None Run 28:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
Split: 10, Run: 02
None time:  2.0611031109001487
None Run 29:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.80
Split: 10, Run: 03
None time:  1.9860359709709883
None Run 30:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 5.975351572036743
total time:  62.4645506918896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 1.93
  Final Train: 100.00 ± 0.00
   Final Test: 73.26 ± 2.29
best run test_acc: 74.42000579833984
[I 2023-06-12 00:29:15,728] Trial 20 finished with value: 74.12667083740234 and parameters: {'Fwd': 2.2020051210287004e-05, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 9.241121194111724, 'loop': 1, 'loss': 'CE', 'lr': 0.0046864560208897685, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00027828821536077665, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.35000000000000003
lr:  0.005463651669016262
weight_decay:  3.8592554662740074e-05
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9009070789907128
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 02
None time:  1.8718768551480025
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  1.914046955993399
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.50
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0052182821091264
None Run 04:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.30
Split: 02, Run: 02
None time:  1.963209938025102
None Run 05:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 74.70
Split: 02, Run: 03
None time:  2.323149163974449
None Run 06:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.341991915134713
None Run 07:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 98.57
   Final Test: 75.00
Split: 03, Run: 02
None time:  1.8430707638617605
None Run 08:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.90
Split: 03, Run: 03
None time:  2.0664995859842747
None Run 09:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 74.00
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.9338144641369581
None Run 10:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.70
Split: 04, Run: 02
None time:  2.0794152750167996
None Run 11:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 77.70
Split: 04, Run: 03
None time:  1.9033111028838903
None Run 12:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 78.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1516012570355088
None Run 13:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.50
Split: 05, Run: 02
None time:  2.046650097006932
None Run 14:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.60
Split: 05, Run: 03
None time:  1.9559888581279665
None Run 15:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 74.60
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.04621430602856
None Run 16:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 71.00
Split: 06, Run: 02
None time:  2.0317052889149636
None Run 17:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 71.60
Split: 06, Run: 03
None time:  2.1119723520241678
None Run 18:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 72.20
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.375692127039656
None Run 19:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.80
Split: 07, Run: 02
None time:  2.032656775088981
None Run 20:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.20
Split: 07, Run: 03
None time:  2.1611067219637334
None Run 21:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.80
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9661333609838039
None Run 22:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.90
Split: 08, Run: 02
None time:  1.8885165110696107
None Run 23:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.30
Split: 08, Run: 03
None time:  2.1940688299946487
None Run 24:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.00
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.0489075840450823
None Run 25:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.30
Split: 09, Run: 02
None time:  1.9651271889451891
None Run 26:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.10
Split: 09, Run: 03
None time:  2.0028941431082785
None Run 27:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0487872380763292
None Run 28:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.50
Split: 10, Run: 02
None time:  2.127632124815136
None Run 29:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.20
Split: 10, Run: 03
None time:  2.1899926150217652
None Run 30:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.40
run time now: 6.388993263244629
total time:  62.001707694958895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 2.48
  Final Train: 99.95 ± 0.26
   Final Test: 73.52 ± 2.37
best run test_acc: 74.3499984741211
[I 2023-06-12 00:30:18,233] Trial 21 finished with value: 74.26667022705078 and parameters: {'Fwd': 9.891623821575426e-05, 'K': 4, 'alpha': 0.35000000000000003, 'dropout': 0.1, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 8.801255764960702, 'loop': 0, 'loss': 'CE', 'lr': 0.005463651669016262, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.8592554662740074e-05, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.6000000000000001
lr:  0.002616474429639004
weight_decay:  0.0003119647461187022
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4149050570558757
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.4802788610104471
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  1.4099464300088584
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.50
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.565665140049532
None Run 04:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 77.60
Split: 02, Run: 02
None time:  1.9359159611631185
None Run 05:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.90
Split: 02, Run: 03
None time:  1.564343687146902
None Run 06:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6720602049026638
None Run 07:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.60
Split: 03, Run: 02
None time:  1.7225833169650286
None Run 08:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.40
Split: 03, Run: 03
None time:  1.6535419528372586
None Run 09:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.267803143011406
None Run 10:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.20
Split: 04, Run: 02
None time:  1.525751112960279
None Run 11:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.20
Split: 04, Run: 03
None time:  1.7187463140580803
None Run 12:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 76.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5825318470597267
None Run 13:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 76.30
Split: 05, Run: 02
None time:  1.5056745540350676
None Run 14:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.70
Split: 05, Run: 03
None time:  1.5754542120266706
None Run 15:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6333095799200237
None Run 16:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 71.60
Split: 06, Run: 02
None time:  2.0417231349274516
None Run 17:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.40
Split: 06, Run: 03
None time:  1.559087528148666
None Run 18:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 71.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7050535399466753
None Run 19:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
Split: 07, Run: 02
None time:  1.706950780004263
None Run 20:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 75.30
Split: 07, Run: 03
None time:  1.5946983478497714
None Run 21:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.10
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5099175749346614
None Run 22:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 73.20
Split: 08, Run: 02
None time:  1.533879250055179
None Run 23:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.60
Split: 08, Run: 03
None time:  1.3423630648758262
None Run 24:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.352793708210811
None Run 25:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.90
Split: 09, Run: 02
None time:  1.490036556031555
None Run 26:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.60
Split: 09, Run: 03
None time:  1.444593865890056
None Run 27:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.50
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.7057227750774473
None Run 28:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.10
Split: 10, Run: 02
None time:  1.3933844168204814
None Run 29:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.40
Split: 10, Run: 03
None time:  1.4130186492111534
None Run 30:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 72.20
run time now: 4.543452739715576
total time:  47.58518800185993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.39 ± 2.63
  Final Train: 100.00 ± 0.00
   Final Test: 73.75 ± 2.47
best run test_acc: 74.69999694824219
[I 2023-06-12 00:31:06,399] Trial 22 finished with value: 74.3933334350586 and parameters: {'Fwd': 0.0001613861030027572, 'K': 5, 'alpha': 0.6000000000000001, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 7.905588408785571, 'loop': 0, 'loss': 'CE', 'lr': 0.002616474429639004, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0003119647461187022, 'weightedloss': False}. Best is trial 15 with value: 74.45999908447266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9500000000000001
lr:  0.0025564072090241336
weight_decay:  0.0003172244988498025
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5308843138627708
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  1.4751560729928315
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  1.4759420440532267
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.80
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8401509639807045
None Run 04:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 78.20
Split: 02, Run: 02
None time:  1.8673399738036096
None Run 05:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.60
Split: 02, Run: 03
None time:  1.600552971009165
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 73.70
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6661264079157263
None Run 07:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.40
Split: 03, Run: 02
None time:  1.7240119299385697
None Run 08:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.80
Split: 03, Run: 03
None time:  1.4783269881736487
None Run 09:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5795704708434641
None Run 10:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.70
Split: 04, Run: 02
None time:  1.6062907110899687
None Run 11:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.00
Split: 04, Run: 03
None time:  1.749392222147435
None Run 12:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5879658160265535
None Run 13:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.40
Split: 05, Run: 02
None time:  1.5183386891148984
None Run 14:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.00
Split: 05, Run: 03
None time:  1.5345152909867465
None Run 15:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.50
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5702188939321786
None Run 16:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 71.40
Split: 06, Run: 02
None time:  1.545796164078638
None Run 17:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 06, Run: 03
None time:  1.4713897351175547
None Run 18:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 72.40
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8194561831187457
None Run 19:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.20
Split: 07, Run: 02
None time:  1.6528298170305789
None Run 20:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.00
Split: 07, Run: 03
None time:  1.6141100758686662
None Run 21:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.30
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.450074345804751
None Run 22:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 73.80
Split: 08, Run: 02
None time:  1.5878605088219047
None Run 23:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.30
Split: 08, Run: 03
None time:  1.4389601598959416
None Run 24:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5134825978893787
None Run 25:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.20
Split: 09, Run: 02
None time:  1.509514186065644
None Run 26:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 75.10
Split: 09, Run: 03
None time:  1.5555693770293146
None Run 27:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.00
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.60928074689582
None Run 28:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 74.60
Split: 10, Run: 02
None time:  1.6532949779648334
None Run 29:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.90
Split: 10, Run: 03
None time:  1.4481309128459543
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 72.20
run time now: 4.745274543762207
total time:  48.190898451954126
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 2.77
  Final Train: 100.00 ± 0.00
   Final Test: 74.02 ± 2.48
best run test_acc: 75.30000305175781
[I 2023-06-12 00:31:55,072] Trial 23 finished with value: 74.47334289550781 and parameters: {'Fwd': 4.075607763635856e-05, 'K': 5, 'alpha': 0.9500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 7.848554395563328, 'loop': 0, 'loss': 'CE', 'lr': 0.0025564072090241336, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0003172244988498025, 'weightedloss': False}. Best is trial 23 with value: 74.47334289550781.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.6000000000000001
lr:  0.0014878536583313277
weight_decay:  0.00035803986260899134
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3048682920634747
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  1.3239218550734222
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  1.3453026309143752
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.80
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3087809660937637
None Run 04:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 02
None time:  1.2631587609648705
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.50
Split: 02, Run: 03
None time:  1.381278065033257
None Run 06:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.80
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.295516906073317
None Run 07:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 63.80
Split: 03, Run: 02
None time:  1.3434562007896602
None Run 08:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 61.10
Split: 03, Run: 03
None time:  1.330442211125046
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5100911590270698
None Run 10:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.50
Split: 04, Run: 02
None time:  1.310698804212734
None Run 11:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.20
Split: 04, Run: 03
None time:  1.650614378042519
None Run 12:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.30
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3466915448661894
None Run 13:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.70
Split: 05, Run: 02
None time:  1.4933512161951512
None Run 14:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.80
Split: 05, Run: 03
None time:  1.4438001199159771
None Run 15:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.70
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.34942887397483
None Run 16:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.40
Split: 06, Run: 02
None time:  1.0836436338722706
None Run 17:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 06, Run: 03
None time:  1.226743625011295
None Run 18:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 58.10
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5034742848947644
None Run 19:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.70
Split: 07, Run: 02
None time:  1.413066509179771
None Run 20:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.70
Split: 07, Run: 03
None time:  1.4445405299775302
None Run 21:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3004403861705214
None Run 22:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.70
Split: 08, Run: 02
None time:  1.5159626919776201
None Run 23:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.40
Split: 08, Run: 03
None time:  1.3267426290549338
None Run 24:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.10
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3911890969611704
None Run 25:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.10
Split: 09, Run: 02
None time:  1.4416392829734832
None Run 26:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.40
Split: 09, Run: 03
None time:  1.2754992400296032
None Run 27:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.363422429189086
None Run 28:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.40
Split: 10, Run: 02
None time:  1.4049825121182948
None Run 29:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.90
Split: 10, Run: 03
None time:  1.4496135800145566
None Run 30:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.80
run time now: 4.280120134353638
total time:  41.748153845081106
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.10 ± 5.33
  Final Train: 100.00 ± 0.00
   Final Test: 71.59 ± 5.11
best run test_acc: 74.12001037597656
[I 2023-06-12 00:32:37,370] Trial 24 finished with value: 72.0999984741211 and parameters: {'Fwd': 6.161820025993711e-05, 'K': 5, 'alpha': 0.6000000000000001, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 9.384745763376646, 'loop': 0, 'loss': 'CE', 'lr': 0.0014878536583313277, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00035803986260899134, 'weightedloss': False}. Best is trial 23 with value: 74.47334289550781.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.0027874743836150554
weight_decay:  0.00028868280593086627
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5603807251900434
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 02
None time:  1.5121783898212016
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  1.4499724248889834
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8945749739650637
None Run 04:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 78.40
Split: 02, Run: 02
None time:  1.6362577739637345
None Run 05:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 78.00
Split: 02, Run: 03
None time:  1.568140177987516
None Run 06:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 73.90
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7014553700573742
None Run 07:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.10
Split: 03, Run: 02
None time:  1.6017663741949946
None Run 08:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 72.30
Split: 03, Run: 03
None time:  1.4266407168470323
None Run 09:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5717905049677938
None Run 10:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.80
Split: 04, Run: 02
None time:  1.6384510139469057
None Run 11:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.90
Split: 04, Run: 03
None time:  1.658723120810464
None Run 12:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.30
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.6380910880398005
None Run 13:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.60
Split: 05, Run: 02
None time:  1.5707745179533958
None Run 14:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.40
Split: 05, Run: 03
None time:  1.5478152967989445
None Run 15:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.622528227046132
None Run 16:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 71.00
Split: 06, Run: 02
None time:  1.5896284559275955
None Run 17:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.90
Split: 06, Run: 03
None time:  1.6542445470113307
None Run 18:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6052231499925256
None Run 19:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.60
Split: 07, Run: 02
None time:  1.7833794739563018
None Run 20:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 03
None time:  1.5685736809391528
None Run 21:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6615935119334608
None Run 22:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 74.40
Split: 08, Run: 02
None time:  1.627173257060349
None Run 23:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.00
Split: 08, Run: 03
None time:  1.4952904409728944
None Run 24:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.40
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.518149304902181
None Run 25:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.50
Split: 09, Run: 02
None time:  1.5750109278596938
None Run 26:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.80
Split: 09, Run: 03
None time:  1.5610764229204506
None Run 27:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.5805352898314595
None Run 28:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.60
Split: 10, Run: 02
None time:  1.6976652261801064
None Run 29:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.30
Split: 10, Run: 03
None time:  1.5263695858884603
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 72.30
run time now: 4.830063819885254
total time:  48.57731618802063
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.46 ± 2.72
  Final Train: 100.00 ± 0.00
   Final Test: 74.04 ± 2.50
best run test_acc: 75.08000183105469
[I 2023-06-12 00:33:26,375] Trial 25 finished with value: 74.45999908447266 and parameters: {'Fwd': 0.00012718321825095686, 'K': 7, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 7.723506232054232, 'loop': 0, 'loss': 'CE', 'lr': 0.0027874743836150554, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00028868280593086627, 'weightedloss': False}. Best is trial 23 with value: 74.47334289550781.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0027625909987400122
weight_decay:  2.8818847091938285e-05
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.40% Test: 72.00%
Split: 01, Run: 01
None time:  3.1173621139023453
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.60% Test: 73.30%
Split: 01, Run: 02
None time:  3.540753884939477
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 72.10%
Split: 01, Run: 03
None time:  3.6419612471945584
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.10
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 75.20%
Split: 02, Run: 01
None time:  3.696970108198002
None Run 04:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 75.20
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.80% Test: 75.60%
Split: 02, Run: 02
None time:  3.7274980838410556
None Run 05:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 75.50
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.20% Test: 74.70%
Split: 02, Run: 03
None time:  3.654071698896587
None Run 06:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 74.80
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 71.20%
Split: 03, Run: 01
None time:  3.6844880969729275
None Run 07:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 71.10
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 69.70%
Split: 03, Run: 02
None time:  3.6482738559134305
None Run 08:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.70
Split: 03, Run: 03
None time:  1.6797136799432337
None Run 09:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.30
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 76.30%
Split: 04, Run: 01
None time:  3.7217663400806487
None Run 10:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 76.30
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 75.60%
Split: 04, Run: 02
None time:  3.746248120907694
None Run 11:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 75.50
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 76.50%
Split: 04, Run: 03
None time:  3.6869414770044386
None Run 12:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 76.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 75.30%
Split: 05, Run: 01
None time:  3.643508195877075
None Run 13:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 75.20
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 75.10%
Split: 05, Run: 02
None time:  3.678218818968162
None Run 14:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.90
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.20% Test: 75.30%
Split: 05, Run: 03
None time:  3.6959245428442955
None Run 15:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 75.00
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 71.10%
Split: 06, Run: 01
None time:  3.512769300956279
None Run 16:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.10
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.20% Test: 72.10%
Split: 06, Run: 02
None time:  3.745386094087735
None Run 17:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.00
Split: 06, Run: 03
None time:  1.6790930330753326
None Run 18:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6945250190328807
None Run 19:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.80% Test: 75.50%
Split: 07, Run: 02
None time:  3.6809298410080373
None Run 20:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 75.40
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.20% Test: 75.20%
Split: 07, Run: 03
None time:  3.6492692758329213
None Run 21:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6172215109691024
None Run 22:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 75.50
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.40% Test: 75.10%
Split: 08, Run: 02
None time:  3.672173049999401
None Run 23:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 74.90
Split: 08, Run: 03
None time:  1.5951446099206805
None Run 24:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 75.50
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 71.50%
Split: 09, Run: 01
None time:  3.6857005760539323
None Run 25:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.50
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 70.90%
Split: 09, Run: 02
None time:  3.4352304658386856
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.80
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 70.80%
Split: 09, Run: 03
None time:  3.6739144949242473
None Run 27:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.70
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 73.40%
Split: 10, Run: 01
None time:  3.630653902189806
None Run 28:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.40
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.20% Test: 73.90%
Split: 10, Run: 02
None time:  3.6809704748447984
None Run 29:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.10
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 74.20%
Split: 10, Run: 03
None time:  3.3213098749984056
None Run 30:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 74.10
run time now: 10.659765243530273
total time:  99.39653851091862
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.43 ± 2.74
  Final Train: 100.00 ± 0.00
   Final Test: 73.57 ± 2.06
best run test_acc: 74.01000213623047
[I 2023-06-12 00:35:06,219] Trial 26 finished with value: 73.43333435058594 and parameters: {'Fwd': 3.317806184942163e-05, 'K': 7, 'alpha': 0.9, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.212941791285985, 'loop': 0, 'loss': 'MSE', 'lr': 0.0027625909987400122, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8818847091938285e-05, 'weightedloss': False}. Best is trial 23 with value: 74.47334289550781.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.0014536095853015284
weight_decay:  0.000188213568797121
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1091409409418702
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  1.0713294791057706
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.083468671888113
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.50
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0968301098328084
None Run 04:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 02
None time:  1.1302069020457566
None Run 05:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 03
None time:  1.0637203070800751
None Run 06:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 67.50
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2764010429382324
None Run 07:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.70
Split: 03, Run: 02
None time:  1.3241430141497403
None Run 08:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.70
Split: 03, Run: 03
None time:  1.3337631199974567
None Run 09:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.70
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.20%
Split: 04, Run: 01
None time:  3.098029162036255
None Run 10:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.20%
Split: 04, Run: 02
None time:  3.0558285370934755
None Run 11:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.20%
Split: 04, Run: 03
None time:  3.0606457870453596
None Run 12:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0865012221038342
None Run 13:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.90
Split: 05, Run: 02
None time:  1.1030802500899881
None Run 14:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.90
Split: 05, Run: 03
None time:  1.063435056945309
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.90
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.041670739883557
None Run 16:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 62.70
Split: 06, Run: 02
None time:  1.0013391398824751
None Run 17:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 62.70
Split: 06, Run: 03
None time:  1.03774005593732
None Run 18:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 62.70
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.947343269828707
None Run 19:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.40
Split: 07, Run: 02
None time:  0.9485135779250413
None Run 20:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.40
Split: 07, Run: 03
None time:  0.9360932388808578
None Run 21:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3107358501292765
None Run 22:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.10
Split: 08, Run: 02
None time:  1.3238665219396353
None Run 23:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.10
Split: 08, Run: 03
None time:  1.2867845818400383
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.10
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0158135020174086
None Run 25:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.70
Split: 09, Run: 02
None time:  0.9906361529137939
None Run 26:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.70
Split: 09, Run: 03
None time:  0.8750351890921593
None Run 27:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.70
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9866268469486386
None Run 28:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.30
Split: 10, Run: 02
None time:  1.0492220630403608
None Run 29:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.30
Split: 10, Run: 03
None time:  1.0732221771031618
None Run 30:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.30
run time now: 3.153038740158081
total time:  39.296272333944216
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.98 ± 3.41
  Final Train: 100.00 ± 0.00
   Final Test: 65.58 ± 2.28
best run test_acc: 65.57999420166016
[I 2023-06-12 00:35:45,952] Trial 27 finished with value: 65.97999572753906 and parameters: {'Fwd': 7.396116625479727e-06, 'K': 7, 'alpha': 0.75, 'dropout': 0.6000000000000001, 'gnnepoch': 40, 'lambda1': 0.0, 'lambda2': 9.049974470917673, 'loop': 0, 'loss': 'CE', 'lr': 0.0014536095853015284, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000188213568797121, 'weightedloss': False}. Best is trial 23 with value: 74.47334289550781.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.005514584957353101
weight_decay:  0.0005651439290567973
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.662054339190945
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 02
None time:  1.6299998690374196
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 03
None time:  1.584986377041787
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.70
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7143586198799312
None Run 04:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 79.70
Split: 02, Run: 02
None time:  1.7714256921317428
None Run 05:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 78.20
Split: 02, Run: 03
None time:  1.8233266728930175
None Run 06:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 74.00
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7526787030510604
None Run 07:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.90
Split: 03, Run: 02
None time:  1.7365640262141824
None Run 08:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.40
Split: 03, Run: 03
None time:  1.7217736330348998
None Run 09:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.60
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.670257139019668
None Run 10:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.80
Split: 04, Run: 02
None time:  1.4886253271251917
None Run 11:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.30
Split: 04, Run: 03
None time:  1.594939508009702
None Run 12:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.40
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.628360090078786
None Run 13:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.60
Split: 05, Run: 02
None time:  1.6851270229090005
None Run 14:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.60
Split: 05, Run: 03
None time:  1.6726163341663778
None Run 15:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.80
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6427562409080565
None Run 16:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 72.50
Split: 06, Run: 02
None time:  1.7235209660138935
None Run 17:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 72.10
Split: 06, Run: 03
None time:  1.6632354687899351
None Run 18:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 73.10
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8699716441333294
None Run 19:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.70
Split: 07, Run: 02
None time:  1.7104847161099315
None Run 20:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 76.90
Split: 07, Run: 03
None time:  1.6147111640311778
None Run 21:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6504008469637483
None Run 22:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.60
Split: 08, Run: 02
None time:  1.6313815289177
None Run 23:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.60
Split: 08, Run: 03
None time:  1.5816560229286551
None Run 24:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3967317519709468
None Run 25:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.30
Split: 09, Run: 02
None time:  1.5880172359757125
None Run 26:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.80
Split: 09, Run: 03
None time:  1.7279574221465737
None Run 27:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6584721240215003
None Run 28:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.90
Split: 10, Run: 02
None time:  2.509365402860567
None Run 29:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.10
Split: 10, Run: 03
None time:  1.6330725101288408
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.30
run time now: 5.830535650253296
total time:  51.27014108304866
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.51 ± 2.60
  Final Train: 100.00 ± 0.00
   Final Test: 74.12 ± 2.45
best run test_acc: 75.31999206542969
[I 2023-06-12 00:36:37,664] Trial 28 finished with value: 74.5133285522461 and parameters: {'Fwd': 5.6378565161894736e-05, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.892839242708195, 'loop': 0, 'loss': 'CE', 'lr': 0.005514584957353101, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005651439290567973, 'weightedloss': False}. Best is trial 28 with value: 74.5133285522461.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.006066297930945572
weight_decay:  0.00014104665052334253
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1628712099045515
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 02
None time:  1.1545911100693047
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 74.30%
Split: 01, Run: 03
None time:  3.467367087956518
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.40
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 76.10%
Split: 02, Run: 01
None time:  3.4817259509582072
None Run 04:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 76.10
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.40% Test: 74.60%
Split: 02, Run: 02
None time:  3.461480472004041
None Run 05:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 74.30
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 76.40%
Split: 02, Run: 03
None time:  3.5041171291377395
None Run 06:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 76.30
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 72.40%
Split: 03, Run: 01
None time:  3.4364031990990043
None Run 07:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 72.30
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 71.80%
Split: 03, Run: 02
None time:  3.464031184092164
None Run 08:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 71.70
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 71.90%
Split: 03, Run: 03
None time:  3.2515095369890332
None Run 09:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 76.30%
Split: 04, Run: 01
None time:  3.5898713059723377
None Run 10:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 76.30
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.60% Test: 77.80%
Split: 04, Run: 02
None time:  3.49368814798072
None Run 11:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.80
Split: 04, Run: 03
None time:  1.0988260060548782
None Run 12:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 75.90
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 74.90%
Split: 05, Run: 01
None time:  3.3642686158418655
None Run 13:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.90
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 73.90%
Split: 05, Run: 02
None time:  3.416655675973743
None Run 14:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.80
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 75.60%
Split: 05, Run: 03
None time:  3.5672419799957424
None Run 15:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 75.70
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1755186847876757
None Run 16:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.10
Split: 06, Run: 02
None time:  1.1795073298271745
None Run 17:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.80
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 71.20%
Split: 06, Run: 03
None time:  3.482507001841441
None Run 18:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 77.00%
Split: 07, Run: 01
None time:  3.4187050361651927
None Run 19:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.90
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.80% Test: 77.10%
Split: 07, Run: 02
None time:  3.316137344110757
None Run 20:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.10
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.60% Test: 75.30%
Split: 07, Run: 03
None time:  3.468626002082601
None Run 21:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.80% Test: 75.40%
Split: 08, Run: 01
None time:  3.408165972912684
None Run 22:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.60
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.60% Test: 75.20%
Split: 08, Run: 02
None time:  3.4740467709489167
None Run 23:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 75.10
Split: 08, Run: 03
None time:  1.2146004340611398
None Run 24:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 75.30
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 69.80%
Split: 09, Run: 01
None time:  3.4513709989842027
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.80
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 70.90%
Split: 09, Run: 02
None time:  3.46849605999887
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.80
Split: 09, Run: 03
None time:  1.1441920190118253
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.30
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1421798209194094
None Run 28:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.90
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.60% Test: 73.30%
Split: 10, Run: 02
None time:  3.386857341043651
None Run 29:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.30
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 74.30%
Split: 10, Run: 03
None time:  3.42877663183026
None Run 30:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.30
run time now: 7.999284982681274
total time:  85.63199175801128
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.59 ± 3.06
  Final Train: 100.00 ± 0.00
   Final Test: 73.96 ± 2.24
best run test_acc: 74.81999206542969
[I 2023-06-12 00:38:03,818] Trial 29 finished with value: 73.59333801269531 and parameters: {'Fwd': 0.00044025392549512844, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.15000000000000002, 'lambda2': 9.945831997241768, 'loop': 0, 'loss': 'MSE', 'lr': 0.006066297930945572, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014104665052334253, 'weightedloss': False}. Best is trial 28 with value: 74.5133285522461.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.001126575529583951
weight_decay:  0.0006801231478603375
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.345374854048714
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  2.135229910025373
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  2.220215694978833
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4165258530993015
None Run 04:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 75.50
Split: 02, Run: 02
None time:  2.4232771748211235
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 73.30
Split: 02, Run: 03
None time:  2.255302082048729
None Run 06:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.3282594280317426
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.40
Split: 03, Run: 02
None time:  2.3103400780819356
None Run 08:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.50
Split: 03, Run: 03
None time:  2.305969636887312
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 67.50
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.429405701113865
None Run 10:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 76.60
Split: 04, Run: 02
None time:  2.3073558129835874
None Run 11:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 75.60
Split: 04, Run: 03
None time:  2.3047730741091073
None Run 12:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.70
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.996811836026609
None Run 13:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.60
Split: 05, Run: 02
None time:  2.310117576038465
None Run 14:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 70.10
Split: 05, Run: 03
None time:  2.351232481887564
None Run 15:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.70
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.2205917600076646
None Run 16:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 68.10
Split: 06, Run: 02
None time:  2.4325474589131773
None Run 17:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.50
Split: 06, Run: 03
None time:  2.484873594949022
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.501857026014477
None Run 19:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.30
Split: 07, Run: 02
None time:  2.4901492749340832
None Run 20:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.60
Split: 07, Run: 03
None time:  2.541289222892374
None Run 21:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.4379757849965245
None Run 22:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.10
Split: 08, Run: 02
None time:  2.582412311108783
None Run 23:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.20
Split: 08, Run: 03
None time:  2.374550868058577
None Run 24:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.90
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.49116386892274
None Run 25:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.10
Split: 09, Run: 02
None time:  2.4321271770168096
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.60
Split: 09, Run: 03
None time:  2.4141799388453364
None Run 27:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.456247144145891
None Run 28:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.20
Split: 10, Run: 02
None time:  2.4967651260085404
None Run 29:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 75.30
Split: 10, Run: 03
None time:  2.4660623141098768
None Run 30:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.50
run time now: 7.445909738540649
total time:  71.83855862612836
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.51 ± 4.41
  Final Train: 100.00 ± 0.00
   Final Test: 73.16 ± 3.64
best run test_acc: 74.91999816894531
[I 2023-06-12 00:39:16,093] Trial 30 finished with value: 73.50666809082031 and parameters: {'Fwd': 6.23082810711632e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 9.421057041594562, 'loop': 1, 'loss': 'CE', 'lr': 0.001126575529583951, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006801231478603375, 'weightedloss': False}. Best is trial 28 with value: 74.5133285522461.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0032438064394938932
weight_decay:  0.0004021259895471451
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6634887929540128
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 02
None time:  1.7028865590691566
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  1.6583480490371585
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.866556306136772
None Run 04:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 78.70
Split: 02, Run: 02
None time:  1.8489324739202857
None Run 05:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 78.80
Split: 02, Run: 03
None time:  1.7241797330789268
None Run 06:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 74.80
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7738391410093755
None Run 07:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 74.80
Split: 03, Run: 02
None time:  1.8525531669147313
None Run 08:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.20
Split: 03, Run: 03
None time:  1.7609068700112402
None Run 09:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6867457400076091
None Run 10:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 78.50
Split: 04, Run: 02
None time:  1.753719808999449
None Run 11:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 77.50
Split: 04, Run: 03
None time:  1.8861687660682946
None Run 12:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.90
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7987338188104331
None Run 13:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.70
Split: 05, Run: 02
None time:  1.5609006120357662
None Run 14:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.40
Split: 05, Run: 03
None time:  1.6963637541048229
None Run 15:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.80
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7212219738867134
None Run 16:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 71.70
Split: 06, Run: 02
None time:  1.7726975979749113
None Run 17:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.20
Split: 06, Run: 03
None time:  1.8399153330828995
None Run 18:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7852029411587864
None Run 19:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.70
Split: 07, Run: 02
None time:  1.7830072150100023
None Run 20:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 03
None time:  1.672767078038305
None Run 21:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.90
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6996163250878453
None Run 22:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 74.20
Split: 08, Run: 02
None time:  1.7513203250709921
None Run 23:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 72.70
Split: 08, Run: 03
None time:  1.7055786701384932
None Run 24:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.80
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.706576350145042
None Run 25:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.60
Split: 09, Run: 02
None time:  1.6946512858849019
None Run 26:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.00
Split: 09, Run: 03
None time:  1.7709294860251248
None Run 27:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 74.70
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.7567228151019663
None Run 28:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 74.20
Split: 10, Run: 02
None time:  1.7614679550752044
None Run 29:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.30
Split: 10, Run: 03
None time:  1.712348410859704
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.70
run time now: 5.256962776184082
total time:  52.95780527195893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.55 ± 2.61
  Final Train: 100.00 ± 0.00
   Final Test: 74.29 ± 2.52
best run test_acc: 75.4800033569336
[I 2023-06-12 00:40:09,444] Trial 31 finished with value: 74.55333709716797 and parameters: {'Fwd': 3.0033306553848524e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.49219339111891, 'loop': 0, 'loss': 'CE', 'lr': 0.0032438064394938932, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004021259895471451, 'weightedloss': False}. Best is trial 31 with value: 74.55333709716797.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.006137660275307383
weight_decay:  0.0016834440750106113
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8033186469692737
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 02
None time:  1.7180610389914364
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  1.6483832439407706
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.70
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9028971220832318
None Run 04:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 79.70
Split: 02, Run: 02
None time:  1.810101123061031
None Run 05:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 78.00
Split: 02, Run: 03
None time:  1.9187346759717911
None Run 06:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 74.30
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.9143945849500597
None Run 07:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.50
Split: 03, Run: 02
None time:  1.7795402130577713
None Run 08:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.10
Split: 03, Run: 03
None time:  1.8735844939947128
None Run 09:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.30
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.831227757036686
None Run 10:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.30
Split: 04, Run: 02
None time:  1.722959497012198
None Run 11:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.50
Split: 04, Run: 03
None time:  1.7199897679965943
None Run 12:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.60
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8266431100200862
None Run 13:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.20
Split: 05, Run: 02
None time:  1.7461329600773752
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.00
Split: 05, Run: 03
None time:  1.7628988118376583
None Run 15:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.70
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.762152241077274
None Run 16:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 71.90
Split: 06, Run: 02
None time:  1.8186818668618798
None Run 17:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 71.90
Split: 06, Run: 03
None time:  1.8327583149075508
None Run 18:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 72.40
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.208748097065836
None Run 19:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.80
Split: 07, Run: 02
None time:  1.8961785780265927
None Run 20:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 76.70
Split: 07, Run: 03
None time:  1.8787129379343241
None Run 21:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.20
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7542331379372627
None Run 22:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.50
Split: 08, Run: 02
None time:  1.7159374819602817
None Run 23:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.30
Split: 08, Run: 03
None time:  1.7344596590846777
None Run 24:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7152329171076417
None Run 25:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.90
Split: 09, Run: 02
None time:  1.7513510088901967
None Run 26:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.70
Split: 09, Run: 03
None time:  1.7554741268977523
None Run 27:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.30
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6268510399386287
None Run 28:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.20
Split: 10, Run: 02
None time:  1.6358090960420668
None Run 29:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.30
Split: 10, Run: 03
None time:  1.74786834907718
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.10
run time now: 5.036050796508789
total time:  54.34444900415838
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.40 ± 2.56
  Final Train: 100.00 ± 0.00
   Final Test: 73.78 ± 2.68
best run test_acc: 74.87999725341797
[I 2023-06-12 00:41:04,235] Trial 32 finished with value: 74.4000015258789 and parameters: {'Fwd': 3.478799258763817e-05, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.46905186213095, 'loop': 0, 'loss': 'CE', 'lr': 0.006137660275307383, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0016834440750106113, 'weightedloss': False}. Best is trial 31 with value: 74.55333709716797.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.003316615535860193
weight_decay:  0.0005948199718800954
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4596491290722042
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 02
None time:  1.5247118941042572
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 03
None time:  1.469871467910707
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.00
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.517698827199638
None Run 04:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 75.10
Split: 02, Run: 02
None time:  1.5485208749305457
None Run 05:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 76.40
Split: 02, Run: 03
None time:  1.5347102619707584
None Run 06:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 74.20
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6501643110532314
None Run 07:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.40
Split: 03, Run: 02
None time:  1.4796826280653477
None Run 08:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.50
Split: 03, Run: 03
None time:  1.5336009350139648
None Run 09:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.60
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7771837629843503
None Run 10:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 76.80
Split: 04, Run: 02
None time:  1.3465062340255827
None Run 11:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.90
Split: 04, Run: 03
None time:  1.5155065949074924
None Run 12:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 78.30
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.488615893991664
None Run 13:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.70
Split: 05, Run: 02
None time:  1.7882648499216884
None Run 14:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.90
Split: 05, Run: 03
None time:  1.5015169000253081
None Run 15:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 76.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4859067250508815
None Run 16:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 72.40
Split: 06, Run: 02
None time:  1.4641852150671184
None Run 17:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 72.40
Split: 06, Run: 03
None time:  1.9197707260027528
None Run 18:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.413801752962172
None Run 19:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.20
Split: 07, Run: 02
None time:  1.9352475348860025
None Run 20:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.00
Split: 07, Run: 03
None time:  1.193792093778029
None Run 21:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.70
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3560202340595424
None Run 22:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.30
Split: 08, Run: 02
None time:  1.4719486681278795
None Run 23:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.50
Split: 08, Run: 03
None time:  1.4334595350082964
None Run 24:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 73.60
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4630436489824206
None Run 25:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 75.40
Split: 09, Run: 02
None time:  1.4370804789941758
None Run 26:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.60
Split: 09, Run: 03
None time:  1.4059150060638785
None Run 27:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2263539819978178
None Run 28:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.10
Split: 10, Run: 02
None time:  1.99387285602279
None Run 29:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 76.90
Split: 10, Run: 03
None time:  1.5483347801491618
None Run 30:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.60
run time now: 4.7955827713012695
total time:  46.44795203092508
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.22 ± 3.12
  Final Train: 100.00 ± 0.00
   Final Test: 74.55 ± 2.80
best run test_acc: 75.91000366210938
[I 2023-06-12 00:41:51,168] Trial 33 finished with value: 75.22000122070312 and parameters: {'Fwd': 2.162673276377633e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.349643124136097, 'loop': 0, 'loss': 'CE', 'lr': 0.003316615535860193, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005948199718800954, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0032232411403135494
weight_decay:  0.00016991374562425472
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4206585430074483
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.2255020460579544
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 03
None time:  1.3162862800527364
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.70
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.20% Test: 75.30%
Split: 02, Run: 01
None time:  3.555915026925504
None Run 04:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 75.50
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.60% Test: 75.40%
Split: 02, Run: 02
None time:  3.528901089914143
None Run 05:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 75.40
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.20% Test: 75.10%
Split: 02, Run: 03
None time:  3.608830679906532
None Run 06:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 71.00%
Split: 03, Run: 01
None time:  3.595899833831936
None Run 07:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 71.00
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 70.40%
Split: 03, Run: 02
None time:  3.573225607862696
None Run 08:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.80
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 71.50%
Split: 03, Run: 03
None time:  3.494090160820633
None Run 09:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 71.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 76.60%
Split: 04, Run: 01
None time:  3.517298833001405
None Run 10:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 76.60
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 75.70%
Split: 04, Run: 02
None time:  3.562545951223001
None Run 11:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 75.60
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 75.10%
Split: 04, Run: 03
None time:  3.570632772985846
None Run 12:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 75.60%
Split: 05, Run: 01
None time:  3.504565562820062
None Run 13:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 75.50
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 76.00%
Split: 05, Run: 02
None time:  3.518106766976416
None Run 14:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 76.00
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 76.30%
Split: 05, Run: 03
None time:  3.49810141697526
None Run 15:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 76.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 71.00%
Split: 06, Run: 01
None time:  3.4877641438506544
None Run 16:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.00
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 70.80%
Split: 06, Run: 02
None time:  3.502767967991531
None Run 17:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.70
Split: 06, Run: 03
None time:  1.3563190398272127
None Run 18:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.80% Test: 75.80%
Split: 07, Run: 01
None time:  3.473688940051943
None Run 19:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.70
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 76.90%
Split: 07, Run: 02
None time:  3.5308960068505257
None Run 20:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.90
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.00% Test: 74.30%
Split: 07, Run: 03
None time:  2.6828680231701583
None Run 21:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.30
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 81.40% Test: 76.50%
Split: 08, Run: 01
None time:  3.3229502509348094
None Run 22:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 76.60
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.80% Test: 75.60%
Split: 08, Run: 02
None time:  3.234582853037864
None Run 23:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 75.40
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.00% Test: 76.50%
Split: 08, Run: 03
None time:  3.341572473058477
None Run 24:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 76.40
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.20% Test: 72.60%
Split: 09, Run: 01
None time:  3.337077054893598
None Run 25:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.60
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 72.40%
Split: 09, Run: 02
None time:  3.306289402069524
None Run 26:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.40
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.20% Test: 72.50%
Split: 09, Run: 03
None time:  3.2739842948503792
None Run 27:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 73.30%
Split: 10, Run: 01
None time:  3.25887051015161
None Run 28:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.30
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 74.40%
Split: 10, Run: 02
None time:  3.264411665033549
None Run 29:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.30
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.60% Test: 73.50%
Split: 10, Run: 03
None time:  3.3037127119023353
None Run 30:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.30
run time now: 9.853723287582397
total time:  94.6739529541228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.90 ± 2.92
  Final Train: 100.00 ± 0.00
   Final Test: 73.89 ± 2.15
best run test_acc: 74.52000427246094
[I 2023-06-12 00:43:26,334] Trial 34 finished with value: 73.9000015258789 and parameters: {'Fwd': 4.490195035930188e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 9.104079690740711, 'loop': 0, 'loss': 'MSE', 'lr': 0.0032232411403135494, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00016991374562425472, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.002217324980098342
weight_decay:  0.0005005790381243236
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4219548380933702
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 02
None time:  1.5217377638909966
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.421199443982914
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.70
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4211423660162836
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 72.10
Split: 02, Run: 02
None time:  1.5345967030152678
None Run 05:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.40
Split: 02, Run: 03
None time:  1.2277345289476216
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5270658750087023
None Run 07:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.40
Split: 03, Run: 02
None time:  1.4497852011118084
None Run 08:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 03
None time:  1.5250869831070304
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.30
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5620729350484908
None Run 10:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.60
Split: 04, Run: 02
None time:  1.8606847091577947
None Run 11:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 75.90
Split: 04, Run: 03
None time:  1.7485967201646417
None Run 12:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4813717200886458
None Run 13:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.80
Split: 05, Run: 02
None time:  1.7893239329569042
None Run 14:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 77.70
Split: 05, Run: 03
None time:  2.448293286142871
None Run 15:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.24490787088871
None Run 16:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.80
Split: 06, Run: 02
None time:  2.047652843873948
None Run 17:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 70.70
Split: 06, Run: 03
None time:  1.5251996079459786
None Run 18:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 66.30
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5592100569047034
None Run 19:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.80
Split: 07, Run: 02
None time:  1.7305592400953174
None Run 20:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.00
Split: 07, Run: 03
None time:  1.4052453339099884
None Run 21:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.60
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4682514478918165
None Run 22:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.10
Split: 08, Run: 02
None time:  1.5064363479614258
None Run 23:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.80
Split: 08, Run: 03
None time:  1.4610054010991007
None Run 24:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.40
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.547087028855458
None Run 25:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.10
Split: 09, Run: 02
None time:  1.426419059978798
None Run 26:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 75.00
Split: 09, Run: 03
None time:  1.4533641550224274
None Run 27:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.512083865934983
None Run 28:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 10, Run: 02
None time:  1.8112057240214199
None Run 29:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 76.80
Split: 10, Run: 03
None time:  1.5770480711944401
None Run 30:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.10
run time now: 4.928454875946045
total time:  48.74973434396088
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.96 ± 3.89
  Final Train: 100.00 ± 0.00
   Final Test: 73.64 ± 3.67
best run test_acc: 75.6199951171875
[I 2023-06-12 00:44:15,531] Trial 35 finished with value: 73.95999908447266 and parameters: {'Fwd': 1.7794596840315468e-05, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 8.29527709779895, 'loop': 0, 'loss': 'CE', 'lr': 0.002217324980098342, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005005790381243236, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.003223192783355221
weight_decay:  0.001038697576566456
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.678221900947392
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  0.702415038831532
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  0.6906569418497384
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.80
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6977794929407537
None Run 04:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 61.50
Split: 02, Run: 02
None time:  0.5999983618967235
None Run 05:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 61.50
Split: 02, Run: 03
None time:  0.678526340983808
None Run 06:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 61.50
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5629296370316297
None Run 07:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.50
Split: 03, Run: 02
None time:  0.6502851941622794
None Run 08:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.50
Split: 03, Run: 03
None time:  0.6191325220279396
None Run 09:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.50
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6915040570311248
None Run 10:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.10
Split: 04, Run: 02
None time:  0.6726917279884219
None Run 11:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.10
Split: 04, Run: 03
None time:  0.6160094940569252
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7463700908701867
None Run 13:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.80
Split: 05, Run: 02
None time:  0.6390800869558007
None Run 14:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.70
Split: 05, Run: 03
None time:  0.6943768460769206
None Run 15:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.70
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6743778539821506
None Run 16:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 57.20
Split: 06, Run: 02
None time:  0.6731438608840108
None Run 17:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 57.20
Split: 06, Run: 03
None time:  0.66996187902987
None Run 18:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 57.20
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6662355118896812
None Run 19:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 66.40
Split: 07, Run: 02
None time:  0.6796097541227937
None Run 20:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 66.40
Split: 07, Run: 03
None time:  0.6741863100323826
None Run 21:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 66.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6553735940251499
None Run 22:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.20
Split: 08, Run: 02
None time:  0.6929559409618378
None Run 23:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.20
Split: 08, Run: 03
None time:  0.7106614790391177
None Run 24:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.679568252991885
None Run 25:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.00
Split: 09, Run: 02
None time:  0.6784131019376218
None Run 26:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.00
Split: 09, Run: 03
None time:  0.6963336749467999
None Run 27:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.00
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6926494429353625
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 71.10
Split: 10, Run: 02
None time:  0.7384477769955993
None Run 29:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.20
Split: 10, Run: 03
None time:  0.660617555025965
None Run 30:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.1219053268432617
total time:  21.137011729879305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.27 ± 3.92
  Final Train: 100.00 ± 0.00
   Final Test: 62.76 ± 4.12
best run test_acc: 63.07999801635742
[I 2023-06-12 00:44:37,161] Trial 36 finished with value: 63.27333068847656 and parameters: {'Fwd': 9.459325397052039e-05, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.30000000000000004, 'lambda2': 9.352847283778612, 'loop': 0, 'loss': 'CE', 'lr': 0.003223192783355221, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001038697576566456, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.00103745948241455
weight_decay:  0.00041077745906873726
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4422810620162636
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  1.3899002871476114
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 03
None time:  1.4238250439520925
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4019473909866065
None Run 04:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.50
Split: 02, Run: 02
None time:  1.428283531917259
None Run 05:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 75.60
Split: 02, Run: 03
None time:  1.4571010048966855
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 72.00
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3712779029738158
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.80
Split: 03, Run: 02
None time:  1.4079685369506478
None Run 08:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.00
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 67.20%
Split: 03, Run: 03
None time:  3.522880263160914
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.20
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 74.80%
Split: 04, Run: 01
None time:  3.3801180061418563
None Run 10:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 74.60
Split: 04, Run: 02
None time:  1.4740166920237243
None Run 11:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 73.40
Split: 04, Run: 03
None time:  1.459699409082532
None Run 12:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 73.90
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 72.70%
Split: 05, Run: 01
None time:  3.3022606801241636
None Run 13:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.20
Split: 05, Run: 02
None time:  1.4585580909624696
None Run 14:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.50
Split: 05, Run: 03
None time:  1.4211046500131488
None Run 15:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 69.90%
Split: 06, Run: 01
None time:  3.472329509910196
None Run 16:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.10
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.80%
Split: 06, Run: 02
None time:  3.196592116029933
None Run 17:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.00% Test: 69.00%
Split: 06, Run: 03
None time:  3.4476834621746093
None Run 18:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.00
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.60% Test: 77.30%
Split: 07, Run: 01
None time:  3.3890680340118706
None Run 19:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.80
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.00% Test: 74.90%
Split: 07, Run: 02
None time:  3.5273453020490706
None Run 20:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.70
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.20% Test: 77.10%
Split: 07, Run: 03
None time:  3.4660585538949817
None Run 21:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.70
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.20% Test: 76.30%
Split: 08, Run: 01
None time:  3.4776375971268862
None Run 22:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.30
Split: 08, Run: 02
None time:  1.4615776729770005
None Run 23:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.70
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 74.50%
Split: 08, Run: 03
None time:  3.483578101033345
None Run 24:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 74.70
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 76.50%
Split: 09, Run: 01
None time:  3.5208990019746125
None Run 25:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.40
Split: 09, Run: 02
None time:  1.419648437993601
None Run 26:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.60
Split: 09, Run: 03
None time:  1.2275566949974746
None Run 27:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.50
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3987143421545625
None Run 28:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.90
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.40% Test: 74.20%
Split: 10, Run: 02
None time:  3.4088733119424433
None Run 29:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.10
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.80% Test: 75.00%
Split: 10, Run: 03
None time:  3.4665040930267423
None Run 30:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 75.00
run time now: 8.30072546005249
total time:  71.20110133709386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.09 ± 3.78
  Final Train: 100.00 ± 0.00
   Final Test: 72.97 ± 2.93
best run test_acc: 74.31999969482422
[I 2023-06-12 00:45:48,870] Trial 37 finished with value: 73.09333801269531 and parameters: {'Fwd': 0.00031842832953484586, 'K': 8, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 6.998171214713898, 'loop': 0, 'loss': 'MSE', 'lr': 0.00103745948241455, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00041077745906873726, 'weightedloss': True}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0008099863609170014
weight_decay:  0.0001186107901474079
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2774122098926455
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.2340611978434026
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.3299682170618325
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.40
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2691005740780383
None Run 04:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.10
Split: 02, Run: 02
None time:  1.302140365820378
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 67.10
Split: 02, Run: 03
None time:  1.3143964170012623
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0453026660252362
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.60
Split: 03, Run: 02
None time:  1.6198223021347076
None Run 08:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 66.20
Split: 03, Run: 03
None time:  1.6723000679630786
None Run 09:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4038597559556365
None Run 10:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.70
Split: 04, Run: 02
None time:  1.6245820440817624
None Run 11:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.90
Split: 04, Run: 03
None time:  1.5410622719209641
None Run 12:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.367506843060255
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.90
Split: 05, Run: 02
None time:  1.8671216720249504
None Run 14:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 74.00
Split: 05, Run: 03
None time:  1.6869362390134484
None Run 15:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 74.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.378677680855617
None Run 16:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 64.50
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.60% Test: 66.80%
Split: 06, Run: 02
None time:  3.397268012864515
None Run 17:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 66.70
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 64.60%
Split: 06, Run: 03
None time:  3.0031371540389955
None Run 18:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 64.30
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.192307021934539
None Run 19:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.50
Split: 07, Run: 02
None time:  1.9394220679532737
None Run 20:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.80
Split: 07, Run: 03
None time:  1.4961444798391312
None Run 21:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 75.00
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.516180485021323
None Run 22:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.80
Split: 08, Run: 02
None time:  2.9769059021491557
None Run 23:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.40
Split: 08, Run: 03
None time:  1.9234814278315753
None Run 24:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.00
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2816537939943373
None Run 25:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.20
Split: 09, Run: 02
None time:  1.8172113420441747
None Run 26:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.20
Split: 09, Run: 03
None time:  2.32376320194453
None Run 27:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.70
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4109126180410385
None Run 28:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.90
Split: 10, Run: 02
None time:  1.9672727561555803
None Run 29:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.50
Split: 10, Run: 03
None time:  1.398742564022541
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.801841974258423
total time:  53.147462961031124
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.28 ± 3.85
  Final Train: 100.00 ± 0.00
   Final Test: 70.62 ± 3.64
best run test_acc: 72.72999572753906
[I 2023-06-12 00:46:42,520] Trial 38 finished with value: 71.27999877929688 and parameters: {'Fwd': 5.323948944354865e-05, 'K': 7, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.05, 'lambda2': 8.091401545722574, 'loop': 0, 'loss': 'CE', 'lr': 0.0008099863609170014, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001186107901474079, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.006976362606824773
weight_decay:  0.0016293592076178757
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.156949354801327
None Run 01:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 02
None time:  1.2280403161421418
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.57
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.1083571179769933
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.40
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2061186591163278
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 71.40
Split: 02, Run: 02
None time:  1.1936641610227525
None Run 05:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.20
Split: 02, Run: 03
None time:  1.0926885900553316
None Run 06:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 72.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.038621996063739
None Run 07:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.50
Split: 03, Run: 02
None time:  1.1365924950223416
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.40
Split: 03, Run: 03
None time:  1.096109070116654
None Run 09:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.60
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2545646710786968
None Run 10:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.80
Split: 04, Run: 02
None time:  1.132734894985333
None Run 11:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.90
Split: 04, Run: 03
None time:  1.1347504539880902
None Run 12:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3140356219373643
None Run 13:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.10
Split: 05, Run: 02
None time:  1.0914421319030225
None Run 14:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 63.50
Split: 05, Run: 03
None time:  1.0946768429130316
None Run 15:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 70.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.139248216059059
None Run 16:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 66.30
Split: 06, Run: 02
None time:  1.1069606579840183
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.60
Split: 06, Run: 03
None time:  1.147543763043359
None Run 18:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2979689710773528
None Run 19:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.20
Split: 07, Run: 02
None time:  1.08599977591075
None Run 20:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 07, Run: 03
None time:  1.1161719779483974
None Run 21:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.266256630886346
None Run 22:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.40
Split: 08, Run: 02
None time:  1.0815527979284525
None Run 23:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.20
Split: 08, Run: 03
None time:  1.2009856011718512
None Run 24:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1172496529761702
None Run 25:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.50
Split: 09, Run: 02
None time:  1.0417667299043387
None Run 26:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.00
Split: 09, Run: 03
None time:  0.9990194588899612
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1048214219044894
None Run 28:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 75.40
Split: 10, Run: 02
None time:  1.1135272728279233
None Run 29:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.00
Split: 10, Run: 03
None time:  1.0964830790180713
None Run 30:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 62.90
run time now: 3.342761754989624
total time:  34.7575143519789
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.65 ± 5.10
  Final Train: 99.95 ± 0.26
   Final Test: 69.77 ± 4.91
best run test_acc: 73.55999755859375
[I 2023-06-12 00:47:17,843] Trial 39 finished with value: 69.65333557128906 and parameters: {'Fwd': 0.0001623216058297578, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.735006385154385, 'loop': 1, 'loss': 'CE', 'lr': 0.006976362606824773, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0016293592076178757, 'weightedloss': True}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.003667529835593077
weight_decay:  0.00022268732618502176
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.80% Test: 76.80%
Split: 01, Run: 01
None time:  2.2448809610214084
None Run 01:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 73.30%
Split: 01, Run: 02
None time:  2.1670574960298836
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 03
None time:  1.075803594198078
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9742301090154797
None Run 04:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 77.00
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.40% Test: 81.50%
Split: 02, Run: 02
None time:  2.2939590541645885
None Run 05:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 81.50
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.40% Test: 79.00%
Split: 02, Run: 03
None time:  2.2261201781220734
None Run 06:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 79.00
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.928312508855015
None Run 07:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 74.30
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 75.10%
Split: 03, Run: 02
None time:  2.0755524900741875
None Run 08:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 75.10
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 72.60%
Split: 03, Run: 03
None time:  2.109379098052159
None Run 09:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 72.30
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 71.20%
Split: 04, Run: 01
None time:  2.097082511987537
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 71.20
Split: 04, Run: 02
None time:  0.9590052289422601
None Run 11:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.30
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 74.90%
Split: 04, Run: 03
None time:  2.1371344120707363
None Run 12:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.70
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 74.10%
Split: 05, Run: 01
None time:  2.1601754440926015
None Run 13:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.90
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.40% Test: 74.20%
Split: 05, Run: 02
None time:  2.0894740181975067
None Run 14:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.20
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.00% Test: 74.20%
Split: 05, Run: 03
None time:  2.0242133459541947
None Run 15:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 71.60%
Split: 06, Run: 01
None time:  2.0816749990917742
None Run 16:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.70
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.80% Test: 73.00%
Split: 06, Run: 02
None time:  2.1057773928623646
None Run 17:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 72.90
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.40% Test: 74.60%
Split: 06, Run: 03
None time:  2.155665749916807
None Run 18:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 74.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 72.70%
Split: 07, Run: 01
None time:  2.0821393688675016
None Run 19:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.80
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 74.50%
Split: 07, Run: 02
None time:  2.102108370978385
None Run 20:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.50
Split: 07, Run: 03
None time:  0.9737623108085245
None Run 21:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.60
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0643341389950365
None Run 22:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.60
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 72.00%
Split: 08, Run: 02
None time:  2.166033928981051
None Run 23:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.00
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.40% Test: 74.60%
Split: 08, Run: 03
None time:  2.1022067531012
None Run 24:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 74.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.40% Test: 74.40%
Split: 09, Run: 01
None time:  2.1129663619212806
None Run 25:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.50
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 74.30%
Split: 09, Run: 02
None time:  2.122539726085961
None Run 26:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.20
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.40% Test: 73.70%
Split: 09, Run: 03
None time:  2.0876964849885553
None Run 27:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.70
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 76.70%
Split: 10, Run: 01
None time:  2.053148102015257
None Run 28:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 76.70
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 74.90%
Split: 10, Run: 02
None time:  2.1976024301256984
None Run 29:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 74.90
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 73.70%
Split: 10, Run: 03
None time:  2.065677964827046
None Run 30:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.30
run time now: 6.341455459594727
total time:  57.784521457972005
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.59 ± 1.91
  Final Train: 100.00 ± 0.00
   Final Test: 74.56 ± 2.11
best run test_acc: 75.84000396728516
[I 2023-06-12 00:48:16,076] Trial 40 finished with value: 74.58666229248047 and parameters: {'Fwd': 0.0007830595152623301, 'K': 6, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 6.32754224158475, 'loop': 0, 'loss': 'MSE', 'lr': 0.003667529835593077, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00022268732618502176, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.004946273789068204
weight_decay:  0.0001831238172362074
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.20% Test: 77.30%
Split: 01, Run: 01
None time:  2.0984212851617485
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.00% Test: 71.70%
Split: 01, Run: 02
None time:  2.139228524873033
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 68.70%
Split: 01, Run: 03
None time:  2.134238436119631
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.70
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.40% Test: 76.50%
Split: 02, Run: 01
None time:  2.0467300140298903
None Run 04:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 76.50
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 77.40%
Split: 02, Run: 02
None time:  2.0029288469813764
None Run 05:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 77.40
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.60% Test: 73.90%
Split: 02, Run: 03
None time:  2.060071876971051
None Run 06:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 74.20
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 74.40%
Split: 03, Run: 01
None time:  2.1112523251213133
None Run 07:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 74.40
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 75.70%
Split: 03, Run: 02
None time:  2.089367949170992
None Run 08:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 75.60
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 72.40%
Split: 03, Run: 03
None time:  2.141659551067278
None Run 09:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 72.40%
Split: 04, Run: 01
None time:  2.073572247987613
None Run 10:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.40
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.00% Test: 73.90%
Split: 04, Run: 02
None time:  2.254938486032188
None Run 11:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.50
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.40% Test: 72.20%
Split: 04, Run: 03
None time:  2.186805088073015
None Run 12:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.60% Test: 75.40%
Split: 05, Run: 01
None time:  2.154209326952696
None Run 13:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.30
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.40% Test: 75.00%
Split: 05, Run: 02
None time:  2.179619616828859
None Run 14:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 75.00
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 75.10%
Split: 05, Run: 03
None time:  2.1531360850203782
None Run 15:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9939924031496048
None Run 16:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.10
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 67.70%
Split: 06, Run: 02
None time:  2.2872735888231546
None Run 17:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.70
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.80% Test: 71.60%
Split: 06, Run: 03
None time:  2.192137751961127
None Run 18:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.60
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.20% Test: 72.70%
Split: 07, Run: 01
None time:  2.1729129089508206
None Run 19:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.60
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 76.20%
Split: 07, Run: 02
None time:  2.293511122930795
None Run 20:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.20
Split: 07, Run: 03
None time:  1.0775471269153059
None Run 21:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.80% Test: 74.50%
Split: 08, Run: 01
None time:  2.219177593011409
None Run 22:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 74.50
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.80% Test: 74.60%
Split: 08, Run: 02
None time:  2.229265599977225
None Run 23:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 74.50
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.20% Test: 75.60%
Split: 08, Run: 03
None time:  2.1850928319618106
None Run 24:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.60
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 72.40%
Split: 09, Run: 01
None time:  2.2206045109778643
None Run 25:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.40
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 74.00%
Split: 09, Run: 02
None time:  2.1631495931651443
None Run 26:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.00
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 72.30%
Split: 09, Run: 03
None time:  2.256289141951129
None Run 27:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.20
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 71.80%
Split: 10, Run: 01
None time:  1.9503928010817617
None Run 28:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 72.20
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.10%
Split: 10, Run: 02
None time:  2.1789813979994506
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.10
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 71.10%
Split: 10, Run: 03
None time:  2.229143399046734
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 71.00
run time now: 6.397062063217163
total time:  62.973023316822946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.61 ± 2.98
  Final Train: 100.00 ± 0.00
   Final Test: 73.21 ± 3.04
best run test_acc: 74.98999786376953
[I 2023-06-12 00:49:19,581] Trial 41 finished with value: 73.61332702636719 and parameters: {'Fwd': 0.0011701775066513618, 'K': 6, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 7.25610637640709, 'loop': 0, 'loss': 'MSE', 'lr': 0.004946273789068204, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0001831238172362074, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0037485360317785718
weight_decay:  0.00042491191752429654
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0043859540019184
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.40% Test: 73.80%
Split: 01, Run: 02
None time:  2.496664194855839
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.60% Test: 75.30%
Split: 01, Run: 03
None time:  2.5039541218429804
None Run 03:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0174205179791898
None Run 04:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 78.50
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.40% Test: 77.60%
Split: 02, Run: 02
None time:  2.510867987992242
None Run 05:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.90
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.60% Test: 77.60%
Split: 02, Run: 03
None time:  2.449135195929557
None Run 06:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 77.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9435862659011036
None Run 07:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.90
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 72.80%
Split: 03, Run: 02
None time:  2.5317629259079695
None Run 08:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 72.80
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 71.70%
Split: 03, Run: 03
None time:  2.481661655008793
None Run 09:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.60
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 76.30%
Split: 04, Run: 01
None time:  2.2781410210300237
None Run 10:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 76.20
Split: 04, Run: 02
None time:  0.959165430162102
None Run 11:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.90
Split: 04, Run: 03
None time:  0.9356038649566472
None Run 12:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.80
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.20% Test: 72.80%
Split: 05, Run: 01
None time:  2.3575392868369818
None Run 13:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.80
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.60% Test: 77.00%
Split: 05, Run: 02
None time:  2.382929306011647
None Run 14:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.00
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 76.30%
Split: 05, Run: 03
None time:  2.3355541019700468
None Run 15:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 76.40
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 71.10%
Split: 06, Run: 01
None time:  2.3613238900434226
None Run 16:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.00
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.80% Test: 69.90%
Split: 06, Run: 02
None time:  2.3746962652076036
None Run 17:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.90
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 68.20%
Split: 06, Run: 03
None time:  2.3564631110057235
None Run 18:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.80
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.00% Test: 73.70%
Split: 07, Run: 01
None time:  2.336085488088429
None Run 19:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.70
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.00% Test: 73.90%
Split: 07, Run: 02
None time:  2.3894799249246716
None Run 20:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.40
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.00% Test: 77.30%
Split: 07, Run: 03
None time:  2.335916806012392
None Run 21:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.30
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 73.90%
Split: 08, Run: 01
None time:  2.5133249300997704
None Run 22:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.50
Split: 08, Run: 02
None time:  0.8954252270050347
None Run 23:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 75.10
Split: 08, Run: 03
None time:  0.8186205709353089
None Run 24:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.40% Test: 71.80%
Split: 09, Run: 01
None time:  2.3360715871676803
None Run 25:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.80
Split: 09, Run: 02
None time:  0.9417158397845924
None Run 26:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.40% Test: 72.60%
Split: 09, Run: 03
None time:  2.3440879930276424
None Run 27:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.60
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9279818129725754
None Run 28:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.30
Split: 10, Run: 02
None time:  0.8499211880844086
None Run 29:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.50
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.10%
Split: 10, Run: 03
None time:  2.267250595148653
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.074662923812866
total time:  57.74810750503093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.91 ± 2.99
  Final Train: 100.00 ± 0.00
   Final Test: 73.46 ± 3.39
best run test_acc: 74.98999786376953
[I 2023-06-12 00:50:17,854] Trial 42 finished with value: 73.913330078125 and parameters: {'Fwd': 3.227032053648096e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 7.969571548183423, 'loop': 0, 'loss': 'MSE', 'lr': 0.0037485360317785718, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00042491191752429654, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.7000000000000001
lr:  0.0029740995046769717
weight_decay:  0.00022618068728373788
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.20% Test: 72.80%
Split: 01, Run: 01
None time:  1.9237140850163996
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 02
None time:  0.7831953710410744
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.40% Test: 73.60%
Split: 01, Run: 03
None time:  1.908136076061055
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.60
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8243174431845546
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 75.00
Split: 02, Run: 02
None time:  0.8343152331653982
None Run 05:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 76.50
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.80% Test: 78.40%
Split: 02, Run: 03
None time:  1.9016191980335861
None Run 06:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 78.00
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.00% Test: 59.10%
Split: 03, Run: 01
None time:  1.98886448610574
None Run 07:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 58.90
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.80% Test: 76.40%
Split: 03, Run: 02
None time:  1.997535350965336
None Run 08:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 76.20
Split: 03, Run: 03
None time:  0.8468057019636035
None Run 09:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 73.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.00% Test: 69.20%
Split: 04, Run: 01
None time:  1.8395147018600255
None Run 10:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 69.20
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.40% Test: 66.30%
Split: 04, Run: 02
None time:  1.9462372758425772
None Run 11:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 66.40
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 69.70%
Split: 04, Run: 03
None time:  1.8784256679937243
None Run 12:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.70
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 71.10%
Split: 05, Run: 01
None time:  1.893352247076109
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.40
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.60% Test: 75.70%
Split: 05, Run: 02
None time:  1.9509041109122336
None Run 14:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.60
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.80% Test: 75.20%
Split: 05, Run: 03
None time:  1.9974031751044095
None Run 15:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 74.90
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.00% Test: 68.80%
Split: 06, Run: 01
None time:  1.9796258111018687
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 68.60
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.50%
Split: 06, Run: 02
None time:  1.898750833934173
None Run 17:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.60% Test: 72.90%
Split: 06, Run: 03
None time:  1.9510664360132068
None Run 18:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.00
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7284590438939631
None Run 19:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 64.00
Split: 07, Run: 02
None time:  0.7937385800760239
None Run 20:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.30
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 74.20%
Split: 07, Run: 03
None time:  1.9336960262153298
None Run 21:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.20
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7738404821138829
None Run 22:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 74.30
Split: 08, Run: 02
None time:  0.8195585259236395
None Run 23:
Highest Train: 100.00
Highest Valid: 84.60
  Final Train: 100.00
   Final Test: 77.50
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 81.80% Test: 77.00%
Split: 08, Run: 03
None time:  1.865515073062852
None Run 24:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.10
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.80% Test: 76.20%
Split: 09, Run: 01
None time:  1.7594339719507843
None Run 25:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.80
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 75.20%
Split: 09, Run: 02
None time:  1.8483452429063618
None Run 26:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.20
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.40% Test: 77.10%
Split: 09, Run: 03
None time:  1.9340197059791535
None Run 27:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.00
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 75.20%
Split: 10, Run: 01
None time:  1.8149731829762459
None Run 28:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 75.20
Split: 10, Run: 02
None time:  0.798868804005906
None Run 29:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.80
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 74.10%
Split: 10, Run: 03
None time:  1.9171535139903426
None Run 30:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.70
run time now: 4.556575775146484
total time:  47.87545454897918
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.95 ± 5.58
  Final Train: 100.00 ± 0.00
   Final Test: 72.73 ± 4.38
best run test_acc: 75.11000061035156
[I 2023-06-12 00:51:06,279] Trial 43 finished with value: 72.94666290283203 and parameters: {'Fwd': 1.727606445811118e-05, 'K': 6, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 6.460158229133177, 'loop': 0, 'loss': 'MSE', 'lr': 0.0029740995046769717, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00022618068728373788, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9500000000000001
lr:  0.00475723488771979
weight_decay:  8.282314290416435e-05
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 74.70%
Split: 01, Run: 01
None time:  1.7868085000663996
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 73.80%
Split: 01, Run: 02
None time:  1.754966292064637
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.00% Test: 75.20%
Split: 01, Run: 03
None time:  1.5160820700693876
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7867801918182522
None Run 04:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 76.00
Split: 02, Run: 02
None time:  0.7574639909435064
None Run 05:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 77.80
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.60% Test: 77.70%
Split: 02, Run: 03
None time:  1.7213831602130085
None Run 06:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 77.50
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7176135249901563
None Run 07:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 72.50%
Split: 03, Run: 02
None time:  1.7473895691800863
None Run 08:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 72.50
Split: 03, Run: 03
None time:  0.7859059788752347
None Run 09:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 72.00
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 71.90%
Split: 04, Run: 01
None time:  1.7109612470958382
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 72.10
Split: 04, Run: 02
None time:  0.7640423211269081
None Run 11:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 74.50
Split: 04, Run: 03
None time:  0.6932504600845277
None Run 12:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.90
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 67.60%
Split: 05, Run: 01
None time:  1.710986491991207
None Run 13:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.60
Split: 05, Run: 02
None time:  0.7846986760850996
None Run 14:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.50
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 71.30%
Split: 05, Run: 03
None time:  1.8094503169413656
None Run 15:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 71.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7324385829269886
None Run 16:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.40
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.60% Test: 69.00%
Split: 06, Run: 02
None time:  1.7301989630796015
None Run 17:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.50
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.00% Test: 71.10%
Split: 06, Run: 03
None time:  1.726393569028005
None Run 18:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7810117031913251
None Run 19:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 63.20
Split: 07, Run: 02
None time:  0.8088656929321587
None Run 20:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.80
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.60% Test: 75.50%
Split: 07, Run: 03
None time:  1.746901186183095
None Run 21:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 75.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.00% Test: 71.40%
Split: 08, Run: 01
None time:  1.726353714009747
None Run 22:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.10
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 71.30%
Split: 08, Run: 02
None time:  1.6938980740960687
None Run 23:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.00
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.40% Test: 72.30%
Split: 08, Run: 03
None time:  1.6962269770447165
None Run 24:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.60% Test: 74.90%
Split: 09, Run: 01
None time:  1.7159908569883555
None Run 25:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.70
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 71.50%
Split: 09, Run: 02
None time:  1.7395378381479532
None Run 26:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.50
Split: 09, Run: 03
None time:  0.7936084191314876
None Run 27:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.50
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7151841309387237
None Run 28:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.60
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 70.80%
Split: 10, Run: 02
None time:  1.7637716471217573
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.90
Split: 10, Run: 03
None time:  0.7420613630674779
None Run 30:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.251403331756592
total time:  39.738023459911346
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.06 ± 3.44
  Final Train: 100.00 ± 0.00
   Final Test: 71.92 ± 3.48
best run test_acc: 73.83000183105469
[I 2023-06-12 00:51:46,511] Trial 44 finished with value: 72.05998992919922 and parameters: {'Fwd': 0.0002756054837073971, 'K': 5, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 4.883269839637186, 'loop': 0, 'loss': 'MSE', 'lr': 0.00475723488771979, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.282314290416435e-05, 'weightedloss': True}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.006993366857028564
weight_decay:  0.0010620385882610546
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9733808289747685
None Run 01:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  0.9946874659508467
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.0622286039870232
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.958525727968663
None Run 04:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 77.20
Split: 02, Run: 02
None time:  0.9975686261896044
None Run 05:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 79.80
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.80% Test: 76.50%
Split: 02, Run: 03
None time:  2.440970493014902
None Run 06:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 76.30
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 75.30%
Split: 03, Run: 01
None time:  2.412493416108191
None Run 07:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 75.20
Split: 03, Run: 02
None time:  0.9947544671595097
None Run 08:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.10
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 74.00%
Split: 03, Run: 03
None time:  2.4500821330584586
None Run 09:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 73.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0338134139310569
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 72.50
Split: 04, Run: 02
None time:  1.005311283050105
None Run 11:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 72.90
Split: 04, Run: 03
None time:  1.0456459480337799
None Run 12:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.80% Test: 74.00%
Split: 05, Run: 01
None time:  2.381530305137858
None Run 13:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.90
Split: 05, Run: 02
None time:  1.0993851129896939
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.40% Test: 77.80%
Split: 05, Run: 03
None time:  2.441063764039427
None Run 15:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.60
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.06771547999233
None Run 16:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.40
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 71.10%
Split: 06, Run: 02
None time:  2.406441204017028
None Run 17:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.10
Split: 06, Run: 03
None time:  0.9939534279983491
None Run 18:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 72.90%
Split: 07, Run: 01
None time:  2.3730714248958975
None Run 19:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.80
Split: 07, Run: 02
None time:  0.8702527268324047
None Run 20:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.30
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 74.50%
Split: 07, Run: 03
None time:  2.440453713061288
None Run 21:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.50
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9898588240612298
None Run 22:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.40
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 81.60% Test: 77.70%
Split: 08, Run: 02
None time:  2.4472743950318545
None Run 23:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.70
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.40% Test: 77.40%
Split: 08, Run: 03
None time:  2.4212718750350177
None Run 24:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.40
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0739100920036435
None Run 25:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.20
Split: 09, Run: 02
None time:  1.0404508931096643
None Run 26:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.20
Split: 09, Run: 03
None time:  1.0072704020421952
None Run 27:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.60
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9960939351003617
None Run 28:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.10
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.90%
Split: 10, Run: 02
None time:  2.374591015977785
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.80
Split: 10, Run: 03
None time:  0.9656331019941717
None Run 30:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 4.362231492996216
total time:  46.270350717939436
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.01 ± 3.28
  Final Train: 100.00 ± 0.00
   Final Test: 73.72 ± 3.33
best run test_acc: 75.36000061035156
[I 2023-06-12 00:52:33,261] Trial 45 finished with value: 74.0133285522461 and parameters: {'Fwd': 7.69808781977752e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.548459305049684, 'loop': 0, 'loss': 'MSE', 'lr': 0.006993366857028564, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0010620385882610546, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.65
lr:  0.0024745329853939593
weight_decay:  5.480787193713073e-05
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6990971530321985
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.10
Split: 01, Run: 02
None time:  0.6827737907879055
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.10
Split: 01, Run: 03
None time:  0.7025716609787196
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.10
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6728996599558741
None Run 04:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.40
Split: 02, Run: 02
None time:  0.6502981591038406
None Run 05:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.40
Split: 02, Run: 03
None time:  0.6413635879289359
None Run 06:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.40
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7320119519717991
None Run 07:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.40
Split: 03, Run: 02
None time:  0.701600732980296
None Run 08:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.40
Split: 03, Run: 03
None time:  0.6714929880108684
None Run 09:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6932555618695915
None Run 10:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.00
Split: 04, Run: 02
None time:  0.7055197348818183
None Run 11:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 63.40
Split: 04, Run: 03
None time:  0.831367488950491
None Run 12:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.20
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6635274030268192
None Run 13:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 58.80
Split: 05, Run: 02
None time:  0.7485958919860423
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 05, Run: 03
None time:  0.6393933789804578
None Run 15:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 58.80
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6704802771564573
None Run 16:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.50
Split: 06, Run: 02
None time:  0.6954321388620883
None Run 17:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.50
Split: 06, Run: 03
None time:  0.6158359439577907
None Run 18:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.50
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6861878868658096
None Run 19:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.70
Split: 07, Run: 02
None time:  0.680460361065343
None Run 20:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.70
Split: 07, Run: 03
None time:  0.6574489420745522
None Run 21:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.70
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6414947342127562
None Run 22:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.70
Split: 08, Run: 02
None time:  0.6726770428940654
None Run 23:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.70
Split: 08, Run: 03
None time:  0.6603957039769739
None Run 24:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.70
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7091365361120552
None Run 25:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.70
Split: 09, Run: 02
None time:  0.5753468649927527
None Run 26:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.30
Split: 09, Run: 03
None time:  0.8218878679908812
None Run 27:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6026760048698634
None Run 28:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.10
Split: 10, Run: 02
None time:  0.6493948912248015
None Run 29:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.10
Split: 10, Run: 03
None time:  0.7615603259764612
None Run 30:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.10
run time now: 2.03593111038208
total time:  21.133484203135595
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.29 ± 5.12
  Final Train: 100.00 ± 0.00
   Final Test: 61.31 ± 4.29
best run test_acc: 62.72999954223633
[I 2023-06-12 00:52:54,925] Trial 46 finished with value: 62.2933349609375 and parameters: {'Fwd': 0.00012368459194890544, 'K': 6, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 7.3360077752188015, 'loop': 0, 'loss': 'CE', 'lr': 0.0024745329853939593, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.480787193713073e-05, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0037216539930043212
weight_decay:  1.993539970361874e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0291054639965296
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 02
None time:  2.0534843609202653
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 03
None time:  2.046290242811665
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1929682118352503
None Run 04:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 75.70
Split: 02, Run: 02
None time:  2.1306208218447864
None Run 05:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 76.20
Split: 02, Run: 03
None time:  2.115648726001382
None Run 06:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 76.40
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.2684178499039263
None Run 07:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 76.40
Split: 03, Run: 02
None time:  2.073228331981227
None Run 08:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.40
Split: 03, Run: 03
None time:  2.2570016148965806
None Run 09:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.40
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.2051468559075147
None Run 10:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.40
Split: 04, Run: 02
None time:  2.113317489158362
None Run 11:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 78.40
Split: 04, Run: 03
None time:  1.7513872210402042
None Run 12:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.90
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.3353781159967184
None Run 13:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.70
Split: 05, Run: 02
None time:  2.154577993089333
None Run 14:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.50
Split: 05, Run: 03
None time:  2.0713415190111846
None Run 15:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.50
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.1342200429644436
None Run 16:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 72.80
Split: 06, Run: 02
None time:  2.149811167968437
None Run 17:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 73.80
Split: 06, Run: 03
None time:  2.0754278518725187
None Run 18:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 73.20
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.1894040738698095
None Run 19:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.10
Split: 07, Run: 02
None time:  2.073786721099168
None Run 20:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.00
Split: 07, Run: 03
None time:  2.097146996995434
None Run 21:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.0709883379749954
None Run 22:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.50
Split: 08, Run: 02
None time:  2.080317568965256
None Run 23:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.00
Split: 08, Run: 03
None time:  2.0641680900007486
None Run 24:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.30
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.151129791047424
None Run 25:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.10
Split: 09, Run: 02
None time:  2.087221159832552
None Run 26:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 74.60
Split: 09, Run: 03
None time:  2.1310783848166466
None Run 27:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.169525077799335
None Run 28:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.60
Split: 10, Run: 02
None time:  2.1640301109291613
None Run 29:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.00
Split: 10, Run: 03
None time:  2.0683910879306495
None Run 30:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 74.60
run time now: 6.430932998657227
total time:  63.99578973511234
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.13 ± 2.70
  Final Train: 100.00 ± 0.00
   Final Test: 74.67 ± 2.45
best run test_acc: 75.99999237060547
[I 2023-06-12 00:53:59,345] Trial 47 finished with value: 75.12666320800781 and parameters: {'Fwd': 0.000700105873940873, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 9.634588590883505, 'loop': 0, 'loss': 'CE', 'lr': 0.0037216539930043212, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.993539970361874e-05, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0038900292924922736
weight_decay:  1.6193355790546322e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4988921510521322
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  2.4824900499079376
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 03
None time:  3.2201446190010756
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.4774335890542716
None Run 04:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 73.30
Split: 02, Run: 02
None time:  2.497736888937652
None Run 05:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 72.50
Split: 02, Run: 03
None time:  2.5900375868659467
None Run 06:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.30
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.479118515038863
None Run 07:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.50
Split: 03, Run: 02
None time:  2.5435269880108535
None Run 08:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.30
Split: 03, Run: 03
None time:  2.478261678945273
None Run 09:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.70
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.5619066359940916
None Run 10:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.60
Split: 04, Run: 02
None time:  2.942540714982897
None Run 11:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.80
Split: 04, Run: 03
None time:  2.551178202033043
None Run 12:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 74.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.344582424033433
None Run 13:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 73.70
Split: 05, Run: 02
None time:  3.133849420119077
None Run 14:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.00
Split: 05, Run: 03
None time:  3.0142659419216216
None Run 15:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.50
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.541089439066127
None Run 16:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.60
Split: 06, Run: 02
None time:  2.540306462906301
None Run 17:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.20
Split: 06, Run: 03
None time:  2.6199938079807907
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.40
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7117181019857526
None Run 19:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.00
Split: 07, Run: 02
None time:  2.6231672938447446
None Run 20:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.50
Split: 07, Run: 03
None time:  2.417632641037926
None Run 21:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.00
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.886308348039165
None Run 22:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 72.80
Split: 08, Run: 02
None time:  3.684525183867663
None Run 23:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 75.70
Split: 08, Run: 03
None time:  5.00173943513073
None Run 24:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.629470590967685
None Run 25:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.40
Split: 09, Run: 02
None time:  2.7724776631221175
None Run 26:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.30
Split: 09, Run: 03
None time:  3.7576596620492637
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.40
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.860488392878324
None Run 28:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.20
Split: 10, Run: 02
None time:  2.7361446560826153
None Run 29:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.40
Split: 10, Run: 03
None time:  2.737185959937051
None Run 30:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.50
run time now: 8.368303298950195
total time:  89.90481177298352
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 3.03
  Final Train: 100.00 ± 0.00
   Final Test: 72.00 ± 2.59
best run test_acc: 72.81000518798828
[I 2023-06-12 00:55:29,695] Trial 48 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0008558051458213741, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 9.609448390972544, 'loop': 2, 'loss': 'MSE', 'lr': 0.0038900292924922736, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.6193355790546322e-05, 'weightedloss': True}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.003252462521488999
weight_decay:  1.580391376655705e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.250707650091499
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 02
None time:  1.3063563911709934
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 03
None time:  1.382633461151272
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.50
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.255841514095664
None Run 04:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 02
None time:  1.2748513051774353
None Run 05:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.80
Split: 02, Run: 03
None time:  1.2772426279261708
None Run 06:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 64.80
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2590791538823396
None Run 07:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.90
Split: 03, Run: 02
None time:  1.3978587570600212
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.60
Split: 03, Run: 03
None time:  1.3463485818356276
None Run 09:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 61.80
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3754632940981537
None Run 10:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.20
Split: 04, Run: 02
None time:  1.3626629738137126
None Run 11:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.70
Split: 04, Run: 03
None time:  1.2805216908454895
None Run 12:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2993835150264204
None Run 13:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.80
Split: 05, Run: 02
None time:  1.2895188801921904
None Run 14:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 05, Run: 03
None time:  1.311109754955396
None Run 15:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4005958351772279
None Run 16:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.60
Split: 06, Run: 02
None time:  1.3320328721310943
None Run 17:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.50
Split: 06, Run: 03
None time:  1.3384121598210186
None Run 18:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.70
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2632619100622833
None Run 19:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.70
Split: 07, Run: 02
None time:  1.3460729788057506
None Run 20:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.20
Split: 07, Run: 03
None time:  1.2862571750301868
None Run 21:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.10
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.274756196187809
None Run 22:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.70
Split: 08, Run: 02
None time:  1.3118516558315605
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 67.60
Split: 08, Run: 03
None time:  1.3027828340418637
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3048947909846902
None Run 25:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
Split: 09, Run: 02
None time:  1.2363457889296114
None Run 26:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 09, Run: 03
None time:  1.3592700178269297
None Run 27:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3497821630444378
None Run 28:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 72.10
Split: 10, Run: 02
None time:  1.328462810954079
None Run 29:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.80
Split: 10, Run: 03
None time:  1.417104144115001
None Run 30:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 74.70
run time now: 4.120039701461792
total time:  40.08007163810544
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.89 ± 5.62
  Final Train: 100.00 ± 0.00
   Final Test: 68.34 ± 5.49
best run test_acc: 71.74999237060547
[I 2023-06-12 00:56:10,187] Trial 49 finished with value: 68.88667297363281 and parameters: {'Fwd': 0.0017304141272744874, 'K': 10, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 8.88391975690982, 'loop': 0, 'loss': 'CE', 'lr': 0.003252462521488999, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.580391376655705e-05, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.0018896034092880294
weight_decay:  0.0001087844939241552
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7244375778827816
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.7159635941497982
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  0.7820785730145872
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 76.90
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7799093171488494
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 02
None time:  0.7452836779411882
None Run 05:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 73.40
Split: 02, Run: 03
None time:  0.7614246469456702
None Run 06:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 63.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.389149796916172
None Run 07:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.80
Split: 03, Run: 02
None time:  0.7689925080630928
None Run 08:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.00
Split: 03, Run: 03
None time:  0.9973296881653368
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.20
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1679627900011837
None Run 10:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 76.10
Split: 04, Run: 02
None time:  0.722907496150583
None Run 11:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.10
Split: 04, Run: 03
None time:  0.8420467011164874
None Run 12:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9917208119295537
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.70
Split: 05, Run: 02
None time:  0.9834041548892856
None Run 14:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 05, Run: 03
None time:  0.8869988159276545
None Run 15:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7572005048859864
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 61.80
Split: 06, Run: 02
None time:  0.7008001420181245
None Run 17:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 57.20
Split: 06, Run: 03
None time:  0.7738325831014663
None Run 18:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 65.40
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5964239600580186
None Run 19:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.30
Split: 07, Run: 02
None time:  0.703049493022263
None Run 20:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 07, Run: 03
None time:  0.694230335066095
None Run 21:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8350248120259494
None Run 22:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.20
Split: 08, Run: 02
None time:  1.170294692972675
None Run 23:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.70
Split: 08, Run: 03
None time:  0.7566810389980674
None Run 24:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.90
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7071021350566298
None Run 25:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.60
Split: 09, Run: 02
None time:  0.782737686065957
None Run 26:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.40
Split: 09, Run: 03
None time:  0.8760982567910105
None Run 27:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.00
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.743901661131531
None Run 28:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
Split: 10, Run: 02
None time:  0.9036680399440229
None Run 29:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.70
Split: 10, Run: 03
None time:  0.7447707180399448
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.4293618202209473
total time:  25.6696779509075
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.97 ± 4.75
  Final Train: 100.00 ± 0.00
   Final Test: 70.26 ± 5.07
best run test_acc: 73.8499984741211
[I 2023-06-12 00:56:36,479] Trial 50 finished with value: 70.97333526611328 and parameters: {'Fwd': 0.00044661065236929656, 'K': 9, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 20, 'lambda1': 0.35000000000000003, 'lambda2': 9.5219376746019, 'loop': 0, 'loss': 'CE', 'lr': 0.0018896034092880294, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001087844939241552, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.004181722170606021
weight_decay:  5.782351887732219e-06
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7376547458115965
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.771724411053583
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.90
Split: 01, Run: 03
None time:  1.5310363280586898
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.00
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0144000879954547
None Run 04:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 78.60
Split: 02, Run: 02
None time:  1.9273666720837355
None Run 05:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.90
Split: 02, Run: 03
None time:  1.9317063989583403
None Run 06:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.00
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.9563487889245152
None Run 07:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.70
Split: 03, Run: 02
None time:  2.00269084982574
None Run 08:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.90
Split: 03, Run: 03
None time:  1.92688739602454
None Run 09:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.90
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8560741269029677
None Run 10:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.10
Split: 04, Run: 02
None time:  1.913869810057804
None Run 11:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.20
Split: 04, Run: 03
None time:  1.8932368790265173
None Run 12:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.40
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.0589436660520732
None Run 13:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.20
Split: 05, Run: 02
None time:  1.8355408490169793
None Run 14:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.40
Split: 05, Run: 03
None time:  1.960132515989244
None Run 15:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.20
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9498281890992075
None Run 16:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 72.70
Split: 06, Run: 02
None time:  1.9203457408584654
None Run 17:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 73.70
Split: 06, Run: 03
None time:  1.870185571955517
None Run 18:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 70.80
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.431421715999022
None Run 19:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 02
None time:  1.853104469133541
None Run 20:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.70
Split: 07, Run: 03
None time:  1.8846077539492399
None Run 21:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.00
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.839242622954771
None Run 22:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.20
Split: 08, Run: 02
None time:  1.8543157610110939
None Run 23:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.80
Split: 08, Run: 03
None time:  1.873716213973239
None Run 24:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 73.20
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8451113130431622
None Run 25:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.80
Split: 09, Run: 02
None time:  1.694908384932205
None Run 26:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.00
Split: 09, Run: 03
None time:  1.6609194339253008
None Run 27:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.90
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8818419030867517
None Run 28:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.70
Split: 10, Run: 02
None time:  1.7941731908358634
None Run 29:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.40
Split: 10, Run: 03
None time:  1.8061094239819795
None Run 30:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.90
run time now: 5.506350517272949
total time:  57.07260555308312
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.20 ± 2.41
  Final Train: 100.00 ± 0.00
   Final Test: 74.51 ± 2.35
best run test_acc: 75.58000183105469
[I 2023-06-12 00:57:34,075] Trial 51 finished with value: 75.19999694824219 and parameters: {'Fwd': 0.004638934732680908, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 8.876545563817647, 'loop': 0, 'loss': 'CE', 'lr': 0.004181722170606021, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.782351887732219e-06, 'weightedloss': False}. Best is trial 33 with value: 75.22000122070312.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0042345794542312035
weight_decay:  7.999896976431955e-06
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8362593171186745
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 02
None time:  1.833727156976238
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 03
None time:  1.7815187331289053
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 73.10
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.038849385920912
None Run 04:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 78.20
Split: 02, Run: 02
None time:  1.887110122013837
None Run 05:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.10
Split: 02, Run: 03
None time:  1.8882592062000185
None Run 06:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.60
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8877309479285032
None Run 07:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.50
Split: 03, Run: 02
None time:  1.8341261269524693
None Run 08:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.50
Split: 03, Run: 03
None time:  1.7182739980053157
None Run 09:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.50
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8378429098520428
None Run 10:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.90
Split: 04, Run: 02
None time:  1.890345696825534
None Run 11:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.90
Split: 04, Run: 03
None time:  1.9975022019352764
None Run 12:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.50
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.949666891945526
None Run 13:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.00
Split: 05, Run: 02
None time:  1.824882399989292
None Run 14:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.40
Split: 05, Run: 03
None time:  1.8445178382098675
None Run 15:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.30
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8533300650306046
None Run 16:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 73.30
Split: 06, Run: 02
None time:  1.8668306269682944
None Run 17:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 73.90
Split: 06, Run: 03
None time:  1.9062049691565335
None Run 18:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.10
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8161131411325186
None Run 19:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 76.30
Split: 07, Run: 02
None time:  1.6780261069070548
None Run 20:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 74.00
Split: 07, Run: 03
None time:  2.00314904586412
None Run 21:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.20
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8485497049987316
None Run 22:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.30
Split: 08, Run: 02
None time:  1.8806893951259553
None Run 23:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.80
Split: 08, Run: 03
None time:  1.7918127400334924
None Run 24:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8787749430630356
None Run 25:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.90
Split: 09, Run: 02
None time:  1.755447693169117
None Run 26:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.80
Split: 09, Run: 03
None time:  1.7512413188815117
None Run 27:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.50
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9185933840926737
None Run 28:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.00
Split: 10, Run: 02
None time:  1.8418503839056939
None Run 29:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 75.00
Split: 10, Run: 03
None time:  1.816582078114152
None Run 30:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.90
run time now: 5.7269768714904785
total time:  56.385678762802854
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.23 ± 2.36
  Final Train: 100.00 ± 0.00
   Final Test: 74.63 ± 2.28
best run test_acc: 75.63999938964844
[I 2023-06-12 00:58:30,974] Trial 52 finished with value: 75.23332977294922 and parameters: {'Fwd': 0.002703631057216338, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 8.997200332585939, 'loop': 0, 'loss': 'CE', 'lr': 0.0042345794542312035, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.999896976431955e-06, 'weightedloss': False}. Best is trial 52 with value: 75.23332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.003988117967329442
weight_decay:  5.161005091363567e-06
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7958365001250058
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.50
Split: 01, Run: 02
None time:  1.7761457921005785
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 03
None time:  1.7335095580201596
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.20
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7913568869698793
None Run 04:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 78.10
Split: 02, Run: 02
None time:  1.9918818429578096
None Run 05:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 78.50
Split: 02, Run: 03
None time:  1.8492549969814718
None Run 06:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.50
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8154480690136552
None Run 07:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.10
Split: 03, Run: 02
None time:  1.925316674867645
None Run 08:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.30
Split: 03, Run: 03
None time:  1.8409081590361893
None Run 09:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8531443551182747
None Run 10:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.30
Split: 04, Run: 02
None time:  1.9576180591247976
None Run 11:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 77.50
Split: 04, Run: 03
None time:  1.7940485998988152
None Run 12:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.10
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8575584809295833
None Run 13:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.90
Split: 05, Run: 02
None time:  1.66830187686719
None Run 14:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.80
Split: 05, Run: 03
None time:  1.8705280318390578
None Run 15:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.866898925974965
None Run 16:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 74.60
Split: 06, Run: 02
None time:  1.788600207073614
None Run 17:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.50
Split: 06, Run: 03
None time:  1.7361018860246986
None Run 18:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 71.20
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7610307969152927
None Run 19:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.80
Split: 07, Run: 02
None time:  1.9021369928959757
None Run 20:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.00
Split: 07, Run: 03
None time:  1.8129076389595866
None Run 21:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.00
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7120622219517827
None Run 22:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.20
Split: 08, Run: 02
None time:  1.77405341505073
None Run 23:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.90
Split: 08, Run: 03
None time:  1.843934497795999
None Run 24:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.30
len(train) 70
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7742031479720026
None Run 25:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 73.10
Split: 09, Run: 02
None time:  1.6999287360813469
None Run 26:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.60
Split: 09, Run: 03
None time:  1.7684453788679093
None Run 27:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.10
len(train) 70
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8445393762085587
None Run 28:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.70
Split: 10, Run: 02
None time:  1.554788564098999
None Run 29:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.00
Split: 10, Run: 03
None time:  1.5530281749088317
None Run 30:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.00
run time now: 4.9759156703948975
total time:  54.498736273963004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.65 ± 2.40
  Final Train: 100.00 ± 0.00
   Final Test: 75.11 ± 2.31
best run test_acc: 76.16999816894531
[I 2023-06-12 00:59:26,021] Trial 53 finished with value: 75.65333557128906 and parameters: {'Fwd': 0.0060787235419226355, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 8.982137031923534, 'loop': 0, 'loss': 'CE', 'lr': 0.003988117967329442, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.161005091363567e-06, 'weightedloss': False}. Best is trial 53 with value: 75.65333557128906.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.004195353996577382
weight_decay:  4.150821168237023e-06
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 70
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7222147709690034
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.715584437828511
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03
None time:  1.7403231558855623
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.30
len(train) 70
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6491352948360145
None Run 04:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 78.60
Split: 02, Run: 02
None time:  1.9144517141394317
None Run 05:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 77.70
Split: 02, Run: 03
None time:  1.8222906989976764
None Run 06:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.70
len(train) 70
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7934141180012375
None Run 07:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.20
Split: 03, Run: 02
None time:  1.863222304964438
None Run 08:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.10
Split: 03, Run: 03
None time:  1.7906048940494657
None Run 09:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.30
len(train) 70
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.814556635916233
None Run 10:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.70
Split: 04, Run: 02
None time:  1.7472680071368814
None Run 11:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.80
Split: 04, Run: 03
None time:  1.7609351738356054
None Run 12:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.00
len(train) 70
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8739005459938198
None Run 13:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.80
Split: 05, Run: 02
None time:  1.7874249818269163
None Run 14:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.60
Split: 05, Run: 03
None time:  1.792035159189254
None Run 15:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.10
len(train) 70
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8126664760056883
None Run 16:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 74.20
Split: 06, Run: 02
None time:  1.7715642959810793
None Run 17:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.40
Split: 06, Run: 03
None time:  1.9631401288788766
None Run 18:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 71.80
len(train) 70
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7117114108987153
None Run 19:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.90
Split: 07, Run: 02
None time:  1.7907762441318482
None Run 20:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.90
Split: 07, Run: 03
None time:  1.8218577250372618
None Run 21:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.40
len(train) 70
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(70, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8293690339196473
None Run 22:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.10
Split: 08, Run: 02
None time:  1.7952917250804603
None Run 23:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.30
Split: 08, Run: 03
None time:  1.799395859008655
None Run 24:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.10
len(train) 70
