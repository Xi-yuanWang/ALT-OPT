[I 2023-06-11 23:21:26,048] A new study created in RDB with name: CiteSeer_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.00010964784391468924
weight_decay:  6.281686488188481e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.165301902918145
None Run 01:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 36.00
Split: 01, Run: 02
None time:  0.40945029095746577
None Run 02:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 36.00
Split: 01, Run: 03
None time:  0.424302987055853
None Run 03:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 36.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.4081514507997781
None Run 04:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.50
Split: 02, Run: 02
None time:  0.41596828517504036
None Run 05:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.50
Split: 02, Run: 03
None time:  0.39446124993264675
None Run 06:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.45979410293512046
None Run 07:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.90
Split: 03, Run: 02
None time:  0.40199912106618285
None Run 08:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.90
Split: 03, Run: 03
None time:  0.3938517621718347
None Run 09:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.3962385260965675
None Run 10:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.10
Split: 04, Run: 02
None time:  0.4461606021504849
None Run 11:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.10
Split: 04, Run: 03
None time:  0.43700411706231534
None Run 12:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.4185620329808444
None Run 13:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 43.40
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.00% Test: 42.80%
Split: 05, Run: 02
None time:  1.1067945880349725
None Run 14:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 42.80
Split: 05, Run: 03
None time:  0.44264577818103135
None Run 15:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 43.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.3962226309813559
None Run 16:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 41.10
Split: 06, Run: 02
None time:  0.4583472269587219
None Run 17:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 41.10
Split: 06, Run: 03
None time:  0.40429212898015976
None Run 18:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 41.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.4522303540725261
None Run 19:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 34.50
Split: 07, Run: 02
None time:  0.39684310206212103
None Run 20:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 34.50
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 33.20% Test: 33.40%
Split: 07, Run: 03
None time:  1.142692503053695
None Run 21:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 34.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4282917771488428
None Run 22:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 45.30
Split: 08, Run: 02
None time:  0.4381898210849613
None Run 23:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 45.30
Split: 08, Run: 03
None time:  0.42818928603082895
None Run 24:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 45.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.40864349505864084
None Run 25:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 46.30
Split: 09, Run: 02
None time:  0.37137355213053524
None Run 26:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 46.30
Split: 09, Run: 03
None time:  0.4197467949707061
None Run 27:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 46.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.00% Test: 35.70%
Split: 10, Run: 01
None time:  1.1894630428869277
None Run 28:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 35.70
Split: 10, Run: 02
None time:  0.4087456010747701
None Run 29:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 39.50
Split: 10, Run: 03
None time:  0.4285783690866083
None Run 30:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 39.50
run time now: 2.074812173843384
total time:  18.100513506913558
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.23 ± 3.81
  Final Train: 100.00 ± 0.00
   Final Test: 41.01 ± 3.70
best run test_acc: 41.15999984741211
[I 2023-06-11 23:21:44,703] Trial 0 finished with value: 40.22666931152344 and parameters: {'Fwd': 0.0719289025334255, 'K': 9, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 1.0, 'lambda2': 3.0788145161726757, 'loop': 0, 'loss': 'MSE', 'lr': 0.00010964784391468924, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.281686488188481e-05, 'weightedloss': True}. Best is trial 0 with value: 40.22666931152344.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.25
lr:  0.0002953097105819
weight_decay:  0.0020181942933737013
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.42000896809622645
None Run 01:
Highest Train: 100.00
Highest Valid: 32.60
  Final Train: 100.00
   Final Test: 35.40
Split: 01, Run: 02
None time:  1.295410931110382
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 88.33
   Final Test: 55.70
Split: 01, Run: 03
None time:  0.5157138102222234
None Run 03:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.4107256578281522
None Run 04:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 41.90
Split: 02, Run: 02
None time:  0.8945293431170285
None Run 05:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.80
Split: 02, Run: 03
None time:  0.4963740089442581
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4011054220609367
None Run 07:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 41.50
Split: 03, Run: 02, Epoch: 100, Loss: 0.7745, Train: 81.67%, Valid: 61.40% Test: 57.00%
Split: 03, Run: 02
None time:  2.0097135158721358
None Run 08:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 88.33
   Final Test: 57.10
Split: 03, Run: 03
None time:  0.43149518803693354
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.4282174550462514
None Run 10:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 40.70
Split: 04, Run: 02
None time:  0.8823153330013156
None Run 11:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.50
Split: 04, Run: 03
None time:  0.517256576102227
None Run 12:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.3951051849871874
None Run 13:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 42.90
Split: 05, Run: 02
None time:  0.9792394349351525
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 69.00
Split: 05, Run: 03
None time:  0.41705539892427623
None Run 15:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.43018439202569425
None Run 16:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 40.50
Split: 06, Run: 02
None time:  0.6708929939195514
None Run 17:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.50
Split: 06, Run: 03
None time:  0.4821992740035057
None Run 18:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.41659168316982687
None Run 19:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.70
Split: 07, Run: 02
None time:  1.7040450279600918
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 81.67
   Final Test: 54.60
Split: 07, Run: 03
None time:  0.3927546769846231
None Run 21:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 56.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4134247130714357
None Run 22:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 44.80
Split: 08, Run: 02
None time:  1.3305625231005251
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 90.00
   Final Test: 67.80
Split: 08, Run: 03
None time:  0.47176708211191
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.41976699512451887
None Run 25:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 45.40
Split: 09, Run: 02
None time:  0.9113784730434418
None Run 26:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 98.33
   Final Test: 65.20
Split: 09, Run: 03
None time:  0.38457241794094443
None Run 27:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 70.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.42256526416167617
None Run 28:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 39.00
Split: 10, Run: 02
None time:  0.7581435679458082
None Run 29:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 64.50
Split: 10, Run: 03
None time:  0.5224009389057755
None Run 30:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 1.743089199066162
total time:  21.280213888036087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.11 ± 13.20
  Final Train: 98.06 ± 4.59
   Final Test: 56.45 ± 12.15
best run test_acc: 65.79000091552734
[I 2023-06-11 23:22:06,351] Trial 1 finished with value: 57.11333084106445 and parameters: {'Fwd': 3.51566490990813e-06, 'K': 7, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 5.067466126699999, 'loop': 2, 'loss': 'CE', 'lr': 0.0002953097105819, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0020181942933737013, 'weightedloss': True}. Best is trial 1 with value: 57.11333084106445.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.65
lr:  0.00019722253484030338
weight_decay:  1.8011008657277606e-06
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.20% Test: 45.90%
Split: 01, Run: 01
None time:  1.1015706369653344
None Run 01:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 46.00
Split: 01, Run: 02
None time:  0.6336429719813168
None Run 02:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 48.80
Split: 01, Run: 03
None time:  0.7325869370251894
None Run 03:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 40.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6735847909003496
None Run 04:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 46.60
Split: 02, Run: 02
None time:  0.7887797132134438
None Run 05:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 51.10
Split: 02, Run: 03
None time:  0.7638504619244486
None Run 06:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 34.80% Test: 39.50%
Split: 03, Run: 01
None time:  1.168809216003865
None Run 07:
Highest Train: 100.00
Highest Valid: 34.80
  Final Train: 100.00
   Final Test: 39.40
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.60% Test: 46.70%
Split: 03, Run: 02
None time:  1.175268325023353
None Run 08:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 46.60
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.20% Test: 39.90%
Split: 03, Run: 03
None time:  1.200432116864249
None Run 09:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 39.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.40% Test: 49.70%
Split: 04, Run: 01
None time:  1.2269717280287296
None Run 10:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 49.70
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.00% Test: 48.60%
Split: 04, Run: 02
None time:  1.2014949689619243
None Run 11:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 48.50
Split: 04, Run: 03
None time:  0.673663686029613
None Run 12:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 43.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6877052609343082
None Run 13:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 56.40
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 50.10%
Split: 05, Run: 02
None time:  1.200282411184162
None Run 14:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 50.10
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 36.80% Test: 40.70%
Split: 05, Run: 03
None time:  1.1161385469604284
None Run 15:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 40.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.60% Test: 40.90%
Split: 06, Run: 01
None time:  1.1687841170933098
None Run 16:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 40.80
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.20% Test: 56.60%
Split: 06, Run: 02
None time:  1.1982603641226888
None Run 17:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.60
Split: 06, Run: 03
None time:  0.7741612389218062
None Run 18:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 50.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 46.40%
Split: 07, Run: 01
None time:  1.232224042993039
None Run 19:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 46.50
Split: 07, Run: 02
None time:  0.8134478158317506
None Run 20:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 41.70
Split: 07, Run: 03
None time:  0.6817197070922703
None Run 21:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 33.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.00% Test: 53.10%
Split: 08, Run: 01
None time:  1.179818530101329
None Run 22:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 53.20
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 31.00% Test: 33.10%
Split: 08, Run: 02
None time:  1.2064399139489979
None Run 23:
Highest Train: 100.00
Highest Valid: 31.00
  Final Train: 100.00
   Final Test: 33.10
Split: 08, Run: 03
None time:  0.7604954871349037
None Run 24:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 43.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.20% Test: 49.90%
Split: 09, Run: 01
None time:  1.1248065989930183
None Run 25:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 50.00
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.20% Test: 52.50%
Split: 09, Run: 02
None time:  1.1637518720235676
None Run 26:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 52.50
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 39.60% Test: 42.20%
Split: 09, Run: 03
None time:  1.1301828040741384
None Run 27:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 42.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6840607700869441
None Run 28:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 33.60
Split: 10, Run: 02
None time:  0.7265400169417262
None Run 29:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 40.40
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 35.20% Test: 32.70%
Split: 10, Run: 03
None time:  1.2342059249058366
None Run 30:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 33.20
run time now: 2.6800894737243652
total time:  30.411066110013053
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 44.55 ± 7.32
  Final Train: 100.00 ± 0.00
   Final Test: 45.16 ± 6.95
best run test_acc: 50.71000289916992
[I 2023-06-11 23:22:37,115] Trial 2 finished with value: 44.54667282104492 and parameters: {'Fwd': 0.0034492428370525696, 'K': 3, 'alpha': 0.65, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.432178451141603, 'loop': 0, 'loss': 'MSE', 'lr': 0.00019722253484030338, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8011008657277606e-06, 'weightedloss': True}. Best is trial 1 with value: 57.11333084106445.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.65
lr:  0.006920207751743197
weight_decay:  0.054792600331894016
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8781963000074029
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 02
None time:  0.6260421480983496
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 03
None time:  0.6556729229632765
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 66.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9565419319551438
None Run 04:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 57.80
Split: 02, Run: 02
None time:  0.8527962919324636
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 03
None time:  0.632406221004203
None Run 06:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6570899318903685
None Run 07:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.10
Split: 03, Run: 02
None time:  0.7182436289731413
None Run 08:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 57.00
Split: 03, Run: 03
None time:  0.7350936990696937
None Run 09:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7042495808564126
None Run 10:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.30
Split: 04, Run: 02
None time:  0.6296315770596266
None Run 11:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.20
Split: 04, Run: 03
None time:  0.8363339030183852
None Run 12:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9640821020584553
None Run 13:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.40
Split: 05, Run: 02
None time:  0.6418543399777263
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.20
Split: 05, Run: 03
None time:  0.69792818906717
None Run 15:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9239961749408394
None Run 16:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 57.60
Split: 06, Run: 02
None time:  0.7633870360441506
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 62.20
Split: 06, Run: 03
None time:  0.6817224400583655
None Run 18:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 66.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6352192028425634
None Run 19:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 50.90
Split: 07, Run: 02
None time:  0.7931307291146368
None Run 20:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 57.20
Split: 07, Run: 03
None time:  0.6882920549251139
None Run 21:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 58.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7477677320130169
None Run 22:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 63.00
Split: 08, Run: 02
None time:  0.7580583288799971
None Run 23:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 61.90
Split: 08, Run: 03
None time:  0.6330038441810757
None Run 24:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6039648049045354
None Run 25:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 58.40
Split: 09, Run: 02
None time:  0.9592137460131198
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.80
Split: 09, Run: 03
None time:  0.7748466290067881
None Run 27:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6811195949558169
None Run 28:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 47.60
Split: 10, Run: 02
None time:  0.8301710209343582
None Run 29:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 59.20
Split: 10, Run: 03
None time:  0.9461546968668699
None Run 30:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.30
run time now: 2.4934427738189697
total time:  23.62555340793915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.45 ± 4.76
  Final Train: 100.00 ± 0.00
   Final Test: 61.57 ± 5.06
best run test_acc: 65.08000183105469
[I 2023-06-11 23:23:01,086] Trial 3 finished with value: 62.453330993652344 and parameters: {'Fwd': 3.7045493869449225e-06, 'K': 4, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.9500000000000001, 'lambda2': 8.118979751425012, 'loop': 2, 'loss': 'MSE', 'lr': 0.006920207751743197, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.054792600331894016, 'weightedloss': True}. Best is trial 3 with value: 62.453330993652344.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.0008733213583734693
weight_decay:  0.001218924314927458
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2324747140519321
None Run 01:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 33.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.00% Test: 42.80%
Split: 01, Run: 02
None time:  0.4221883288118988
None Run 02:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 42.80
Split: 01, Run: 03
None time:  0.2719310780521482
None Run 03:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 42.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.24874837091192603
None Run 04:
Highest Train: 100.00
Highest Valid: 27.80
  Final Train: 100.00
   Final Test: 31.40
Split: 02, Run: 02
None time:  0.282797517022118
None Run 05:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 44.70
Split: 02, Run: 03
None time:  0.3159019711893052
None Run 06:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 50.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.2700686240568757
None Run 07:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 32.70
Split: 03, Run: 02
None time:  0.27415298693813384
None Run 08:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 36.00
Split: 03, Run: 03
None time:  0.36469847708940506
None Run 09:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 47.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.24449572898447514
None Run 10:
Highest Train: 100.00
Highest Valid: 27.00
  Final Train: 100.00
   Final Test: 25.60
Split: 04, Run: 02
None time:  0.2056605110410601
None Run 11:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 36.70
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.80% Test: 45.80%
Split: 04, Run: 03
None time:  0.39266751194372773
None Run 12:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 45.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.252136253984645
None Run 13:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 42.10
Split: 05, Run: 02
None time:  0.30958258104510605
None Run 14:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 47.70
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.00% Test: 51.30%
Split: 05, Run: 03
None time:  0.44983214791864157
None Run 15:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 51.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.22625971492379904
None Run 16:
Highest Train: 100.00
Highest Valid: 31.60
  Final Train: 100.00
   Final Test: 28.00
Split: 06, Run: 02
None time:  0.3198407811578363
None Run 17:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 47.40
Split: 06, Run: 03
None time:  0.4571879201103002
None Run 18:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 49.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.2548341869842261
None Run 19:
Highest Train: 100.00
Highest Valid: 23.20
  Final Train: 100.00
   Final Test: 24.60
Split: 07, Run: 02
None time:  0.3319445929955691
None Run 20:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 39.90
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.80% Test: 43.90%
Split: 07, Run: 03
None time:  0.4465994480997324
None Run 21:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 43.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.23030179203487933
None Run 22:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 38.80
Split: 08, Run: 02
None time:  0.398780622985214
None Run 23:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 52.60
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.60% Test: 53.10%
Split: 08, Run: 03
None time:  0.4050850330386311
None Run 24:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 52.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.290446420898661
None Run 25:
Highest Train: 100.00
Highest Valid: 31.40
  Final Train: 100.00
   Final Test: 27.50
Split: 09, Run: 02
None time:  0.32335015293210745
None Run 26:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 35.90
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 43.80% Test: 45.90%
Split: 09, Run: 03
None time:  0.453316377941519
None Run 27:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 45.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.23621562495827675
None Run 28:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 30.80
Split: 10, Run: 02
None time:  0.3793428128119558
None Run 29:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 49.20
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.60% Test: 55.50%
Split: 10, Run: 03
None time:  0.40488123893737793
None Run 30:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 55.20
run time now: 1.052769660949707
total time:  10.666351610096171
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.37 ± 8.66
  Final Train: 100.00 ± 0.00
   Final Test: 41.07 ± 8.83
best run test_acc: 48.46999740600586
[I 2023-06-11 23:23:12,117] Trial 4 finished with value: 41.37333679199219 and parameters: {'Fwd': 0.01988216525435081, 'K': 1, 'alpha': 0.55, 'dropout': 0.0, 'gnnepoch': 40, 'lambda1': 0.45, 'lambda2': 7.05473421593691, 'loop': 0, 'loss': 'CE', 'lr': 0.0008733213583734693, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001218924314927458, 'weightedloss': False}. Best is trial 3 with value: 62.453330993652344.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.45
lr:  0.00030540051783113534
weight_decay:  0.0413668847119134
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.19353924808092415
None Run 01:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 29.80
Split: 01, Run: 02
None time:  0.9321575639769435
None Run 02:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 37.50
Split: 01, Run: 03
None time:  0.21663524908944964
None Run 03:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 37.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.2179989400319755
None Run 04:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 35.40
Split: 02, Run: 02
None time:  0.21613230998627841
None Run 05:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 35.40
Split: 02, Run: 03
None time:  0.5439671161584556
None Run 06:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.2220742830540985
None Run 07:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.50
Split: 03, Run: 02
None time:  0.20209747296757996
None Run 08:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.50
Split: 03, Run: 03
None time:  0.6829045149497688
None Run 09:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 98.33
   Final Test: 44.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.26562766009010375
None Run 10:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 36.50
Split: 04, Run: 02
None time:  0.2189937571529299
None Run 11:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 36.50
Split: 04, Run: 03
None time:  0.5371716450899839
None Run 12:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 41.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.1907724291086197
None Run 13:
Highest Train: 100.00
Highest Valid: 34.80
  Final Train: 100.00
   Final Test: 34.00
Split: 05, Run: 02
None time:  0.19414074486121535
None Run 14:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 42.10
Split: 05, Run: 03
None time:  0.8284617660101503
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.19537015282548964
None Run 16:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 33.20
Split: 06, Run: 02
None time:  0.6606603390537202
None Run 17:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 43.40
Split: 06, Run: 03
None time:  0.363521384075284
None Run 18:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 98.33
   Final Test: 45.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.20097383111715317
None Run 19:
Highest Train: 100.00
Highest Valid: 26.20
  Final Train: 100.00
   Final Test: 27.20
Split: 07, Run: 02
None time:  0.2256978638470173
None Run 20:
Highest Train: 100.00
Highest Valid: 26.20
  Final Train: 100.00
   Final Test: 27.20
Split: 07, Run: 03
None time:  0.20320444600656629
None Run 21:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 29.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.19729832699522376
None Run 22:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 35.70
Split: 08, Run: 02
None time:  0.21906551206484437
None Run 23:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 33.90
Split: 08, Run: 03
None time:  0.9361613199580461
None Run 24:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.22567106620408595
None Run 25:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.60
Split: 09, Run: 02
None time:  0.2073387170676142
None Run 26:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.60
Split: 09, Run: 03
None time:  0.49074543081223965
None Run 27:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 49.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.20358716882765293
None Run 28:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 33.50
Split: 10, Run: 02
None time:  0.6683967241551727
None Run 29:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 98.33
   Final Test: 45.50
Split: 10, Run: 03
None time:  0.2298868598882109
None Run 30:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 45.80
run time now: 1.1382029056549072
total time:  11.900871642166749
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 39.55 ± 10.34
  Final Train: 99.83 ± 0.51
   Final Test: 39.74 ± 9.55
best run test_acc: 48.12000274658203
[I 2023-06-11 23:23:24,371] Trial 5 finished with value: 39.546669006347656 and parameters: {'Fwd': 2.9996328819581605e-05, 'K': 4, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.45, 'lambda2': 6.926409047978092, 'loop': 1, 'loss': 'CE', 'lr': 0.00030540051783113534, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0413668847119134, 'weightedloss': False}. Best is trial 3 with value: 62.453330993652344.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00043101034291030015
weight_decay:  0.01614077148928253
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.14144579507410526
None Run 01:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 36.10
Split: 01, Run: 02
None time:  0.11404647002927959
None Run 02:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 36.10
Split: 01, Run: 03
None time:  0.10658898903056979
None Run 03:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 36.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.13510639895685017
None Run 04:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 42.50
Split: 02, Run: 02
None time:  0.1258277629967779
None Run 05:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 42.50
Split: 02, Run: 03
None time:  0.12019067304208875
None Run 06:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 42.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.1432557050138712
None Run 07:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.80
Split: 03, Run: 02
None time:  0.0967331409920007
None Run 08:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.80
Split: 03, Run: 03
None time:  0.12332480819895864
None Run 09:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.11258904100395739
None Run 10:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.10
Split: 04, Run: 02
None time:  0.108032729011029
None Run 11:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.10
Split: 04, Run: 03
None time:  0.11966221081092954
None Run 12:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.1222263709641993
None Run 13:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 43.60
Split: 05, Run: 02
None time:  0.11583843408152461
None Run 14:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 43.60
Split: 05, Run: 03
None time:  0.1134826501365751
None Run 15:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 43.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.12985933991149068
None Run 16:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.00
Split: 06, Run: 02
None time:  0.13252986199222505
None Run 17:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.00
Split: 06, Run: 03
None time:  0.13458970002830029
None Run 18:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.11229238891974092
None Run 19:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.90
Split: 07, Run: 02
None time:  0.11681683105416596
None Run 20:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.90
Split: 07, Run: 03
None time:  0.12870439584366977
None Run 21:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.12251990800723433
None Run 22:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 45.60
Split: 08, Run: 02
None time:  0.12910529295913875
None Run 23:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 45.60
Split: 08, Run: 03
None time:  0.14048299891874194
None Run 24:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 45.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.12280621402896941
None Run 25:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 46.40
Split: 09, Run: 02
None time:  0.1221455701161176
None Run 26:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 46.40
Split: 09, Run: 03
None time:  0.0965924309566617
None Run 27:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 46.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.12959841103293002
None Run 28:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 39.70
Split: 10, Run: 02
None time:  0.1027629398740828
None Run 29:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 39.70
Split: 10, Run: 03
None time:  0.1404957389459014
None Run 30:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 39.70
run time now: 0.4152793884277344
total time:  4.713437246857211
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.34 ± 3.69
  Final Train: 100.00 ± 0.00
   Final Test: 41.37 ± 3.38
best run test_acc: 41.37000274658203
[I 2023-06-11 23:23:29,525] Trial 6 finished with value: 40.34000015258789 and parameters: {'Fwd': 0.0007423483870520427, 'K': 8, 'alpha': 0.55, 'dropout': 0.1, 'gnnepoch': 10, 'lambda1': 0.15000000000000002, 'lambda2': 3.037395793851758, 'loop': 0, 'loss': 'MSE', 'lr': 0.00043101034291030015, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.01614077148928253, 'weightedloss': False}. Best is trial 3 with value: 62.453330993652344.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.004260735684038439
weight_decay:  0.006370795831617484
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.12166121811606
None Run 01:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 60.60
Split: 01, Run: 02
None time:  1.1859478908590972
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 03
None time:  1.1767937869299203
None Run 03:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.12247574608773
None Run 04:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.50
Split: 02, Run: 02
None time:  1.2535319570451975
None Run 05:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 59.70
Split: 02, Run: 03
None time:  1.0998513239901513
None Run 06:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 61.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.126748255919665
None Run 07:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 55.40
Split: 03, Run: 02
None time:  1.2042639579158276
None Run 08:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 59.50
Split: 03, Run: 03
None time:  1.1439348820131272
None Run 09:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 54.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.195421126903966
None Run 10:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.40
Split: 04, Run: 02
None time:  1.279171725967899
None Run 11:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.50
Split: 04, Run: 03
None time:  1.2267615150194615
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0511156560387462
None Run 13:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.80
Split: 05, Run: 02
None time:  1.0763606480322778
None Run 14:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 03
None time:  1.095348051050678
None Run 15:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2057065709959716
None Run 16:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 61.90
Split: 06, Run: 02
None time:  1.1619758470915258
None Run 17:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 61.60
Split: 06, Run: 03
None time:  1.149198086000979
None Run 18:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 56.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1917922289576381
None Run 19:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 59.30
Split: 07, Run: 02
None time:  1.0891807510051876
None Run 20:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 58.40
Split: 07, Run: 03
None time:  1.07261902699247
None Run 21:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 57.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1170679018832743
None Run 22:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 61.90
Split: 08, Run: 02
None time:  1.1484941430389881
None Run 23:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 62.60
Split: 08, Run: 03
None time:  1.1783145810477436
None Run 24:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 63.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1272940889466554
None Run 25:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 64.10
Split: 09, Run: 02
None time:  1.1116594979539514
None Run 26:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.90
Split: 09, Run: 03
None time:  1.20005041686818
None Run 27:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2024524849839509
None Run 28:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 61.80
Split: 10, Run: 02
None time:  1.1507112849503756
None Run 29:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.20
Split: 10, Run: 03
None time:  1.1426440950017422
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 65.10
run time now: 3.5438756942749023
total time:  35.67624912294559
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.09 ± 3.41
  Final Train: 100.00 ± 0.00
   Final Test: 61.13 ± 2.99
best run test_acc: 62.4900016784668
[I 2023-06-11 23:24:05,537] Trial 7 finished with value: 62.093326568603516 and parameters: {'Fwd': 2.7016702491536455e-05, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 6.542945942154085, 'loop': 2, 'loss': 'CE', 'lr': 0.004260735684038439, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006370795831617484, 'weightedloss': False}. Best is trial 3 with value: 62.453330993652344.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.65
lr:  0.00013572555115862596
weight_decay:  0.0007395822971493235
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2586762090213597
None Run 01:
Highest Train: 100.00
Highest Valid: 32.60
  Final Train: 100.00
   Final Test: 34.60
Split: 01, Run: 02
None time:  0.2910551270470023
None Run 02:
Highest Train: 100.00
Highest Valid: 32.60
  Final Train: 100.00
   Final Test: 34.60
Split: 01, Run: 03
None time:  0.27828869014047086
None Run 03:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 38.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.2615189279895276
None Run 04:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.20
Split: 02, Run: 02
None time:  0.2385135379154235
None Run 05:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.20
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.40% Test: 50.00%
Split: 02, Run: 03
None time:  0.6924999901093543
None Run 06:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 50.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.2823577169328928
None Run 07:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 40.80
Split: 03, Run: 02
None time:  0.2784454049542546
None Run 08:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 40.80
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.40% Test: 44.20%
Split: 03, Run: 03
None time:  0.6947771550621837
None Run 09:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 44.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.246847502887249
None Run 10:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 40.10
Split: 04, Run: 02
None time:  0.27299560606479645
None Run 11:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 40.10
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.60% Test: 43.60%
Split: 04, Run: 03
None time:  0.6734477740246803
None Run 12:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 43.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.23996984818950295
None Run 13:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 42.30
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 38.40% Test: 39.00%
Split: 05, Run: 02
None time:  0.674142814008519
None Run 14:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 42.30
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.60% Test: 50.50%
Split: 05, Run: 03
None time:  0.6908861531410366
None Run 15:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 50.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.2780410230625421
None Run 16:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 38.90
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.20% Test: 38.90%
Split: 06, Run: 02
None time:  0.6315927961841226
None Run 17:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 38.90
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.60% Test: 47.60%
Split: 06, Run: 03
None time:  0.7120535389985889
None Run 18:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 47.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.2563443621620536
None Run 19:
Highest Train: 100.00
Highest Valid: 33.00
  Final Train: 100.00
   Final Test: 34.10
Split: 07, Run: 02
None time:  0.26044952287338674
None Run 20:
Highest Train: 100.00
Highest Valid: 33.00
  Final Train: 100.00
   Final Test: 34.10
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 37.60% Test: 38.40%
Split: 07, Run: 03
None time:  0.6644686611834913
None Run 21:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 38.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.2763263010419905
None Run 22:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 43.10
Split: 08, Run: 02
None time:  0.2801644168794155
None Run 23:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 50.00
Split: 08, Run: 03
None time:  0.3059066869318485
None Run 24:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.2778593059629202
None Run 25:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 43.20
Split: 09, Run: 02
None time:  0.3033704769331962
None Run 26:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 43.20
Split: 09, Run: 03
None time:  0.2773411001544446
None Run 27:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 51.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.2633938561193645
None Run 28:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 37.70
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.80% Test: 44.20%
Split: 10, Run: 02
None time:  0.6567468100693077
None Run 29:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 44.20
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 47.60% Test: 50.50%
Split: 10, Run: 03
None time:  0.6775805768556893
None Run 30:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 50.50
run time now: 1.6382999420166016
total time:  13.227281542029232
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.08 ± 5.27
  Final Train: 100.00 ± 0.00
   Final Test: 42.38 ± 5.33
best run test_acc: 46.60000228881836
[I 2023-06-11 23:24:19,118] Trial 8 finished with value: 41.08000183105469 and parameters: {'Fwd': 7.535335460328804e-06, 'K': 6, 'alpha': 0.65, 'dropout': 0.0, 'gnnepoch': 40, 'lambda1': 0.55, 'lambda2': 1.8689792563461871, 'loop': 0, 'loss': 'MSE', 'lr': 0.00013572555115862596, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0007395822971493235, 'weightedloss': False}. Best is trial 3 with value: 62.453330993652344.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00243903147878431
weight_decay:  2.975025725207887e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7219461430795491
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 93.33
   Final Test: 59.90
Split: 01, Run: 02
None time:  0.6076252690982074
None Run 02:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 59.70
Split: 01, Run: 03
None time:  0.5447178920730948
None Run 03:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 58.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5094308839179575
None Run 04:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.00
Split: 02, Run: 02
None time:  0.5675074369646609
None Run 05:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.40
Split: 02, Run: 03
None time:  0.5319957800675184
None Run 06:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.542815521126613
None Run 07:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 58.60
Split: 03, Run: 02
None time:  0.5087111289612949
None Run 08:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.60
Split: 03, Run: 03
None time:  0.557659471873194
None Run 09:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 59.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6480741170234978
None Run 10:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 93.33
   Final Test: 60.30
Split: 04, Run: 02
None time:  0.6270774370059371
None Run 11:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 95.00
   Final Test: 62.90
Split: 04, Run: 03
None time:  0.5668296408839524
None Run 12:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 96.67
   Final Test: 59.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5210443891119212
None Run 13:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.40
Split: 05, Run: 02
None time:  0.720699222991243
None Run 14:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.70
Split: 05, Run: 03
None time:  0.5237638328690082
None Run 15:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5286129789892584
None Run 16:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.10
Split: 06, Run: 02
None time:  0.6060110169928521
None Run 17:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 61.20
Split: 06, Run: 03
None time:  0.6128966938704252
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5084531330503523
None Run 19:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 59.70
Split: 07, Run: 02
None time:  0.5230902340263128
None Run 20:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 59.80
Split: 07, Run: 03
None time:  0.6429772928822786
None Run 21:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 63.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7181863461155444
None Run 22:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 65.00
Split: 08, Run: 02
None time:  0.4980497460346669
None Run 23:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 68.00
Split: 08, Run: 03
None time:  0.6466198489069939
None Run 24:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 65.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5254266951233149
None Run 25:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.80
Split: 09, Run: 02
None time:  0.5456088320352137
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.40
Split: 09, Run: 03
None time:  0.5945167290046811
None Run 27:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 98.33
   Final Test: 66.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5617308961227536
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.00
Split: 10, Run: 02
None time:  0.6005089371465147
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.00
Split: 10, Run: 03
None time:  0.5573171589057893
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 98.33
   Final Test: 62.80
run time now: 1.750978946685791
total time:  18.33642286900431
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.10 ± 3.18
  Final Train: 98.89 ± 2.02
   Final Test: 62.94 ± 3.15
best run test_acc: 64.25
[I 2023-06-11 23:24:37,843] Trial 9 finished with value: 64.10000610351562 and parameters: {'Fwd': 0.0004377810658379368, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 0.24175169946271668, 'loop': 0, 'loss': 'CE', 'lr': 0.00243903147878431, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.975025725207887e-06, 'weightedloss': False}. Best is trial 9 with value: 64.10000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.002266374094943804
weight_decay:  1.4550769816575285e-06
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1957138620782644
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.60
Split: 01, Run: 02
None time:  1.1761486609466374
None Run 02:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 03
None time:  1.1996475111227483
None Run 03:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 55.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0571533548645675
None Run 04:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 58.40
Split: 02, Run: 02
None time:  1.0908305370248854
None Run 05:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.80
Split: 02, Run: 03
None time:  1.099978854879737
None Run 06:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0437381721567363
None Run 07:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.20
Split: 03, Run: 02
None time:  1.0935644339770079
None Run 08:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.10
Split: 03, Run: 03
None time:  1.1572461780160666
None Run 09:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 54.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2645205471199006
None Run 10:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.80
Split: 04, Run: 02
None time:  1.3567722069565207
None Run 11:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 61.60
Split: 04, Run: 03
None time:  1.2020778011064976
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0896072909235954
None Run 13:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.40
Split: 05, Run: 02
None time:  1.133039501029998
None Run 14:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 03
None time:  1.0787097050342709
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0485913138836622
None Run 16:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 60.70
Split: 06, Run: 02
None time:  1.0560476500540972
None Run 17:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 58.30
Split: 06, Run: 03
None time:  1.1791841760277748
None Run 18:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1406977819278836
None Run 19:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 58.30
Split: 07, Run: 02
None time:  1.069809954147786
None Run 20:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 56.70
Split: 07, Run: 03
None time:  1.1173667521215975
None Run 21:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 57.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.20314160711132
None Run 22:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 59.30
Split: 08, Run: 02
None time:  1.0677914198022336
None Run 23:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 60.70
Split: 08, Run: 03
None time:  1.1343033500015736
None Run 24:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0644672319758683
None Run 25:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 62.60
Split: 09, Run: 02
None time:  1.1012176061049104
None Run 26:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 63.00
Split: 09, Run: 03
None time:  1.1309045979287475
None Run 27:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 62.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.156747767003253
None Run 28:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.10
Split: 10, Run: 02
None time:  1.1546266470104456
None Run 29:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.60
Split: 10, Run: 03
None time:  1.1439664899371564
None Run 30:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.00
run time now: 3.4887094497680664
total time:  35.02770103397779
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.44 ± 2.83
  Final Train: 100.00 ± 0.00
   Final Test: 59.65 ± 2.85
best run test_acc: 60.600006103515625
[I 2023-06-11 23:25:13,411] Trial 10 finished with value: 60.44000244140625 and parameters: {'Fwd': 0.0002511144256469103, 'K': 1, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 0.3347786235937147, 'loop': 1, 'loss': 'CE', 'lr': 0.002266374094943804, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4550769816575285e-06, 'weightedloss': False}. Best is trial 9 with value: 64.10000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9
lr:  0.00993647308024484
weight_decay:  0.07037131504738216
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3341321689076722
None Run 01:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 56.90
Split: 01, Run: 02
None time:  1.6170405067969114
None Run 02:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 58.70
Split: 01, Run: 03
None time:  1.274337155977264
None Run 03:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 58.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3477701640222222
None Run 04:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 63.30
Split: 02, Run: 02
None time:  1.0950604979880154
None Run 05:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.30
Split: 02, Run: 03
None time:  1.5558099059853703
None Run 06:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6480333891231567
None Run 07:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 57.50
Split: 03, Run: 02
None time:  2.070914658019319
None Run 08:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.00
Split: 03, Run: 03
None time:  1.8810810428112745
None Run 09:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1483021180611104
None Run 10:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 58.30
Split: 04, Run: 02
None time:  0.9270575530827045
None Run 11:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 59.80
Split: 04, Run: 03
None time:  1.4133773080538958
None Run 12:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9890976501628757
None Run 13:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 63.70
Split: 05, Run: 02
None time:  1.0045169789809734
None Run 14:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 63.20
Split: 05, Run: 03
None time:  1.1917521271388978
None Run 15:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 62.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.193984687095508
None Run 16:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.30
Split: 06, Run: 02
None time:  1.4693492820952088
None Run 17:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 59.80
Split: 06, Run: 03
None time:  1.651481272885576
None Run 18:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6931800430174917
None Run 19:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 59.70
Split: 07, Run: 02
None time:  1.3641927030403167
None Run 20:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 55.80
Split: 07, Run: 03
None time:  1.3335402170196176
None Run 21:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 55.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.055651009781286
None Run 22:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 64.00
Split: 08, Run: 02
None time:  1.5767750258091837
None Run 23:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 64.00
Split: 08, Run: 03
None time:  1.434203480836004
None Run 24:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6912252851761878
None Run 25:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 68.30
Split: 09, Run: 02
None time:  0.9504304339643568
None Run 26:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 61.10
Split: 09, Run: 03
None time:  1.2676889128051698
None Run 27:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 67.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.564911985071376
None Run 28:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 56.00
Split: 10, Run: 02
None time:  1.4810418980196118
None Run 29:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.50
Split: 10, Run: 03
None time:  1.1479648700915277
None Run 30:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.30
run time now: 4.230860233306885
total time:  44.3847746939864
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.70 ± 2.78
  Final Train: 100.00 ± 0.00
   Final Test: 60.51 ± 3.36
best run test_acc: 61.97999954223633
[I 2023-06-11 23:25:58,220] Trial 11 finished with value: 60.70000076293945 and parameters: {'Fwd': 1.736236012642102e-06, 'K': 4, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 9.697595413068392, 'loop': 2, 'loss': 'MSE', 'lr': 0.00993647308024484, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07037131504738216, 'weightedloss': True}. Best is trial 9 with value: 64.10000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.0027019316565606213
weight_decay:  6.120322608982803e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6691692490130663
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 98.33
   Final Test: 61.00
Split: 01, Run: 02
None time:  0.6692984090186656
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 98.33
   Final Test: 63.60
Split: 01, Run: 03
None time:  1.304254920920357
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5912663377821445
None Run 04:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.80
Split: 02, Run: 02
None time:  0.6058163270354271
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.90
Split: 02, Run: 03
None time:  1.066853109980002
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7321105529554188
None Run 07:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.10
Split: 03, Run: 02
None time:  0.916972589911893
None Run 08:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 98.33
   Final Test: 64.20
Split: 03, Run: 03
None time:  0.6093719510827214
None Run 09:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 63.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7311430959962308
None Run 10:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 98.33
   Final Test: 57.70
Split: 04, Run: 02
None time:  0.6401159840170294
None Run 11:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.80
Split: 04, Run: 03
None time:  0.6797737460583448
None Run 12:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 60.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6622773029375821
None Run 13:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.60
Split: 05, Run: 02
None time:  0.6146474638953805
None Run 14:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.00
Split: 05, Run: 03
None time:  0.8133414939511567
None Run 15:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6691612068098038
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 98.33
   Final Test: 60.80
Split: 06, Run: 02
None time:  0.6026691561564803
None Run 17:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 59.80
Split: 06, Run: 03
None time:  0.8017310108989477
None Run 18:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 62.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6700438300613314
None Run 19:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 98.33
   Final Test: 60.40
Split: 07, Run: 02
None time:  0.8585710150655359
None Run 20:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 63.30
Split: 07, Run: 03
None time:  0.8713929709047079
None Run 21:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 63.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6230010001454502
None Run 22:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.30
Split: 08, Run: 02
None time:  0.6678788170684129
None Run 23:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 65.20
Split: 08, Run: 03
None time:  0.736516023054719
None Run 24:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 67.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.025051733944565
None Run 25:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 98.33
   Final Test: 66.10
Split: 09, Run: 02
None time:  0.6514566789846867
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 71.40
Split: 09, Run: 03
None time:  0.8231784012168646
None Run 27:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 72.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6314036780968308
None Run 28:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.00
Split: 10, Run: 02
None time:  0.8525593609083444
None Run 29:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 60.30
Split: 10, Run: 03
None time:  0.5663975030183792
None Run 30:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.70
run time now: 2.088383674621582
total time:  23.392087226035073
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.17 ± 2.99
  Final Train: 99.56 ± 0.75
   Final Test: 63.95 ± 3.54
best run test_acc: 65.49000549316406
[I 2023-06-11 23:26:22,027] Trial 12 finished with value: 64.17333221435547 and parameters: {'Fwd': 1.0517189946737968e-06, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 0.05254588859274989, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027019316565606213, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.120322608982803e-05, 'weightedloss': True}. Best is trial 12 with value: 64.17333221435547.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0020861027067745285
weight_decay:  3.125731679765226e-05
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.123792561935261
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 85.00
   Final Test: 60.70
Split: 01, Run: 02
None time:  1.3932547690346837
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 75.00
   Final Test: 63.30
Split: 01, Run: 03
None time:  1.0116958010476083
None Run 03:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 88.33
   Final Test: 62.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7525760747957975
None Run 04:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.50
Split: 02, Run: 02
None time:  0.8133688631933182
None Run 05:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 59.80
Split: 02, Run: 03
None time:  1.162246799096465
None Run 06:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 91.67
   Final Test: 64.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4348155071493238
None Run 07:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 86.67
   Final Test: 61.30
Split: 03, Run: 02
None time:  0.6371742130722851
None Run 08:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.50
Split: 03, Run: 03
None time:  0.6303770609665662
None Run 09:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 55.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9190941739361733
None Run 10:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 91.67
   Final Test: 59.60
Split: 04, Run: 02
None time:  1.414087112993002
None Run 11:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 78.33
   Final Test: 64.50
Split: 04, Run: 03
None time:  0.7170349350199103
None Run 12:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0811157410498708
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 68.90
Split: 05, Run: 02
None time:  1.3792455468792468
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 90.00
   Final Test: 70.60
Split: 05, Run: 03
None time:  1.1364504958037287
None Run 15:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 69.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7086511498782784
None Run 16:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 61.70
Split: 06, Run: 02
None time:  0.6955892271362245
None Run 17:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 58.40
Split: 06, Run: 03
None time:  0.728973075048998
None Run 18:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.751257715979591
None Run 19:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 98.33
   Final Test: 60.60
Split: 07, Run: 02
None time:  0.7201766648795456
None Run 20:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 57.10
Split: 07, Run: 03
None time:  0.6394890199881047
None Run 21:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 58.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.359976588981226
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 67.90
Split: 08, Run: 02
None time:  1.4986292598769069
None Run 23:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 88.33
   Final Test: 66.90
Split: 08, Run: 03
None time:  1.3456447070930153
None Run 24:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 86.67
   Final Test: 65.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0588448841590434
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 68.90
Split: 09, Run: 02
None time:  1.4692717019934207
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 81.67
   Final Test: 68.80
Split: 09, Run: 03
None time:  1.4131440469063818
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 68.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7610601668711752
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 63.50
Split: 10, Run: 02
None time:  0.9561454618815333
None Run 29:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 65.40
Split: 10, Run: 03
None time:  0.6237485359888524
None Run 30:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.30
run time now: 2.3763575553894043
total time:  31.46919327392243
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.83 ± 3.30
  Final Train: 93.17 ± 7.26
   Final Test: 63.14 ± 4.21
best run test_acc: 64.88999938964844
[I 2023-06-11 23:26:53,897] Trial 13 finished with value: 64.82666778564453 and parameters: {'Fwd': 0.0001532853559522425, 'K': 2, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 0.37145857249777253, 'loop': 1, 'loss': 'CE', 'lr': 0.0020861027067745285, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.125731679765226e-05, 'weightedloss': True}. Best is trial 13 with value: 64.82666778564453.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.0014513459575187094
weight_decay:  6.682064131446342e-05
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6472709660883993
None Run 01:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 98.33
   Final Test: 43.60
Split: 01, Run: 02
None time:  1.0450671189464629
None Run 02:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 85.00
   Final Test: 51.90
Split: 01, Run: 03
None time:  1.0425538949202746
None Run 03:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 86.67
   Final Test: 52.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.124327143188566
None Run 04:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 91.67
   Final Test: 59.10
Split: 02, Run: 02
None time:  0.7323420417960733
None Run 05:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 60.10
Split: 02, Run: 03
None time:  0.9389881351962686
None Run 06:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 95.00
   Final Test: 58.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0179533560294658
None Run 07:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 85.00
   Final Test: 59.10
Split: 03, Run: 02
None time:  0.9022859779652208
None Run 08:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 88.33
   Final Test: 58.50
Split: 03, Run: 03
None time:  1.232262637000531
None Run 09:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 80.00
   Final Test: 58.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1669668639078736
None Run 10:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 81.67
   Final Test: 53.00
Split: 04, Run: 02
None time:  0.9681904308963567
None Run 11:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 86.67
   Final Test: 54.60
Split: 04, Run: 03
None time:  0.9137560850940645
None Run 12:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 83.33
   Final Test: 55.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.00499314093031
None Run 13:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 96.67
   Final Test: 62.60
Split: 05, Run: 02
None time:  0.8708410849794745
None Run 14:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 95.00
   Final Test: 66.20
Split: 05, Run: 03
None time:  0.75401505921036
None Run 15:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 65.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.817790657049045
None Run 16:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 98.33
   Final Test: 54.80
Split: 06, Run: 02
None time:  0.8960219449363649
None Run 17:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 90.00
   Final Test: 62.60
Split: 06, Run: 03
None time:  0.7484256268944591
None Run 18:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 98.33
   Final Test: 61.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8554637099150568
None Run 19:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 90.00
   Final Test: 55.50
Split: 07, Run: 02
None time:  0.9645226199645549
None Run 20:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 86.67
   Final Test: 58.10
Split: 07, Run: 03
None time:  0.7432833330240101
None Run 21:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 59.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8939349791035056
None Run 22:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 91.67
   Final Test: 55.00
Split: 08, Run: 02
None time:  1.1716072601266205
None Run 23:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 83.33
   Final Test: 60.20
Split: 08, Run: 03
None time:  0.6596505371853709
None Run 24:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8687272209208459
None Run 25:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 88.33
   Final Test: 62.00
Split: 09, Run: 02
None time:  1.3357641589827836
None Run 26:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 80.00
   Final Test: 63.80
Split: 09, Run: 03
None time:  0.6239926919806749
None Run 27:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0534, Train: 83.33%, Valid: 53.80% Test: 52.30%
Split: 10, Run: 01
None time:  1.6173141088802367
None Run 28:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 85.00
   Final Test: 52.40
Split: 10, Run: 02
None time:  0.8660311261191964
None Run 29:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 93.33
   Final Test: 53.80
Split: 10, Run: 03
None time:  0.945705289952457
None Run 30:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 93.33
   Final Test: 53.00
run time now: 3.4649922847747803
total time:  29.374537139898166
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.79 ± 5.23
  Final Train: 90.94 ± 6.49
   Final Test: 57.84 ± 4.98
best run test_acc: 59.410003662109375
[I 2023-06-11 23:27:23,724] Trial 14 finished with value: 59.78666687011719 and parameters: {'Fwd': 1.1047922969225281e-06, 'K': 3, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 0.02640200042532187, 'loop': 1, 'loss': 'CE', 'lr': 0.0014513459575187094, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.682064131446342e-05, 'weightedloss': True}. Best is trial 13 with value: 64.82666778564453.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0008787289005220071
weight_decay:  0.00011044928437300333
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1294264269527048
None Run 01:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 57.50
Split: 01, Run: 02
None time:  0.8773093179333955
None Run 02:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 58.30
Split: 01, Run: 03
None time:  1.0103784201201051
None Run 03:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 56.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6392299260478467
None Run 04:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.70
Split: 02, Run: 02
None time:  0.794345720903948
None Run 05:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.60
Split: 02, Run: 03
None time:  0.7948233878705651
None Run 06:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 63.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0674795689992607
None Run 07:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 57.30
Split: 03, Run: 02
None time:  0.7278317220043391
None Run 08:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.10
Split: 03, Run: 03
None time:  1.7956981000024825
None Run 09:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 56.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4806076760869473
None Run 10:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.50
Split: 04, Run: 02
None time:  0.9722528918646276
None Run 11:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.90
Split: 04, Run: 03
None time:  0.6830434501171112
None Run 12:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1707391238305718
None Run 13:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.60
Split: 05, Run: 02
None time:  0.9489922509528697
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.00
Split: 05, Run: 03
None time:  0.7710394950117916
None Run 15:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8692469329107553
None Run 16:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 61.80
Split: 06, Run: 02
None time:  0.903315301053226
None Run 17:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 61.30
Split: 06, Run: 03
None time:  1.141778843011707
None Run 18:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 58.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1702373449224979
None Run 19:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 58.10
Split: 07, Run: 02
None time:  0.8533371069934219
None Run 20:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 59.80
Split: 07, Run: 03
None time:  1.4482522269245237
None Run 21:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 57.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7036610990762711
None Run 22:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 65.40
Split: 08, Run: 02
None time:  1.0170319101307541
None Run 23:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 66.40
Split: 08, Run: 03
None time:  1.604851873125881
None Run 24:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 66.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1798373439814895
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.80
Split: 09, Run: 02
None time:  1.277499099029228
None Run 26:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.40
Split: 09, Run: 03
None time:  1.383142787963152
None Run 27:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 68.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.762743387138471
None Run 28:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.30
Split: 10, Run: 02
None time:  0.9348316439427435
None Run 29:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 60.90
Split: 10, Run: 03
None time:  0.9124469051603228
None Run 30:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.20
run time now: 2.6440346240997314
total time:  32.02602302702144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.43 ± 2.96
  Final Train: 100.00 ± 0.00
   Final Test: 61.29 ± 3.39
best run test_acc: 62.829994201660156
[I 2023-06-11 23:27:56,314] Trial 15 finished with value: 62.43333435058594 and parameters: {'Fwd': 4.413286188368285e-05, 'K': 2, 'alpha': 0.9, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 1.4634633623510784, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008787289005220071, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011044928437300333, 'weightedloss': True}. Best is trial 13 with value: 64.82666778564453.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.004331849287226871
weight_decay:  1.1151587653129761e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2572853930760175
None Run 01:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 90.00
   Final Test: 61.70
Split: 01, Run: 02
None time:  1.2418196420185268
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 86.67
   Final Test: 62.00
Split: 01, Run: 03
None time:  1.2807090189307928
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 93.33
   Final Test: 61.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.486140863969922
None Run 04:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 91.67
   Final Test: 63.30
Split: 02, Run: 02
None time:  0.9954339067917317
None Run 05:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 63.50
Split: 02, Run: 03
None time:  1.1370057461317629
None Run 06:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 96.67
   Final Test: 58.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.257991187972948
None Run 07:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 60.10
Split: 03, Run: 02
None time:  1.836139019113034
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 86.67
   Final Test: 60.50
Split: 03, Run: 03
None time:  2.135872781975195
None Run 09:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 93.33
   Final Test: 58.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4276267501991242
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 85.00
   Final Test: 63.90
Split: 04, Run: 02
None time:  1.5406713359989226
None Run 11:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 86.67
   Final Test: 65.10
Split: 04, Run: 03
None time:  1.7881008440162987
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 83.33
   Final Test: 65.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2903396720066667
None Run 13:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 68.40
Split: 05, Run: 02
None time:  1.006925541907549
None Run 14:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 98.33
   Final Test: 69.30
Split: 05, Run: 03
None time:  1.0430474109016359
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0395492801908404
None Run 16:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 60.80
Split: 06, Run: 02
None time:  1.1051306168083102
None Run 17:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 95.00
   Final Test: 62.10
Split: 06, Run: 03
None time:  1.0682477038353682
None Run 18:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 60.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2129306921269745
None Run 19:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 60.40
Split: 07, Run: 02
None time:  1.2898519989103079
None Run 20:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 91.67
   Final Test: 59.70
Split: 07, Run: 03
None time:  1.1609011539258063
None Run 21:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 60.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0838742789346725
None Run 22:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 95.00
   Final Test: 65.10
Split: 08, Run: 02
None time:  1.1457974968943745
None Run 23:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 64.10
Split: 08, Run: 03
None time:  1.2335679708048701
None Run 24:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 64.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0945718290749937
None Run 25:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 98.33
   Final Test: 67.30
Split: 09, Run: 02
None time:  1.1815403900109231
None Run 26:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 67.30
Split: 09, Run: 03
None time:  1.2599848629906774
None Run 27:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 95.00
   Final Test: 66.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2275524239521474
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 63.20
Split: 10, Run: 02
None time:  1.1859037140384316
None Run 29:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.00
Split: 10, Run: 03
None time:  1.1207690809387714
None Run 30:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.10
run time now: 3.571027994155884
total time:  39.20675774104893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.18 ± 2.45
  Final Train: 93.94 ± 4.54
   Final Test: 63.26 ± 3.03
best run test_acc: 63.8599967956543
[I 2023-06-11 23:28:35,949] Trial 16 finished with value: 65.18000793457031 and parameters: {'Fwd': 9.614098932177776e-05, 'K': 5, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 1.5457593128852425, 'loop': 1, 'loss': 'CE', 'lr': 0.004331849287226871, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1151587653129761e-05, 'weightedloss': True}. Best is trial 16 with value: 65.18000793457031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.004655770799376784
weight_decay:  1.1105620590063897e-05
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1379864050541073
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 98.33
   Final Test: 60.00
Split: 01, Run: 02
None time:  1.2471036280039698
None Run 02:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 96.67
   Final Test: 59.70
Split: 01, Run: 03
None time:  1.2010342159774154
None Run 03:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 96.67
   Final Test: 61.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2200571720022708
None Run 04:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 93.33
   Final Test: 59.90
Split: 02, Run: 02
None time:  1.1102270861156285
None Run 05:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 57.50
Split: 02, Run: 03
None time:  1.1819040079135448
None Run 06:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3085206791292876
None Run 07:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 98.33
   Final Test: 57.90
Split: 03, Run: 02
None time:  1.679649501806125
None Run 08:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 88.33
   Final Test: 57.70
Split: 03, Run: 03
None time:  1.2929782229475677
None Run 09:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 98.33
   Final Test: 59.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4246591599658132
None Run 10:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 63.70
Split: 04, Run: 02
None time:  1.600829906994477
None Run 11:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 88.33
   Final Test: 64.60
Split: 04, Run: 03
None time:  1.4956086140591651
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 86.67
   Final Test: 64.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0801273211836815
None Run 13:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 68.50
Split: 05, Run: 02
None time:  1.1920996331609786
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 67.90
Split: 05, Run: 03
None time:  1.1042221740353853
None Run 15:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0453298958018422
None Run 16:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 59.30
Split: 06, Run: 02
None time:  1.5684314619284123
None Run 17:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 85.00
   Final Test: 59.60
Split: 06, Run: 03
None time:  1.1800366688985378
None Run 18:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 95.00
   Final Test: 61.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2810062419157475
None Run 19:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 91.67
   Final Test: 59.20
Split: 07, Run: 02
None time:  1.1581552010029554
None Run 20:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 93.33
   Final Test: 59.50
Split: 07, Run: 03
None time:  1.1915461930911988
None Run 21:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 59.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1720531310420483
None Run 22:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 98.33
   Final Test: 63.60
Split: 08, Run: 02
None time:  1.4635236780159175
None Run 23:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 93.33
   Final Test: 65.60
Split: 08, Run: 03
None time:  1.397901268908754
None Run 24:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 91.67
   Final Test: 63.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1485572988167405
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 68.50
Split: 09, Run: 02
None time:  1.3538593740668148
None Run 26:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 95.00
   Final Test: 67.70
Split: 09, Run: 03
None time:  1.184217622037977
None Run 27:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 95.00
   Final Test: 67.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1658688529860228
None Run 28:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.30
Split: 10, Run: 02
None time:  1.2651365138590336
None Run 29:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 91.67
   Final Test: 61.00
Split: 10, Run: 03
None time:  1.0964271819684654
None Run 30:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.20
run time now: 3.5668601989746094
total time:  38.98751676711254
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.95 ± 2.76
  Final Train: 94.78 ± 4.15
   Final Test: 62.28 ± 3.71
best run test_acc: 63.20000076293945
[I 2023-06-11 23:29:15,361] Trial 17 finished with value: 63.953330993652344 and parameters: {'Fwd': 0.00010005982827203261, 'K': 6, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 1.9400095323350863, 'loop': 1, 'loss': 'CE', 'lr': 0.004655770799376784, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1105620590063897e-05, 'weightedloss': True}. Best is trial 16 with value: 65.18000793457031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.0013751141455486903
weight_decay:  1.2181806207576163e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8402539489325136
None Run 01:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.00
Split: 01, Run: 02
None time:  0.8470368280541152
None Run 02:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.20
Split: 01, Run: 03
None time:  0.926908157998696
None Run 03:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 59.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.814883426995948
None Run 04:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.20
Split: 02, Run: 02
None time:  0.7767035397700965
None Run 05:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.90
Split: 02, Run: 03
None time:  0.9759245878085494
None Run 06:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8703441449906677
None Run 07:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 57.20
Split: 03, Run: 02
None time:  0.8653977799694985
None Run 08:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.10
Split: 03, Run: 03
None time:  0.8024884921032935
None Run 09:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7704415020998567
None Run 10:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 57.10
Split: 04, Run: 02
None time:  1.0009699941147119
None Run 11:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.60
Split: 04, Run: 03
None time:  0.927317232824862
None Run 12:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 57.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7662161379121244
None Run 13:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 61.40
Split: 05, Run: 02
None time:  0.9512680359184742
None Run 14:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.60
Split: 05, Run: 03
None time:  0.7926795030944049
None Run 15:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 62.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7984721881803125
None Run 16:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.70
Split: 06, Run: 02
None time:  0.8312056958675385
None Run 17:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.10
Split: 06, Run: 03
None time:  0.8113886849023402
None Run 18:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 61.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8629386660177261
None Run 19:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 59.60
Split: 07, Run: 02
None time:  0.8582482959609479
None Run 20:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 60.50
Split: 07, Run: 03
None time:  0.7697753510437906
None Run 21:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 51.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8672605918254703
None Run 22:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 61.90
Split: 08, Run: 02
None time:  0.8898766760248691
None Run 23:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.10
Split: 08, Run: 03
None time:  0.9418027771171182
None Run 24:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.024338613031432
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.10
Split: 09, Run: 02
None time:  0.8239016539882869
None Run 26:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.30
Split: 09, Run: 03
None time:  0.8103121689055115
None Run 27:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.1366758609656245
None Run 28:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 66.70
Split: 10, Run: 02
None time:  1.1253503689076751
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.30
Split: 10, Run: 03
None time:  0.7783141229301691
None Run 30:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 60.40
run time now: 4.083850622177124
total time:  28.371353526134044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.11 ± 3.75
  Final Train: 99.89 ± 0.61
   Final Test: 60.82 ± 3.65
best run test_acc: 63.040000915527344
[I 2023-06-11 23:29:44,228] Trial 18 finished with value: 62.11333084106445 and parameters: {'Fwd': 0.0014470383295236092, 'K': 10, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 3.6364123894640215, 'loop': 1, 'loss': 'CE', 'lr': 0.0013751141455486903, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2181806207576163e-05, 'weightedloss': True}. Best is trial 16 with value: 65.18000793457031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.00395805728957752
weight_decay:  0.00022368694844222546
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3904393399134278
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 95.00
   Final Test: 62.10
Split: 01, Run: 02
None time:  1.5679481418337673
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 88.33
   Final Test: 62.70
Split: 01, Run: 03
None time:  1.5381147919688374
None Run 03:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 86.67
   Final Test: 63.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8590656179003417
None Run 04:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 91.67
   Final Test: 62.40
Split: 02, Run: 02
None time:  1.6315120428334922
None Run 05:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 91.67
   Final Test: 62.90
Split: 02, Run: 03
None time:  1.4604178240988404
None Run 06:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 96.67
   Final Test: 60.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5785315048415214
None Run 07:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 60.70
Split: 03, Run: 02
None time:  1.5221600339282304
None Run 08:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 95.00
   Final Test: 59.30
Split: 03, Run: 03
None time:  1.944298286922276
None Run 09:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 83.33
   Final Test: 59.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.9365507259499282
None Run 10:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 85.00
   Final Test: 64.50
Split: 04, Run: 02
None time:  1.862510141916573
None Run 11:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 83.33
   Final Test: 64.60
Split: 04, Run: 03
None time:  1.7275019851513207
None Run 12:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 83.33
   Final Test: 64.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3319444288499653
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 69.20
Split: 05, Run: 02
None time:  1.4872093759477139
None Run 14:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 70.10
Split: 05, Run: 03
None time:  1.512795144924894
None Run 15:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 68.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2910608118399978
None Run 16:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.30
Split: 06, Run: 02
None time:  1.3732298398390412
None Run 17:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 62.20
Split: 06, Run: 03
None time:  1.347172558074817
None Run 18:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 95.00
   Final Test: 62.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7424952881410718
None Run 19:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 60.50
Split: 07, Run: 02
None time:  1.7797010641079396
None Run 20:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 61.60
Split: 07, Run: 03
None time:  1.5611014941241592
None Run 21:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 60.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.617243826156482
None Run 22:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 88.33
   Final Test: 66.10
Split: 08, Run: 02
None time:  1.5563733950257301
None Run 23:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 91.67
   Final Test: 66.30
Split: 08, Run: 03
None time:  1.429504114901647
None Run 24:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 95.00
   Final Test: 66.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3213288290426135
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 67.40
Split: 09, Run: 02
None time:  1.3814440169371665
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 67.60
Split: 09, Run: 03
None time:  1.435007503023371
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 69.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.381719963857904
None Run 28:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 62.70
Split: 10, Run: 02
None time:  1.3994391758460552
None Run 29:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 63.20
Split: 10, Run: 03
None time:  1.292667926987633
None Run 30:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 95.00
   Final Test: 61.80
run time now: 4.110896587371826
total time:  47.289898784132674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.57 ± 2.14
  Final Train: 92.67 ± 4.83
   Final Test: 63.83 ± 3.13
best run test_acc: 64.44999694824219
[I 2023-06-11 23:30:31,949] Trial 19 finished with value: 65.56666564941406 and parameters: {'Fwd': 0.00014658070413891313, 'K': 5, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 1.2864516667349561, 'loop': 2, 'loss': 'CE', 'lr': 0.00395805728957752, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00022368694844222546, 'weightedloss': True}. Best is trial 19 with value: 65.56666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.004633847691245099
weight_decay:  0.0003118210721343921
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.520062018884346
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.60
Split: 01, Run: 02
None time:  1.7402407929766923
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 63.40
Split: 01, Run: 03
None time:  1.579674826003611
None Run 03:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 90.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5460878987796605
None Run 04:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 95.00
   Final Test: 63.20
Split: 02, Run: 02
None time:  1.599255007924512
None Run 05:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 63.00
Split: 02, Run: 03
None time:  1.247040401911363
None Run 06:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.234695225022733
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 61.30
Split: 03, Run: 02
None time:  2.1868882458657026
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 60.40
Split: 03, Run: 03
None time:  2.28876999206841
None Run 09:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 91.67
   Final Test: 61.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.032647585030645
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 86.67
   Final Test: 65.30
Split: 04, Run: 02
None time:  1.8764166180044413
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 86.67
   Final Test: 64.70
Split: 04, Run: 03
None time:  1.541584325954318
None Run 12:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 64.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4245010979939252
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 70.70
Split: 05, Run: 02
None time:  1.294258370064199
None Run 14:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 71.30
Split: 05, Run: 03
None time:  1.2734720569569618
None Run 15:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.559373659780249
None Run 16:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 95.00
   Final Test: 62.20
Split: 06, Run: 02
None time:  1.271901424974203
None Run 17:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 61.80
Split: 06, Run: 03
None time:  1.3453312560450286
None Run 18:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 98.33
   Final Test: 60.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4136634389869869
None Run 19:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 61.20
Split: 07, Run: 02
None time:  1.6014924799092114
None Run 20:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 91.67
   Final Test: 60.60
Split: 07, Run: 03
None time:  2.0808265609666705
None Run 21:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 90.00
   Final Test: 59.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3483126268256456
None Run 22:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 67.30
Split: 08, Run: 02
None time:  1.5415308310184628
None Run 23:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 98.33
   Final Test: 65.90
Split: 08, Run: 03
None time:  1.849405623972416
None Run 24:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 66.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.569613551022485
None Run 25:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 95.00
   Final Test: 68.60
Split: 09, Run: 02
None time:  1.4505112068727612
None Run 26:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 66.70
Split: 09, Run: 03
None time:  1.3199518469627947
None Run 27:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3736273441463709
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 02
None time:  1.257942717988044
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 03
None time:  1.603854486020282
None Run 30:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 61.90
run time now: 4.2722249031066895
total time:  48.9823803070467
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.17 ± 1.94
  Final Train: 95.44 ± 4.10
   Final Test: 64.19 ± 3.22
best run test_acc: 64.94999694824219
[I 2023-06-11 23:31:21,343] Trial 20 finished with value: 66.16666412353516 and parameters: {'Fwd': 9.781105864158649e-05, 'K': 5, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.276166025011679, 'loop': 2, 'loss': 'CE', 'lr': 0.004633847691245099, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003118210721343921, 'weightedloss': True}. Best is trial 20 with value: 66.16666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.004480267848361967
weight_decay:  0.00033076747759892854
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.305429111002013
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 98.33
   Final Test: 62.30
Split: 01, Run: 02
None time:  1.6814461757894605
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 90.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.5133036139886826
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 62.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6659729038365185
None Run 04:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 62.90
Split: 02, Run: 02
None time:  1.657019258942455
None Run 05:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 65.60
Split: 02, Run: 03
None time:  1.3232619690243155
None Run 06:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.9595264189410955
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 61.60
Split: 03, Run: 02
None time:  1.8226845702156425
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 95.00
   Final Test: 61.40
Split: 03, Run: 03
None time:  2.2625254970043898
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 90.00
   Final Test: 60.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.9363694989588112
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 91.67
   Final Test: 63.90
Split: 04, Run: 02
None time:  1.6975912870839238
None Run 11:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 64.80
Split: 04, Run: 03
None time:  1.3668912230059505
None Run 12:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4917905922047794
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 71.10
Split: 05, Run: 02
None time:  1.2133994800969958
None Run 14:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 69.80
Split: 05, Run: 03
None time:  1.4124382010195404
None Run 15:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4235392599366605
None Run 16:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 61.70
Split: 06, Run: 02
None time:  1.4692950320895761
None Run 17:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 95.00
   Final Test: 62.40
Split: 06, Run: 03
None time:  1.357603422831744
None Run 18:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 61.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6016858238726854
None Run 19:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 60.90
Split: 07, Run: 02
None time:  1.4734645620919764
None Run 20:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 95.00
   Final Test: 62.30
Split: 07, Run: 03
None time:  1.5069432409945875
None Run 21:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 61.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4900177840609103
None Run 22:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 98.33
   Final Test: 64.00
Split: 08, Run: 02
None time:  1.6699827779084444
None Run 23:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 66.90
Split: 08, Run: 03
None time:  1.7283357188571244
None Run 24:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 66.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3927792890463024
None Run 25:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.80
Split: 09, Run: 02
None time:  1.4737191719468683
None Run 26:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 98.33
   Final Test: 68.00
Split: 09, Run: 03
None time:  1.4854472188744694
None Run 27:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 68.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4763180899899453
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 63.00
Split: 10, Run: 02
None time:  1.357821643119678
None Run 29:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.10
Split: 10, Run: 03
None time:  1.3732074841391295
None Run 30:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.50
run time now: 4.251037836074829
total time:  47.61477726791054
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.31 ± 2.01
  Final Train: 96.33 ± 2.92
   Final Test: 64.38 ± 3.13
best run test_acc: 65.31999969482422
[I 2023-06-11 23:32:09,415] Trial 21 finished with value: 66.3066635131836 and parameters: {'Fwd': 8.596140425323985e-05, 'K': 5, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 4.6001029351754035, 'loop': 2, 'loss': 'CE', 'lr': 0.004480267848361967, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00033076747759892854, 'weightedloss': True}. Best is trial 21 with value: 66.3066635131836.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.75
lr:  0.006524762031754825
weight_decay:  0.0001833438490606542
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6829734989441931
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 91.67
   Final Test: 62.80
Split: 01, Run: 02
None time:  1.4344477960839868
None Run 02:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 95.00
   Final Test: 62.90
Split: 01, Run: 03
None time:  1.6359116190578789
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 96.67
   Final Test: 62.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7214028530288488
None Run 04:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.80
Split: 02, Run: 02
None time:  1.5001916440669447
None Run 05:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.50
Split: 02, Run: 03
None time:  1.831158468965441
None Run 06:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 61.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.722663369961083
None Run 07:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.90
Split: 03, Run: 02
None time:  1.3932532689068466
None Run 08:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.90
Split: 03, Run: 03
None time:  1.4307907239999622
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.867764291819185
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 88.33
   Final Test: 63.80
Split: 04, Run: 02
None time:  1.5700605378951877
None Run 11:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 63.80
Split: 04, Run: 03
None time:  1.9310314741451293
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 86.67
   Final Test: 64.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7146040110383183
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 71.00
Split: 05, Run: 02
None time:  1.693632789188996
None Run 14:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.80
Split: 05, Run: 03
None time:  1.546787170926109
None Run 15:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 70.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3529477631673217
None Run 16:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 62.40
Split: 06, Run: 02
None time:  1.5165051240473986
None Run 17:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 62.30
Split: 06, Run: 03
None time:  1.5883573631290346
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7442485480569303
None Run 19:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 61.30
Split: 07, Run: 02
None time:  1.515027011046186
None Run 20:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 95.00
   Final Test: 60.20
Split: 07, Run: 03
None time:  1.4881537698674947
None Run 21:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 95.00
   Final Test: 60.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7585459880065173
None Run 22:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 95.00
   Final Test: 66.40
Split: 08, Run: 02
None time:  1.7025781071279198
None Run 23:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 66.20
Split: 08, Run: 03
None time:  1.966278127860278
None Run 24:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 66.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.437948688864708
None Run 25:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 68.30
Split: 09, Run: 02
None time:  1.5788881331682205
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 68.90
Split: 09, Run: 03
None time:  1.4881871149409562
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.5233581350184977
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.70
Split: 10, Run: 02
None time:  1.4823319220449775
None Run 29:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.90
Split: 10, Run: 03
None time:  1.3301937559153885
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.10
run time now: 4.372278213500977
total time:  49.1960667129606
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.95 ± 2.28
  Final Train: 96.39 ± 3.42
   Final Test: 64.27 ± 3.15
best run test_acc: 64.90999603271484
[I 2023-06-11 23:32:59,180] Trial 22 finished with value: 65.94667053222656 and parameters: {'Fwd': 1.8287685154323088e-05, 'K': 5, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 4.617686315782454, 'loop': 2, 'loss': 'CE', 'lr': 0.006524762031754825, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001833438490606542, 'weightedloss': True}. Best is trial 21 with value: 66.3066635131836.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.009500145896002565
weight_decay:  0.00042090904544320423
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5704641428310424
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 93.33
   Final Test: 62.00
Split: 01, Run: 02
None time:  1.8183799090329558
None Run 02:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 86.67
   Final Test: 61.00
Split: 01, Run: 03
None time:  1.517550284974277
None Run 03:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 95.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6898599949199706
None Run 04:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 95.00
   Final Test: 62.70
Split: 02, Run: 02
None time:  1.600257714977488
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 62.60
Split: 02, Run: 03
None time:  1.4711007471196353
None Run 06:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7901589469984174
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 63.90
Split: 03, Run: 02
None time:  2.109791769878939
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 88.33
   Final Test: 60.80
Split: 03, Run: 03
None time:  1.7990749788004905
None Run 09:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 93.33
   Final Test: 59.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6359205499757081
None Run 10:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 91.67
   Final Test: 64.20
Split: 04, Run: 02
None time:  1.6854077188763767
None Run 11:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 63.50
Split: 04, Run: 03
None time:  1.9004282099194825
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 85.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7948737770784646
None Run 13:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 69.60
Split: 05, Run: 02
None time:  1.5533489780500531
None Run 14:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.90
Split: 05, Run: 03
None time:  1.391382406000048
None Run 15:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3879341899883002
None Run 16:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 59.10
Split: 06, Run: 02
None time:  1.784727827180177
None Run 17:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 85.00
   Final Test: 65.40
Split: 06, Run: 03
None time:  1.564910912886262
None Run 18:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 91.67
   Final Test: 61.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4206019998528063
None Run 19:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 60.80
Split: 07, Run: 02
None time:  1.4850018208380789
None Run 20:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 61.70
Split: 07, Run: 03
None time:  1.8687807340174913
None Run 21:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 86.67
   Final Test: 61.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4926171200349927
None Run 22:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 98.33
   Final Test: 64.80
Split: 08, Run: 02
None time:  1.724449277156964
None Run 23:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 64.90
Split: 08, Run: 03
None time:  1.479720100061968
None Run 24:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 98.33
   Final Test: 64.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5571555700153112
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 68.20
Split: 09, Run: 02
None time:  1.7012338389176875
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.70
Split: 09, Run: 03
None time:  1.5509569589048624
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 69.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4345590209122747
None Run 28:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 63.30
Split: 10, Run: 02
None time:  1.342074953019619
None Run 29:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 03
None time:  1.5582727370783687
None Run 30:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 98.33
   Final Test: 63.60
run time now: 4.3736231327056885
total time:  49.70529095712118
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.48 ± 2.65
  Final Train: 94.61 ± 4.41
   Final Test: 63.92 ± 3.23
best run test_acc: 64.88999938964844
[I 2023-06-11 23:33:49,423] Trial 23 finished with value: 65.47999572753906 and parameters: {'Fwd': 1.3442271311822487e-05, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 4.994006245780482, 'loop': 2, 'loss': 'CE', 'lr': 0.009500145896002565, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00042090904544320423, 'weightedloss': True}. Best is trial 21 with value: 66.3066635131836.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.45
lr:  0.006439254405795136
weight_decay:  0.00026399523478419485
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6275458121672273
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 93.33
   Final Test: 62.60
Split: 01, Run: 02
None time:  1.5419302410446107
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 90.00
   Final Test: 61.70
Split: 01, Run: 03
None time:  1.6605233589652926
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 91.67
   Final Test: 64.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7538478039205074
None Run 04:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 60.70
Split: 02, Run: 02
None time:  1.357628070982173
None Run 05:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.80
Split: 02, Run: 03
None time:  1.2692915808875114
None Run 06:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.1568794660270214
None Run 07:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 61.30
Split: 03, Run: 02
None time:  2.1934933809097856
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 85.00
   Final Test: 61.20
Split: 03, Run: 03
None time:  1.9491776500362903
None Run 09:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 90.00
   Final Test: 60.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.506243326002732
None Run 10:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 85.00
   Final Test: 65.00
Split: 04, Run: 02
None time:  1.7407122780568898
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 64.60
Split: 04, Run: 03
None time:  2.1108066660817713
None Run 12:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 88.33
   Final Test: 65.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3827838588040322
None Run 13:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 05, Run: 02
None time:  1.5049703060649335
None Run 14:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 70.70
Split: 05, Run: 03
None time:  1.4214445061516017
None Run 15:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 71.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.284206372918561
None Run 16:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 62.20
Split: 06, Run: 02
None time:  1.3647989330347627
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 63.00
Split: 06, Run: 03
None time:  1.3324638521298766
None Run 18:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 95.00
   Final Test: 61.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6999655680265278
None Run 19:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 60.90
Split: 07, Run: 02
None time:  1.8352778730913997
None Run 20:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 95.00
   Final Test: 60.80
Split: 07, Run: 03
None time:  1.468024805188179
None Run 21:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 60.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.663323723943904
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 67.20
Split: 08, Run: 02
None time:  1.6384382110554725
None Run 23:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 63.50
Split: 08, Run: 03
None time:  1.6605904249008745
None Run 24:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 98.33
   Final Test: 65.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6140836339909583
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 69.10
Split: 09, Run: 02
None time:  1.5085923918522894
None Run 26:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 67.60
Split: 09, Run: 03
None time:  1.5600477568805218
None Run 27:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.454874775139615
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 02
None time:  1.5462725840043277
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 03
None time:  1.6337693489622325
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 64.60
run time now: 4.671812057495117
total time:  50.503385527059436
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.79 ± 2.34
  Final Train: 95.22 ± 4.37
   Final Test: 64.06 ± 3.25
best run test_acc: 64.85000610351562
[I 2023-06-11 23:34:40,453] Trial 24 finished with value: 65.7933349609375 and parameters: {'Fwd': 5.241082565598722e-05, 'K': 5, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 4.823347522521394, 'loop': 2, 'loss': 'CE', 'lr': 0.006439254405795136, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00026399523478419485, 'weightedloss': True}. Best is trial 21 with value: 66.3066635131836.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.75
lr:  0.006153714324577127
weight_decay:  0.0026541137751319678
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1707535840105265
None Run 01:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 39.80
Split: 01, Run: 02
None time:  2.1918877880088985
None Run 02:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 39.80
Split: 01, Run: 03
None time:  2.1204537679441273
None Run 03:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 39.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5392880418803543
None Run 04:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 42.70
Split: 02, Run: 02
None time:  1.4529684928711504
None Run 05:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 42.70
Split: 02, Run: 03
None time:  1.573841338045895
None Run 06:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 42.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4208046630956233
None Run 07:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 43.50
Split: 03, Run: 02
None time:  1.5338777860160917
None Run 08:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 43.50
Split: 03, Run: 03
None time:  1.4355279169976711
None Run 09:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 43.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.3844984269235283
None Run 10:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 45.00
Split: 04, Run: 02
None time:  3.317018144065514
None Run 11:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 45.00
Split: 04, Run: 03
None time:  3.3370250989682972
None Run 12:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 45.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1265735807828605
None Run 13:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 47.40
Split: 05, Run: 02
None time:  1.9822638118639588
None Run 14:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 47.40
Split: 05, Run: 03
None time:  2.0548554551787674
None Run 15:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 47.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8244661500211805
None Run 16:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 43.40
Split: 06, Run: 02
None time:  1.9273734958842397
None Run 17:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 43.40
Split: 06, Run: 03
None time:  1.8511615409515798
None Run 18:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 43.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.517118020914495
None Run 19:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 39.40
Split: 07, Run: 02
None time:  1.5720880741719157
None Run 20:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 39.40
Split: 07, Run: 03
None time:  1.582910561002791
None Run 21:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 39.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3347065350972116
None Run 22:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 46.90
Split: 08, Run: 02
None time:  1.2853959298226982
None Run 23:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 46.90
Split: 08, Run: 03
None time:  1.4330511470325291
None Run 24:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 46.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5813805449288338
None Run 25:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 46.90
Split: 09, Run: 02
None time:  1.6712899329140782
None Run 26:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 46.90
Split: 09, Run: 03
None time:  1.5976371611468494
None Run 27:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 46.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.860704598017037
None Run 28:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 42.90
Split: 10, Run: 02
None time:  1.8436483249533921
None Run 29:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 42.90
Split: 10, Run: 03
None time:  1.8520223998930305
None Run 30:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 42.90
run time now: 5.596624135971069
total time:  57.439339281991124
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 44.54 ± 2.60
  Final Train: 100.00 ± 0.00
   Final Test: 43.79 ± 2.71
best run test_acc: 43.78999710083008
[I 2023-06-11 23:35:38,327] Trial 25 finished with value: 44.53999710083008 and parameters: {'Fwd': 1.2806201299811485e-05, 'K': 6, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.0, 'lambda2': 4.037911478934911, 'loop': 2, 'loss': 'CE', 'lr': 0.006153714324577127, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0026541137751319678, 'weightedloss': True}. Best is trial 21 with value: 66.3066635131836.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.003261362680226691
weight_decay:  0.0005833935788190023
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4444792089052498
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 61.70
Split: 01, Run: 02
None time:  1.70654963189736
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 93.33
   Final Test: 63.00
Split: 01, Run: 03
None time:  1.7063410570845008
None Run 03:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 88.33
   Final Test: 61.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6091344961896539
None Run 04:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 63.80
Split: 02, Run: 02
None time:  1.872505177045241
None Run 05:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 62.60
Split: 02, Run: 03
None time:  1.8542427991051227
None Run 06:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 93.33
   Final Test: 62.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6604501970577985
None Run 07:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 98.33
   Final Test: 60.90
Split: 03, Run: 02
None time:  1.8456604881212115
None Run 08:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 60.50
Split: 03, Run: 03
None time:  1.6258799429051578
None Run 09:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 98.33
   Final Test: 59.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.9740577701013535
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 64.80
Split: 04, Run: 02
None time:  1.9056704919785261
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 64.60
Split: 04, Run: 03
None time:  1.5405807439237833
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 64.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5407612861599773
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.50
Split: 05, Run: 02
None time:  1.512939119944349
None Run 14:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.00
Split: 05, Run: 03
None time:  1.5867021309677511
None Run 15:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5478480579331517
None Run 16:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 95.00
   Final Test: 61.00
Split: 06, Run: 02
None time:  1.626445627072826
None Run 17:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 61.80
Split: 06, Run: 03
None time:  1.4727831440977752
None Run 18:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7369274639058858
None Run 19:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 61.80
Split: 07, Run: 02
None time:  1.4566686369944364
None Run 20:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 60.70
Split: 07, Run: 03
None time:  1.6744585640262812
None Run 21:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 60.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5492156990803778
None Run 22:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 66.60
Split: 08, Run: 02
None time:  1.6879832961130887
None Run 23:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 65.90
Split: 08, Run: 03
None time:  1.4665449471212924
None Run 24:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 98.33
   Final Test: 65.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.503774587996304
None Run 25:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.60
Split: 09, Run: 02
None time:  1.5902529039885849
None Run 26:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.30
Split: 09, Run: 03
None time:  1.3919171181041747
None Run 27:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 67.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4493719360325485
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.20
Split: 10, Run: 02
None time:  1.4395493839401752
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.00
Split: 10, Run: 03
None time:  1.5690161858219653
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 63.50
run time now: 4.499073266983032
total time:  49.61882024607621
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 2.24
  Final Train: 97.00 ± 3.14
   Final Test: 64.02 ± 3.24
best run test_acc: 64.7199935913086
[I 2023-06-11 23:36:28,543] Trial 26 finished with value: 65.53334045410156 and parameters: {'Fwd': 6.03898336397859e-05, 'K': 7, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 5.7865866016487635, 'loop': 2, 'loss': 'CE', 'lr': 0.003261362680226691, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005833935788190023, 'weightedloss': True}. Best is trial 21 with value: 66.3066635131836.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.00578402696060028
weight_decay:  0.00022145510173868425
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9979371610097587
None Run 01:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 56.70
Split: 01, Run: 02
None time:  1.0311721342150122
None Run 02:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 03
None time:  0.9164539340417832
None Run 03:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 56.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0518513689748943
None Run 04:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 54.80
Split: 02, Run: 02
None time:  1.0156449319329113
None Run 05:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.70
Split: 02, Run: 03
None time:  0.9914529919624329
None Run 06:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0042641879990697
None Run 07:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 55.00
Split: 03, Run: 02
None time:  1.0764956469647586
None Run 08:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.10
Split: 03, Run: 03
None time:  1.0389207110274583
None Run 09:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.30
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9669268869329244
None Run 10:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.70
Split: 04, Run: 02
None time:  0.9785301911178976
None Run 11:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.10
Split: 04, Run: 03
None time:  1.11819122498855
None Run 12:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9952769118826836
None Run 13:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.80
Split: 05, Run: 02
None time:  1.096457145176828
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.10
Split: 05, Run: 03
None time:  1.106873707845807
None Run 15:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0421599759720266
None Run 16:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.60
Split: 06, Run: 02
None time:  0.9785058740526438
None Run 17:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.70
Split: 06, Run: 03
None time:  1.087273851968348
None Run 18:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 59.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9942788989283144
None Run 19:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 57.80
Split: 07, Run: 02
None time:  0.9418000828009099
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 54.10
Split: 07, Run: 03
None time:  0.9290925869718194
None Run 21:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 55.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0402078521437943
None Run 22:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 60.60
Split: 08, Run: 02
None time:  0.9872679410036653
None Run 23:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.10
Split: 08, Run: 03
None time:  1.050500829005614
None Run 24:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 61.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0547302800696343
None Run 25:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 62.90
Split: 09, Run: 02
None time:  0.9884758319240063
None Run 26:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 58.20
Split: 09, Run: 03
None time:  0.9481816838961095
None Run 27:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0744088909123093
None Run 28:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 59.70
Split: 10, Run: 02
None time:  1.0367678990587592
None Run 29:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.10
Split: 10, Run: 03
None time:  1.0086222339887172
None Run 30:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 58.30
run time now: 3.1573150157928467
total time:  31.570704034995288
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.26 ± 3.46
  Final Train: 100.00 ± 0.00
   Final Test: 58.71 ± 3.01
best run test_acc: 59.849998474121094
[I 2023-06-11 23:37:00,671] Trial 27 finished with value: 59.26000213623047 and parameters: {'Fwd': 2.2879768048257113e-05, 'K': 4, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 4.07434641315899, 'loop': 2, 'loss': 'CE', 'lr': 0.00578402696060028, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00022145510173868425, 'weightedloss': True}. Best is trial 21 with value: 66.3066635131836.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.008096006481446327
weight_decay:  0.0011127596687212748
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6222536058630794
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 66.10
Split: 01, Run: 02
None time:  1.6505558439530432
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 65.20
Split: 01, Run: 03
None time:  1.6212683040648699
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 90.00
   Final Test: 62.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4614886487834156
None Run 04:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.60
Split: 02, Run: 02
None time:  1.8472491439897567
None Run 05:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 66.00
Split: 02, Run: 03
None time:  1.150279178051278
None Run 06:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6873910550493747
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 60.50
Split: 03, Run: 02
None time:  1.85798448510468
None Run 08:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 62.80
Split: 03, Run: 03
None time:  1.274088754085824
None Run 09:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 59.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8650862099602818
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 88.33
   Final Test: 65.60
Split: 04, Run: 02
None time:  2.7330372270662338
None Run 11:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 85.00
   Final Test: 66.30
Split: 04, Run: 03
None time:  2.3660579801071435
None Run 12:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 85.00
   Final Test: 65.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3552588680759072
None Run 13:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 98.33
   Final Test: 69.90
Split: 05, Run: 02
None time:  1.2600318710319698
None Run 14:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.10
Split: 05, Run: 03
None time:  1.3859304541256279
None Run 15:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 71.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4604676789604127
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 61.70
Split: 06, Run: 02
None time:  1.6588318808935583
None Run 17:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 65.30
Split: 06, Run: 03
None time:  1.5780529868789017
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 95.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.272625647019595
None Run 19:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 61.70
Split: 07, Run: 02
None time:  1.6664634288754314
None Run 20:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 61.10
Split: 07, Run: 03
None time:  1.3386334960814565
None Run 21:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 95.00
   Final Test: 61.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5233329508919269
None Run 22:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 67.30
Split: 08, Run: 02
None time:  1.6664365821052343
None Run 23:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 67.70
Split: 08, Run: 03
None time:  1.542843331117183
None Run 24:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 67.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.375864356989041
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.30
Split: 09, Run: 02
None time:  1.344199582003057
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.20
Split: 09, Run: 03
None time:  1.4009898509830236
None Run 27:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 69.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4646163990255445
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 65.80
Split: 10, Run: 02
None time:  1.3182398220524192
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 64.70
Split: 10, Run: 03
None time:  1.5541669121012092
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 64.20
run time now: 4.373991012573242
total time:  48.3109613659326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.13 ± 1.82
  Final Train: 95.67 ± 4.23
   Final Test: 65.24 ± 3.00
best run test_acc: 66.25
[I 2023-06-11 23:37:49,406] Trial 28 finished with value: 67.12667083740234 and parameters: {'Fwd': 0.00023672550877057834, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 5.609790450460338, 'loop': 2, 'loss': 'CE', 'lr': 0.008096006481446327, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0011127596687212748, 'weightedloss': True}. Best is trial 28 with value: 67.12667083740234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.003311149049759977
weight_decay:  0.0011408639047461313
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.040648833150044
None Run 01:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 59.80
Split: 01, Run: 02
None time:  0.9822122198529541
None Run 02:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 58.70
Split: 01, Run: 03
None time:  1.1068193181417882
None Run 03:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8917311429977417
None Run 04:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 59.60
Split: 02, Run: 02
None time:  0.9889141130261123
None Run 05:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 61.10
Split: 02, Run: 03
None time:  1.072807878954336
None Run 06:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 61.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.055765698896721
None Run 07:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 56.70
Split: 03, Run: 02
None time:  1.0210020001977682
None Run 08:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.00
Split: 03, Run: 03
None time:  1.01376593997702
None Run 09:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0448588500730693
None Run 10:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.60
Split: 04, Run: 02
None time:  1.0953546431846917
None Run 11:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.30
Split: 04, Run: 03
None time:  1.081721865106374
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 61.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1259769510943443
None Run 13:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.40
Split: 05, Run: 02
None time:  1.0925030631478876
None Run 14:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.20
Split: 05, Run: 03
None time:  1.0816087569110096
None Run 15:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0001975751947612
None Run 16:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 57.10
Split: 06, Run: 02
None time:  0.9585683178156614
None Run 17:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 59.20
Split: 06, Run: 03
None time:  1.0058576399460435
None Run 18:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9676142781972885
None Run 19:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 55.30
Split: 07, Run: 02
None time:  1.0312386199366301
None Run 20:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 57.40
Split: 07, Run: 03
None time:  0.9898468870669603
None Run 21:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 57.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.05389418406412
None Run 22:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.70
Split: 08, Run: 02
None time:  1.0049411940854043
None Run 23:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 61.50
Split: 08, Run: 03
None time:  0.9848411399871111
None Run 24:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 60.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.003239399055019
None Run 25:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 64.80
Split: 09, Run: 02
None time:  1.0323619488626719
None Run 26:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 65.10
Split: 09, Run: 03
None time:  0.9511290239170194
None Run 27:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 69.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9898131131194532
None Run 28:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.10
Split: 10, Run: 02
None time:  0.9644774589687586
None Run 29:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.10
Split: 10, Run: 03
None time:  1.038189773913473
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.10
run time now: 3.034174680709839
total time:  31.744953630957752
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.75 ± 2.85
  Final Train: 100.00 ± 0.00
   Final Test: 60.94 ± 3.35
best run test_acc: 61.8699951171875
[I 2023-06-11 23:38:21,606] Trial 29 finished with value: 61.753334045410156 and parameters: {'Fwd': 0.000251083738058158, 'K': 8, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 5.930646769874336, 'loop': 2, 'loss': 'CE', 'lr': 0.003311149049759977, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011408639047461313, 'weightedloss': True}. Best is trial 28 with value: 67.12667083740234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.008787945353313767
weight_decay:  0.003051215343331127
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4590304540470243
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 91.67
   Final Test: 64.70
Split: 01, Run: 02
None time:  1.3881330138538033
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 66.30
Split: 01, Run: 03
None time:  1.619298969162628
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 88.33
   Final Test: 65.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1405515200458467
None Run 04:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 62.40
Split: 02, Run: 02
None time:  1.567803307902068
None Run 05:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 66.60
Split: 02, Run: 03
None time:  1.3480579140596092
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 66.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9151767701841891
None Run 07:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.20
Split: 03, Run: 02
None time:  1.265346186934039
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 61.00
Split: 03, Run: 03
None time:  1.639160956023261
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 88.33
   Final Test: 62.30
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2937139661516994
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 88.33
   Final Test: 65.50
Split: 04, Run: 02
None time:  1.6490825018845499
None Run 11:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 86.67
   Final Test: 65.60
Split: 04, Run: 03
None time:  1.1122785839252174
None Run 12:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 63.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.104091937886551
None Run 13:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 70.60
Split: 05, Run: 02
None time:  1.1543671020772308
None Run 14:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 70.10
Split: 05, Run: 03
None time:  1.283945009112358
None Run 15:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 69.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4336993650067598
None Run 16:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 88.33
   Final Test: 65.80
Split: 06, Run: 02
None time:  1.2975608501583338
None Run 17:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 91.67
   Final Test: 64.60
Split: 06, Run: 03
None time:  1.2355692039709538
None Run 18:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3302382158581167
None Run 19:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 95.00
   Final Test: 61.40
Split: 07, Run: 02
None time:  1.3226797201205045
None Run 20:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 62.90
Split: 07, Run: 03
None time:  1.2137709690723568
None Run 21:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 61.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4703582120127976
None Run 22:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 67.70
Split: 08, Run: 02
None time:  1.648867679061368
None Run 23:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 68.10
Split: 08, Run: 03
None time:  1.242114368127659
None Run 24:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 67.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.285248853964731
None Run 25:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 68.90
Split: 09, Run: 02
None time:  1.2823437580373138
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 69.40
Split: 09, Run: 03
None time:  1.2812113529071212
None Run 27:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 95.00
   Final Test: 68.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2247810380067676
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.90
Split: 10, Run: 02
None time:  1.0042343160603195
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.20
Split: 10, Run: 03
None time:  1.0787126880604774
None Run 30:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.30
run time now: 3.347012996673584
total time:  40.34879735391587
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.25 ± 1.88
  Final Train: 94.06 ± 4.10
   Final Test: 65.49 ± 2.87
best run test_acc: 66.20999908447266
[I 2023-06-11 23:39:02,455] Trial 30 finished with value: 67.25333404541016 and parameters: {'Fwd': 0.0008351602362131448, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 3.0158063954453245, 'loop': 2, 'loss': 'CE', 'lr': 0.008787945353313767, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003051215343331127, 'weightedloss': True}. Best is trial 30 with value: 67.25333404541016.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8500000000000001
lr:  0.008504912788540429
weight_decay:  0.003967825766863541
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5203883291687816
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 88.33
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.4631693959236145
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 65.30
Split: 01, Run: 03
None time:  1.3170745430979878
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 67.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.514553447952494
None Run 04:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.30
Split: 02, Run: 02
None time:  1.3334080760832876
None Run 05:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 64.80
Split: 02, Run: 03
None time:  1.3922876149881631
None Run 06:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 66.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8162265568971634
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 60.70
Split: 03, Run: 02
None time:  1.1158117239829153
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.00
Split: 03, Run: 03
None time:  1.4774345040787011
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 86.67
   Final Test: 63.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3757663241121918
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 88.33
   Final Test: 65.10
Split: 04, Run: 02
None time:  1.8297251649200916
None Run 11:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 86.67
   Final Test: 65.40
Split: 04, Run: 03
None time:  1.6020094000268728
None Run 12:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 86.67
   Final Test: 64.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.138688093982637
None Run 13:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 69.70
Split: 05, Run: 02
None time:  1.177075588842854
None Run 14:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 70.40
Split: 05, Run: 03
None time:  1.2444275480229408
None Run 15:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.00
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2390609469730407
None Run 16:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 62.60
Split: 06, Run: 02
None time:  1.3822116579394788
None Run 17:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 90.00
   Final Test: 64.20
Split: 06, Run: 03
None time:  1.1642316761426628
None Run 18:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 62.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.516904469113797
None Run 19:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 91.67
   Final Test: 60.40
Split: 07, Run: 02
None time:  1.3232545680366457
None Run 20:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 62.50
Split: 07, Run: 03
None time:  1.1348803720902652
None Run 21:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 62.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3394846532028168
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 67.60
Split: 08, Run: 02
None time:  1.4839343999046832
None Run 23:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 68.10
Split: 08, Run: 03
None time:  1.4721160421613604
None Run 24:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 95.00
   Final Test: 66.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2218644530512393
None Run 25:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 68.50
Split: 09, Run: 02
None time:  1.480831130873412
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 91.67
   Final Test: 68.30
Split: 09, Run: 03
None time:  1.1694188159890473
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 69.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.423327371943742
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 91.67
   Final Test: 65.10
Split: 10, Run: 02
None time:  1.0517801009118557
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 64.00
Split: 10, Run: 03
None time:  1.2681789270136505
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 65.40
run time now: 3.7825984954833984
total time:  42.014508810825646
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.35 ± 1.48
  Final Train: 93.83 ± 3.94
   Final Test: 65.39 ± 2.85
best run test_acc: 66.29999542236328
[I 2023-06-11 23:39:44,890] Trial 31 finished with value: 67.34666442871094 and parameters: {'Fwd': 0.0005674855991259283, 'K': 5, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 2.9905325075249083, 'loop': 2, 'loss': 'CE', 'lr': 0.008504912788540429, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003967825766863541, 'weightedloss': True}. Best is trial 31 with value: 67.34666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.008814731974063053
weight_decay:  0.004400485860437867
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.020231544971466
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 64.10
Split: 01, Run: 02
None time:  1.278987516881898
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.2492315617855638
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 88.33
   Final Test: 65.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9273353018797934
None Run 04:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.40
Split: 02, Run: 02
None time:  1.2648682091385126
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.50
Split: 02, Run: 03
None time:  0.9707259810529649
None Run 06:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 66.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2406944839749485
None Run 07:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 91.67
   Final Test: 63.10
Split: 03, Run: 02
None time:  1.362213338026777
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 62.60
Split: 03, Run: 03
None time:  1.1635373530443758
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 62.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7036197050474584
None Run 10:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 85.00
   Final Test: 66.20
Split: 04, Run: 02
None time:  2.338757626945153
None Run 11:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 85.00
   Final Test: 66.40
Split: 04, Run: 03
None time:  1.3590004469733685
None Run 12:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 86.67
   Final Test: 66.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.884194398066029
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 70.70
Split: 05, Run: 02
None time:  0.9733567500952631
None Run 14:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 71.00
Split: 05, Run: 03
None time:  0.9151211939752102
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9409830099903047
None Run 16:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 63.00
Split: 06, Run: 02
None time:  0.9142507640644908
None Run 17:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 65.30
Split: 06, Run: 03
None time:  1.0672153870109469
None Run 18:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1650322289206088
None Run 19:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 60.30
Split: 07, Run: 02
None time:  1.269889677176252
None Run 20:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 62.40
Split: 07, Run: 03
None time:  1.0928122540935874
None Run 21:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 62.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1377902091480792
None Run 22:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 67.70
Split: 08, Run: 02
None time:  1.5784896439872682
None Run 23:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 67.40
Split: 08, Run: 03
None time:  1.3732987528201193
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 68.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1613291220273823
None Run 25:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 70.00
Split: 09, Run: 02
None time:  1.1345464219339192
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 68.10
Split: 09, Run: 03
None time:  1.5000499549787492
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 68.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0816477909684181
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 64.30
Split: 10, Run: 02
None time:  1.0628489390946925
None Run 29:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 64.10
Split: 10, Run: 03
None time:  1.195505402982235
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 64.60
run time now: 3.380136489868164
total time:  37.37675406085327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.76 ± 1.94
  Final Train: 94.89 ± 4.69
   Final Test: 65.78 ± 2.70
best run test_acc: 66.43000793457031
[I 2023-06-11 23:40:22,813] Trial 32 finished with value: 67.76000213623047 and parameters: {'Fwd': 0.0006804836117415999, 'K': 6, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 2.853887926158508, 'loop': 2, 'loss': 'CE', 'lr': 0.008814731974063053, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004400485860437867, 'weightedloss': True}. Best is trial 32 with value: 67.76000213623047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.008635530108289557
weight_decay:  0.004109859523449162
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9864696271251887
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 63.80
Split: 01, Run: 02
None time:  1.0519638259429485
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.0623284089379013
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 66.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3746987979393452
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 65.30
Split: 02, Run: 02
None time:  1.1177096129395068
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.40
Split: 02, Run: 03
None time:  1.7110753171145916
None Run 06:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 66.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.903952341992408
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.30
Split: 03, Run: 02
None time:  1.1258427831344306
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 61.90
Split: 03, Run: 03
None time:  2.235992762958631
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 83.33
   Final Test: 63.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1705124399159104
None Run 10:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 65.90
Split: 04, Run: 02
None time:  1.085252549033612
None Run 11:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.30
Split: 04, Run: 03
None time:  1.4736735869664699
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 88.33
   Final Test: 66.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8841483779251575
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 69.90
Split: 05, Run: 02
None time:  0.8264232180081308
None Run 14:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 05, Run: 03
None time:  1.0630972180515528
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 71.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8901149539742619
None Run 16:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 64.80
Split: 06, Run: 02
None time:  0.9897978829685599
None Run 17:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 65.40
Split: 06, Run: 03
None time:  1.3437129170633852
None Run 18:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 64.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1672590640373528
None Run 19:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 62.70
Split: 07, Run: 02
None time:  1.2579237041063607
None Run 20:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 91.67
   Final Test: 62.40
Split: 07, Run: 03
None time:  1.2404216669965535
None Run 21:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 62.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.192462211009115
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 67.50
Split: 08, Run: 02
None time:  1.4801053418777883
None Run 23:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 67.70
Split: 08, Run: 03
None time:  1.2115554281044751
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 68.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1821067240089178
None Run 25:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 67.50
Split: 09, Run: 02
None time:  0.9905533138662577
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.40
Split: 09, Run: 03
None time:  1.4985741639975458
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 90.00
   Final Test: 69.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.400541827082634
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 90.00
   Final Test: 66.40
Split: 10, Run: 02
None time:  1.136339025106281
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 65.40
Split: 10, Run: 03
None time:  1.0978527460247278
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 95.00
   Final Test: 65.20
run time now: 3.6743617057800293
total time:  37.231292989104986
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.85 ± 1.78
  Final Train: 94.89 ± 4.06
   Final Test: 66.02 ± 2.37
best run test_acc: 66.6300048828125
[I 2023-06-11 23:41:00,479] Trial 33 finished with value: 67.84666442871094 and parameters: {'Fwd': 0.001345658195980738, 'K': 6, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 3.171353725300008, 'loop': 2, 'loss': 'CE', 'lr': 0.008635530108289557, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004109859523449162, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.009879242028525938
weight_decay:  0.0043806482834193505
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0731755010783672
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 65.20
Split: 01, Run: 02
None time:  1.4854886361863464
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 88.33
   Final Test: 66.80
Split: 01, Run: 03
None time:  0.9520171859767288
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.288073322037235
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 66.80
Split: 02, Run: 02
None time:  1.1654403868597
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 67.90
Split: 02, Run: 03
None time:  1.1454664999619126
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7782714820932597
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 60.50
Split: 03, Run: 02
None time:  1.3609818639233708
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 95.00
   Final Test: 62.80
Split: 03, Run: 03
None time:  1.1227193160448223
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 62.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0186332338489592
None Run 10:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 65.40
Split: 04, Run: 02
None time:  1.178047525929287
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 88.33
   Final Test: 65.10
Split: 04, Run: 03
None time:  1.579378048889339
None Run 12:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 86.67
   Final Test: 66.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8579219349194318
None Run 13:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.40
Split: 05, Run: 02
None time:  1.1139967651106417
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 71.10
Split: 05, Run: 03
None time:  0.9001921489834785
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2270197530742735
None Run 16:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 66.10
Split: 06, Run: 02
None time:  0.9632113750558347
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 62.80
Split: 06, Run: 03
None time:  1.060443544993177
None Run 18:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 66.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1083662109449506
None Run 19:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 62.40
Split: 07, Run: 02
None time:  1.1490325529593974
None Run 20:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 63.70
Split: 07, Run: 03
None time:  0.9642862959299237
None Run 21:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 98.33
   Final Test: 62.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.682925860863179
None Run 22:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 88.33
   Final Test: 68.30
Split: 08, Run: 02
None time:  1.1545243880245835
None Run 23:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 67.10
Split: 08, Run: 03
None time:  1.4483859180472791
None Run 24:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 83.33
   Final Test: 68.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9000437611248344
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.40
Split: 09, Run: 02
None time:  0.9998543241526932
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.40
Split: 09, Run: 03
None time:  0.967784077161923
None Run 27:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.162076418986544
None Run 28:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 63.00
Split: 10, Run: 02
None time:  0.6767165099736303
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.40
Split: 10, Run: 03
None time:  0.9676633840426803
None Run 30:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.40
run time now: 2.847428560256958
total time:  34.49104323913343
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.79 ± 1.91
  Final Train: 95.56 ± 4.62
   Final Test: 65.75 ± 2.66
best run test_acc: 66.63999938964844
[I 2023-06-11 23:41:35,426] Trial 34 finished with value: 67.78665924072266 and parameters: {'Fwd': 0.0021287406868171366, 'K': 7, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 3.190201186529647, 'loop': 2, 'loss': 'CE', 'lr': 0.009879242028525938, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0043806482834193505, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.009873418868201216
weight_decay:  0.005881114329252919
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0020952930208296
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 64.90
Split: 01, Run: 02
None time:  1.23945801705122
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.2516555660404265
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 66.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0630489399190992
None Run 04:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.30
Split: 02, Run: 02
None time:  1.1556151020340621
None Run 05:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.70
Split: 02, Run: 03
None time:  1.101433940930292
None Run 06:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 65.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6219263121020049
None Run 07:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 64.00
Split: 03, Run: 02
None time:  1.7248220760375261
None Run 08:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 85.00
   Final Test: 63.60
Split: 03, Run: 03
None time:  1.1483062820043415
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 62.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2596603981219232
None Run 10:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 88.33
   Final Test: 65.70
Split: 04, Run: 02
None time:  1.4540991839021444
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 65.80
Split: 04, Run: 03
None time:  1.5181420971639454
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 88.33
   Final Test: 66.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2409421859774739
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.00
   Final Test: 70.70
Split: 05, Run: 02
None time:  1.0615805338602513
None Run 14:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.90
Split: 05, Run: 03
None time:  0.9727729849983007
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 69.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9450655009131879
None Run 16:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 62.80
Split: 06, Run: 02
None time:  0.939251716947183
None Run 17:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 65.50
Split: 06, Run: 03
None time:  1.376756135141477
None Run 18:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 88.33
   Final Test: 64.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1634492818266153
None Run 19:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 60.70
Split: 07, Run: 02
None time:  1.0067772481124848
None Run 20:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 61.50
Split: 07, Run: 03
None time:  1.4418799781706184
None Run 21:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 63.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1908921909052879
None Run 22:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 67.50
Split: 08, Run: 02
None time:  1.3296445910818875
None Run 23:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 98.33
   Final Test: 66.40
Split: 08, Run: 03
None time:  1.2926805370952934
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 67.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0696908740792423
None Run 25:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.40
Split: 09, Run: 02
None time:  1.078190152067691
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 68.90
Split: 09, Run: 03
None time:  1.1153131269384176
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2328316788189113
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.10
Split: 10, Run: 02
None time:  1.5388809081632644
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 91.67
   Final Test: 64.40
Split: 10, Run: 03
None time:  1.0305971109773964
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 98.33
   Final Test: 64.00
run time now: 3.8415651321411133
total time:  37.621242709923536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.66 ± 1.83
  Final Train: 95.28 ± 4.20
   Final Test: 65.71 ± 2.51
best run test_acc: 66.61000061035156
[I 2023-06-11 23:42:13,498] Trial 35 finished with value: 67.66000366210938 and parameters: {'Fwd': 0.0032154154571754742, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 2.7312447904756865, 'loop': 2, 'loss': 'CE', 'lr': 0.009873418868201216, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.005881114329252919, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.007059855009066308
weight_decay:  0.016332522972998687
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1001844729762524
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 95.00
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.1550487019121647
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 90.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  1.280074381036684
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 65.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2395103520248085
None Run 04:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 66.20
Split: 02, Run: 02
None time:  0.8989337489474565
None Run 05:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.90
Split: 02, Run: 03
None time:  0.9226371492259204
None Run 06:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.549080366967246
None Run 07:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 91.67
   Final Test: 63.50
Split: 03, Run: 02
None time:  1.0197958149947226
None Run 08:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 59.80
Split: 03, Run: 03
None time:  1.4311247300356627
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 95.00
   Final Test: 61.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6421560659073293
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 65.20
Split: 04, Run: 02
None time:  1.2447464589495212
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.50
Split: 04, Run: 03
None time:  1.1260537209454924
None Run 12:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 66.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9372096338775009
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 98.33
   Final Test: 69.60
Split: 05, Run: 02
None time:  0.9539248838555068
None Run 14:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.00
Split: 05, Run: 03
None time:  1.0542534459382296
None Run 15:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 95.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4895940870046616
None Run 16:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 88.33
   Final Test: 65.40
Split: 06, Run: 02
None time:  0.9232060241047293
None Run 17:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 65.40
Split: 06, Run: 03
None time:  0.9054985670372844
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.254352161893621
None Run 19:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 62.10
Split: 07, Run: 02
None time:  1.6148438879754394
None Run 20:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 62.70
Split: 07, Run: 03
None time:  1.0353090111166239
None Run 21:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 63.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2306330250576138
None Run 22:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 98.33
   Final Test: 67.20
Split: 08, Run: 02
None time:  0.9703300381079316
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.50
Split: 08, Run: 03
None time:  1.460141927935183
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 67.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.124107499141246
None Run 25:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 68.00
Split: 09, Run: 02
None time:  1.1705309259705245
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 68.70
Split: 09, Run: 03
None time:  1.0678362401667982
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9654557190369815
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 62.70
Split: 10, Run: 02
None time:  1.2098412711638957
None Run 29:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.50
Split: 10, Run: 03
None time:  1.2585768478456885
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.50
run time now: 3.4768149852752686
total time:  36.33884879713878
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.36 ± 1.94
  Final Train: 96.22 ± 3.53
   Final Test: 65.66 ± 2.63
best run test_acc: 66.49000549316406
[I 2023-06-11 23:42:50,311] Trial 36 finished with value: 67.36000061035156 and parameters: {'Fwd': 0.0037669618912677216, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 2.513968096834022, 'loop': 2, 'loss': 'CE', 'lr': 0.007059855009066308, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.016332522972998687, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.005553011176924184
weight_decay:  0.006359565494457807
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5227043880149722
None Run 01:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 02
None time:  0.6109714859630913
None Run 02:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 62.50
Split: 01, Run: 03
None time:  0.6486863151658326
None Run 03:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 58.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.591525066178292
None Run 04:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.50
Split: 02, Run: 02
None time:  0.5945933139882982
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.60
Split: 02, Run: 03
None time:  0.534977809060365
None Run 06:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5183523399755359
None Run 07:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 59.50
Split: 03, Run: 02
None time:  0.5509661280084401
None Run 08:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.90
Split: 03, Run: 03
None time:  0.5680324209388345
None Run 09:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5537867730017751
None Run 10:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.90
Split: 04, Run: 02
None time:  0.6319715529680252
None Run 11:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.90
Split: 04, Run: 03
None time:  0.6077007388230413
None Run 12:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5641072900034487
None Run 13:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 66.40
Split: 05, Run: 02
None time:  0.6039750680793077
None Run 14:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 61.70
Split: 05, Run: 03
None time:  0.5337776180822402
None Run 15:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5967406611889601
None Run 16:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.50
Split: 06, Run: 02
None time:  0.58721181191504
None Run 17:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 57.10
Split: 06, Run: 03
None time:  0.616782717872411
None Run 18:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 60.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6247443580068648
None Run 19:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 59.00
Split: 07, Run: 02
None time:  0.6086236659903079
None Run 20:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 59.20
Split: 07, Run: 03
None time:  0.5268707750365138
None Run 21:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 59.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5677827489562333
None Run 22:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 66.80
Split: 08, Run: 02
None time:  0.6420277149882168
None Run 23:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 68.20
Split: 08, Run: 03
None time:  0.6499840880278498
None Run 24:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5665251731406897
None Run 25:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 66.70
Split: 09, Run: 02
None time:  0.6009566739667207
None Run 26:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 69.50
Split: 09, Run: 03
None time:  0.5286878540646285
None Run 27:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 67.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6566932410933077
None Run 28:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 60.40
Split: 10, Run: 02
None time:  0.5729403649456799
None Run 29:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.70
Split: 10, Run: 03
None time:  0.6238010451197624
None Run 30:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 59.50
run time now: 1.8923568725585938
total time:  18.635792817221954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.25 ± 2.72
  Final Train: 100.00 ± 0.00
   Final Test: 62.11 ± 3.75
best run test_acc: 63.599998474121094
[I 2023-06-11 23:43:09,421] Trial 37 finished with value: 62.25333786010742 and parameters: {'Fwd': 0.00367701162272768, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.4, 'lambda2': 3.5886333987280867, 'loop': 2, 'loss': 'CE', 'lr': 0.005553011176924184, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006359565494457807, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.007353895154308634
weight_decay:  0.017245480527389175
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.38089135894551873
None Run 01:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 35.40
Split: 01, Run: 02
None time:  0.4766629950609058
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 60.60
Split: 01, Run: 03
None time:  0.5026292388793081
None Run 03:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.37872871407307684
None Run 04:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 41.90
Split: 02, Run: 02
None time:  0.500565208029002
None Run 05:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 55.40
Split: 02, Run: 03
None time:  0.8400716588366777
None Run 06:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.3438888229429722
None Run 07:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 41.40
Split: 03, Run: 02
None time:  0.5473098391667008
None Run 08:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.90
Split: 03, Run: 03
None time:  0.4279199349693954
None Run 09:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 52.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.38168581388890743
None Run 10:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 40.70
Split: 04, Run: 02
None time:  0.7406256780959666
None Run 11:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 55.20
Split: 04, Run: 03
None time:  0.3822466190904379
None Run 12:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 63.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.38729438418522477
None Run 13:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 42.80
Split: 05, Run: 02
None time:  0.4940949601586908
None Run 14:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 53.10
Split: 05, Run: 03
None time:  0.4372765268199146
None Run 15:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.33645709906704724
None Run 16:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 40.50
Split: 06, Run: 02
None time:  0.5813832590356469
None Run 17:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 53.00
Split: 06, Run: 03
None time:  0.4832030169200152
None Run 18:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.3472159442026168
None Run 19:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 35.00
Split: 07, Run: 02
None time:  0.44909371598623693
None Run 20:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 49.80
Split: 07, Run: 03
None time:  0.6279061129316688
None Run 21:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 60.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.37599168810993433
None Run 22:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 44.90
Split: 08, Run: 02
None time:  0.5213728779926896
None Run 23:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 60.90
Split: 08, Run: 03
None time:  0.49705196009017527
None Run 24:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 66.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.3659835490398109
None Run 25:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 45.10
Split: 09, Run: 02
None time:  0.42678923695348203
None Run 26:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 63.40
Split: 09, Run: 03
None time:  0.77539754495956
None Run 27:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 66.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.35832668584771454
None Run 28:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 38.80
Split: 10, Run: 02
None time:  0.5268781820777804
None Run 29:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 51.80
Split: 10, Run: 03
None time:  0.7602795260027051
None Run 30:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 51.90
run time now: 1.6851351261138916
total time:  15.695649932138622
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.62 ± 10.19
  Final Train: 100.00 ± 0.00
   Final Test: 52.38 ± 9.65
best run test_acc: 60.95000076293945
[I 2023-06-11 23:43:25,611] Trial 38 finished with value: 52.619998931884766 and parameters: {'Fwd': 0.007890695744832402, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.55, 'lambda2': 2.2808295084847474, 'loop': 2, 'loss': 'MSE', 'lr': 0.007353895154308634, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.017245480527389175, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.009747818250661356
weight_decay:  0.001499207869368836
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6925886149983853
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 61.60
Split: 01, Run: 02
None time:  0.7720578659791499
None Run 02:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 57.90
Split: 01, Run: 03
None time:  0.6974602118134499
None Run 03:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 60.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7305018140468746
None Run 04:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 63.20
Split: 02, Run: 02
None time:  0.7367952789645642
None Run 05:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.80
Split: 02, Run: 03
None time:  0.7533138580620289
None Run 06:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.730757521931082
None Run 07:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 57.30
Split: 03, Run: 02
None time:  0.7490403919946402
None Run 08:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 53.60
Split: 03, Run: 03
None time:  0.7136279889382422
None Run 09:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 56.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7541183771099895
None Run 10:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.40
Split: 04, Run: 02
None time:  0.7688679180573672
None Run 11:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 62.70
Split: 04, Run: 03
None time:  0.7801117191556841
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 63.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7877986659295857
None Run 13:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.90
Split: 05, Run: 02
None time:  0.7154566620010883
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.90
Split: 05, Run: 03
None time:  0.7353140991181135
None Run 15:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.704392512794584
None Run 16:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 61.00
Split: 06, Run: 02
None time:  0.6800950709730387
None Run 17:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 58.80
Split: 06, Run: 03
None time:  0.7404253450222313
None Run 18:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6819348561111838
None Run 19:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 60.00
Split: 07, Run: 02
None time:  0.7199748649727553
None Run 20:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 58.90
Split: 07, Run: 03
None time:  0.7536167711950839
None Run 21:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 57.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7315836700145155
None Run 22:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 64.40
Split: 08, Run: 02
None time:  0.6928943509701639
None Run 23:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 61.90
Split: 08, Run: 03
None time:  0.7014747331850231
None Run 24:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 63.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7136942739598453
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.10
Split: 09, Run: 02
None time:  0.7158317340072244
None Run 26:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 65.70
Split: 09, Run: 03
None time:  0.6541353289503604
None Run 27:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7244966120924801
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 02
None time:  0.8098873519338667
None Run 29:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 61.40
Split: 10, Run: 03
None time:  0.6766023910604417
None Run 30:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.80
run time now: 2.25323486328125
total time:  22.903988115955144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.35 ± 3.10
  Final Train: 100.00 ± 0.00
   Final Test: 61.66 ± 3.27
best run test_acc: 62.93000030517578
[I 2023-06-11 23:43:48,938] Trial 39 finished with value: 62.353336334228516 and parameters: {'Fwd': 0.0014264257228992269, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 2.624016595676448, 'loop': 2, 'loss': 'CE', 'lr': 0.009747818250661356, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001499207869368836, 'weightedloss': False}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.007909483130655358
weight_decay:  0.006875929892066621
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.18431226001121104
None Run 01:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 36.00
Split: 01, Run: 02
None time:  0.7768492109607905
None Run 02:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 71.67
   Final Test: 44.60
Split: 01, Run: 03
None time:  0.7016148350667208
None Run 03:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 70.00
   Final Test: 45.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.2612487799488008
None Run 04:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 42.30
Split: 02, Run: 02
None time:  0.2043194961734116
None Run 05:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 42.30
Split: 02, Run: 03
None time:  0.21443484700284898
None Run 06:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 42.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.23043909901753068
None Run 07:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.90
Split: 03, Run: 02
None time:  0.20676143001765013
None Run 08:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.90
Split: 03, Run: 03
None time:  0.20675344904884696
None Run 09:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.22275862307287753
None Run 10:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 41.50
Split: 04, Run: 02
None time:  0.21367726591415703
None Run 11:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 41.50
Split: 04, Run: 03
None time:  0.26734870998188853
None Run 12:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 41.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.21090665413066745
None Run 13:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 43.60
Split: 05, Run: 02
None time:  0.2146314571145922
None Run 14:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 43.60
Split: 05, Run: 03
None time:  0.2090760029386729
None Run 15:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 43.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.19499857886694372
None Run 16:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.10
Split: 06, Run: 02
None time:  0.251118334941566
None Run 17:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.10
Split: 06, Run: 03
None time:  0.2137954810168594
None Run 18:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.20756423682905734
None Run 19:
Highest Train: 100.00
Highest Valid: 34.40
  Final Train: 100.00
   Final Test: 36.10
Split: 07, Run: 02
None time:  0.22763843787834048
None Run 20:
Highest Train: 100.00
Highest Valid: 34.40
  Final Train: 100.00
   Final Test: 36.10
Split: 07, Run: 03
None time:  0.23466115212067962
None Run 21:
Highest Train: 100.00
Highest Valid: 34.40
  Final Train: 100.00
   Final Test: 36.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.2152106398716569
None Run 22:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 45.70
Split: 08, Run: 02
None time:  0.1924963139463216
None Run 23:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 45.70
Split: 08, Run: 03
None time:  0.20495203183963895
None Run 24:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 45.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.222479515010491
None Run 25:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 46.20
Split: 09, Run: 02
None time:  0.20943582616746426
None Run 26:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 46.20
Split: 09, Run: 03
None time:  0.2409014089498669
None Run 27:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 46.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.19893259089440107
None Run 28:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 39.90
Split: 10, Run: 02
None time:  0.2050727040041238
None Run 29:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 39.90
Split: 10, Run: 03
None time:  0.18894571880809963
None Run 30:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 39.90
run time now: 0.635908842086792
total time:  8.619484161026776
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.23 ± 3.38
  Final Train: 98.06 ± 7.40
   Final Test: 42.03 ± 3.09
best run test_acc: 42.37000274658203
[I 2023-06-11 23:43:58,009] Trial 40 finished with value: 41.22666931152344 and parameters: {'Fwd': 0.02003745652482111, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 0, 'lambda1': 0.65, 'lambda2': 3.602143900820911, 'loop': 2, 'loss': 'CE', 'lr': 0.007909483130655358, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006875929892066621, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.007034673977136598
weight_decay:  0.01541156520655801
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1644818261265755
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 95.00
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.0978766190819442
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 91.67
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.0953357978723943
None Run 03:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 90.00
   Final Test: 64.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4613335649482906
None Run 04:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 91.67
   Final Test: 64.80
Split: 02, Run: 02
None time:  0.9381742998957634
None Run 05:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.50
Split: 02, Run: 03
None time:  0.8817132001277059
None Run 06:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4775918971281499
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 62.30
Split: 03, Run: 02
None time:  0.8646521400660276
None Run 08:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 60.50
Split: 03, Run: 03
None time:  1.4242598658893257
None Run 09:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 91.67
   Final Test: 59.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.477411544881761
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 65.40
Split: 04, Run: 02
None time:  1.6666105489712209
None Run 11:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 81.67
   Final Test: 67.50
Split: 04, Run: 03
None time:  1.0196356179658324
None Run 12:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 65.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8976724070962518
None Run 13:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 05, Run: 02
None time:  0.835971592925489
None Run 14:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.30
Split: 05, Run: 03
None time:  1.1760203919839114
None Run 15:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 71.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9944736170582473
None Run 16:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 65.10
Split: 06, Run: 02
None time:  0.960855983896181
None Run 17:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 64.60
Split: 06, Run: 03
None time:  1.2389636340085417
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 65.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.207584141055122
None Run 19:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 61.60
Split: 07, Run: 02
None time:  1.164940585847944
None Run 20:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 61.80
Split: 07, Run: 03
None time:  1.4031013629864901
None Run 21:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 91.67
   Final Test: 62.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4445198951289058
None Run 22:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 66.40
Split: 08, Run: 02
None time:  1.2115825801156461
None Run 23:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 67.00
Split: 08, Run: 03
None time:  1.3622432800475508
None Run 24:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 64.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1132907019928098
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 67.40
Split: 09, Run: 02
None time:  1.118873885832727
None Run 26:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.40
Split: 09, Run: 03
None time:  0.9276775571051985
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1097785390447825
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 64.10
Split: 10, Run: 02
None time:  0.9864435640629381
None Run 29:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.20
Split: 10, Run: 03
None time:  1.071817517047748
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 66.10
run time now: 3.209564447402954
total time:  35.88005565898493
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.96 ± 2.35
  Final Train: 96.39 ± 4.29
   Final Test: 65.03 ± 2.79
best run test_acc: 66.06000518798828
[I 2023-06-11 23:44:34,348] Trial 41 finished with value: 66.95999908447266 and parameters: {'Fwd': 0.002745849628507609, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 2.4888812819771724, 'loop': 2, 'loss': 'CE', 'lr': 0.007034673977136598, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01541156520655801, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.005678596870903335
weight_decay:  0.026469159324748803
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.031101802131161
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.90
Split: 01, Run: 02
None time:  1.318539576837793
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 88.33
   Final Test: 63.90
Split: 01, Run: 03
None time:  1.1815379129257053
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 91.67
   Final Test: 64.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7620010699611157
None Run 04:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.50
Split: 02, Run: 02
None time:  0.8844064369332045
None Run 05:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.20
Split: 02, Run: 03
None time:  0.8427616020198911
None Run 06:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9937847179826349
None Run 07:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 62.90
Split: 03, Run: 02
None time:  1.5778109880629927
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 62.10
Split: 03, Run: 03
None time:  1.8756161339115351
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 86.67
   Final Test: 61.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8138901889324188
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 85.00
   Final Test: 66.80
Split: 04, Run: 02
None time:  1.8723515120800585
None Run 11:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 80.00
   Final Test: 68.00
Split: 04, Run: 03
None time:  1.419507954036817
None Run 12:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 88.33
   Final Test: 66.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.881799838040024
None Run 13:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.60
Split: 05, Run: 02
None time:  1.151007561944425
None Run 14:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.00
   Final Test: 70.90
Split: 05, Run: 03
None time:  0.8430419340729713
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9079545398708433
None Run 16:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 65.00
Split: 06, Run: 02
None time:  0.7611207799054682
None Run 17:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 62.40
Split: 06, Run: 03
None time:  1.0202946099452674
None Run 18:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 98.33
   Final Test: 55.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.3625614820048213
None Run 19:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 78.33
   Final Test: 62.50
Split: 07, Run: 02
None time:  1.3763603100087494
None Run 20:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 62.10
Split: 07, Run: 03
None time:  1.6644140460994095
None Run 21:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 85.00
   Final Test: 63.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9977765048388392
None Run 22:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.10
Split: 08, Run: 02
None time:  1.3210804359987378
None Run 23:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 98.33
   Final Test: 66.10
Split: 08, Run: 03
None time:  1.6289657331071794
None Run 24:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 85.00
   Final Test: 66.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1846690941601992
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 95.00
   Final Test: 68.00
Split: 09, Run: 02
None time:  1.0252171540632844
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.90
Split: 09, Run: 03
None time:  0.8526287069544196
None Run 27:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 67.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1370006201323122
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 65.90
Split: 10, Run: 02
None time:  1.0076722700614482
None Run 29:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.70
Split: 10, Run: 03
None time:  0.7818991309031844
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 63.00
run time now: 2.9688472747802734
total time:  37.58693207707256
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.92 ± 2.28
  Final Train: 94.56 ± 6.79
   Final Test: 65.07 ± 3.05
best run test_acc: 66.15998840332031
[I 2023-06-11 23:45:12,443] Trial 42 finished with value: 66.91999816894531 and parameters: {'Fwd': 0.0011801034477132396, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.45, 'lambda2': 3.428370867833751, 'loop': 2, 'loss': 'CE', 'lr': 0.005678596870903335, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.026469159324748803, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.009992446274668674
weight_decay:  0.01008893378811174
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9188797129318118
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 91.67
   Final Test: 64.20
Split: 01, Run: 02
None time:  1.131797423120588
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 88.33
   Final Test: 66.60
Split: 01, Run: 03
None time:  2.741919257910922
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 78.33
   Final Test: 69.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.23042192007415
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 66.90
Split: 02, Run: 02
None time:  1.4837925971951336
None Run 05:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 90.00
   Final Test: 66.40
Split: 02, Run: 03
None time:  0.8278414860833436
None Run 06:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1917457340750843
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 61.20
Split: 03, Run: 02
None time:  0.7834042957983911
None Run 08:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.40
Split: 03, Run: 03
None time:  0.8994275878649205
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 60.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9910140228457749
None Run 10:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 91.67
   Final Test: 65.60
Split: 04, Run: 02
None time:  1.082744964864105
None Run 11:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 86.67
   Final Test: 66.10
Split: 04, Run: 03
None time:  1.2937865068670362
None Run 12:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 83.33
   Final Test: 65.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7883784740697592
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.60
Split: 05, Run: 02
None time:  0.7958023550454527
None Run 14:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.30
Split: 05, Run: 03
None time:  0.7556019180919975
None Run 15:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8615572729613632
None Run 16:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 64.40
Split: 06, Run: 02
None time:  0.7688801740296185
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 62.60
Split: 06, Run: 03
None time:  1.000043512089178
None Run 18:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0227662101387978
None Run 19:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 62.30
Split: 07, Run: 02
None time:  0.9571160220075399
None Run 20:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 61.80
Split: 07, Run: 03
None time:  1.0610958591569215
None Run 21:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 61.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.118937544990331
None Run 22:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 91.67
   Final Test: 67.20
Split: 08, Run: 02
None time:  1.2221235551405698
None Run 23:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 65.30
Split: 08, Run: 03
None time:  1.0678788989316672
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 66.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0582697519566864
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 68.10
Split: 09, Run: 02
None time:  0.9357463039923459
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.90
Split: 09, Run: 03
None time:  0.913577055092901
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.824901525862515
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.70
Split: 10, Run: 02
None time:  0.8188193689566106
None Run 29:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 63.80
Split: 10, Run: 03
None time:  0.9053727020509541
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.50
run time now: 2.5928356647491455
total time:  32.51248098118231
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.47 ± 1.65
  Final Train: 95.06 ± 5.75
   Final Test: 65.20 ± 2.76
best run test_acc: 66.05000305175781
[I 2023-06-11 23:45:45,386] Trial 43 finished with value: 67.46666717529297 and parameters: {'Fwd': 0.0027361319951305424, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.5, 'lambda2': 2.214198481673482, 'loop': 2, 'loss': 'CE', 'lr': 0.009992446274668674, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01008893378811174, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.009940798857312432
weight_decay:  0.09426708704153358
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5149136940017343
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.90
Split: 01, Run: 02
None time:  0.5847572099883109
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 63.80
Split: 01, Run: 03
None time:  0.5915719969198108
None Run 03:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5931251829024404
None Run 04:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.70
Split: 02, Run: 02
None time:  0.5603769919835031
None Run 05:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.90
Split: 02, Run: 03
None time:  0.5776480040512979
None Run 06:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5089857298880816
None Run 07:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.10
Split: 03, Run: 02
None time:  0.5681018780451268
None Run 08:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.90
Split: 03, Run: 03
None time:  0.5978196510113776
None Run 09:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 59.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5879910460207611
None Run 10:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 63.40
Split: 04, Run: 02
None time:  0.611156954895705
None Run 11:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 63.30
Split: 04, Run: 03
None time:  0.7198886082042009
None Run 12:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5328975981101394
None Run 13:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.00
Split: 05, Run: 02
None time:  0.6469117989763618
None Run 14:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.80
Split: 05, Run: 03
None time:  0.593049064045772
None Run 15:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5438813678920269
None Run 16:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.30
Split: 06, Run: 02
None time:  0.5996867010835558
None Run 17:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 60.90
Split: 06, Run: 03
None time:  0.5839095648843795
None Run 18:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5782878391910344
None Run 19:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 58.50
Split: 07, Run: 02
None time:  0.625964405015111
None Run 20:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 57.60
Split: 07, Run: 03
None time:  0.6013607820495963
None Run 21:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 57.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.65675059100613
None Run 22:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 61.40
Split: 08, Run: 02
None time:  0.6432068140711635
None Run 23:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 64.00
Split: 08, Run: 03
None time:  0.577278234064579
None Run 24:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 66.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5905012779403478
None Run 25:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 63.10
Split: 09, Run: 02
None time:  0.6045704148709774
None Run 26:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 65.70
Split: 09, Run: 03
None time:  0.6366517608985305
None Run 27:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 68.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5928353709168732
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 02
None time:  0.6351008999627084
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.40
Split: 10, Run: 03
None time:  0.5540824481286108
None Run 30:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.80
run time now: 1.8225970268249512
total time:  18.8726449359674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.95 ± 2.62
  Final Train: 100.00 ± 0.00
   Final Test: 62.97 ± 2.93
best run test_acc: 64.3800048828125
[I 2023-06-11 23:46:04,711] Trial 44 finished with value: 63.94667053222656 and parameters: {'Fwd': 0.00046081430123545307, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.6000000000000001, 'lambda2': 2.990576743975044, 'loop': 2, 'loss': 'CE', 'lr': 0.009940798857312432, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.09426708704153358, 'weightedloss': False}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.35000000000000003
lr:  0.007943346392907231
weight_decay:  0.008843573397298991
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.128195869969204
None Run 01:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 02
None time:  0.7429839470423758
None Run 02:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.90
Split: 01, Run: 03
None time:  1.3605655999854207
None Run 03:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6138502380345017
None Run 04:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.60
Split: 02, Run: 02
None time:  0.7853125950787216
None Run 05:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.10
Split: 02, Run: 03
None time:  0.8028154280036688
None Run 06:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6499700208660215
None Run 07:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 58.80
Split: 03, Run: 02
None time:  0.7147313479799777
None Run 08:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 56.60
Split: 03, Run: 03
None time:  0.6048597258049995
None Run 09:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6621929719112813
None Run 10:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.60
Split: 04, Run: 02
None time:  0.7497299599926919
None Run 11:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.60
Split: 04, Run: 03
None time:  0.7448875710833818
None Run 12:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6334456549957395
None Run 13:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.60
Split: 05, Run: 02
None time:  0.7450397601351142
None Run 14:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.80
Split: 05, Run: 03
None time:  0.6242360360920429
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6540136570110917
None Run 16:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.70
Split: 06, Run: 02
None time:  0.8528103909920901
None Run 17:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 61.20
Split: 06, Run: 03
None time:  0.6591125978156924
None Run 18:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 56.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0355307289864868
None Run 19:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 57.60
Split: 07, Run: 02
None time:  0.6542410550173372
None Run 20:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 54.80
Split: 07, Run: 03
None time:  0.6283035660162568
None Run 21:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 55.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6679215941112489
None Run 22:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.70
Split: 08, Run: 02
None time:  0.6564314269926399
None Run 23:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.30
Split: 08, Run: 03
None time:  0.8833494200371206
None Run 24:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.652874720050022
None Run 25:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.90
Split: 09, Run: 02
None time:  0.6664887219667435
None Run 26:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 65.70
Split: 09, Run: 03
None time:  0.9810631719883531
None Run 27:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 68.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6738377010915428
None Run 28:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.40
Split: 10, Run: 02
None time:  0.9627339360304177
None Run 29:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.50
Split: 10, Run: 03
None time:  0.6397032048553228
None Run 30:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.20
run time now: 2.3148539066314697
total time:  23.870033679995686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.07 ± 2.84
  Final Train: 100.00 ± 0.00
   Final Test: 60.92 ± 3.45
best run test_acc: 62.469993591308594
[I 2023-06-11 23:46:29,078] Trial 45 finished with value: 62.06666564941406 and parameters: {'Fwd': 0.0008310800029140244, 'K': 6, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.75, 'lambda2': 2.1018246477411577, 'loop': 2, 'loss': 'MSE', 'lr': 0.007943346392907231, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.008843573397298991, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.005562771741473815
weight_decay:  0.0021878758790083064
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.48558607907034457
None Run 01:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 57.80
Split: 01, Run: 02
None time:  0.5359118070919067
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  0.47952925809659064
None Run 03:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.4903006961103529
None Run 04:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.00
Split: 02, Run: 02
None time:  0.5350327380001545
None Run 05:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.90
Split: 02, Run: 03
None time:  0.46810365514829755
None Run 06:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 61.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.47041348391212523
None Run 07:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.60
Split: 03, Run: 02
None time:  0.5168395598884672
None Run 08:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.70
Split: 03, Run: 03
None time:  0.45406661508604884
None Run 09:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 60.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.4805200709961355
None Run 10:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 52.60
Split: 04, Run: 02
None time:  0.5159333900082856
None Run 11:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 60.40
Split: 04, Run: 03
None time:  0.5331625510007143
None Run 12:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 51.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5550901640672237
None Run 13:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.10
Split: 05, Run: 02
None time:  0.5473502660170197
None Run 14:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 65.50
Split: 05, Run: 03
None time:  0.4410541399847716
None Run 15:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.4987877660896629
None Run 16:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.90
Split: 06, Run: 02
None time:  0.47678135382011533
None Run 17:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 55.40
Split: 06, Run: 03
None time:  0.46579020214267075
None Run 18:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 58.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.47390029206871986
None Run 19:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 57.30
Split: 07, Run: 02
None time:  0.4437305610626936
None Run 20:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 54.20
Split: 07, Run: 03
None time:  0.49737132410518825
None Run 21:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.49912362708710134
None Run 22:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 63.80
Split: 08, Run: 02
None time:  0.4606853509321809
None Run 23:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 65.10
Split: 08, Run: 03
None time:  0.5040688370354474
None Run 24:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 62.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.49000670691020787
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 68.30
Split: 09, Run: 02
None time:  0.5222099658567458
None Run 26:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 65.60
Split: 09, Run: 03
None time:  0.5036666260566562
None Run 27:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 67.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.4849310708232224
None Run 28:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.70
Split: 10, Run: 02
None time:  0.4467307550366968
None Run 29:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 61.30
Split: 10, Run: 03
None time:  0.5313830249942839
None Run 30:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.30
run time now: 1.5034523010253906
total time:  15.875897552119568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.60 ± 3.57
  Final Train: 100.00 ± 0.00
   Final Test: 60.69 ± 4.26
best run test_acc: 63.06999588012695
[I 2023-06-11 23:46:45,379] Trial 46 finished with value: 60.599998474121094 and parameters: {'Fwd': 0.0021596888632947936, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.30000000000000004, 'lambda2': 2.690004820602917, 'loop': 2, 'loss': 'CE', 'lr': 0.005562771741473815, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0021878758790083064, 'weightedloss': False}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.009730286736554017
weight_decay:  0.004060008677640587
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.39903836604207754
None Run 01:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 53.60
Split: 01, Run: 02
None time:  0.4698046990670264
None Run 02:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 88.33
   Final Test: 55.50
Split: 01, Run: 03
None time:  0.6166975281666964
None Run 03:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 86.67
   Final Test: 57.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.3914158751722425
None Run 04:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 53.30
Split: 02, Run: 02
None time:  0.5778349370229989
None Run 05:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 91.67
   Final Test: 60.20
Split: 02, Run: 03
None time:  0.4838042398914695
None Run 06:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 95.00
   Final Test: 59.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6027042858768255
None Run 07:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 53.90
Split: 03, Run: 02
None time:  0.7682177689857781
None Run 08:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 88.33
   Final Test: 54.00
Split: 03, Run: 03
None time:  0.6066241939552128
None Run 09:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 90.00
   Final Test: 55.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7744262190535665
None Run 10:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 63.10
Split: 04, Run: 02
None time:  0.4412757691461593
None Run 11:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 61.20
Split: 04, Run: 03
None time:  0.8646308188326657
None Run 12:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 83.33
   Final Test: 63.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.374066666001454
None Run 13:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.20
Split: 05, Run: 02
None time:  0.4418904399499297
None Run 14:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 98.33
   Final Test: 63.90
Split: 05, Run: 03
None time:  0.4613254799041897
None Run 15:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 64.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.3412764719687402
None Run 16:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.10
Split: 06, Run: 02
None time:  0.5935189188458025
None Run 17:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 91.67
   Final Test: 62.40
Split: 06, Run: 03
None time:  0.47604594798758626
None Run 18:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 61.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.49781895079649985
None Run 19:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 49.80
Split: 07, Run: 02
None time:  0.4817778361029923
None Run 20:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 57.10
Split: 07, Run: 03
None time:  0.41720075788907707
None Run 21:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 96.67
   Final Test: 55.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.39166317298077047
None Run 22:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 57.10
Split: 08, Run: 02
None time:  1.4979435720015317
None Run 23:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 76.67
   Final Test: 63.10
Split: 08, Run: 03
None time:  0.440950338030234
None Run 24:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 66.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.3692639989312738
None Run 25:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 46.20
Split: 09, Run: 02
None time:  0.44674462103284895
None Run 26:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 61.50
Split: 09, Run: 03
None time:  0.40151707199402153
None Run 27:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5302997408434749
None Run 28:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 95.00
   Final Test: 43.10
Split: 10, Run: 02
None time:  0.6953690259251744
None Run 29:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 90.00
   Final Test: 57.10
Split: 10, Run: 03
None time:  0.6134745310992002
None Run 30:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 88.33
   Final Test: 62.10
run time now: 1.8813214302062988
total time:  17.53091412014328
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.57 ± 6.70
  Final Train: 94.33 ± 5.98
   Final Test: 57.55 ± 6.27
best run test_acc: 61.19999313354492
[I 2023-06-11 23:47:03,360] Trial 47 finished with value: 58.56666564941406 and parameters: {'Fwd': 0.005920439553838431, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 3.3246732005913366, 'loop': 1, 'loss': 'CE', 'lr': 0.009730286736554017, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004060008677640587, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.1
lr:  0.007560930062570238
weight_decay:  0.03638188669226259
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7410530899651349
None Run 01:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 54.70
Split: 01, Run: 02
None time:  0.754873784026131
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 03
None time:  0.7976820550393313
None Run 03:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 57.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8553225079085678
None Run 04:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.20
Split: 02, Run: 02
None time:  0.8196543441154063
None Run 05:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 61.60
Split: 02, Run: 03
None time:  0.9637289168313146
None Run 06:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9188706069253385
None Run 07:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 58.70
Split: 03, Run: 02
None time:  0.921128252055496
None Run 08:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 54.10
Split: 03, Run: 03
None time:  0.9574727739673108
None Run 09:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 56.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7957718789111823
None Run 10:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 60.30
Split: 04, Run: 02
None time:  0.8036709751468152
None Run 11:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.80
Split: 04, Run: 03
None time:  0.9702575160190463
None Run 12:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 62.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8607590841129422
None Run 13:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.80
Split: 05, Run: 02
None time:  1.0236565810628235
None Run 14:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 66.80
Split: 05, Run: 03
None time:  0.787876213202253
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7878021989017725
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 58.90
Split: 06, Run: 02
None time:  0.860831038095057
None Run 17:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.40
Split: 06, Run: 03
None time:  0.8322871220298111
None Run 18:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 55.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7956390511244535
None Run 19:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 53.60
Split: 07, Run: 02
None time:  0.8538809900637716
None Run 20:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 51.00
Split: 07, Run: 03
None time:  0.9137469308916479
None Run 21:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 55.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9028334598988295
None Run 22:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.70
Split: 08, Run: 02
None time:  0.8715302019845694
None Run 23:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 63.70
Split: 08, Run: 03
None time:  0.870080664055422
None Run 24:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 59.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7798161760438234
None Run 25:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 65.20
Split: 09, Run: 02
None time:  0.8557792359497398
None Run 26:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 65.10
Split: 09, Run: 03
None time:  0.860889530973509
None Run 27:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 63.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7975945689249784
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 02
None time:  0.8774630301631987
None Run 29:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.60
Split: 10, Run: 03
None time:  0.7963335178792477
None Run 30:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.30
run time now: 2.512380599975586
total time:  26.66689384006895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.07 ± 3.27
  Final Train: 100.00 ± 0.00
   Final Test: 60.22 ± 4.13
best run test_acc: 61.68000030517578
[I 2023-06-11 23:47:30,486] Trial 48 finished with value: 61.06666564941406 and parameters: {'Fwd': 0.0014820573159280263, 'K': 6, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 1.1299665729618624, 'loop': 2, 'loss': 'MSE', 'lr': 0.007560930062570238, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.03638188669226259, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.005374021138658691
weight_decay:  0.009387970851519727
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.38100254302844405
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.10
Split: 01, Run: 02
None time:  0.4694723729044199
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.80
Split: 01, Run: 03
None time:  0.3616470249835402
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.33545087999664247
None Run 04:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 63.00
Split: 02, Run: 02
None time:  0.4305400501471013
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.30
Split: 02, Run: 03
None time:  0.31348932697437704
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4600357769522816
None Run 07:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 57.70
Split: 03, Run: 02
None time:  0.3943101358599961
None Run 08:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.50
Split: 03, Run: 03
None time:  0.6721720988862216
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 61.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.3754584470298141
None Run 10:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 54.20
Split: 04, Run: 02
None time:  0.37002879194915295
None Run 11:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 57.50
Split: 04, Run: 03
None time:  0.37630664301104844
None Run 12:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 54.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.33245435589924455
None Run 13:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 63.60
Split: 05, Run: 02
None time:  0.37910523102618754
None Run 14:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.90
Split: 05, Run: 03
None time:  0.48319046292454004
None Run 15:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.333373683039099
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 02
None time:  0.3846462438814342
None Run 17:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 59.20
Split: 06, Run: 03
None time:  0.4314237560611218
None Run 18:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 59.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.37377556203864515
None Run 19:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 55.30
Split: 07, Run: 02
None time:  0.3882788219489157
None Run 20:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.00
Split: 07, Run: 03
None time:  0.3335297310259193
None Run 21:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 61.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4529295021202415
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.00
Split: 08, Run: 02
None time:  0.3707359288819134
None Run 23:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 64.30
Split: 08, Run: 03
None time:  0.4044929731171578
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.36138568399474025
None Run 25:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 64.10
Split: 09, Run: 02
None time:  0.37404342205263674
None Run 26:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 66.30
Split: 09, Run: 03
None time:  0.36387776397168636
None Run 27:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 66.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.36440286110155284
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 61.80
Split: 10, Run: 02
None time:  0.48576714587397873
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.90
Split: 10, Run: 03
None time:  0.3598462559748441
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 61.80
run time now: 1.250671148300171
total time:  12.950399725930765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.19 ± 3.81
  Final Train: 100.00 ± 0.00
   Final Test: 61.71 ± 3.97
best run test_acc: 63.469993591308594
[I 2023-06-11 23:47:43,970] Trial 49 finished with value: 63.193336486816406 and parameters: {'Fwd': 0.0005863334201889939, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.6000000000000001, 'lambda2': 1.9753977011279522, 'loop': 0, 'loss': 'CE', 'lr': 0.005374021138658691, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.009387970851519727, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003658064121489989
weight_decay:  0.004210516905938908
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3645500228740275
None Run 01:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 02
None time:  0.4690596249420196
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.40
Split: 01, Run: 03
None time:  0.4208108389284462
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.41055274684913456
None Run 04:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.50
Split: 02, Run: 02
None time:  0.5213040590751916
None Run 05:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.80
Split: 02, Run: 03
None time:  0.38367140502668917
None Run 06:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 42.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4235246670432389
None Run 07:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 56.00
Split: 03, Run: 02
None time:  0.45936047309078276
None Run 08:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.30
Split: 03, Run: 03
None time:  0.413360966835171
None Run 09:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 56.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.3949240280780941
None Run 10:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 48.90
Split: 04, Run: 02
None time:  0.3994558430276811
None Run 11:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 45.20
Split: 04, Run: 03
None time:  0.501132712000981
None Run 12:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 47.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.4370636970270425
None Run 13:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.30
Split: 05, Run: 02
None time:  0.5105570540763438
None Run 14:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.90
Split: 05, Run: 03
None time:  0.4064962309785187
None Run 15:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 43.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.45266016107052565
None Run 16:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.70
Split: 06, Run: 02
None time:  0.4596248809248209
None Run 17:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.10
Split: 06, Run: 03
None time:  0.4826885941438377
None Run 18:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 53.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.4671980650164187
None Run 19:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 61.50
Split: 07, Run: 02
None time:  0.41638166294433177
None Run 20:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 56.20
Split: 07, Run: 03
None time:  0.4227054310031235
None Run 21:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 59.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4583028119523078
None Run 22:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 60.40
Split: 08, Run: 02
None time:  0.39963764208368957
None Run 23:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.70
Split: 08, Run: 03
None time:  0.46401464892551303
None Run 24:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 66.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.4472153710667044
None Run 25:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 66.80
Split: 09, Run: 02
None time:  0.407805701950565
None Run 26:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 68.60
Split: 09, Run: 03
None time:  0.4039488339331001
None Run 27:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 61.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.3550429509487003
None Run 28:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.10
Split: 10, Run: 02
None time:  0.4276335439644754
None Run 29:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 62.40
Split: 10, Run: 03
None time:  0.3882524811197072
None Run 30:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.30
run time now: 1.2145953178405762
total time:  14.060547639150172
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.97 ± 6.52
  Final Train: 100.00 ± 0.00
   Final Test: 58.32 ± 7.23
best run test_acc: 62.219993591308594
[I 2023-06-11 23:47:58,482] Trial 50 finished with value: 58.96666717529297 and parameters: {'Fwd': 0.00037162120229458146, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.65, 'lambda2': 0.7913982757715308, 'loop': 1, 'loss': 'CE', 'lr': 0.003658064121489989, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004210516905938908, 'weightedloss': False}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.006906401630586593
weight_decay:  0.01709415535832669
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0705194529145956
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 63.90
Split: 01, Run: 02
None time:  1.203103429172188
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 88.33
   Final Test: 65.60
Split: 01, Run: 03
None time:  1.1014886610209942
None Run 03:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 93.33
   Final Test: 65.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9100595170166343
None Run 04:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.50
Split: 02, Run: 02
None time:  1.285985364113003
None Run 05:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 91.67
   Final Test: 67.00
Split: 02, Run: 03
None time:  0.8826024730224162
None Run 06:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2285568621009588
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 61.80
Split: 03, Run: 02
None time:  2.076912452932447
None Run 08:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 83.33
   Final Test: 65.00
Split: 03, Run: 03
None time:  1.0753036518581212
None Run 09:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.371320977108553
None Run 10:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 91.67
   Final Test: 66.10
Split: 04, Run: 02
None time:  1.2062125669326633
None Run 11:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 88.33
   Final Test: 65.40
Split: 04, Run: 03
None time:  1.4161818220745772
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 85.00
   Final Test: 66.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0440795980393887
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 70.10
Split: 05, Run: 02
None time:  0.9764044370967895
None Run 14:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.10
Split: 05, Run: 03
None time:  0.7549423228483647
None Run 15:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0044595119543374
None Run 16:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 64.20
Split: 06, Run: 02
None time:  1.1499602189287543
None Run 17:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 66.00
Split: 06, Run: 03
None time:  0.8423619710374624
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 63.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4922226930502802
None Run 19:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 85.00
   Final Test: 63.70
Split: 07, Run: 02
None time:  1.039790395880118
None Run 20:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 60.10
Split: 07, Run: 03
None time:  1.1561533878557384
None Run 21:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 91.67
   Final Test: 62.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2382029229775071
None Run 22:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 65.70
Split: 08, Run: 02
None time:  1.1541376179084182
None Run 23:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 67.00
Split: 08, Run: 03
None time:  1.7845239620655775
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 86.67
   Final Test: 68.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9375092040281743
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 67.70
Split: 09, Run: 02
None time:  0.8216040129773319
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.10
Split: 09, Run: 03
None time:  0.7531832579988986
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 69.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.027819162933156
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 64.80
Split: 10, Run: 02
None time:  0.7900014240294695
None Run 29:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.80
Split: 10, Run: 03
None time:  0.8789284999947995
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.10
run time now: 2.7388556003570557
total time:  34.783362288959324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.34 ± 2.13
  Final Train: 95.06 ± 5.39
   Final Test: 65.60 ± 2.68
best run test_acc: 66.6500015258789
[I 2023-06-11 23:48:33,814] Trial 51 finished with value: 67.33999633789062 and parameters: {'Fwd': 0.00444983926831095, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 2.3465543149627432, 'loop': 2, 'loss': 'CE', 'lr': 0.006906401630586593, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01709415535832669, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.008252432365062987
weight_decay:  0.05162214418311731
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0932320959400386
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 91.67
   Final Test: 64.00
Split: 01, Run: 02
None time:  1.4118927891831845
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 88.33
   Final Test: 66.70
Split: 01, Run: 03
None time:  1.1319893458858132
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 90.00
   Final Test: 64.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8927863179706037
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.00
Split: 02, Run: 02
None time:  1.1606842940673232
None Run 05:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 65.70
Split: 02, Run: 03
None time:  0.8911943070124835
None Run 06:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1917369971051812
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 95.00
   Final Test: 61.10
Split: 03, Run: 02
None time:  1.8256380050443113
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 81.67
   Final Test: 62.00
Split: 03, Run: 03
None time:  1.2667284801136702
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 62.30
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3110883419867605
None Run 10:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 86.67
   Final Test: 66.90
Split: 04, Run: 02
None time:  1.2562042218632996
None Run 11:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 86.67
   Final Test: 66.10
Split: 04, Run: 03
None time:  1.342452451121062
None Run 12:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 88.33
   Final Test: 66.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8761009550653398
None Run 13:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.30
Split: 05, Run: 02
None time:  0.8957249030936509
None Run 14:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 98.33
   Final Test: 69.70
Split: 05, Run: 03
None time:  0.7932328740134835
None Run 15:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.792671058094129
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 58.40
Split: 06, Run: 02
None time:  1.016233861912042
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 95.00
   Final Test: 62.20
Split: 06, Run: 03
None time:  1.009584676939994
None Run 18:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 62.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1254662291612476
None Run 19:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 63.40
Split: 07, Run: 02
None time:  1.7131573620717973
None Run 20:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 80.00
   Final Test: 61.50
Split: 07, Run: 03
None time:  1.4451406949665397
None Run 21:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 80.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4786757661495358
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 86.67
   Final Test: 66.50
Split: 08, Run: 02
None time:  1.2253744232002646
None Run 23:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 91.67
   Final Test: 66.70
Split: 08, Run: 03
None time:  1.1270801729988307
None Run 24:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 91.67
   Final Test: 66.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3178870789706707
None Run 25:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 95.00
   Final Test: 68.20
Split: 09, Run: 02
None time:  1.0913387360051274
None Run 26:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 91.67
   Final Test: 68.20
Split: 09, Run: 03
None time:  1.0080724619328976
None Run 27:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 98.33
   Final Test: 68.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2035551718436182
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 64.30
Split: 10, Run: 02
None time:  1.1390365920960903
None Run 29:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 64.00
Split: 10, Run: 03
None time:  0.9701117358636111
None Run 30:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.50
run time now: 3.3550028800964355
total time:  36.08096939185634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.16 ± 1.74
  Final Train: 92.89 ± 6.00
   Final Test: 65.09 ± 2.75
best run test_acc: 65.72000885009766
[I 2023-06-11 23:49:10,454] Trial 52 finished with value: 67.16000366210938 and parameters: {'Fwd': 0.0022509151443990895, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 1.6714632787214843, 'loop': 2, 'loss': 'CE', 'lr': 0.008252432365062987, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05162214418311731, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.006916943863954896
weight_decay:  0.012257150666807107
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6338710659183562
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 91.67
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.2696405099704862
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 98.33
   Final Test: 66.20
Split: 01, Run: 03
None time:  1.4351327868644148
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.187087656930089
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.90
Split: 02, Run: 02
None time:  0.957327248994261
None Run 05:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.60
Split: 02, Run: 03
None time:  1.5477815058548003
None Run 06:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 63.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0745262340642512
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.00
Split: 03, Run: 02
None time:  1.536285107024014
None Run 08:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 91.67
   Final Test: 64.20
Split: 03, Run: 03
None time:  1.3244458220433444
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 61.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5945090542081743
None Run 10:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 66.20
Split: 04, Run: 02
None time:  1.6174691920168698
None Run 11:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 65.80
Split: 04, Run: 03
None time:  1.7358024148270488
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 86.67
   Final Test: 65.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9926751439925283
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.90
Split: 05, Run: 02
None time:  1.103179780067876
None Run 14:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.50
Split: 05, Run: 03
None time:  1.093578903004527
None Run 15:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0794779059942812
None Run 16:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 61.10
Split: 06, Run: 02
None time:  1.116572376107797
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 63.30
Split: 06, Run: 03
None time:  1.0031110590789467
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 59.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6863637459464371
None Run 19:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 61.90
Split: 07, Run: 02
None time:  1.377512936014682
None Run 20:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 62.40
Split: 07, Run: 03
None time:  1.4067111581098288
None Run 21:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 60.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1161903492175043
None Run 22:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 67.10
Split: 08, Run: 02
None time:  1.331891082925722
None Run 23:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 66.40
Split: 08, Run: 03
None time:  1.5253882568795234
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 67.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.269653034163639
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.80
Split: 09, Run: 02
None time:  1.3520792280323803
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.40
Split: 09, Run: 03
None time:  1.2742551581468433
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1965573648922145
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 64.80
Split: 10, Run: 02
None time:  1.3447717861272395
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 64.40
Split: 10, Run: 03
None time:  1.3761165090836585
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 65.10
run time now: 3.9595112800598145
total time:  40.61983349500224
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.59 ± 1.26
  Final Train: 97.00 ± 3.65
   Final Test: 65.43 ± 2.80
best run test_acc: 66.3499984741211
[I 2023-06-11 23:49:51,556] Trial 53 finished with value: 67.59333801269531 and parameters: {'Fwd': 0.009610734774595842, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 2.666729115835174, 'loop': 2, 'loss': 'CE', 'lr': 0.006916943863954896, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.012257150666807107, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.009945783968579215
weight_decay:  0.0014969479973069978
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2922911709174514
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 91.67
   Final Test: 65.00
Split: 01, Run: 02
None time:  1.2974136881530285
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 88.33
   Final Test: 66.70
Split: 01, Run: 03
None time:  1.7211224739439785
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 88.33
   Final Test: 66.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.2093063860666007
None Run 04:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 66.40
Split: 02, Run: 02
None time:  2.088733021868393
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 91.67
   Final Test: 65.60
Split: 02, Run: 03
None time:  1.2960195909254253
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6356043759733438
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 63.00
Split: 03, Run: 02
None time:  0.9010705519467592
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 61.00
Split: 03, Run: 03
None time:  1.1957979509606957
None Run 09:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 98.33
   Final Test: 61.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8191558280959725
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 85.00
   Final Test: 66.90
Split: 04, Run: 02
None time:  1.2373600178398192
None Run 11:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.00
Split: 04, Run: 03
None time:  1.1677022918593138
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 64.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0573799540288746
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 70.30
Split: 05, Run: 02
None time:  1.1334270751103759
None Run 14:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 69.50
Split: 05, Run: 03
None time:  1.0837496938183904
None Run 15:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 70.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.156133535085246
None Run 16:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 62.50
Split: 06, Run: 02
None time:  1.1117933648638427
None Run 17:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 61.50
Split: 06, Run: 03
None time:  1.358720799908042
None Run 18:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 66.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5061405249871314
None Run 19:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 91.67
   Final Test: 62.90
Split: 07, Run: 02
None time:  1.469448696123436
None Run 20:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 91.67
   Final Test: 61.60
Split: 07, Run: 03
None time:  1.270962567999959
None Run 21:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 62.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2610434570815414
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 67.80
Split: 08, Run: 02
None time:  1.2225475611630827
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 98.33
   Final Test: 68.30
Split: 08, Run: 03
None time:  1.553165690973401
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 95.00
   Final Test: 68.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1814654769841582
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.00
Split: 09, Run: 02
None time:  1.5148030610289425
None Run 26:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 95.00
   Final Test: 68.10
Split: 09, Run: 03
None time:  1.1759333892259747
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3325403151102364
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 63.70
Split: 10, Run: 02
None time:  1.0947883350308985
None Run 29:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.10
Split: 10, Run: 03
None time:  1.25603656610474
None Run 30:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 64.60
run time now: 3.7242088317871094
total time:  41.6775625529699
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.17 ± 1.57
  Final Train: 95.50 ± 3.89
   Final Test: 65.61 ± 2.75
best run test_acc: 66.46000671386719
[I 2023-06-11 23:50:33,765] Trial 54 finished with value: 67.17333221435547 and parameters: {'Fwd': 0.009565822747841823, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 1.8762408604336862, 'loop': 2, 'loss': 'CE', 'lr': 0.009945783968579215, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0014969479973069978, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.005083496131128678
weight_decay:  0.00550782509129067
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4212660319171846
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 91.67
   Final Test: 66.00
Split: 01, Run: 02
None time:  1.2818413160275668
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.5536619571503252
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 66.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.5772317259106785
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 67.90
Split: 02, Run: 02
None time:  0.8832641821354628
None Run 05:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.40
Split: 02, Run: 03
None time:  0.9627517971675843
None Run 06:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9775605979375541
None Run 07:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.40
Split: 03, Run: 02
None time:  2.595726578962058
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 90.00
   Final Test: 63.30
Split: 03, Run: 03
None time:  0.9740641221869737
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5573853228706867
None Run 10:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.60
Split: 04, Run: 02
None time:  1.9397468362003565
None Run 11:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 88.33
   Final Test: 65.90
Split: 04, Run: 03
None time:  2.388322653947398
None Run 12:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 65.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2549023739993572
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 71.40
Split: 05, Run: 02
None time:  1.0162680940702558
None Run 14:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.80
Split: 05, Run: 03
None time:  1.1964298801030964
None Run 15:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8851276261266321
None Run 16:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 64.40
Split: 06, Run: 02
None time:  1.0221536110620946
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 62.60
Split: 06, Run: 03
None time:  1.1033921390771866
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4910390321165323
None Run 19:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 62.70
Split: 07, Run: 02
None time:  0.8295091250911355
None Run 20:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 59.20
Split: 07, Run: 03
None time:  1.8512579470407218
None Run 21:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 91.67
   Final Test: 63.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2662392400670797
None Run 22:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 66.40
Split: 08, Run: 02
None time:  1.7704688720405102
None Run 23:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 68.00
Split: 08, Run: 03
None time:  1.3703865758143365
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 67.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4491030608769506
None Run 25:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 69.30
Split: 09, Run: 02
None time:  1.530077061150223
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.30
Split: 09, Run: 03
None time:  1.3972176269162446
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4079399951733649
None Run 28:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.30
Split: 10, Run: 02
None time:  1.1529678900260478
None Run 29:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 03
None time:  0.9798150109127164
None Run 30:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 62.90
run time now: 3.582261085510254
total time:  43.20621882984415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.31 ± 1.77
  Final Train: 97.56 ± 3.55
   Final Test: 65.25 ± 2.89
best run test_acc: 66.33000183105469
[I 2023-06-11 23:51:17,430] Trial 55 finished with value: 67.3133316040039 and parameters: {'Fwd': 0.012772176369010282, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.4, 'lambda2': 2.7345398079378693, 'loop': 2, 'loss': 'CE', 'lr': 0.005083496131128678, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00550782509129067, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.006270353309401192
weight_decay:  0.002442642512676571
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2886801799759269
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 86.67
   Final Test: 66.90
Split: 01, Run: 02
None time:  0.7370530809275806
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 90.00
   Final Test: 65.50
Split: 01, Run: 03
None time:  0.6302714459598064
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 91.67
   Final Test: 64.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.45772802899591625
None Run 04:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 41.20
Split: 02, Run: 02
None time:  0.547557023121044
None Run 05:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.30
Split: 02, Run: 03
None time:  0.46927404310554266
None Run 06:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.39744247891940176
None Run 07:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 40.70
Split: 03, Run: 02
None time:  0.9596493858844042
None Run 08:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 95.00
   Final Test: 55.30
Split: 03, Run: 03
None time:  0.8047773661091924
None Run 09:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 86.67
   Final Test: 57.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.3976572770625353
None Run 10:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 40.10
Split: 04, Run: 02
None time:  0.4558977719862014
None Run 11:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.70
Split: 04, Run: 03
None time:  0.4932928129564971
None Run 12:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 54.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0245637311600149
None Run 13:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 90.00
   Final Test: 61.40
Split: 05, Run: 02
None time:  1.2659178369212896
None Run 14:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 70.00
Split: 05, Run: 03
None time:  0.5922588540706784
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 69.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.4616008219309151
None Run 16:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 41.40
Split: 06, Run: 02
None time:  0.9368182211183012
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 62.30
Split: 06, Run: 03
None time:  0.6038043219596148
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 63.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5062128459103405
None Run 19:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 47.70
Split: 07, Run: 02
None time:  0.7320877609308809
None Run 20:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 91.67
   Final Test: 59.60
Split: 07, Run: 03
None time:  0.435325930127874
None Run 21:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5289085481781512
None Run 22:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 46.20
Split: 08, Run: 02
None time:  0.7143935700878501
None Run 23:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 95.00
   Final Test: 68.90
Split: 08, Run: 03
None time:  0.7218082859180868
None Run 24:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 67.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.43148268200457096
None Run 25:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 43.60
Split: 09, Run: 02
None time:  1.9098163568414748
None Run 26:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 85.00
   Final Test: 62.00
Split: 09, Run: 03
None time:  0.5163227270822972
None Run 27:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 63.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.42821511696092784
None Run 28:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 37.80
Split: 10, Run: 02
None time:  1.1842676340602338
None Run 29:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 95.00
   Final Test: 62.50
Split: 10, Run: 03
None time:  0.6941631219815463
None Run 30:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.10
run time now: 2.345655918121338
total time:  22.349137676879764
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.22 ± 10.81
  Final Train: 96.11 ± 4.76
   Final Test: 57.35 ± 10.07
best run test_acc: 63.5200080871582
[I 2023-06-11 23:51:40,276] Trial 56 finished with value: 58.21999740600586 and parameters: {'Fwd': 0.0053527805002046396, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.35000000000000003, 'lambda2': 3.841258862430239, 'loop': 2, 'loss': 'CE', 'lr': 0.006270353309401192, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002442642512676571, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.004901949996843678
weight_decay:  0.011077107523057825
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9062237909529358
None Run 01:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 58.20
Split: 01, Run: 02
None time:  1.435000847093761
None Run 02:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 60.50
Split: 01, Run: 03
None time:  0.9692909319419414
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8814015740063041
None Run 04:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.90
Split: 02, Run: 02
None time:  0.8828848381526768
None Run 05:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.50
Split: 02, Run: 03
None time:  2.441664498997852
None Run 06:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6966766989789903
None Run 07:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 55.80
Split: 03, Run: 02
None time:  1.7811427188571543
None Run 08:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.10
Split: 03, Run: 03
None time:  0.8749700440093875
None Run 09:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 53.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8345090460497886
None Run 10:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.70
Split: 04, Run: 02
None time:  0.8841911689378321
None Run 11:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.10
Split: 04, Run: 03
None time:  0.9290458231698722
None Run 12:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.186090689152479
None Run 13:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.10
Split: 05, Run: 02
None time:  1.030838768929243
None Run 14:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 66.00
Split: 05, Run: 03
None time:  1.3367403168231249
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 66.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5266786660067737
None Run 16:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 57.90
Split: 06, Run: 02
None time:  1.0949136710260063
None Run 17:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 59.00
Split: 06, Run: 03
None time:  1.2567516930866987
None Run 18:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 60.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1033715759404004
None Run 19:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 56.00
Split: 07, Run: 02
None time:  0.8520462021697313
None Run 20:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 57.30
Split: 07, Run: 03
None time:  1.4643344609066844
None Run 21:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 56.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3869117440190166
None Run 22:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 63.60
Split: 08, Run: 02
None time:  1.264164777006954
None Run 23:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 66.00
Split: 08, Run: 03
None time:  0.8637644869741052
None Run 24:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 60.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6139917708933353
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 66.10
Split: 09, Run: 02
None time:  0.9089352160226554
None Run 26:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 66.80
Split: 09, Run: 03
None time:  0.8905311969574541
None Run 27:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 62.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9009726149961352
None Run 28:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.00
Split: 10, Run: 02
None time:  0.9313038759864867
None Run 29:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.70
Split: 10, Run: 03
None time:  1.6795898019336164
None Run 30:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.50
run time now: 3.5540611743927
total time:  37.848214250057936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.67 ± 2.47
  Final Train: 100.00 ± 0.00
   Final Test: 60.86 ± 3.42
best run test_acc: 62.209999084472656
[I 2023-06-11 23:52:18,660] Trial 57 finished with value: 61.66666793823242 and parameters: {'Fwd': 0.00244524028787547, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 3.3082750148448743, 'loop': 2, 'loss': 'MSE', 'lr': 0.004901949996843678, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.011077107523057825, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.008360189526266945
weight_decay:  0.0295880951857113
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.013487190939486
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.70
Split: 01, Run: 02
None time:  1.1581365310121328
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 03
None time:  1.2997083780355752
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 67.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8119395098183304
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.40
Split: 02, Run: 02
None time:  0.8694530720822513
None Run 05:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.20
Split: 02, Run: 03
None time:  0.862523945979774
None Run 06:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8649979650508612
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.90
Split: 03, Run: 02
None time:  0.8496196079067886
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 03
None time:  0.8199282828718424
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3264183748979121
None Run 10:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 63.90
Split: 04, Run: 02
None time:  1.9347753578331321
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 63.80
Split: 04, Run: 03
None time:  1.8461367529816926
None Run 12:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 66.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2750540429260582
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.00
Split: 05, Run: 02
None time:  0.8896377340424806
None Run 14:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.00
Split: 05, Run: 03
None time:  1.2033491430338472
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8537717410363257
None Run 16:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 63.40
Split: 06, Run: 02
None time:  0.9042643490247428
None Run 17:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 63.20
Split: 06, Run: 03
None time:  0.9405188888777047
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4662883488927037
None Run 19:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 63.90
Split: 07, Run: 02
None time:  1.1250738091766834
None Run 20:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 62.10
Split: 07, Run: 03
None time:  1.412965598050505
None Run 21:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 63.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1797006709966809
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 67.90
Split: 08, Run: 02
None time:  1.25895173009485
None Run 23:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 67.60
Split: 08, Run: 03
None time:  1.0225391068961471
None Run 24:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.266094250138849
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.70
Split: 09, Run: 02
None time:  1.0968125460203737
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.10
Split: 09, Run: 03
None time:  0.9855822469107807
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0217066558543593
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 02
None time:  0.869824297958985
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.10
Split: 10, Run: 03
None time:  0.9401724170893431
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.50
run time now: 2.8727166652679443
total time:  34.462776836939156
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.51 ± 1.84
  Final Train: 99.06 ± 2.13
   Final Test: 65.74 ± 2.50
best run test_acc: 66.56999969482422
[I 2023-06-11 23:52:53,590] Trial 58 finished with value: 67.50666809082031 and parameters: {'Fwd': 0.020795633383075496, 'K': 7, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 40, 'lambda1': 0.2, 'lambda2': 2.1642642141946316, 'loop': 2, 'loss': 'CE', 'lr': 0.008360189526266945, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0295880951857113, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.008209202414583014
weight_decay:  0.027091840284119924
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.349065562011674
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 02
None time:  0.897523924941197
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.50
Split: 01, Run: 03
None time:  1.6658410551026464
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 67.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8137768590822816
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.50
Split: 02, Run: 02
None time:  0.8402992030605674
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.10
Split: 02, Run: 03
None time:  0.8596084110904485
None Run 06:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.135708557907492
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.20
Split: 03, Run: 02
None time:  0.9873551640193909
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.90
Split: 03, Run: 03
None time:  1.2870853920467198
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.98825294803828
None Run 10:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.80
Split: 04, Run: 02
None time:  0.6620229729451239
None Run 11:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.20
Split: 04, Run: 03
None time:  1.5980739160440862
None Run 12:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7846769550815225
None Run 13:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.10
Split: 05, Run: 02
None time:  0.7694723140448332
None Run 14:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.50
Split: 05, Run: 03
None time:  0.7962926670443267
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0447956880088896
None Run 16:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 62.60
Split: 06, Run: 02
None time:  1.3141716469544917
None Run 17:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 63.80
Split: 06, Run: 03
None time:  0.8476531060878187
None Run 18:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.17915008100681
None Run 19:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 62.50
Split: 07, Run: 02
None time:  1.095851005986333
None Run 20:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 61.90
Split: 07, Run: 03
None time:  1.4459420659113675
None Run 21:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8097175029106438
None Run 22:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.70
Split: 08, Run: 02
None time:  0.8228142329026014
None Run 23:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 66.10
Split: 08, Run: 03
None time:  0.8560087140649557
None Run 24:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4373454907909036
None Run 25:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.50
Split: 09, Run: 02
None time:  1.4730729861184955
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 69.30
Split: 09, Run: 03
None time:  1.3758689230307937
None Run 27:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.913647070992738
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.40
Split: 10, Run: 02
None time:  0.8636907918844372
None Run 29:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 03
None time:  0.8746167051140219
None Run 30:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.60
run time now: 2.6979877948760986
total time:  32.876795288873836
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.31 ± 2.07
  Final Train: 100.00 ± 0.00
   Final Test: 64.74 ± 2.26
best run test_acc: 65.52000427246094
[I 2023-06-11 23:53:26,926] Trial 59 finished with value: 66.3133316040039 and parameters: {'Fwd': 0.04067207475270981, 'K': 7, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.15000000000000002, 'lambda2': 3.2157945139432407, 'loop': 1, 'loss': 'CE', 'lr': 0.008209202414583014, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.027091840284119924, 'weightedloss': True}. Best is trial 33 with value: 67.84666442871094.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.75
lr:  0.004125967684832269
weight_decay:  0.005619743438396714
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0791470808908343
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.1065708920359612
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  1.2850606399588287
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 67.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.469082280062139
None Run 04:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.90
Split: 02, Run: 02
None time:  1.4460979509167373
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.40
Split: 02, Run: 03
None time:  1.4516734350472689
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.275510041974485
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.60
Split: 03, Run: 02
None time:  1.8219133738894016
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.20
Split: 03, Run: 03
None time:  1.4945486770011485
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3855243029538542
None Run 10:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.70
Split: 04, Run: 02
None time:  0.997170661110431
None Run 11:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.00
Split: 04, Run: 03
None time:  1.3880740890745074
None Run 12:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.40991338994354
None Run 13:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 05, Run: 02
None time:  1.7073560049757361
None Run 14:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.60
Split: 05, Run: 03
None time:  1.3206075199414045
None Run 15:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7020623011048883
None Run 16:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.20
Split: 06, Run: 02
None time:  0.737642094027251
None Run 17:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.50
Split: 06, Run: 03
None time:  0.7037180832121521
None Run 18:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.480693638091907
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 65.20
Split: 07, Run: 02
None time:  1.689567408990115
None Run 20:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 66.20
Split: 07, Run: 03
None time:  1.7709922050125897
None Run 21:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1506217520218343
None Run 22:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.60
Split: 08, Run: 02
None time:  1.4439480321016163
None Run 23:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 68.30
Split: 08, Run: 03
None time:  1.2266546511091292
None Run 24:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4898275029845536
None Run 25:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 71.20
Split: 09, Run: 02
None time:  1.3107759931590408
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 71.40
Split: 09, Run: 03
None time:  1.4790082438848913
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 72.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2711492269299924
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.30
Split: 10, Run: 02
None time:  1.2363027879036963
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.00
Split: 10, Run: 03
None time:  1.5122777780052274
None Run 30:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 66.60
run time now: 4.057856798171997
total time:  40.85626718401909
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.95 ± 2.19
  Final Train: 100.00 ± 0.00
   Final Test: 67.02 ± 2.64
best run test_acc: 67.50999450683594
[I 2023-06-11 23:54:08,234] Trial 60 finished with value: 67.95333099365234 and parameters: {'Fwd': 0.09246905137300569, 'K': 6, 'alpha': 0.75, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.2, 'lambda2': 1.6619467906038148, 'loop': 2, 'loss': 'CE', 'lr': 0.004125967684832269, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.005619743438396714, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.006913344266194951
weight_decay:  0.006638085198631195
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9770124189089984
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 02
None time:  0.8954356140457094
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 62.30
Split: 01, Run: 03
None time:  0.8709761570207775
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 63.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9406057291198522
None Run 04:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.10
Split: 02, Run: 02
None time:  1.125748774036765
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.00
Split: 02, Run: 03
None time:  0.9440311559010297
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8958671928849071
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 02
None time:  1.4509660711046308
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.70
Split: 03, Run: 03
None time:  0.9080204099882394
None Run 09:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4054705549497157
None Run 10:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 63.80
Split: 04, Run: 02
None time:  1.731818423140794
None Run 11:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.40
Split: 04, Run: 03
None time:  2.826322952983901
None Run 12:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0987114771269262
None Run 13:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.70
Split: 05, Run: 02
None time:  0.9023130608256906
None Run 14:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.80
Split: 05, Run: 03
None time:  0.9146635381039232
None Run 15:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6330683869309723
None Run 16:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 63.30
Split: 06, Run: 02
None time:  1.6704463979694992
None Run 17:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 63.60
Split: 06, Run: 03
None time:  1.5797830780502409
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0815103391651064
None Run 19:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 63.10
Split: 07, Run: 02
None time:  1.4977671569213271
None Run 20:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 63.70
Split: 07, Run: 03
None time:  1.3020718910265714
None Run 21:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 62.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.0403941811528057
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.10
Split: 08, Run: 02
None time:  2.1764003089629114
None Run 23:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.20
Split: 08, Run: 03
None time:  1.5803640179801732
None Run 24:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3113821088336408
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 69.30
Split: 09, Run: 02
None time:  1.6647835460025817
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 69.90
Split: 09, Run: 03
None time:  1.3811181441415101
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9458561479113996
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 02
None time:  0.8867092619184405
None Run 29:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 03
None time:  0.9826839969027787
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.80
run time now: 2.862929582595825
total time:  42.643353587947786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.35 ± 2.39
  Final Train: 100.00 ± 0.00
   Final Test: 65.67 ± 2.42
best run test_acc: 66.42999267578125
[I 2023-06-11 23:54:51,402] Trial 61 finished with value: 67.35334014892578 and parameters: {'Fwd': 0.07483060619655793, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.2, 'lambda2': 1.8485281413051178, 'loop': 2, 'loss': 'CE', 'lr': 0.006913344266194951, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006638085198631195, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.75
lr:  0.004291759683030707
weight_decay:  0.003328651867689996
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5861872190143913
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.5121505120769143
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 98.33
   Final Test: 65.30
Split: 01, Run: 03
None time:  1.543666381854564
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 98.33
   Final Test: 67.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5503011129330844
None Run 04:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.20
Split: 02, Run: 02
None time:  1.4482338309753686
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.60
Split: 02, Run: 03
None time:  1.6404454500880092
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0310708680190146
None Run 07:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.10
Split: 03, Run: 02
None time:  0.6819029480684549
None Run 08:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 57.10
Split: 03, Run: 03
None time:  0.6946874028071761
None Run 09:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 57.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0659535699523985
None Run 10:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.90
Split: 04, Run: 02
None time:  2.6436243450734764
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.00
Split: 04, Run: 03
None time:  1.0660517278593034
None Run 12:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8004510311875492
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.80
Split: 05, Run: 02
None time:  2.2145378720015287
None Run 14:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 71.50
Split: 05, Run: 03
None time:  1.6794491109903902
None Run 15:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6454529960174114
None Run 16:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.10
Split: 06, Run: 02
None time:  0.6776918198447675
None Run 17:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.00
Split: 06, Run: 03
None time:  0.6909766041208059
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 62.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7342069579754025
None Run 19:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 66.30
Split: 07, Run: 02
None time:  1.4245076759252697
None Run 20:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.20
Split: 07, Run: 03
None time:  0.7121149620506912
None Run 21:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 59.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.641253548907116
None Run 22:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.50
Split: 08, Run: 02
None time:  1.6732918720226735
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.80
Split: 08, Run: 03
None time:  1.1816027599852532
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4514995680656284
None Run 25:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 71.00
Split: 09, Run: 02
None time:  1.6264910669997334
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 71.40
Split: 09, Run: 03
None time:  1.287384947994724
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 70.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4327312870882452
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.00
Split: 10, Run: 02
None time:  1.4423804101534188
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.70
Split: 10, Run: 03
None time:  0.6415691960137337
None Run 30:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 59.90
run time now: 3.5554635524749756
total time:  42.446659269044176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.21 ± 3.05
  Final Train: 99.72 ± 0.77
   Final Test: 65.59 ± 3.99
best run test_acc: 67.16999816894531
[I 2023-06-11 23:55:34,286] Trial 62 finished with value: 67.20665740966797 and parameters: {'Fwd': 0.04017628807861501, 'K': 6, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 40, 'lambda1': 0.1, 'lambda2': 1.1681350256503433, 'loop': 2, 'loss': 'CE', 'lr': 0.004291759683030707, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003328651867689996, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.006070834386370109
weight_decay:  0.004953995126569104
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.220604701898992
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 02
None time:  1.1602352398913354
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  1.3984031539876014
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 67.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4269332431722432
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 66.10
Split: 02, Run: 02
None time:  0.9981494569219649
None Run 05:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.80
Split: 02, Run: 03
None time:  1.1063916210550815
None Run 06:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3484176460187882
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.50
Split: 03, Run: 02
None time:  1.5811394520569593
None Run 08:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 63.60
Split: 03, Run: 03
None time:  1.392010924173519
None Run 09:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.30
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5083415149711072
None Run 10:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.10
Split: 04, Run: 02
None time:  1.7733219170477241
None Run 11:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 65.20
Split: 04, Run: 03
None time:  2.1459189909510314
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 65.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2765265458729118
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 71.60
Split: 05, Run: 02
None time:  1.3920671050436795
None Run 14:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 70.90
Split: 05, Run: 03
None time:  1.098703219089657
None Run 15:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1834891091566533
None Run 16:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 63.80
Split: 06, Run: 02
None time:  1.03279686300084
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 63.20
Split: 06, Run: 03
None time:  1.1031407921109349
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 62.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7416114420630038
None Run 19:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 62.20
Split: 07, Run: 02
None time:  1.5376484808512032
None Run 20:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 63.20
Split: 07, Run: 03
None time:  1.3398319599218667
None Run 21:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 62.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1692812498658895
None Run 22:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.00
Split: 08, Run: 02
None time:  1.758905852213502
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 69.10
Split: 08, Run: 03
None time:  1.3354073429945856
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 67.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1643992520403117
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.50
Split: 09, Run: 02
None time:  1.319886703044176
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.00
Split: 09, Run: 03
None time:  1.3655785010196269
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 70.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8724525980651379
None Run 28:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.80
Split: 10, Run: 02
None time:  1.2052436829544604
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 63.80
Split: 10, Run: 03
None time:  1.0576609240379184
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 62.60
run time now: 3.175241708755493
total time:  42.0481243908871
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.53 ± 1.61
  Final Train: 98.72 ± 1.89
   Final Test: 65.61 ± 2.96
best run test_acc: 66.41000366210938
[I 2023-06-11 23:56:16,771] Trial 63 finished with value: 67.52666473388672 and parameters: {'Fwd': 0.020056518974617993, 'K': 7, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 2.842651509914946, 'loop': 2, 'loss': 'CE', 'lr': 0.006070834386370109, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004953995126569104, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0061306393944248775
weight_decay:  0.001927425006577227
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3655728029552847
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 91.67
   Final Test: 65.70
Split: 01, Run: 02
None time:  1.3728582449257374
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 90.00
   Final Test: 64.50
Split: 01, Run: 03
None time:  1.2352507710456848
None Run 03:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 91.67
   Final Test: 63.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.484081984963268
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 65.30
Split: 02, Run: 02
None time:  1.5448941991198808
None Run 05:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 66.30
Split: 02, Run: 03
None time:  1.5894933710806072
None Run 06:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 65.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2699237999040633
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 62.60
Split: 03, Run: 02
None time:  1.1977452270220965
None Run 08:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 61.30
Split: 03, Run: 03
None time:  1.0695335899945349
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 60.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4171562138944864
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 65.70
Split: 04, Run: 02
None time:  1.8084184301551431
None Run 11:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 65.00
Split: 04, Run: 03
None time:  2.5742350521031767
None Run 12:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 85.00
   Final Test: 65.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2413909749593586
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 70.50
Split: 05, Run: 02
None time:  1.1757387551479042
None Run 14:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 71.10
Split: 05, Run: 03
None time:  1.0610864120535553
None Run 15:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 70.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.136151819024235
None Run 16:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 63.30
Split: 06, Run: 02
None time:  1.1103480390738696
None Run 17:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 95.00
   Final Test: 61.50
Split: 06, Run: 03
None time:  1.0681935048196465
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 63.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6051625071559101
None Run 19:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 91.67
   Final Test: 63.40
Split: 07, Run: 02
None time:  1.085772171849385
None Run 20:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 62.20
Split: 07, Run: 03
None time:  1.2003554599359632
None Run 21:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 61.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2672067189123482
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 67.10
Split: 08, Run: 02
None time:  1.2682103300467134
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 67.70
Split: 08, Run: 03
None time:  1.6701114519964904
None Run 24:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 91.67
   Final Test: 68.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.311431545065716
None Run 25:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 69.30
Split: 09, Run: 02
None time:  1.1930677581112832
None Run 26:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 69.20
Split: 09, Run: 03
None time:  1.188277609879151
None Run 27:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0951024200767279
None Run 28:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 63.40
Split: 10, Run: 02
None time:  1.1022202998865396
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 03
None time:  0.992569318972528
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.00
run time now: 3.229698657989502
total time:  40.727769400924444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.13 ± 1.71
  Final Train: 95.33 ± 3.62
   Final Test: 65.31 ± 2.96
best run test_acc: 65.97000122070312
[I 2023-06-11 23:56:57,947] Trial 64 finished with value: 67.13333129882812 and parameters: {'Fwd': 0.01275549881975555, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 2.707197834165935, 'loop': 2, 'loss': 'CE', 'lr': 0.0061306393944248775, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.001927425006577227, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.004866539625336841
weight_decay:  0.004907453365482164
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7061139808502048
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 02
None time:  1.8717088371049613
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  1.8026611879467964
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1178303230553865
None Run 04:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.70
Split: 02, Run: 02
None time:  1.0925890221260488
None Run 05:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.00
Split: 02, Run: 03
None time:  1.0230875241104513
None Run 06:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0517735709436238
None Run 07:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.30
Split: 03, Run: 02
None time:  1.1023745900020003
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.80
Split: 03, Run: 03
None time:  0.9978559990413487
None Run 09:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.920576211065054
None Run 10:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.60
Split: 04, Run: 02
None time:  1.9280681009404361
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.30
Split: 04, Run: 03
None time:  1.610046094050631
None Run 12:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0377106820233166
None Run 13:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.70
Split: 05, Run: 02
None time:  1.9153583229053766
None Run 14:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.90
Split: 05, Run: 03
None time:  1.683793099829927
None Run 15:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4822863670997322
None Run 16:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 65.60
Split: 06, Run: 02
None time:  1.1712143879849464
None Run 17:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 64.40
Split: 06, Run: 03
None time:  1.4714940178673714
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 64.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4311345610767603
None Run 19:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 61.30
Split: 07, Run: 02
None time:  1.394598193001002
None Run 20:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 61.80
Split: 07, Run: 03
None time:  1.2078647390007973
None Run 21:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 62.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.143552620895207
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.60
Split: 08, Run: 02
None time:  1.7566316698212177
None Run 23:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.80
Split: 08, Run: 03
None time:  1.4828181660268456
None Run 24:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 69.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4628637719433755
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.20
Split: 09, Run: 02
None time:  1.4533975489903241
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 70.10
Split: 09, Run: 03
None time:  1.4445084240287542
None Run 27:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 68.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.130922205047682
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.90
Split: 10, Run: 02
None time:  1.1168607019353658
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 63.90
Split: 10, Run: 03
None time:  1.1617154930718243
None Run 30:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 64.60
run time now: 3.4472529888153076
total time:  44.22181400703266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.12 ± 1.72
  Final Train: 100.00 ± 0.00
   Final Test: 65.66 ± 2.51
best run test_acc: 66.44999694824219
[I 2023-06-11 23:57:42,799] Trial 65 finished with value: 67.12000274658203 and parameters: {'Fwd': 0.05097742479047814, 'K': 6, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 3.0235971694096553, 'loop': 2, 'loss': 'CE', 'lr': 0.004866539625336841, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004907453365482164, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.004073429112257695
weight_decay:  0.003231312194088044
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7290466190315783
None Run 01:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.00
Split: 01, Run: 02
None time:  0.7453825070988387
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 03
None time:  0.7305540621746331
None Run 03:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7370417402125895
None Run 04:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 60.90
Split: 02, Run: 02
None time:  0.785874447086826
None Run 05:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.50
Split: 02, Run: 03
None time:  0.751674389000982
None Run 06:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7183823569212109
None Run 07:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.70
Split: 03, Run: 02
None time:  0.7484245100058615
None Run 08:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 52.50
Split: 03, Run: 03
None time:  0.7948878640308976
None Run 09:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 56.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.74817781499587
None Run 10:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.60
Split: 04, Run: 02
None time:  0.7347963589709252
None Run 11:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.30
Split: 04, Run: 03
None time:  0.7218601831700653
None Run 12:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 59.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7246091729030013
None Run 13:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.60
Split: 05, Run: 02
None time:  0.772489074151963
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.70
Split: 05, Run: 03
None time:  0.7537338479887694
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7499517039395869
None Run 16:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.20
Split: 06, Run: 02
None time:  0.7586360292043537
None Run 17:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.50
Split: 06, Run: 03
None time:  0.6904184711165726
None Run 18:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 58.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7832422079518437
None Run 19:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 56.40
Split: 07, Run: 02
None time:  0.7130127530544996
None Run 20:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 56.10
Split: 07, Run: 03
None time:  0.7355347929988056
None Run 21:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 57.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7934760339558125
None Run 22:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 63.80
Split: 08, Run: 02
None time:  0.7199235749430954
None Run 23:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 61.10
Split: 08, Run: 03
None time:  0.7791788319591433
None Run 24:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 60.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7049394429195672
None Run 25:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.50
Split: 09, Run: 02
None time:  0.7187613190617412
None Run 26:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 63.80
Split: 09, Run: 03
None time:  0.7072477960027754
None Run 27:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7079353840090334
None Run 28:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.20
Split: 10, Run: 02
None time:  0.7866481479723006
None Run 29:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.10
Split: 10, Run: 03
None time:  0.7123730829916894
None Run 30:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.60
run time now: 2.2477059364318848
total time:  23.318049441091716
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.29 ± 2.58
  Final Train: 100.00 ± 0.00
   Final Test: 60.22 ± 3.32
best run test_acc: 61.339996337890625
[I 2023-06-11 23:58:06,578] Trial 66 finished with value: 61.28666687011719 and parameters: {'Fwd': 0.0071637893491731395, 'K': 8, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 3.85551575753263, 'loop': 2, 'loss': 'CE', 'lr': 0.004073429112257695, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003231312194088044, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.006343898135201386
weight_decay:  0.005090508077613912
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.140247831121087
None Run 01:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.40
Split: 01, Run: 02
None time:  1.0625957159791142
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.70
Split: 01, Run: 03
None time:  1.1667921668849885
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 93.33
   Final Test: 62.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9614360621199012
None Run 04:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.50
Split: 02, Run: 02
None time:  0.9655033410526812
None Run 05:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.30
Split: 02, Run: 03
None time:  0.9308451779652387
None Run 06:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.998222084948793
None Run 07:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.50
Split: 03, Run: 02
None time:  1.099145266925916
None Run 08:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.00
Split: 03, Run: 03
None time:  1.0020953060593456
None Run 09:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 56.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6942959371954203
None Run 10:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 81.67
   Final Test: 63.80
Split: 04, Run: 02
None time:  1.7831532838754356
None Run 11:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 80.00
   Final Test: 64.90
Split: 04, Run: 03
None time:  2.136230520904064
None Run 12:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 81.67
   Final Test: 64.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0470328740775585
None Run 13:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.70
Split: 05, Run: 02
None time:  1.0425879119429737
None Run 14:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.20
Split: 05, Run: 03
None time:  1.1816278989426792
None Run 15:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9964018149767071
None Run 16:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 60.90
Split: 06, Run: 02
None time:  0.9681724079418927
None Run 17:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 62.10
Split: 06, Run: 03
None time:  1.0474342969246209
None Run 18:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0599541899282485
None Run 19:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 60.10
Split: 07, Run: 02
None time:  0.99197409581393
None Run 20:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 60.30
Split: 07, Run: 03
None time:  0.9627609238959849
None Run 21:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 61.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.162272108020261
None Run 22:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 66.20
Split: 08, Run: 02
None time:  1.243305804906413
None Run 23:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 95.00
   Final Test: 66.40
Split: 08, Run: 03
None time:  1.1052334948908538
None Run 24:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.033140196930617
None Run 25:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 67.00
Split: 09, Run: 02
None time:  1.1497153430245817
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 68.60
Split: 09, Run: 03
None time:  1.1558943188283592
None Run 27:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 68.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0667777021881193
None Run 28:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.40
Split: 10, Run: 02
None time:  0.9649793349672109
None Run 29:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 03
None time:  1.0439657880924642
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.20
run time now: 3.115703821182251
total time:  35.17882110993378
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.95 ± 2.29
  Final Train: 97.61 ± 5.82
   Final Test: 63.53 ± 3.13
best run test_acc: 64.44000244140625
[I 2023-06-11 23:58:42,236] Trial 67 finished with value: 64.95333862304688 and parameters: {'Fwd': 0.004586398960263547, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 1.511459248253149, 'loop': 2, 'loss': 'CE', 'lr': 0.006343898135201386, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.005090508077613912, 'weightedloss': False}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.007263807668870557
weight_decay:  0.0008030285658377039
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5589347491040826
None Run 01:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 76.67
   Final Test: 39.20
Split: 01, Run: 02
None time:  1.3778033589478582
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 81.67
   Final Test: 50.10
Split: 01, Run: 03
None time:  1.0659660659730434
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 85.00
   Final Test: 50.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1992279079277068
None Run 04:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 95.00
   Final Test: 59.30
Split: 02, Run: 02
None time:  0.5266644039656967
None Run 05:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.60
Split: 02, Run: 03
None time:  0.6007635958958417
None Run 06:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5470429379492998
None Run 07:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 48.10
Split: 03, Run: 02
None time:  1.0338180409744382
None Run 08:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 81.67
   Final Test: 50.80
Split: 03, Run: 03
None time:  0.6136714490130544
None Run 09:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 98.33
   Final Test: 51.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6685004280880094
None Run 10:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 98.33
   Final Test: 57.70
Split: 04, Run: 02
None time:  1.0602912961039692
None Run 11:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 86.67
   Final Test: 60.70
Split: 04, Run: 03
None time:  0.7188966600224376
None Run 12:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 95.00
   Final Test: 62.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.542019747197628
None Run 13:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 51.50
Split: 05, Run: 02
None time:  1.248364589875564
None Run 14:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 90.00
   Final Test: 65.40
Split: 05, Run: 03
None time:  0.6036587608978152
None Run 15:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 95.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9912577108480036
None Run 16:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 83.33
   Final Test: 62.50
Split: 06, Run: 02
None time:  0.5622388401534408
None Run 17:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.50
Split: 06, Run: 03
None time:  0.6551404800266027
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 91.67
   Final Test: 62.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.511462592985481
None Run 19:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 48.70
Split: 07, Run: 02
None time:  0.8556647789664567
None Run 20:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 85.00
   Final Test: 56.10
Split: 07, Run: 03
None time:  0.8204890370834619
None Run 21:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 88.33
   Final Test: 57.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5365195600315928
None Run 22:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 54.10
Split: 08, Run: 02
None time:  0.8643191950395703
None Run 23:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 81.67
   Final Test: 55.70
Split: 08, Run: 03
None time:  0.5650786459445953
None Run 24:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 59.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6059547699987888
None Run 25:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 44.50
Split: 09, Run: 02
None time:  1.0661555149126798
None Run 26:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 88.33
   Final Test: 65.80
Split: 09, Run: 03
None time:  0.8532370219472796
None Run 27:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 86.67
   Final Test: 65.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1840653670951724
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 86.67
   Final Test: 65.70
Split: 10, Run: 02
None time:  0.6261736140586436
None Run 29:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 64.70
Split: 10, Run: 03
None time:  0.6189440179150552
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.20
run time now: 2.471561908721924
total time:  25.69249680195935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.03 ± 7.31
  Final Train: 92.44 ± 7.49
   Final Test: 57.17 ± 7.00
best run test_acc: 59.81000518798828
[I 2023-06-11 23:59:08,438] Trial 68 finished with value: 58.03334045410156 and parameters: {'Fwd': 0.011054641805537677, 'K': 7, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 2.9293193807091367, 'loop': 2, 'loss': 'CE', 'lr': 0.007263807668870557, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008030285658377039, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.008603961807303629
weight_decay:  0.0017795269883164203
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9024405111558735
None Run 01:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 53.70
Split: 01, Run: 02
None time:  1.5205535700079054
None Run 02:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 03
None time:  1.196771209128201
None Run 03:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 59.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9482064028270543
None Run 04:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 56.90
Split: 02, Run: 02
None time:  0.9546199149917811
None Run 05:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.90
Split: 02, Run: 03
None time:  0.928645450156182
None Run 06:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 60.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9535362250171602
None Run 07:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 57.70
Split: 03, Run: 02
None time:  0.8907864361535758
None Run 08:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 54.60
Split: 03, Run: 03
None time:  0.9012778589967638
None Run 09:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 52.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8177221019286662
None Run 10:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.40
Split: 04, Run: 02
None time:  0.8744637800846249
None Run 11:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.00
Split: 04, Run: 03
None time:  0.9456038440112025
None Run 12:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 55.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9600502219982445
None Run 13:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 63.30
Split: 05, Run: 02
None time:  0.9363238431978971
None Run 14:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 65.10
Split: 05, Run: 03
None time:  0.9791661698836833
None Run 15:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9073830938432366
None Run 16:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 58.70
Split: 06, Run: 02
None time:  0.9409913579002023
None Run 17:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 60.60
Split: 06, Run: 03
None time:  1.7911854670383036
None Run 18:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 61.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3553007920272648
None Run 19:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 53.10
Split: 07, Run: 02
None time:  1.2637529300991446
None Run 20:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 58.10
Split: 07, Run: 03
None time:  0.9035373320803046
None Run 21:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 55.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9036188221070915
None Run 22:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 58.60
Split: 08, Run: 02
None time:  1.0010306369513273
None Run 23:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 65.90
Split: 08, Run: 03
None time:  0.907624133862555
None Run 24:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 61.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.051707583013922
None Run 25:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 65.70
Split: 09, Run: 02
None time:  0.8739872500300407
None Run 26:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 65.40
Split: 09, Run: 03
None time:  0.9994999119080603
None Run 27:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8214262200053781
None Run 28:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.20
Split: 10, Run: 02
None time:  0.8598482341039926
None Run 29:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.30
Split: 10, Run: 03
None time:  0.882321106037125
None Run 30:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.30
run time now: 2.6020667552948
total time:  31.191908437060192
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.59 ± 3.78
  Final Train: 100.00 ± 0.00
   Final Test: 59.85 ± 3.89
best run test_acc: 61.8900032043457
[I 2023-06-11 23:59:40,076] Trial 69 finished with value: 60.586666107177734 and parameters: {'Fwd': 0.03192798908464662, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 4.196126531916244, 'loop': 2, 'loss': 'MSE', 'lr': 0.008603961807303629, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0017795269883164203, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.7000000000000001
lr:  0.0027894092636073864
weight_decay:  0.0026226348924620634
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7245110201183707
None Run 01:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 02
None time:  0.7533156841527671
None Run 02:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 57.60
Split: 01, Run: 03
None time:  0.7015525349415839
None Run 03:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 53.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6697708168067038
None Run 04:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 62.60
Split: 02, Run: 02
None time:  1.5027839760296047
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.20
Split: 02, Run: 03
None time:  0.7219797919970006
None Run 06:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6776621039025486
None Run 07:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.50
Split: 03, Run: 02
None time:  0.7006095701362938
None Run 08:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.30
Split: 03, Run: 03
None time:  1.5382270698901266
None Run 09:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 98.33
   Final Test: 66.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.029128171969205
None Run 10:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 65.90
Split: 04, Run: 02
None time:  1.4572794130071998
None Run 11:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 65.50
Split: 04, Run: 03
None time:  1.880553803872317
None Run 12:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 65.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7774927080608904
None Run 13:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.40
Split: 05, Run: 02
None time:  1.447165152989328
None Run 14:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
Split: 05, Run: 03
None time:  1.3760550019796938
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6807093878742307
None Run 16:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 59.10
Split: 06, Run: 02
None time:  0.7979879488702863
None Run 17:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 60.00
Split: 06, Run: 03
None time:  0.6817696040961891
None Run 18:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 56.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6491125880274922
None Run 19:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 55.50
Split: 07, Run: 02
None time:  1.560844135005027
None Run 20:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 64.90
Split: 07, Run: 03
None time:  0.7552409758791327
None Run 21:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 60.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3709766308311373
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.40
Split: 08, Run: 02
None time:  0.7452810159884393
None Run 23:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 60.50
Split: 08, Run: 03
None time:  1.4893669430166483
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.421824977034703
None Run 25:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 71.00
Split: 09, Run: 02
None time:  0.661634657997638
None Run 26:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 63.00
Split: 09, Run: 03
None time:  1.3795227219816297
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 72.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.253886449150741
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 62.70
Split: 10, Run: 02
None time:  0.7558919759467244
None Run 29:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.30
Split: 10, Run: 03
None time:  1.0819276471156627
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.60
run time now: 3.1358933448791504
total time:  34.213965012924746
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.59 ± 4.88
  Final Train: 99.50 ± 1.17
   Final Test: 63.40 ± 5.08
best run test_acc: 66.1100082397461
[I 2023-06-12 00:00:14,837] Trial 70 finished with value: 64.586669921875 and parameters: {'Fwd': 0.053815352910610306, 'K': 4, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.35000000000000003, 'lambda2': 2.3767863857461635, 'loop': 2, 'loss': 'CE', 'lr': 0.0027894092636073864, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0026226348924620634, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.008468846366470615
weight_decay:  0.01215368444232791
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4185026260092854
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 02
None time:  1.109452557982877
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 03
None time:  0.7439513399731368
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9309908610302955
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 02
None time:  0.8621828579343855
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.70
Split: 02, Run: 03
None time:  0.9043046589940786
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7631487878970802
None Run 07:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.20
Split: 03, Run: 02
None time:  0.8736398781184107
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.30
Split: 03, Run: 03
None time:  0.7780705858021975
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4752745779696852
None Run 10:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.30
Split: 04, Run: 02
None time:  1.8766342028975487
None Run 11:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.70
Split: 04, Run: 03
None time:  2.21937349694781
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9494747200515121
None Run 13:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.00
Split: 05, Run: 02
None time:  0.7689806278795004
None Run 14:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.50
Split: 05, Run: 03
None time:  0.8525042389519513
None Run 15:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0813014230225235
None Run 16:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 64.30
Split: 06, Run: 02
None time:  0.8085112541448325
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 63.90
Split: 06, Run: 03
None time:  1.2596347820945084
None Run 18:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 63.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.349238262977451
None Run 19:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 63.10
Split: 07, Run: 02
None time:  1.215678655076772
None Run 20:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 65.20
Split: 07, Run: 03
None time:  1.182410247856751
None Run 21:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 62.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.809077639132738
None Run 22:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.90
Split: 08, Run: 02
None time:  1.636709300801158
None Run 23:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.60
Split: 08, Run: 03
None time:  2.0905423078220338
None Run 24:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.165375775191933
None Run 25:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 70.70
Split: 09, Run: 02
None time:  1.3584172159899026
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 69.50
Split: 09, Run: 03
None time:  1.559547317912802
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8344023360405117
None Run 28:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.30
Split: 10, Run: 02
None time:  0.8098826159257442
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.70
Split: 10, Run: 03
None time:  0.8623852638993412
None Run 30:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.10
run time now: 2.5469160079956055
total time:  37.586203273851424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.67 ± 2.19
  Final Train: 100.00 ± 0.00
   Final Test: 66.03 ± 2.27
best run test_acc: 66.75999450683594
[I 2023-06-12 00:00:52,916] Trial 71 finished with value: 67.67333221435547 and parameters: {'Fwd': 0.0803882071372482, 'K': 7, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 40, 'lambda1': 0.25, 'lambda2': 2.362205324402012, 'loop': 2, 'loss': 'CE', 'lr': 0.008468846366470615, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01215368444232791, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.006269173923409342
weight_decay:  0.006993540928500597
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3476241379976273
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 02
None time:  2.1943659738171846
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.958035429008305
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8475657920353115
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.10
Split: 02, Run: 02
None time:  0.979460502974689
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.50
Split: 02, Run: 03
None time:  0.8508004818577319
None Run 06:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8720180399250239
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.90
Split: 03, Run: 02
None time:  1.0842085350304842
None Run 08:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.40
Split: 03, Run: 03
None time:  1.069778034929186
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.71976908785291
None Run 10:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.10
Split: 04, Run: 02
None time:  2.746903755934909
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.40
Split: 04, Run: 03
None time:  2.118635863997042
None Run 12:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0874544410035014
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 05, Run: 02
None time:  1.1577129538636655
None Run 14:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 05, Run: 03
None time:  0.9987533160019666
None Run 15:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.945136345922947
None Run 16:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 62.90
Split: 06, Run: 02
None time:  0.9478793770540506
None Run 17:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 63.70
Split: 06, Run: 03
None time:  1.1895558850374073
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2777542790863663
None Run 19:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 62.70
Split: 07, Run: 02
None time:  1.3146519740112126
None Run 20:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 64.80
Split: 07, Run: 03
None time:  1.611415792023763
None Run 21:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 61.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.357538081938401
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.20
Split: 08, Run: 02
None time:  1.2819987209513783
None Run 23:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.20
Split: 08, Run: 03
None time:  1.7242249681148678
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.786001211963594
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.70
Split: 09, Run: 02
None time:  1.4610073370859027
None Run 26:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 70.10
Split: 09, Run: 03
None time:  1.369349492015317
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0400760329794139
None Run 28:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.20
Split: 10, Run: 02
None time:  1.0354289738461375
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.10
Split: 10, Run: 03
None time:  1.1063252359163016
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.00
run time now: 3.2203996181488037
total time:  44.502925887936726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.91 ± 1.54
  Final Train: 100.00 ± 0.00
   Final Test: 66.12 ± 2.51
best run test_acc: 66.75999450683594
[I 2023-06-12 00:01:37,857] Trial 72 finished with value: 67.90666198730469 and parameters: {'Fwd': 0.07966851464019949, 'K': 6, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.25, 'lambda2': 3.2848559178032684, 'loop': 2, 'loss': 'CE', 'lr': 0.006269173923409342, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006993540928500597, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.007559492824189253
weight_decay:  0.007942526186921445
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1106500579044223
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 02
None time:  1.3727264110930264
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 03
None time:  1.0104410839267075
None Run 03:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9284512721933424
None Run 04:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.00
Split: 02, Run: 02
None time:  0.8450130322016776
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.70
Split: 02, Run: 03
None time:  0.8610034300945699
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9262527639511973
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.30
Split: 03, Run: 02
None time:  0.8164466999005526
None Run 08:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 03
None time:  1.1271361419931054
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.576782278949395
None Run 10:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.60
Split: 04, Run: 02
None time:  2.1505752850789577
None Run 11:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.30
Split: 04, Run: 03
None time:  1.669350357959047
None Run 12:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0822814819402993
None Run 13:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.70
Split: 05, Run: 02
None time:  1.1035048810299486
None Run 14:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.90
Split: 05, Run: 03
None time:  1.008201444055885
None Run 15:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9050643229857087
None Run 16:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 63.30
Split: 06, Run: 02
None time:  1.464013459160924
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 63.40
Split: 06, Run: 03
None time:  1.351508763153106
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2196162098553032
None Run 19:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 64.60
Split: 07, Run: 02
None time:  1.5581565599422902
None Run 20:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.60
Split: 07, Run: 03
None time:  2.233395084971562
None Run 21:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.5496472909580916
None Run 22:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 66.30
Split: 08, Run: 02
None time:  1.3431663708761334
None Run 23:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 66.60
Split: 08, Run: 03
None time:  1.293950333027169
None Run 24:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0675959170330316
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.60
Split: 09, Run: 02
None time:  1.2277840080205351
None Run 26:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 69.30
Split: 09, Run: 03
None time:  1.365464333910495
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8924179119057953
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.00
Split: 10, Run: 02
None time:  0.9469674259889871
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.10
Split: 10, Run: 03
None time:  1.0027414760552347
None Run 30:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.00
run time now: 2.8821260929107666
total time:  40.01934967190027
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.84 ± 2.23
  Final Train: 100.00 ± 0.00
   Final Test: 65.74 ± 2.03
best run test_acc: 66.33000183105469
[I 2023-06-12 00:02:18,329] Trial 73 finished with value: 66.83999633789062 and parameters: {'Fwd': 0.08339320007655601, 'K': 6, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.15000000000000002, 'lambda2': 3.3599050135109687, 'loop': 2, 'loss': 'CE', 'lr': 0.007559492824189253, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007942526186921445, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.00832833716890711
weight_decay:  0.012213323516496068
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0008214979898185
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 02
None time:  0.839166667079553
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 03
None time:  0.8839489622041583
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.122287493897602
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.10
Split: 02, Run: 02
None time:  1.1251192009076476
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.70
Split: 02, Run: 03
None time:  1.0821054039988667
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9155278010293841
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.40
Split: 03, Run: 02
None time:  1.0902294341940433
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.20
Split: 03, Run: 03
None time:  0.9120805261190981
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.793843090068549
None Run 10:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.60
Split: 04, Run: 02
None time:  1.2888404070399702
None Run 11:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.80
Split: 04, Run: 03
None time:  1.6025147859472781
None Run 12:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9776351249311119
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.10
Split: 05, Run: 02
None time:  1.5596337348688394
None Run 14:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
Split: 05, Run: 03
None time:  1.0485527708660811
None Run 15:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2039464670233428
None Run 16:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.40
Split: 06, Run: 02
None time:  1.6664756019599736
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 63.90
Split: 06, Run: 03
None time:  0.949850020930171
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.669377475976944
None Run 19:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 64.40
Split: 07, Run: 02
None time:  2.3025099420920014
None Run 20:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.00
Split: 07, Run: 03
None time:  1.4504173737950623
None Run 21:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8616813281551003
None Run 22:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.70
Split: 08, Run: 02
None time:  0.9860724851023406
None Run 23:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.90
Split: 08, Run: 03
None time:  0.9943424242082983
None Run 24:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7952945320867002
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.80
Split: 09, Run: 02
None time:  1.1769018049817532
None Run 26:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 69.20
Split: 09, Run: 03
None time:  1.1822818180080503
None Run 27:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 69.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9712909751106054
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.50
Split: 10, Run: 02
None time:  0.9506865318398923
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.20
Split: 10, Run: 03
None time:  1.0400277879089117
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.70
run time now: 3.002434253692627
total time:  37.45766951609403
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.33 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 66.21 ± 1.92
best run test_acc: 66.71000671386719
[I 2023-06-12 00:02:56,227] Trial 74 finished with value: 67.32666778564453 and parameters: {'Fwd': 0.07493477402769155, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 40, 'lambda1': 0.1, 'lambda2': 2.623969588784766, 'loop': 2, 'loss': 'CE', 'lr': 0.00832833716890711, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.012213323516496068, 'weightedloss': True}. Best is trial 60 with value: 67.95333099365234.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.008930559735222506
weight_decay:  0.007518779849149428
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6325522910337895
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.5708119589835405
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.590436588972807
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 69.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3247459779959172
None Run 04:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.30
Split: 02, Run: 02
None time:  1.2040128482040018
None Run 05:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.30
Split: 02, Run: 03
None time:  1.6258100101258606
None Run 06:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9844562618527561
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 02
None time:  1.6905599508900195
None Run 08:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.40
Split: 03, Run: 03
None time:  0.9631485908757895
None Run 09:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.30
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.360888518160209
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.10
Split: 04, Run: 02
None time:  1.579830399947241
None Run 11:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.40
Split: 04, Run: 03
None time:  2.946438310900703
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 65.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.641526079038158
None Run 13:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 71.70
Split: 05, Run: 02
None time:  1.447129702894017
None Run 14:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 71.80
Split: 05, Run: 03
None time:  1.3593559679575264
None Run 15:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 71.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7811967690940946
None Run 16:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 60.70
Split: 06, Run: 02
None time:  0.8786401790566742
None Run 17:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 64.60
Split: 06, Run: 03
None time:  0.9364923760294914
None Run 18:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 64.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.60483029903844
None Run 19:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 67.00
Split: 07, Run: 02
None time:  2.5073070109356195
None Run 20:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 96.67
   Final Test: 66.20
Split: 07, Run: 03
None time:  1.4335225438699126
None Run 21:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5728196240961552
None Run 22:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.30
Split: 08, Run: 02
None time:  2.009659486822784
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 70.10
Split: 08, Run: 03
None time:  2.5922491198871285
None Run 24:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 71.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2708980459719896
None Run 25:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 70.70
Split: 09, Run: 02
None time:  1.6252175059635192
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 72.10
Split: 09, Run: 03
None time:  1.9146417558658868
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 72.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4261264260858297
None Run 28:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 65.70
Split: 10, Run: 02
None time:  2.586037493078038
None Run 29:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 95.00
   Final Test: 68.40
Split: 10, Run: 03, Epoch: 100, Loss: 0.1826, Train: 95.00%, Valid: 73.00% Test: 69.80%
Split: 10, Run: 03
None time:  2.9333623200654984
None Run 30:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 96.67
   Final Test: 69.50
run time now: 6.984619140625
total time:  51.01187586900778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 2.15
  Final Train: 98.78 ± 1.85
   Final Test: 67.96 ± 3.10
best run test_acc: 69.07000732421875
[I 2023-06-12 00:03:47,761] Trial 75 finished with value: 69.73332977294922 and parameters: {'Fwd': 0.08567519861687184, 'K': 5, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 3.1688792504298426, 'loop': 2, 'loss': 'CE', 'lr': 0.008930559735222506, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007518779849149428, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.00886067271877687
weight_decay:  0.007533559501305404
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8460507031995803
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  1.0461108239833266
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  1.0592613930348307
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6506824439857155
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.60
Split: 02, Run: 02
None time:  1.4025004841387272
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.30
Split: 02, Run: 03
None time:  1.6498123451601714
None Run 06:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7874416140839458
None Run 07:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.90
Split: 03, Run: 02
None time:  0.7988507710397243
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 03
None time:  0.7623187080025673
None Run 09:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0094457778614014
None Run 10:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.30
Split: 04, Run: 02
None time:  1.1082904229406267
None Run 11:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.00
Split: 04, Run: 03
None time:  1.2638912829570472
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.979574111988768
None Run 13:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.40
Split: 05, Run: 02
None time:  0.9214190521743149
None Run 14:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 70.90
Split: 05, Run: 03
None time:  1.0251946998760104
None Run 15:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 70.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2441805619746447
None Run 16:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 64.90
Split: 06, Run: 02
None time:  0.9397401800379157
None Run 17:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.10
Split: 06, Run: 03
None time:  1.0208536291029304
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2640700910706073
None Run 19:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 65.10
Split: 07, Run: 02
None time:  1.179129116004333
None Run 20:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 65.10
Split: 07, Run: 03
None time:  1.1769295411650091
None Run 21:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 98.33
   Final Test: 66.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9922302400227636
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.10
Split: 08, Run: 02
None time:  1.1473009989131242
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 69.30
Split: 08, Run: 03
None time:  1.1772183279972523
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0416648990940303
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 72.70
Split: 09, Run: 02
None time:  1.3599647809751332
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 72.10
Split: 09, Run: 03
None time:  1.1590806432068348
None Run 27:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 72.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.734623686876148
None Run 28:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.00
Split: 10, Run: 02
None time:  0.7751672191079706
None Run 29:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 61.90
Split: 10, Run: 03
None time:  0.7074079089798033
None Run 30:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.20
run time now: 2.2545692920684814
total time:  33.256968333153054
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.35 ± 2.21
  Final Train: 99.50 ± 0.99
   Final Test: 66.83 ± 3.16
best run test_acc: 67.63999938964844
[I 2023-06-12 00:04:21,447] Trial 76 finished with value: 68.35334014892578 and parameters: {'Fwd': 0.09743366628720382, 'K': 5, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 0.8500000000000001, 'lambda2': 3.559887549885466, 'loop': 2, 'loss': 'CE', 'lr': 0.00886067271877687, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007533559501305404, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.008836446165484277
weight_decay:  0.007956538944422725
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.49461799999698997
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 58.30
Split: 01, Run: 02
None time:  0.4336649081669748
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  0.49382218695245683
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 60.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.4035052019171417
None Run 04:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.80
Split: 02, Run: 02
None time:  0.4425985428970307
None Run 05:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 62.20
Split: 02, Run: 03
None time:  0.5129996750038117
None Run 06:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 60.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4657671900931746
None Run 07:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.10
Split: 03, Run: 02
None time:  0.5192516781389713
None Run 08:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.10
Split: 03, Run: 03
None time:  0.4564203219488263
None Run 09:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 53.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.49226182512938976
None Run 10:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.30
Split: 04, Run: 02
None time:  0.5130838539917022
None Run 11:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 58.70
Split: 04, Run: 03
None time:  0.4959684801287949
None Run 12:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.49336552899330854
None Run 13:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.30
Split: 05, Run: 02
None time:  0.47891677799634635
None Run 14:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 64.00
Split: 05, Run: 03
None time:  0.4751727010589093
None Run 15:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.4641359159722924
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 58.60
Split: 06, Run: 02
None time:  0.5063678349833935
None Run 17:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 03
None time:  0.5241015981882811
None Run 18:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 58.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.46844106796197593
None Run 19:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.20
Split: 07, Run: 02
None time:  0.4387583299539983
None Run 20:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 56.40
Split: 07, Run: 03
None time:  0.3992358869872987
None Run 21:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 57.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4617685179691762
None Run 22:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 66.60
Split: 08, Run: 02
None time:  0.47834962396882474
None Run 23:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 58.50
Split: 08, Run: 03
None time:  0.4621696569956839
None Run 24:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.3839285911526531
None Run 25:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 65.70
Split: 09, Run: 02
None time:  0.46670901705510914
None Run 26:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 66.60
Split: 09, Run: 03
None time:  0.5275420530233532
None Run 27:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 68.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.49252779386006296
None Run 28:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.00
Split: 10, Run: 02
None time:  0.4893151521682739
None Run 29:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 61.70
Split: 10, Run: 03
None time:  0.4898630538955331
None Run 30:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 60.10
run time now: 1.5110297203063965
total time:  15.257724451133981
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.51 ± 3.07
  Final Train: 100.00 ± 0.00
   Final Test: 61.02 ± 3.45
best run test_acc: 62.73999786376953
[I 2023-06-12 00:04:37,154] Trial 77 finished with value: 61.51333236694336 and parameters: {'Fwd': 0.09178036197226877, 'K': 5, 'alpha': 1.0, 'dropout': 0.0, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 3.727378065246064, 'loop': 2, 'loss': 'CE', 'lr': 0.008836446165484277, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007956538944422725, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.005271622736652031
weight_decay:  0.003325090642426821
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2096499830950052
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 66.50
Split: 01, Run: 02
None time:  0.8677986459806561
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.7792740368749946
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 68.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7386575390119106
None Run 04:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.40
Split: 02, Run: 02
None time:  1.1804830338805914
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.00
Split: 02, Run: 03
None time:  1.3085514719132334
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6385953319258988
None Run 07:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 59.40
Split: 03, Run: 02
None time:  0.8903801080305129
None Run 08:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.00
Split: 03, Run: 03
None time:  0.7654022658243775
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.219250078080222
None Run 10:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.20
Split: 04, Run: 02
None time:  1.1461558821611106
None Run 11:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.50
Split: 04, Run: 03
None time:  1.2167637920938432
None Run 12:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.924077556002885
None Run 13:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 95.00
   Final Test: 71.20
Split: 05, Run: 02
None time:  0.9652656340040267
None Run 14:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 05, Run: 03
None time:  1.147536152973771
None Run 15:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 70.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1170045789331198
None Run 16:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 62.90
Split: 06, Run: 02
None time:  0.979452993022278
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.00
Split: 06, Run: 03
None time:  0.8368451020214707
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 63.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9989537571091205
None Run 19:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 62.50
Split: 07, Run: 02
None time:  1.7703264721203595
None Run 20:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 63.10
Split: 07, Run: 03
None time:  1.4323713609483093
None Run 21:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 66.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9987176959402859
None Run 22:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.70
Split: 08, Run: 02
None time:  1.4383524311706424
None Run 23:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 69.00
Split: 08, Run: 03
None time:  1.550742704886943
None Run 24:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 68.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.609569272957742
None Run 25:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 71.40
Split: 09, Run: 02
None time:  1.371682679047808
None Run 26:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 71.80
Split: 09, Run: 03
None time:  1.5142477138433605
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 72.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8183227640110999
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.50
Split: 10, Run: 02
None time:  0.8545627291314304
None Run 29:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.30
Split: 10, Run: 03
None time:  0.8819460698869079
None Run 30:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 62.10
run time now: 2.592160701751709
total time:  37.189693639054894
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.94 ± 2.09
  Final Train: 99.00 ± 1.73
   Final Test: 66.14 ± 3.32
best run test_acc: 67.4000015258789
[I 2023-06-12 00:05:14,800] Trial 78 finished with value: 67.93999481201172 and parameters: {'Fwd': 0.09413709064038982, 'K': 5, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 3.178902113183377, 'loop': 2, 'loss': 'CE', 'lr': 0.005271622736652031, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003325090642426821, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.005323362333181548
weight_decay:  0.003793911948483671
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0574912768788636
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 02
None time:  1.1839322689920664
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 65.40
Split: 01, Run: 03
None time:  1.236481046071276
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2645453931763768
None Run 04:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 02, Run: 02
None time:  0.6622656751424074
None Run 05:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.20
Split: 02, Run: 03
None time:  0.88916179491207
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7673148668836802
None Run 07:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.20
Split: 03, Run: 02
None time:  1.573818770935759
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 65.90
Split: 03, Run: 03
None time:  0.7077290578745306
None Run 09:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0293463170528412
None Run 10:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 65.50
Split: 04, Run: 02
None time:  1.2380144109483808
None Run 11:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 64.70
Split: 04, Run: 03
None time:  1.267439867137
None Run 12:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 64.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8554096529260278
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.60
Split: 05, Run: 02
None time:  1.0831432349514216
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 71.40
Split: 05, Run: 03
None time:  1.0596588789485395
None Run 15:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 71.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.216803832212463
None Run 16:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 66.30
Split: 06, Run: 02
None time:  0.9276839029043913
None Run 17:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.80
Split: 06, Run: 03
None time:  0.8880930310115218
None Run 18:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 64.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3966711920220405
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 65.30
Split: 07, Run: 02
None time:  1.7753197669517249
None Run 20:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 63.40
Split: 07, Run: 03
None time:  1.1689613810740411
None Run 21:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3437547308858484
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 68.30
Split: 08, Run: 02
None time:  1.274341840064153
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.20
Split: 08, Run: 03
None time:  1.2756483398843557
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 69.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6953496411442757
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.90
Split: 09, Run: 02
None time:  1.304453661898151
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 71.00
Split: 09, Run: 03
None time:  1.4970517291221768
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 70.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8218786220531911
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 62.20
Split: 10, Run: 02
None time:  1.136313684983179
None Run 29:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 63.10
Split: 10, Run: 03
None time:  1.2148941240739077
None Run 30:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.40
run time now: 3.2189884185791016
total time:  34.807599029969424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 2.60
  Final Train: 98.56 ± 1.74
   Final Test: 66.02 ± 3.01
best run test_acc: 67.45999908447266
[I 2023-06-12 00:05:50,063] Trial 79 finished with value: 67.73332977294922 and parameters: {'Fwd': 0.06208683934617615, 'K': 4, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 4.36878249448816, 'loop': 2, 'loss': 'CE', 'lr': 0.005323362333181548, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003793911948483671, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.45
lr:  0.004837499402648284
weight_decay:  0.002719794102448582
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.17967594298534095
None Run 01:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 32.80
Split: 01, Run: 02
None time:  0.1877940169069916
None Run 02:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 32.80
Split: 01, Run: 03
None time:  0.15511260996572673
None Run 03:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 32.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.16144898300990462
None Run 04:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 39.30
Split: 02, Run: 02
None time:  0.1567943198606372
None Run 05:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 39.30
Split: 02, Run: 03
None time:  0.16031910618767142
None Run 06:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 39.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.1582677059341222
None Run 07:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 39.60
Split: 03, Run: 02
None time:  0.17315031099133193
None Run 08:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 39.60
Split: 03, Run: 03
None time:  0.17471295385621488
None Run 09:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 39.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.15498484601266682
None Run 10:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 38.70
Split: 04, Run: 02
None time:  0.18488007690757513
None Run 11:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 38.70
Split: 04, Run: 03
None time:  0.1816563419997692
None Run 12:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 38.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.15796404494903982
None Run 13:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 41.10
Split: 05, Run: 02
None time:  0.22303806385025382
None Run 14:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 41.10
Split: 05, Run: 03
None time:  0.19068783684633672
None Run 15:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 41.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.18025136715732515
None Run 16:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 37.50
Split: 06, Run: 02
None time:  0.19487033784389496
None Run 17:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 37.50
Split: 06, Run: 03
None time:  0.19613714702427387
None Run 18:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 37.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.17490142886526883
None Run 19:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 32.20
Split: 07, Run: 02
None time:  0.16124081378802657
None Run 20:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 32.20
Split: 07, Run: 03
None time:  0.18700857600197196
None Run 21:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 32.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.1740043880417943
None Run 22:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 40.50
Split: 08, Run: 02
None time:  0.18951860000379384
None Run 23:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 40.50
Split: 08, Run: 03
None time:  0.1831496770028025
None Run 24:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 40.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.13912999094463885
None Run 25:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 41.70
Split: 09, Run: 02
None time:  0.1701072589494288
None Run 26:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 41.70
Split: 09, Run: 03
None time:  0.16214560205116868
None Run 27:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 41.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.20428684097714722
None Run 28:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 36.00
Split: 10, Run: 02
None time:  0.16246501612477005
None Run 29:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 36.00
Split: 10, Run: 03
None time:  0.1642372510395944
None Run 30:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 36.00
run time now: 0.5685462951660156
total time:  6.256752503104508
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 36.24 ± 2.95
  Final Train: 100.00 ± 0.00
   Final Test: 37.94 ± 3.20
best run test_acc: 37.939998626708984
[I 2023-06-12 00:05:56,783] Trial 80 finished with value: 36.23999786376953 and parameters: {'Fwd': 0.09649688006329137, 'K': 5, 'alpha': 0.45, 'dropout': 0.30000000000000004, 'gnnepoch': 10, 'lambda1': 0.9500000000000001, 'lambda2': 3.5541151900774715, 'loop': 1, 'loss': 'CE', 'lr': 0.004837499402648284, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002719794102448582, 'weightedloss': False}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.005615962394905687
weight_decay:  0.004063143124657121
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4995912900194526
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 91.67
   Final Test: 65.30
Split: 01, Run: 02
None time:  1.207946561044082
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 67.90
Split: 01, Run: 03
None time:  1.246091557200998
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 68.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.925275756046176
None Run 04:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 63.10
Split: 02, Run: 02
None time:  1.74132632301189
None Run 05:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.40
Split: 02, Run: 03
None time:  1.9184672799892724
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3633956010453403
None Run 07:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 66.00
Split: 03, Run: 02
None time:  0.7824878769461066
None Run 08:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.00
Split: 03, Run: 03
None time:  0.9915097181219608
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.332089798990637
None Run 10:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 91.67
   Final Test: 63.60
Split: 04, Run: 02
None time:  1.3418415000196546
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 65.70
Split: 04, Run: 03
None time:  1.246123770950362
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9429834000766277
None Run 13:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 70.60
Split: 05, Run: 02
None time:  1.0219162218272686
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.00
Split: 05, Run: 03
None time:  0.9735089340247214
None Run 15:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 70.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4586622680071741
None Run 16:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 64.50
Split: 06, Run: 02
None time:  0.8908721387851983
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 64.80
Split: 06, Run: 03
None time:  0.6289586969651282
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 63.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3528771759010851
None Run 19:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 98.33
   Final Test: 64.00
Split: 07, Run: 02
None time:  1.4452722379937768
None Run 20:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 64.70
Split: 07, Run: 03
None time:  1.2357406131923199
None Run 21:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 63.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.280017496086657
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 69.10
Split: 08, Run: 02
None time:  1.3380239540711045
None Run 23:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 68.70
Split: 08, Run: 03, Epoch: 100, Loss: 0.0180, Train: 90.00%, Valid: 66.60% Test: 67.30%
Split: 08, Run: 03
None time:  2.759189876029268
None Run 24:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 91.67
   Final Test: 67.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8815875612199306
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 70.00
Split: 09, Run: 02
None time:  1.661461996845901
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 71.70
Split: 09, Run: 03
None time:  1.274011876899749
None Run 27:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 71.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7109782320912927
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.90
Split: 10, Run: 02
None time:  0.7514698188751936
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.10
Split: 10, Run: 03
None time:  0.8190039559267461
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.30
run time now: 2.3232262134552
total time:  38.024311143904924
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.03 ± 2.08
  Final Train: 97.33 ± 2.92
   Final Test: 66.33 ± 2.92
best run test_acc: 67.33000183105469
[I 2023-06-12 00:06:35,325] Trial 81 finished with value: 68.03333282470703 and parameters: {'Fwd': 0.05691272176306122, 'K': 4, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 4.052052746311201, 'loop': 2, 'loss': 'CE', 'lr': 0.005615962394905687, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004063143124657121, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.00586849149498882
weight_decay:  0.006818533545520389
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3130122520960867
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 91.67
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.6131997178308666
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 91.67
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.9149028048850596
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9284876622259617
None Run 04:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.90
Split: 02, Run: 02
None time:  1.067502835066989
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 03
None time:  0.9084404669702053
None Run 06:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.221749312011525
None Run 07:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.90
Split: 03, Run: 02
None time:  1.6626050849445164
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 95.00
   Final Test: 66.20
Split: 03, Run: 03
None time:  0.9318384961225092
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 64.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3159776560496539
None Run 10:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 65.40
Split: 04, Run: 02
None time:  1.1170954019762576
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 65.00
Split: 04, Run: 03
None time:  1.116906536044553
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0384266038890928
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 70.40
Split: 05, Run: 02
None time:  1.0097849760204554
None Run 14:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 71.20
Split: 05, Run: 03
None time:  0.9097574651241302
None Run 15:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5176271349191666
None Run 16:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 67.10
Split: 06, Run: 02
None time:  1.3339960500597954
None Run 17:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 63.40
Split: 06, Run: 03
None time:  0.7366858581081033
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2286137789487839
None Run 19:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 65.50
Split: 07, Run: 02
None time:  1.3355463969055563
None Run 20:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 62.30
Split: 07, Run: 03
None time:  1.1547159259207547
None Run 21:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 63.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3444241341203451
None Run 22:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 69.40
Split: 08, Run: 02
None time:  1.3855901930946857
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 68.80
Split: 08, Run: 03
None time:  1.14184436108917
None Run 24:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 98.33
   Final Test: 68.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1793843349441886
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.90
Split: 09, Run: 02
None time:  1.3594216969795525
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 95.00
   Final Test: 71.40
Split: 09, Run: 03
None time:  1.1190569200553
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 69.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8306771591305733
None Run 28:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 64.50
Split: 10, Run: 02
None time:  1.2994938248302788
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 66.10
Split: 10, Run: 03
None time:  1.6352777071297169
None Run 30:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 93.33
   Final Test: 61.60
run time now: 4.811793327331543
total time:  37.66240884712897
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.26 ± 1.93
  Final Train: 96.89 ± 2.96
   Final Test: 66.56 ± 2.82
best run test_acc: 67.7800064086914
[I 2023-06-12 00:07:13,452] Trial 82 finished with value: 68.26000213623047 and parameters: {'Fwd': 0.029379762124017623, 'K': 3, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 4.005175276822926, 'loop': 2, 'loss': 'CE', 'lr': 0.00586849149498882, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006818533545520389, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.003929424658536143
weight_decay:  0.007799537007942505
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.44883139012381434
None Run 01:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 54.50
Split: 01, Run: 02
None time:  0.4453919450752437
None Run 02:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 03
None time:  0.9847705031279474
None Run 03:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 91.67
   Final Test: 61.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.4613450539764017
None Run 04:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 45.40
Split: 02, Run: 02
None time:  1.3435911019332707
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.00
Split: 02, Run: 03
None time:  1.8728708820417523
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.242010849993676
None Run 07:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 95.00
   Final Test: 66.10
Split: 03, Run: 02
None time:  0.8105571360792965
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.20
Split: 03, Run: 03
None time:  0.44784675096161664
None Run 09:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 54.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.025026983115822
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 65.80
Split: 04, Run: 02
None time:  1.9962057899683714
None Run 11:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 81.67
   Final Test: 63.30
Split: 04, Run: 03
None time:  1.8464619689621031
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 81.67
   Final Test: 62.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4141563340090215
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 70.30
Split: 05, Run: 02
None time:  1.575339769013226
None Run 14:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 70.50
Split: 05, Run: 03
None time:  0.4634435218758881
None Run 15:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5034908989910036
None Run 16:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 59.70
Split: 06, Run: 02
None time:  0.4985037259757519
None Run 17:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.60
Split: 06, Run: 03
None time:  0.47793281311169267
None Run 18:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 58.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3185908771120012
None Run 19:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 88.33
   Final Test: 66.00
Split: 07, Run: 02
None time:  1.2956621050834656
None Run 20:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 88.33
   Final Test: 65.70
Split: 07, Run: 03
None time:  0.5243584129493684
None Run 21:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 46.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4697338289115578
None Run 22:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 62.20
Split: 08, Run: 02
None time:  0.4209742317907512
None Run 23:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 60.20
Split: 08, Run: 03
None time:  0.8182767750695348
None Run 24:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.4915788071230054
None Run 25:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 56.20
Split: 09, Run: 02
None time:  0.5114645739085972
None Run 26:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 54.20
Split: 09, Run: 03
None time:  1.4916604969184846
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 90.00
   Final Test: 71.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8066238099709153
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 61.10
Split: 10, Run: 02
None time:  0.43878223095089197
None Run 29:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.10
Split: 10, Run: 03
None time:  0.48903174698352814
None Run 30:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.70
run time now: 1.7862544059753418
total time:  27.943885660963133
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.32 ± 7.08
  Final Train: 96.44 ± 5.63
   Final Test: 61.51 ± 6.33
best run test_acc: 65.88999938964844
[I 2023-06-12 00:07:41,922] Trial 83 finished with value: 62.31999588012695 and parameters: {'Fwd': 0.02972571558480047, 'K': 2, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 3.934559832392177, 'loop': 2, 'loss': 'CE', 'lr': 0.003929424658536143, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007799537007942505, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.006278881193014514
weight_decay:  0.020143179187213155
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2201052659656852
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 95.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  1.5565246648620814
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 68.40
Split: 01, Run: 03
None time:  1.3711030769627541
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 68.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1598392291925848
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.40
Split: 02, Run: 02
None time:  1.1817220938391984
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.50
Split: 02, Run: 03
None time:  1.3215345819480717
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.373562121996656
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 02
None time:  0.8137478339485824
None Run 08:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.60
Split: 03, Run: 03
None time:  1.2861741569358855
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1735754709225148
None Run 10:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.70
Split: 04, Run: 02
None time:  1.2253862509969622
None Run 11:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 65.30
Split: 04, Run: 03
None time:  1.7782973910216242
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 91.67
   Final Test: 65.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9738637739792466
None Run 13:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 70.70
Split: 05, Run: 02
None time:  1.0908482489176095
None Run 14:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 71.60
Split: 05, Run: 03
None time:  1.5772879249416292
None Run 15:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 71.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2706971829757094
None Run 16:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 63.50
Split: 06, Run: 02
None time:  1.1528963020537049
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 95.00
   Final Test: 63.60
Split: 06, Run: 03
None time:  0.7122018442023546
None Run 18:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1725540289189667
None Run 19:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 93.33
   Final Test: 66.30
Split: 07, Run: 02
None time:  1.2667741740588099
None Run 20:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 65.00
Split: 07, Run: 03
None time:  1.1658402208704501
None Run 21:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 64.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3558478490449488
None Run 22:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 69.70
Split: 08, Run: 02
None time:  1.3501418950036168
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 69.10
Split: 08, Run: 03
None time:  1.528721823124215
None Run 24:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3539591829758137
None Run 25:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 72.20
Split: 09, Run: 02
None time:  1.712822861969471
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 95.00
   Final Test: 71.30
Split: 09, Run: 03
None time:  1.2880762901622802
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 71.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7358279628679156
None Run 28:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.50
Split: 10, Run: 02
None time:  0.7540971380658448
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.00
Split: 10, Run: 03
None time:  0.7677406929433346
None Run 30:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.50
run time now: 2.2940542697906494
total time:  37.735116944881156
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.67 ± 2.34
  Final Train: 98.00 ± 2.45
   Final Test: 66.94 ± 3.25
best run test_acc: 67.90999603271484
[I 2023-06-12 00:08:20,158] Trial 84 finished with value: 68.66666412353516 and parameters: {'Fwd': 0.05789765076001179, 'K': 3, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 4.365542413069033, 'loop': 2, 'loss': 'CE', 'lr': 0.006278881193014514, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.020143179187213155, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.004506897390992321
weight_decay:  0.02114333892543681
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3141615712083876
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 93.33
   Final Test: 66.60
Split: 01, Run: 02
None time:  1.483332535950467
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 95.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  1.4587655731011182
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 91.67
   Final Test: 67.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1542412349954247
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.60
Split: 02, Run: 02
None time:  0.9227977269329131
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.80
Split: 02, Run: 03
None time:  0.645301174139604
None Run 06:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9555950460489839
None Run 07:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.00
Split: 03, Run: 02
None time:  1.5134621618781239
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 95.00
   Final Test: 65.80
Split: 03, Run: 03
None time:  1.8744666820857674
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 66.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4401038708165288
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 91.67
   Final Test: 64.90
Split: 04, Run: 02
None time:  1.733912233961746
None Run 11:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 65.20
Split: 04, Run: 03
None time:  1.4546650999691337
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 65.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.812809550901875
None Run 13:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.80
Split: 05, Run: 02
None time:  1.566835526842624
None Run 14:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 70.30
Split: 05, Run: 03
None time:  1.1468475239817053
None Run 15:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 71.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3982198399025947
None Run 16:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 95.00
   Final Test: 65.60
Split: 06, Run: 02
None time:  1.151566683780402
None Run 17:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.00
Split: 06, Run: 03
None time:  0.6106337199453264
None Run 18:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 59.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7911215180065483
None Run 19:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 90.00
   Final Test: 65.30
Split: 07, Run: 02
None time:  1.7399461390450597
None Run 20:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 65.50
Split: 07, Run: 03
None time:  1.2360160669777542
None Run 21:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 64.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0858952109701931
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.60
Split: 08, Run: 02
None time:  1.4701269450597465
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.90
Split: 08, Run: 03
None time:  1.0134998611174524
None Run 24:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3927746810950339
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.60
Split: 09, Run: 02
None time:  0.6542683069128543
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.10
Split: 09, Run: 03
None time:  1.7380925621837378
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 71.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7703489540144801
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.20
Split: 10, Run: 02
None time:  0.7284474968910217
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 62.40
Split: 10, Run: 03
None time:  0.8787007620558143
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.10
run time now: 2.413419485092163
total time:  40.14347053482197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.29 ± 2.59
  Final Train: 96.72 ± 3.23
   Final Test: 66.60 ± 2.75
best run test_acc: 67.77000427246094
[I 2023-06-12 00:09:00,853] Trial 85 finished with value: 68.28665924072266 and parameters: {'Fwd': 0.05942771424441527, 'K': 3, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 3.953755545588132, 'loop': 2, 'loss': 'CE', 'lr': 0.004506897390992321, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.02114333892543681, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.004437986967666153
weight_decay:  0.019967609518391816
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1901496550999582
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 95.00
   Final Test: 66.70
Split: 01, Run: 02
None time:  1.536359100136906
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 88.33
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.454778438899666
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 93.33
   Final Test: 66.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3174944771453738
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.90
Split: 02, Run: 02
None time:  0.758213970111683
None Run 05:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.10
Split: 02, Run: 03
None time:  1.7978944040369242
None Run 06:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.5107603231444955
None Run 07:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 66.40
Split: 03, Run: 02
None time:  1.3562935281079262
None Run 08:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.60
Split: 03, Run: 03
None time:  1.3607362089678645
None Run 09:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9336130421143025
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 65.50
Split: 04, Run: 02
None time:  1.5867879479192197
None Run 11:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 65.20
Split: 04, Run: 03
None time:  1.4927273208741099
None Run 12:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 63.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.20975145814009
None Run 13:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 70.30
Split: 05, Run: 02
None time:  1.1935494679491967
None Run 14:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 71.50
Split: 05, Run: 03
None time:  1.100431544939056
None Run 15:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5388296879827976
None Run 16:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 55.90
Split: 06, Run: 02
None time:  0.8515089100692421
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.80
Split: 06, Run: 03
None time:  0.5310912770219147
None Run 18:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 56.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3575117499567568
None Run 19:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 98.33
   Final Test: 65.30
Split: 07, Run: 02
None time:  1.7630988310556859
None Run 20:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 90.00
   Final Test: 65.20
Split: 07, Run: 03
None time:  1.2839285868685693
None Run 21:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 65.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5636607490014285
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 68.00
Split: 08, Run: 02
None time:  2.499990962911397
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 69.20
Split: 08, Run: 03
None time:  1.5842080970760435
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 68.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5676647829823196
None Run 25:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 72.50
Split: 09, Run: 02
None time:  2.2633989739697427
None Run 26:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 71.40
Split: 09, Run: 03
None time:  1.7067334328312427
None Run 27:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 71.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9470221251249313
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.40
Split: 10, Run: 02
None time:  1.3519803560338914
None Run 29:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 63.30
Split: 10, Run: 03
None time:  0.8548757501412183
None Run 30:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.40
run time now: 3.18786883354187
total time:  42.4456869000569
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.75 ± 3.43
  Final Train: 97.11 ± 3.58
   Final Test: 66.24 ± 4.02
best run test_acc: 67.7300033569336
[I 2023-06-12 00:09:43,769] Trial 86 finished with value: 67.75333404541016 and parameters: {'Fwd': 0.05990365172200173, 'K': 3, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 4.465402679681196, 'loop': 2, 'loss': 'CE', 'lr': 0.004437986967666153, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.019967609518391816, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.0036242422351862496
weight_decay:  0.024348187511065485
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.40663326694630086
None Run 01:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 52.30
Split: 01, Run: 02
None time:  0.3507361300289631
None Run 02:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 03
None time:  0.4113069539889693
None Run 03:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 60.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.44621507707051933
None Run 04:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 44.80
Split: 02, Run: 02
None time:  0.3568113879300654
None Run 05:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 49.50
Split: 02, Run: 03
None time:  0.3677120078355074
None Run 06:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 57.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.36244680802337825
None Run 07:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 54.80
Split: 03, Run: 02
None time:  0.3899631581734866
None Run 08:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 49.60
Split: 03, Run: 03
None time:  0.4351349431090057
None Run 09:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 51.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.3927839449606836
None Run 10:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 40.70
Split: 04, Run: 02
None time:  0.36611225502565503
None Run 11:
Highest Train: 100.00
Highest Valid: 29.60
  Final Train: 100.00
   Final Test: 29.00
Split: 04, Run: 03
None time:  0.33466210518963635
None Run 12:
Highest Train: 100.00
Highest Valid: 29.60
  Final Train: 100.00
   Final Test: 29.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.38331718486733735
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 63.60
Split: 05, Run: 02
None time:  0.38267839583568275
None Run 14:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 60.00
Split: 05, Run: 03
None time:  0.43790507898665965
None Run 15:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.35226208600215614
None Run 16:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 42.40
Split: 06, Run: 02
None time:  0.4182074139826
None Run 17:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 53.30
Split: 06, Run: 03
None time:  0.3612649778369814
None Run 18:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 55.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.39075034810230136
None Run 19:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 61.70
Split: 07, Run: 02
None time:  0.4138294418808073
None Run 20:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.60
Split: 07, Run: 03
None time:  0.3948929188773036
None Run 21:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.38366501894779503
None Run 22:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.90
Split: 08, Run: 02
None time:  0.4203167390078306
None Run 23:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 54.60
Split: 08, Run: 03
None time:  0.4395504309795797
None Run 24:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 43.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.39472731086425483
None Run 25:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 51.00
Split: 09, Run: 02
None time:  0.38447697507217526
None Run 26:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 66.40
Split: 09, Run: 03
None time:  0.3614605269394815
None Run 27:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 63.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.3496493808925152
None Run 28:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.00
Split: 10, Run: 02
None time:  0.452913595829159
None Run 29:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.40
Split: 10, Run: 03
None time:  0.4771662028506398
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.20
run time now: 1.314910650253296
total time:  12.79382324591279
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.94 ± 9.21
  Final Train: 100.00 ± 0.00
   Final Test: 53.85 ± 9.59
best run test_acc: 58.56999969482422
[I 2023-06-12 00:09:57,000] Trial 87 finished with value: 53.94000244140625 and parameters: {'Fwd': 0.0961614515738175, 'K': 3, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 10, 'lambda1': 0.9500000000000001, 'lambda2': 4.687789514664312, 'loop': 2, 'loss': 'CE', 'lr': 0.0036242422351862496, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.024348187511065485, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.005817928752681174
weight_decay:  0.021419550186234555
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7315013129264116
None Run 01:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  0.871979946969077
None Run 02:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  0.9188039901200682
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 60.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9882715279236436
None Run 04:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 63.10
Split: 02, Run: 02
None time:  1.0459178339224309
None Run 05:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.40
Split: 02, Run: 03
None time:  0.9619772869627923
None Run 06:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0195986260659993
None Run 07:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.80
Split: 03, Run: 02
None time:  1.104097843868658
None Run 08:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.40
Split: 03, Run: 03
None time:  1.1379895131103694
None Run 09:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8773360729683191
None Run 10:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.70
Split: 04, Run: 02
None time:  1.0543914188165218
None Run 11:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.50
Split: 04, Run: 03
None time:  0.7845653612166643
None Run 12:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.983159027993679
None Run 13:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.10
Split: 05, Run: 02
None time:  0.9528425680473447
None Run 14:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.00
Split: 05, Run: 03
None time:  0.9641156049910933
None Run 15:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 66.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6610214009415358
None Run 16:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 60.10
Split: 06, Run: 02
None time:  0.7741269490215927
None Run 17:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 59.30
Split: 06, Run: 03
None time:  0.8782059031073004
None Run 18:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 60.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1960278518963605
None Run 19:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 58.70
Split: 07, Run: 02
None time:  1.0504456488415599
None Run 20:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 60.20
Split: 07, Run: 03
None time:  0.7277222629636526
None Run 21:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 59.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8867474000435323
None Run 22:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 65.20
Split: 08, Run: 02
None time:  1.0583328900393099
None Run 23:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 63.30
Split: 08, Run: 03
None time:  1.3487213898915797
None Run 24:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7170421138871461
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 68.20
Split: 09, Run: 02
None time:  0.835152385989204
None Run 26:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 65.30
Split: 09, Run: 03
None time:  0.8442808580584824
None Run 27:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 66.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7544724510516971
None Run 28:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 61.30
Split: 10, Run: 02
None time:  0.5733110189903527
None Run 29:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.70
Split: 10, Run: 03
None time:  0.9644297400955111
None Run 30:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.80
run time now: 2.3271119594573975
total time:  28.67910777591169
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.46 ± 2.17
  Final Train: 100.00 ± 0.00
   Final Test: 61.89 ± 2.72
best run test_acc: 62.6400032043457
[I 2023-06-12 00:10:26,143] Trial 88 finished with value: 62.46000289916992 and parameters: {'Fwd': 0.04965711630082629, 'K': 3, 'alpha': 1.0, 'dropout': 0.0, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 4.121152875471619, 'loop': 2, 'loss': 'MSE', 'lr': 0.005817928752681174, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.021419550186234555, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9500000000000001
lr:  0.0054575721015580345
weight_decay:  0.014603897885310566
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9279055930674076
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 66.20
Split: 01, Run: 02
None time:  1.2943991380743682
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 95.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.2617450449615717
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 88.33
   Final Test: 66.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7373943999409676
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 68.40
Split: 02, Run: 02
None time:  0.58650804287754
None Run 05:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.90
Split: 02, Run: 03
None time:  1.457979751052335
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9364693711977452
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 98.33
   Final Test: 67.20
Split: 03, Run: 02
None time:  1.6547023139428347
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 65.40
Split: 03, Run: 03
None time:  0.8286642329767346
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 64.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4909321870654821
None Run 10:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 65.20
Split: 04, Run: 02
None time:  1.1071739490143955
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 85.00
   Final Test: 65.70
Split: 04, Run: 03
None time:  0.9784413690213114
None Run 12:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 64.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.954432635102421
None Run 13:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.40
Split: 05, Run: 02
None time:  1.0439551291055977
None Run 14:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 71.80
Split: 05, Run: 03
None time:  1.600300378864631
None Run 15:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 95.00
   Final Test: 71.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.4979112260043621
None Run 16:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 60.80
Split: 06, Run: 02
None time:  0.9757292110007256
None Run 17:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 65.80
Split: 06, Run: 03
None time:  1.0340872679371387
None Run 18:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 98.33
   Final Test: 65.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7808005679398775
None Run 19:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 88.33
   Final Test: 61.30
Split: 07, Run: 02
None time:  1.2301335870288312
None Run 20:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 62.10
Split: 07, Run: 03
None time:  1.6617755119223148
None Run 21:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 90.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.142577582038939
None Run 22:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 98.33
   Final Test: 67.20
Split: 08, Run: 02
None time:  1.197151448810473
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.20
Split: 08, Run: 03
None time:  0.4667516581248492
None Run 24:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 56.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2030383148230612
None Run 25:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 71.70
Split: 09, Run: 02
None time:  1.728365764953196
None Run 26:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 88.33
   Final Test: 72.80
Split: 09, Run: 03
None time:  1.3743763458915055
None Run 27:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 71.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7652687651570886
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 02
None time:  2.1834793749731034
None Run 29:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 95.00
   Final Test: 55.90
Split: 10, Run: 03
None time:  0.7260410219896585
None Run 30:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.20
run time now: 3.711603879928589
total time:  36.855204025050625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.21 ± 3.51
  Final Train: 95.72 ± 4.26
   Final Test: 66.03 ± 4.12
best run test_acc: 67.73999786376953
[I 2023-06-12 00:11:03,461] Trial 89 finished with value: 67.2066650390625 and parameters: {'Fwd': 0.06322048912115992, 'K': 4, 'alpha': 0.9500000000000001, 'dropout': 0.1, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 4.291541724432688, 'loop': 2, 'loss': 'CE', 'lr': 0.0054575721015580345, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.014603897885310566, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004549008087346159
weight_decay:  0.037622319836653824
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.17891011596657336
None Run 01:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 53.00
Split: 01, Run: 02
None time:  0.1321824009064585
None Run 02:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 53.90
Split: 01, Run: 03
None time:  0.16223993408493698
None Run 03:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 50.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.3358151849824935
None Run 04:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 55.30
Split: 02, Run: 02
None time:  0.22140937903895974
None Run 05:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.70
Split: 02, Run: 03
None time:  0.18083338579162955
None Run 06:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 55.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.60% Test: 55.40%
Split: 03, Run: 01
None time:  0.6274159189779311
None Run 07:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 55.40
Split: 03, Run: 02
None time:  0.1707907561212778
None Run 08:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 41.20
Split: 03, Run: 03
None time:  0.24271300085820258
None Run 09:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 53.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 52.40% Test: 50.50%
Split: 04, Run: 01
None time:  0.5816810380201787
None Run 10:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 50.60
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.40% Test: 41.70%
Split: 04, Run: 02
None time:  0.6189129920676351
None Run 11:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 42.50
Split: 04, Run: 03
None time:  0.15410217107273638
None Run 12:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 43.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.2341621108353138
None Run 13:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.90
Split: 05, Run: 02
None time:  0.15005795611068606
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.90
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.00% Test: 65.30%
Split: 05, Run: 03
None time:  0.596699443878606
None Run 15:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.19203745410777628
None Run 16:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 55.50
Split: 06, Run: 02
None time:  0.2408443340100348
None Run 17:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 49.60
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.80% Test: 56.40%
Split: 06, Run: 03
None time:  0.5780317548196763
None Run 18:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 56.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.24913110211491585
None Run 19:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 56.60
Split: 07, Run: 02
None time:  0.30153943016193807
None Run 20:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 53.60
Split: 07, Run: 03
None time:  0.31571206683292985
None Run 21:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 57.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.26481833402067423
None Run 22:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 60.00
Split: 08, Run: 02
None time:  0.15441305097192526
None Run 23:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 59.40
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.20% Test: 63.50%
Split: 08, Run: 03
None time:  0.6327063881326467
None Run 24:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 63.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.19806175213307142
None Run 25:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 61.70
Split: 09, Run: 02
None time:  0.18933256878517568
None Run 26:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 67.40
Split: 09, Run: 03
None time:  0.23208417906425893
None Run 27:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 65.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.13718203292228281
None Run 28:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 53.60
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.00% Test: 56.60%
Split: 10, Run: 02
None time:  0.6528276749886572
None Run 29:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 56.80
Split: 10, Run: 03
None time:  0.22416463494300842
None Run 30:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 59.10
run time now: 1.0698719024658203
total time:  10.127350032096729
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.06 ± 5.89
  Final Train: 100.00 ± 0.00
   Final Test: 56.20 ± 6.65
best run test_acc: 59.349998474121094
[I 2023-06-12 00:11:14,058] Trial 90 finished with value: 57.060001373291016 and parameters: {'Fwd': 0.03778650878224931, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 10, 'lambda1': 0.9500000000000001, 'lambda2': 4.958354523962152, 'loop': 0, 'loss': 'CE', 'lr': 0.004549008087346159, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.037622319836653824, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.00606771030865133
weight_decay:  0.006128925754664586
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.279484269907698
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 91.67
   Final Test: 67.90
Split: 01, Run: 02
None time:  1.678127716993913
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 86.67
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.250052253017202
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 67.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1602492560632527
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.60
Split: 02, Run: 02
None time:  1.1737160901539028
None Run 05:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.60
Split: 02, Run: 03
None time:  0.7525437669828534
None Run 06:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0787545011844486
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 62.10
Split: 03, Run: 02
None time:  0.6931992780882865
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.80
Split: 03, Run: 03
None time:  0.8903243460226804
None Run 09:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0373167099896818
None Run 10:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.10
Split: 04, Run: 02
None time:  1.2537379742134362
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 64.90
Split: 04, Run: 03
None time:  1.842176616191864
None Run 12:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 85.00
   Final Test: 65.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9148920481093228
None Run 13:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 70.50
Split: 05, Run: 02
None time:  0.8886276839766651
None Run 14:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 69.70
Split: 05, Run: 03
None time:  2.1985972789116204
None Run 15:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9578387509100139
None Run 16:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 59.60
Split: 06, Run: 02
None time:  1.201058791950345
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 63.70
Split: 06, Run: 03
None time:  0.7183279569726437
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0556376930326223
None Run 19:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 63.80
Split: 07, Run: 02
None time:  1.2596816779114306
None Run 20:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 62.60
Split: 07, Run: 03
None time:  1.0507976680528373
None Run 21:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 63.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.22787877288647
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.20
Split: 08, Run: 02
None time:  1.3146564199123532
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 69.00
Split: 08, Run: 03
None time:  1.357416272861883
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 68.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.362153546186164
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 91.67
   Final Test: 71.20
Split: 09, Run: 02
None time:  1.9349582679569721
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 71.00
Split: 09, Run: 03
None time:  1.6008317610248923
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 91.67
   Final Test: 70.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7232807560358196
None Run 28:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.10
Split: 10, Run: 02
None time:  0.8080248110927641
None Run 29:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.30
Split: 10, Run: 03
None time:  0.7318230650853366
None Run 30:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 61.50
run time now: 2.300485610961914
total time:  37.47239324217662
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.85 ± 1.96
  Final Train: 95.61 ± 4.28
   Final Test: 65.88 ± 3.36
best run test_acc: 66.53999328613281
[I 2023-06-12 00:11:51,945] Trial 91 finished with value: 67.84666442871094 and parameters: {'Fwd': 0.027964022726812893, 'K': 4, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 0.8500000000000001, 'lambda2': 3.6039257708829724, 'loop': 2, 'loss': 'CE', 'lr': 0.00606771030865133, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006128925754664586, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.006987517851844346
weight_decay:  0.009747546466951496
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1811965180095285
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.50
Split: 01, Run: 02
None time:  1.2788207079283893
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 91.67
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.3916582341771573
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 68.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7840607778634876
None Run 04:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.00
Split: 02, Run: 02
None time:  0.9956439242232591
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 03
None time:  1.4444224887993187
None Run 06:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4658363771159202
None Run 07:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 64.90
Split: 03, Run: 02
None time:  0.768795802956447
None Run 08:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.10
Split: 03, Run: 03
None time:  1.4593660607933998
None Run 09:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 65.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6154451409820467
None Run 10:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 91.67
   Final Test: 65.50
Split: 04, Run: 02
None time:  1.330311454134062
None Run 11:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 64.90
Split: 04, Run: 03
None time:  1.3684214889071882
None Run 12:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 91.67
   Final Test: 66.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.815447554923594
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 70.20
Split: 05, Run: 02
None time:  1.2527364280540496
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.40
Split: 05, Run: 03
None time:  1.0356435659341514
None Run 15:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 70.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7351549849845469
None Run 16:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 63.70
Split: 06, Run: 02
None time:  1.1057680980302393
None Run 17:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 66.10
Split: 06, Run: 03
None time:  1.2508709419053048
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 64.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0599720291793346
None Run 19:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 64.50
Split: 07, Run: 02
None time:  1.2535243399906904
None Run 20:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 63.90
Split: 07, Run: 03
None time:  1.1067226191516966
None Run 21:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 63.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5041085020639002
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 68.70
Split: 08, Run: 02
None time:  1.9130067510996014
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 69.80
Split: 08, Run: 03
None time:  1.8325485580135137
None Run 24:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9411565670743585
None Run 25:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 70.50
Split: 09, Run: 02
None time:  3.369222642853856
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 70.80
Split: 09, Run: 03
None time:  3.496253811987117
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 71.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.5023715649731457
None Run 28:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.00
Split: 10, Run: 02
None time:  1.680250481935218
None Run 29:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.70
Split: 10, Run: 03
None time:  1.514656359795481
None Run 30:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 61.70
run time now: 4.739807844161987
total time:  45.458847645903006
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.44 ± 1.95
  Final Train: 96.83 ± 2.81
   Final Test: 66.65 ± 2.95
best run test_acc: 67.55000305175781
[I 2023-06-12 00:12:37,855] Trial 92 finished with value: 68.44001007080078 and parameters: {'Fwd': 0.05031611559264515, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 3.9571464520691046, 'loop': 2, 'loss': 'CE', 'lr': 0.006987517851844346, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.009747546466951496, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.00661915924535173
weight_decay:  0.009469347101664801
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.809507828904316
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 91.67
   Final Test: 67.10
Split: 01, Run: 02
None time:  3.515790848992765
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  2.8024118500761688
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 66.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.084673715988174
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.30
Split: 02, Run: 02
None time:  3.140203668968752
None Run 05:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 98.33
   Final Test: 67.10
Split: 02, Run: 03
None time:  2.01883836905472
None Run 06:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2265930969733745
None Run 07:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.90
Split: 03, Run: 02
None time:  1.7821220539044589
None Run 08:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.00
Split: 03, Run: 03
None time:  1.290187143953517
None Run 09:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4471420149784535
None Run 10:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 64.00
Split: 04, Run: 02
None time:  2.229891262948513
None Run 11:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 66.40
Split: 04, Run: 03
None time:  2.3422615570016205
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7371585320215672
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 70.10
Split: 05, Run: 02
None time:  1.7407963771838695
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 05, Run: 03
None time:  1.9676473787985742
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 71.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.616342412075028
None Run 16:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 93.33
   Final Test: 68.20
Split: 06, Run: 02
None time:  2.5044809749815613
None Run 17:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 67.40
Split: 06, Run: 03
None time:  2.233012259937823
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 65.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9196252091787755
None Run 19:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 64.50
Split: 07, Run: 02
None time:  2.223208101000637
None Run 20:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 64.60
Split: 07, Run: 03
None time:  2.0883493768051267
None Run 21:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 63.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.5859554950147867
None Run 22:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 68.80
Split: 08, Run: 02
None time:  2.4739465909078717
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 68.20
Split: 08, Run: 03
None time:  2.771904320921749
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.1135963129345328
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 71.40
Split: 09, Run: 02
None time:  2.68737431592308
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 71.60
Split: 09, Run: 03
None time:  2.4208958439994603
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 71.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  4.063421479891986
None Run 28:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 63.00
Split: 10, Run: 02
None time:  1.4882122541312128
None Run 29:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.30
Split: 10, Run: 03
None time:  3.710648851003498
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 65.10
run time now: 9.312811136245728
total time:  73.52646920387633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.34 ± 2.14
  Final Train: 96.78 ± 3.03
   Final Test: 66.68 ± 2.88
best run test_acc: 67.61000061035156
[I 2023-06-12 00:13:51,933] Trial 93 finished with value: 68.34000396728516 and parameters: {'Fwd': 0.04495970315734338, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 4.047453806047341, 'loop': 2, 'loss': 'CE', 'lr': 0.00661915924535173, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.009469347101664801, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.006959497742564334
weight_decay:  0.013441000001031905
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.448288135929033
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.10
Split: 01, Run: 02
None time:  3.416335745016113
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 68.20
Split: 01, Run: 03
None time:  3.2846934809349477
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 95.00
   Final Test: 69.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1586103590670973
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.90
Split: 02, Run: 02
None time:  3.2564647081308067
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.40
Split: 02, Run: 03
None time:  3.3658084119670093
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.094654069049284
None Run 07:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 61.40
Split: 03, Run: 02
None time:  1.5004782490432262
None Run 08:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.90
Split: 03, Run: 03
None time:  2.0091317428741604
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.9432014650665224
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 63.90
Split: 04, Run: 02
None time:  2.8543358671013266
None Run 11:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 63.40
Split: 04, Run: 03
None time:  2.956073827110231
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 65.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.2075111700687557
None Run 13:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.80
Split: 05, Run: 02
None time:  2.6568040819838643
None Run 14:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 71.20
Split: 05, Run: 03
None time:  3.296406925888732
None Run 15:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 71.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.561052491888404
None Run 16:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 63.50
Split: 06, Run: 02
None time:  3.1848527451511472
None Run 17:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 67.20
Split: 06, Run: 03
None time:  1.9811573731712997
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 65.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.512238441966474
None Run 19:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 63.60
Split: 07, Run: 02
None time:  2.2075115609914064
None Run 20:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 63.70
Split: 07, Run: 03
None time:  2.1709671730641276
None Run 21:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 98.33
   Final Test: 63.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.9310582589823753
None Run 22:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.30
Split: 08, Run: 02
None time:  2.869885839987546
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 69.80
Split: 08, Run: 03
None time:  2.60709748393856
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 69.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.829508711118251
None Run 25:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 71.20
Split: 09, Run: 02
None time:  2.771668351953849
None Run 26:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 71.80
Split: 09, Run: 03
None time:  2.3213966358453035
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 70.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4254243280738592
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 62.40
Split: 10, Run: 02
None time:  1.6098239729180932
None Run 29:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.30
Split: 10, Run: 03
None time:  1.3803946229163557
None Run 30:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.00
run time now: 4.461825370788574
total time:  76.98614729009569
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.49 ± 2.00
  Final Train: 97.39 ± 2.34
   Final Test: 66.60 ± 3.30
best run test_acc: 67.43000793457031
[I 2023-06-12 00:15:09,396] Trial 94 finished with value: 68.4866714477539 and parameters: {'Fwd': 0.04795852192608045, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 4.044211976394198, 'loop': 2, 'loss': 'CE', 'lr': 0.006959497742564334, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013441000001031905, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.007039463912261659
weight_decay:  0.013796261124768774
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.409409703919664
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 91.67
   Final Test: 67.70
Split: 01, Run: 02
None time:  3.263158846879378
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 83.33
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.292170853819698
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 91.67
   Final Test: 68.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9804168979171664
None Run 04:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
Split: 02, Run: 02
None time:  2.2682704371400177
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.40
Split: 02, Run: 03
None time:  2.2197376240510494
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.5864749730098993
None Run 07:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 63.10
Split: 03, Run: 02
None time:  2.4007899588905275
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 66.10
Split: 03, Run: 03
None time:  2.9425331640522927
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 95.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4778569869231433
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 64.60
Split: 04, Run: 02
None time:  2.4272817820310593
None Run 11:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 88.33
   Final Test: 65.70
Split: 04, Run: 03
None time:  2.7398054299410433
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 81.67
   Final Test: 66.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.256003072950989
None Run 13:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 70.30
Split: 05, Run: 02
None time:  2.1289405929856002
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 96.67
   Final Test: 70.80
Split: 05, Run: 03
None time:  2.477693128865212
None Run 15:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 71.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.7792153069749475
None Run 16:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 91.67
   Final Test: 67.80
Split: 06, Run: 02
None time:  1.4902423149906099
None Run 17:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 60.40
Split: 06, Run: 03
None time:  1.063794266898185
None Run 18:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.543150819139555
None Run 19:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 88.33
   Final Test: 64.70
Split: 07, Run: 02
None time:  2.256251929095015
None Run 20:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 96.67
   Final Test: 65.30
Split: 07, Run: 03
None time:  2.182311649201438
None Run 21:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 64.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3500698870047927
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.60
Split: 08, Run: 02
None time:  2.8026829659938812
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 69.40
Split: 08, Run: 03
None time:  2.826024510897696
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 68.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.5912176070269197
None Run 25:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 91.67
   Final Test: 71.60
Split: 09, Run: 02
None time:  2.5053299029823393
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 70.60
Split: 09, Run: 03
None time:  2.8153238731902093
None Run 27:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 71.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.439423535950482
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.50
Split: 10, Run: 02
None time:  1.9404917319770902
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 65.60
Split: 10, Run: 03
None time:  1.3789539518766105
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.50
run time now: 4.803203344345093
total time:  71.15291033801623
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.43 ± 2.68
  Final Train: 95.00 ± 4.89
   Final Test: 66.98 ± 3.17
best run test_acc: 68.31999969482422
[I 2023-06-12 00:16:21,084] Trial 95 finished with value: 68.43333435058594 and parameters: {'Fwd': 0.0444182931017364, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 4.019242581173219, 'loop': 2, 'loss': 'CE', 'lr': 0.007039463912261659, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013796261124768774, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.006833900296591076
weight_decay:  0.014326987131512939
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5255902549251914
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  2.083700221031904
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 93.33
   Final Test: 67.10
Split: 01, Run: 03
None time:  2.414257335010916
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 91.67
   Final Test: 67.40
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.651485570007935
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.50
Split: 02, Run: 02
None time:  2.2800212181173265
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.70
Split: 02, Run: 03
None time:  3.3721518740057945
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.155811595963314
None Run 07:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 66.80
Split: 03, Run: 02
None time:  2.5399976551998407
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 66.60
Split: 03, Run: 03
None time:  1.4616852048784494
None Run 09:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 61.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.859255730872974
None Run 10:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 93.33
   Final Test: 62.30
Split: 04, Run: 02
None time:  2.998022167943418
None Run 11:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 85.00
   Final Test: 65.40
Split: 04, Run: 03
None time:  2.6582904851529747
None Run 12:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 65.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.5583154768683016
None Run 13:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 93.33
   Final Test: 70.80
Split: 05, Run: 02
None time:  2.3815081450156868
None Run 14:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.00
   Final Test: 71.10
Split: 05, Run: 03
None time:  2.1162459710612893
None Run 15:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 71.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.1756096680182964
None Run 16:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 91.67
   Final Test: 68.30
Split: 06, Run: 02
None time:  3.786463121185079
None Run 17:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 86.67
   Final Test: 64.10
Split: 06, Run: 03
None time:  1.7670285070780665
None Run 18:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 61.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.503984407056123
None Run 19:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 88.33
   Final Test: 65.50
Split: 07, Run: 02
None time:  2.4849031248595566
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 88.33
   Final Test: 65.00
Split: 07, Run: 03
None time:  2.500719961943105
None Run 21:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 65.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.5924671199172735
None Run 22:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 68.90
Split: 08, Run: 02
None time:  2.6192599839996547
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 68.50
Split: 08, Run: 03
None time:  2.660553471883759
None Run 24:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 67.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.113908554892987
None Run 25:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 88.33
   Final Test: 71.70
Split: 09, Run: 02
None time:  2.4968426700215787
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.20
Split: 09, Run: 03
None time:  3.157072447007522
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0143, Train: 88.33%, Valid: 70.20% Test: 65.70%
Split: 10, Run: 01
None time:  5.565874832915142
None Run 28:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 88.33
   Final Test: 65.60
Split: 10, Run: 02
None time:  2.4571177910547704
None Run 29:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 60.90
Split: 10, Run: 03
None time:  3.536320127081126
None Run 30:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 64.60
run time now: 11.647686004638672
total time:  83.91185411601327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.33 ± 2.71
  Final Train: 94.06 ± 4.26
   Final Test: 66.89 ± 3.00
best run test_acc: 68.05000305175781
[I 2023-06-12 00:17:45,438] Trial 96 finished with value: 68.32666778564453 and parameters: {'Fwd': 0.04662932516854631, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 4.065062657472272, 'loop': 2, 'loss': 'CE', 'lr': 0.006833900296591076, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.014326987131512939, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.0073416279289434585
weight_decay:  0.020583564014515054
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2953563530463725
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 90.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  2.537647687131539
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 91.67
   Final Test: 66.40
Split: 01, Run: 03
None time:  2.153918899130076
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 91.67
   Final Test: 64.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.34364642505534
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.60
Split: 02, Run: 02
None time:  2.347055725986138
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.60
Split: 02, Run: 03
None time:  2.2735625391360372
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.425139462808147
None Run 07:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 98.33
   Final Test: 62.30
Split: 03, Run: 02
None time:  1.6399407188873738
None Run 08:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.60
Split: 03, Run: 03
None time:  2.708134693093598
None Run 09:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.5656945661175996
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 83.33
   Final Test: 64.90
Split: 04, Run: 02
None time:  2.088522885926068
None Run 11:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 95.00
   Final Test: 63.20
Split: 04, Run: 03
None time:  1.9615416899323463
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 64.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.936673792079091
None Run 13:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 70.30
Split: 05, Run: 02
None time:  2.3563749759923667
None Run 14:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.00
   Final Test: 70.70
Split: 05, Run: 03
None time:  2.9376889569684863
None Run 15:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 70.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.098460001172498
None Run 16:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 66.50
Split: 06, Run: 02
None time:  2.0882194149307907
None Run 17:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 88.33
   Final Test: 67.70
Split: 06, Run: 03
None time:  2.689903600839898
None Run 18:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 86.67
   Final Test: 69.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.532970556989312
None Run 19:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 61.00
Split: 07, Run: 02
None time:  2.1326319228392094
None Run 20:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 64.10
Split: 07, Run: 03
None time:  2.3493294820655137
None Run 21:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 86.67
   Final Test: 65.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.7703279638662934
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 68.30
Split: 08, Run: 02
None time:  2.314003329956904
None Run 23:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 68.20
Split: 08, Run: 03
None time:  2.706079844851047
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.4124741689302027
None Run 25:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 69.30
Split: 09, Run: 02
None time:  2.365876441122964
None Run 26:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 70.90
Split: 09, Run: 03
None time:  2.048535863868892
None Run 27:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 71.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.3796324289869517
None Run 28:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 65.00
Split: 10, Run: 02
None time:  4.0143158859573305
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 91.67
   Final Test: 64.00
Split: 10, Run: 03
None time:  3.2721113639418036
None Run 30:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 93.33
   Final Test: 61.50
run time now: 9.70926547050476
total time:  73.90821494301781
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.03 ± 2.81
  Final Train: 94.50 ± 4.38
   Final Test: 66.53 ± 2.91
best run test_acc: 67.47999572753906
[I 2023-06-12 00:18:59,811] Trial 97 finished with value: 68.03334045410156 and parameters: {'Fwd': 0.024894151799682494, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 4.674640917321552, 'loop': 2, 'loss': 'CE', 'lr': 0.0073416279289434585, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.020583564014515054, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006715966635443878
weight_decay:  0.013793406894847874
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6357413011137396
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 91.67
   Final Test: 67.90
Split: 01, Run: 02
None time:  2.667450664099306
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 88.33
   Final Test: 65.70
Split: 01, Run: 03
None time:  3.013472508173436
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 93.33
   Final Test: 66.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7286143670789897
None Run 04:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.90
Split: 02, Run: 02
None time:  3.3160655200481415
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 67.80
Split: 02, Run: 03
None time:  1.8081932249478996
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.239304021000862
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.00
Split: 03, Run: 02
None time:  2.708857804071158
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 63.40
Split: 03, Run: 03
None time:  1.4036236531101167
None Run 09:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4459244499448687
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.10
Split: 04, Run: 02
None time:  3.049333181930706
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 88.33
   Final Test: 65.20
Split: 04, Run: 03
None time:  2.288196891080588
None Run 12:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.073095269035548
None Run 13:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 70.10
Split: 05, Run: 02
None time:  3.4078838261775672
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.20
Split: 05, Run: 03
None time:  3.1012286390177906
None Run 15:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0224113010335714
None Run 16:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 60.20
Split: 06, Run: 02
None time:  2.9556934491265565
None Run 17:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 90.00
   Final Test: 67.80
Split: 06, Run: 03
None time:  1.53120459895581
None Run 18:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 98.33
   Final Test: 53.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.6950909621082246
None Run 19:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 88.33
   Final Test: 65.60
Split: 07, Run: 02
None time:  2.764528915984556
None Run 20:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 88.33
   Final Test: 66.60
Split: 07, Run: 03
None time:  2.6842115810140967
None Run 21:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 93.33
   Final Test: 65.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.1930116021540016
None Run 22:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 70.20
Split: 08, Run: 02
None time:  2.634290616028011
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.30
Split: 08, Run: 03
None time:  2.925258659059182
None Run 24:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 69.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4532071149442345
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 68.80
Split: 09, Run: 02
None time:  2.6875455488916487
None Run 26:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 72.60
Split: 09, Run: 03
None time:  4.288984038867056
None Run 27:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 85.00
   Final Test: 70.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.499100579880178
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 65.00
Split: 10, Run: 02
None time:  3.457695489982143
None Run 29:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 64.20
Split: 10, Run: 03, Epoch: 100, Loss: 0.0128, Train: 90.00%, Valid: 73.40% Test: 67.90%
Split: 10, Run: 03
None time:  5.407057745847851
None Run 30:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 90.00
   Final Test: 67.80
run time now: 11.40643858909607
total time:  81.20694780582562
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.29 ± 3.81
  Final Train: 94.89 ± 4.42
   Final Test: 66.76 ± 3.69
best run test_acc: 68.55000305175781
[I 2023-06-12 00:20:21,489] Trial 98 finished with value: 68.28666687011719 and parameters: {'Fwd': 0.04133423887689661, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 4.418981457185865, 'loop': 2, 'loss': 'CE', 'lr': 0.006715966635443878, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013793406894847874, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.006941621066035249
weight_decay:  0.010020539172764025
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.785038593923673
None Run 01:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 56.00
Split: 01, Run: 02
None time:  0.7869860550854355
None Run 02:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 60.70
Split: 01, Run: 03
None time:  0.8337616538628936
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 59.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7986364550888538
None Run 04:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 56.20
Split: 02, Run: 02
None time:  0.817513523157686
None Run 05:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 52.50
Split: 02, Run: 03
None time:  0.9336988900322467
None Run 06:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9369137489702553
None Run 07:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.00
Split: 03, Run: 02
None time:  0.8224057289771736
None Run 08:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 55.80
Split: 03, Run: 03
None time:  0.8905073758214712
None Run 09:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8049024548381567
None Run 10:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 44.80
Split: 04, Run: 02
None time:  0.8155175819993019
None Run 11:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 42.80
Split: 04, Run: 03
None time:  0.8159971570130438
None Run 12:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 44.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8190893901046365
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.90
Split: 05, Run: 02
None time:  0.8041867490392178
None Run 14:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.70
Split: 05, Run: 03
None time:  0.8191792911384255
None Run 15:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8217231079470366
None Run 16:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 49.40
Split: 06, Run: 02
None time:  0.8255534621421248
None Run 17:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 57.30
Split: 06, Run: 03
None time:  0.7877390221692622
None Run 18:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8180632018484175
None Run 19:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.30
Split: 07, Run: 02
None time:  0.8451172441709787
None Run 20:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 53.20
Split: 07, Run: 03
None time:  0.8457848199177533
None Run 21:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 41.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8111008140258491
None Run 22:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 64.20
Split: 08, Run: 02
None time:  0.8207387290894985
None Run 23:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 57.00
Split: 08, Run: 03
None time:  0.8346912239212543
None Run 24:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 57.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8270647029858083
None Run 25:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 64.40
Split: 09, Run: 02
None time:  0.8160440679639578
None Run 26:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 60.40
Split: 09, Run: 03
None time:  0.8232424559537321
None Run 27:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 60.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7889815978705883
None Run 28:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.30
Split: 10, Run: 02
None time:  0.7637633928097785
None Run 29:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.60
Split: 10, Run: 03
None time:  0.9146068000700325
None Run 30:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.10
run time now: 2.5126309394836426
total time:  26.045812683878466
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.02 ± 5.86
  Final Train: 100.00 ± 0.00
   Final Test: 57.15 ± 6.58
best run test_acc: 60.43000411987305
[I 2023-06-12 00:20:47,988] Trial 99 finished with value: 57.019996643066406 and parameters: {'Fwd': 0.046479698974602184, 'K': 2, 'alpha': 0.1, 'dropout': 0.2, 'gnnepoch': 10, 'lambda1': 1.0, 'lambda2': 4.416701346342199, 'loop': 2, 'loss': 'CE', 'lr': 0.006941621066035249, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.010020539172764025, 'weightedloss': False}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.006724805575707471
weight_decay:  0.014369245625962675
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.530361422104761
None Run 01:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 37.40
Split: 01, Run: 02
None time:  2.02249104809016
None Run 02:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 78.33
   Final Test: 56.90
Split: 01, Run: 03
None time:  0.6167143930215389
None Run 03:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 57.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5071024759672582
None Run 04:
Highest Train: 100.00
Highest Valid: 27.00
  Final Train: 100.00
   Final Test: 24.80
Split: 02, Run: 02
None time:  0.5226477601099759
None Run 05:
Highest Train: 100.00
Highest Valid: 20.60
  Final Train: 100.00
   Final Test: 19.80
Split: 02, Run: 03
None time:  1.7358649040106684
None Run 06:
Highest Train: 100.00
Highest Valid: 36.00
  Final Train: 80.00
   Final Test: 31.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.46919398196041584
None Run 07:
Highest Train: 100.00
Highest Valid: 19.60
  Final Train: 100.00
   Final Test: 17.90
Split: 03, Run: 02
None time:  0.9308525358792394
None Run 08:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 98.33
   Final Test: 38.90
Split: 03, Run: 03
None time:  0.5554313478060067
None Run 09:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 39.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.49445873592048883
None Run 10:
Highest Train: 100.00
Highest Valid: 23.80
  Final Train: 100.00
   Final Test: 24.30
Split: 04, Run: 02
None time:  2.6117109421174973
None Run 11:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 78.33
   Final Test: 45.20
Split: 04, Run: 03
None time:  0.8150731059722602
None Run 12:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 44.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.536865808069706
None Run 13:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 38.10
Split: 05, Run: 02
None time:  1.7777240229770541
None Run 14:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 93.33
   Final Test: 57.60
Split: 05, Run: 03
None time:  0.7511948810424656
None Run 15:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5093406201340258
None Run 16:
Highest Train: 100.00
Highest Valid: 25.00
  Final Train: 100.00
   Final Test: 22.20
Split: 06, Run: 02
None time:  2.3561374959535897
None Run 17:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 75.00
   Final Test: 42.40
Split: 06, Run: 03
None time:  0.5496333609335124
None Run 18:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 45.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5113164111971855
None Run 19:
Highest Train: 100.00
Highest Valid: 23.60
  Final Train: 100.00
   Final Test: 20.70
Split: 07, Run: 02
None time:  2.6968142308760434
None Run 20:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 76.67
   Final Test: 38.60
Split: 07, Run: 03
None time:  2.6685238510835916
None Run 21:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 85.00
   Final Test: 62.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5774388299323618
None Run 22:
Highest Train: 100.00
Highest Valid: 25.60
  Final Train: 100.00
   Final Test: 29.60
Split: 08, Run: 02
None time:  1.7359589040279388
None Run 23:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 85.00
   Final Test: 65.60
Split: 08, Run: 03
None time:  0.8827002639882267
None Run 24:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 64.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5055916628334671
None Run 25:
Highest Train: 100.00
Highest Valid: 18.60
  Final Train: 100.00
   Final Test: 20.80
Split: 09, Run: 02
None time:  1.207632560050115
None Run 26:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 90.00
   Final Test: 34.80
Split: 09, Run: 03, Epoch: 100, Loss: 0.0018, Train: 85.00%, Valid: 55.80% Test: 58.80%
Split: 09, Run: 03
None time:  2.874509444925934
None Run 27:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 85.00
   Final Test: 58.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.572554673999548
None Run 28:
Highest Train: 100.00
Highest Valid: 26.60
  Final Train: 100.00
   Final Test: 25.90
Split: 10, Run: 02
None time:  1.1431106640957296
None Run 29:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 91.67
   Final Test: 37.40
Split: 10, Run: 03
None time:  2.2160620521754026
None Run 30:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 81.67
   Final Test: 52.40
run time now: 3.983729839324951
total time:  37.093877425882965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.14 ± 14.64
  Final Train: 93.17 ± 8.99
   Final Test: 40.41 ± 14.85
best run test_acc: 51.5099983215332
[I 2023-06-12 00:21:25,614] Trial 100 finished with value: 41.1400032043457 and parameters: {'Fwd': 0.035683459618411725, 'K': 2, 'alpha': 0.4, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 5.159515804700991, 'loop': 2, 'loss': 'CE', 'lr': 0.006724805575707471, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.014369245625962675, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.007447552571339599
weight_decay:  0.03388022998306605
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.359085774049163
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 91.67
   Final Test: 67.90
Split: 01, Run: 02
None time:  3.9197359459940344
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 88.33
   Final Test: 68.10
Split: 01, Run: 03
None time:  3.962631355971098
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 88.33
   Final Test: 68.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.159690488129854
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.20
Split: 02, Run: 02
None time:  2.077095437096432
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 03
None time:  1.7643756601028144
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4216941560152918
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.80
Split: 03, Run: 02
None time:  1.5430411780253053
None Run 08:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.20
Split: 03, Run: 03
None time:  2.624728713883087
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 64.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.3511977738235146
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 65.30
Split: 04, Run: 02
None time:  2.3979472061619163
None Run 11:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 66.20
Split: 04, Run: 03
None time:  2.6292530219070613
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 88.33
   Final Test: 64.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.9954753129277378
None Run 13:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 71.00
Split: 05, Run: 02
None time:  2.53872774890624
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.40
Split: 05, Run: 03
None time:  2.766041675116867
None Run 15:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 71.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4946341179311275
None Run 16:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 65.60
Split: 06, Run: 02
None time:  2.1980539141222835
None Run 17:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 65.40
Split: 06, Run: 03
None time:  2.7792411711998284
None Run 18:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 88.33
   Final Test: 69.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.5106607219204307
None Run 19:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 65.70
Split: 07, Run: 02
None time:  2.6753556560724974
None Run 20:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 66.80
Split: 07, Run: 03
None time:  2.2579803590197116
None Run 21:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 65.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.7472873118240386
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 69.80
Split: 08, Run: 02
None time:  2.3310781500767916
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 69.00
Split: 08, Run: 03
None time:  2.4893338510300964
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.9252322639804333
None Run 25:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 71.40
Split: 09, Run: 02
None time:  3.1409296800848097
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 72.00
Split: 09, Run: 03
None time:  2.447573808953166
None Run 27:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 70.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.52898637810722
None Run 28:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 65.90
Split: 10, Run: 02
None time:  3.2349639921449125
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 91.67
   Final Test: 64.80
Split: 10, Run: 03
None time:  2.8229218490887433
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 66.30
run time now: 8.63081431388855
total time:  77.24732909421436
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.01 ± 2.05
  Final Train: 95.50 ± 3.79
   Final Test: 67.46 ± 2.57
best run test_acc: 68.29000091552734
[I 2023-06-12 00:22:43,305] Trial 101 finished with value: 69.0133285522461 and parameters: {'Fwd': 0.041870253307489905, 'K': 3, 'alpha': 0.25, 'dropout': 0.30000000000000004, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.979228556066505, 'loop': 2, 'loss': 'CE', 'lr': 0.007447552571339599, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03388022998306605, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.007750905532603956
weight_decay:  0.05291103600377875
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1889414901379496
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 90.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  4.029207613086328
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 90.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.498026706976816
None Run 03:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 98.33
   Final Test: 62.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.277558865956962
None Run 04:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
Split: 02, Run: 02
None time:  2.200087951030582
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.80
Split: 02, Run: 03
None time:  2.432929008966312
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4411579160951078
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.10
Split: 03, Run: 02
None time:  4.162779069039971
None Run 08:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 59.00
Split: 03, Run: 03
None time:  4.109906461788341
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 65.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4294944561552256
None Run 10:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.90
Split: 04, Run: 02
None time:  3.3752021461259574
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 64.50
Split: 04, Run: 03
None time:  2.9898931151255965
None Run 12:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 65.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.8531507321167737
None Run 13:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.00
   Final Test: 71.90
Split: 05, Run: 02
None time:  2.5381962810643017
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.10
Split: 05, Run: 03
None time:  2.1695562549866736
None Run 15:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 98.33
   Final Test: 70.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.3455270568374544
None Run 16:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 88.33
   Final Test: 68.50
Split: 06, Run: 02
None time:  0.9189157718792558
None Run 17:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 61.70
Split: 06, Run: 03
None time:  0.912463806103915
None Run 18:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.708483776077628
None Run 19:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 86.67
   Final Test: 65.50
Split: 07, Run: 02
None time:  3.369193769991398
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 98.33
   Final Test: 64.90
Split: 07, Run: 03
None time:  4.326158603886142
None Run 21:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 91.67
   Final Test: 62.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.5222430019639432
None Run 22:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.90
Split: 08, Run: 02
None time:  2.6272662018891424
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.40
Split: 08, Run: 03
None time:  2.6094861021265388
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 69.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2208560691215098
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.00
Split: 09, Run: 02
None time:  2.9509524640161544
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 71.40
Split: 09, Run: 03
None time:  1.59354977007024
None Run 27:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 70.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.438398231053725
None Run 28:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.20
Split: 10, Run: 02
None time:  1.535609960788861
None Run 29:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.00
Split: 10, Run: 03
None time:  1.3344147440511733
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.70
run time now: 5.349969387054443
total time:  79.42908425815403
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.97 ± 3.16
  Final Train: 96.61 ± 4.25
   Final Test: 66.38 ± 3.57
best run test_acc: 68.2800064086914
[I 2023-06-12 00:24:03,198] Trial 102 finished with value: 67.97334289550781 and parameters: {'Fwd': 0.04310321242386439, 'K': 1, 'alpha': 0.2, 'dropout': 0.30000000000000004, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.8110825346303536, 'loop': 2, 'loss': 'CE', 'lr': 0.007750905532603956, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05291103600377875, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.006607709671951715
weight_decay:  0.03447118820570333
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.340944058028981
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 91.67
   Final Test: 66.10
Split: 01, Run: 02
None time:  2.6238625571131706
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 91.67
   Final Test: 67.90
Split: 01, Run: 03
None time:  1.9932652688585222
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 67.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.233090410940349
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.00
Split: 02, Run: 02
None time:  2.9040602759923786
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.90
Split: 02, Run: 03
None time:  1.402173771057278
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.20
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.668322741985321
None Run 07:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 66.90
Split: 03, Run: 02
None time:  1.4242866728454828
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.90
Split: 03, Run: 03
None time:  1.5882864559534937
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1283583231270313
None Run 10:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 65.80
Split: 04, Run: 02
None time:  2.18405096209608
None Run 11:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.30
Split: 04, Run: 03
None time:  2.7619592738337815
None Run 12:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 90.00
   Final Test: 65.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3904465239029378
None Run 13:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 70.70
Split: 05, Run: 02
None time:  2.813335244078189
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 70.20
Split: 05, Run: 03
None time:  2.956497938139364
None Run 15:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4227614619303495
None Run 16:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.50
Split: 06, Run: 02
None time:  2.825496207922697
None Run 17:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 90.00
   Final Test: 68.50
Split: 06, Run: 03
None time:  3.562784736044705
None Run 18:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 91.67
   Final Test: 66.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  4.042480607982725
None Run 19:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 88.33
   Final Test: 63.50
Split: 07, Run: 02
None time:  2.485571085009724
None Run 20:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 93.33
   Final Test: 66.60
Split: 07, Run: 03
None time:  2.6157119581475854
None Run 21:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 90.00
   Final Test: 66.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.0146228480152786
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.40
Split: 08, Run: 02
None time:  3.018169129965827
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 69.60
Split: 08, Run: 03
None time:  2.009534182958305
None Run 24:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.854776095133275
None Run 25:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 72.10
Split: 09, Run: 02
None time:  2.702211015159264
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 91.67
   Final Test: 72.60
Split: 09, Run: 03
None time:  1.9679781701415777
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 91.67
   Final Test: 71.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.346087875077501
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 02
None time:  1.5240761400200427
None Run 29:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 03
None time:  1.3927923198789358
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 62.00
run time now: 4.31170129776001
total time:  70.43141745100729
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.83 ± 2.36
  Final Train: 96.00 ± 4.10
   Final Test: 67.13 ± 2.84
best run test_acc: 68.09999084472656
[I 2023-06-12 00:25:14,176] Trial 103 finished with value: 68.83333587646484 and parameters: {'Fwd': 0.0674520779733861, 'K': 3, 'alpha': 0.2, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 4.233082513431176, 'loop': 2, 'loss': 'CE', 'lr': 0.006607709671951715, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03447118820570333, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.009102728933004334
weight_decay:  0.031227224588342456
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6586980929132551
None Run 01:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 40.90
Split: 01, Run: 02
None time:  0.7414301738608629
None Run 02:
Highest Train: 100.00
Highest Valid: 29.00
  Final Train: 100.00
   Final Test: 32.10
Split: 01, Run: 03
None time:  0.7236467148177326
None Run 03:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 34.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5912186910863966
None Run 04:
Highest Train: 100.00
Highest Valid: 29.80
  Final Train: 100.00
   Final Test: 28.00
Split: 02, Run: 02
None time:  0.6139441698323935
None Run 05:
Highest Train: 100.00
Highest Valid: 29.80
  Final Train: 100.00
   Final Test: 28.00
Split: 02, Run: 03
None time:  0.659963448997587
None Run 06:
Highest Train: 100.00
Highest Valid: 29.80
  Final Train: 100.00
   Final Test: 28.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.591888293158263
None Run 07:
Highest Train: 100.00
Highest Valid: 28.00
  Final Train: 100.00
   Final Test: 28.30
Split: 03, Run: 02
None time:  0.5435362469870597
None Run 08:
Highest Train: 100.00
Highest Valid: 28.00
  Final Train: 100.00
   Final Test: 28.30
Split: 03, Run: 03
None time:  0.6556504680775106
None Run 09:
Highest Train: 100.00
Highest Valid: 33.40
  Final Train: 100.00
   Final Test: 29.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6063089480157942
None Run 10:
Highest Train: 100.00
Highest Valid: 29.80
  Final Train: 100.00
   Final Test: 29.00
Split: 04, Run: 02
None time:  0.592877603136003
None Run 11:
Highest Train: 100.00
Highest Valid: 29.80
  Final Train: 100.00
   Final Test: 29.00
Split: 04, Run: 03
None time:  0.746977946953848
None Run 12:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 41.90
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7701960420235991
None Run 13:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 32.40
Split: 05, Run: 02
None time:  0.5987755819223821
None Run 14:
Highest Train: 100.00
Highest Valid: 27.00
  Final Train: 100.00
   Final Test: 30.20
Split: 05, Run: 03
None time:  0.6884862019214779
None Run 15:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 31.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7417087689973414
None Run 16:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 32.40
Split: 06, Run: 02
None time:  0.6251972680911422
None Run 17:
Highest Train: 100.00
Highest Valid: 30.60
  Final Train: 100.00
   Final Test: 27.80
Split: 06, Run: 03
None time:  0.6108787760604173
None Run 18:
Highest Train: 100.00
Highest Valid: 30.60
  Final Train: 100.00
   Final Test: 27.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6053577861748636
None Run 19:
Highest Train: 100.00
Highest Valid: 21.80
  Final Train: 100.00
   Final Test: 19.30
Split: 07, Run: 02
None time:  0.7425314460415393
None Run 20:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 40.90
Split: 07, Run: 03
None time:  0.8847850009333342
None Run 21:
Highest Train: 100.00
Highest Valid: 28.40
  Final Train: 100.00
   Final Test: 29.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.238320894073695
None Run 22:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 60.00
   Final Test: 45.20
Split: 08, Run: 02
None time:  1.4469099710695446
None Run 23:
Highest Train: 100.00
Highest Valid: 34.80
  Final Train: 50.00
   Final Test: 34.40
Split: 08, Run: 03
None time:  0.5530458448920399
None Run 24:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.721652400912717
None Run 25:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.80
Split: 09, Run: 02
None time:  0.6551875779405236
None Run 26:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 41.00
Split: 09, Run: 03
None time:  0.6603724888991565
None Run 27:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 41.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.66947713191621
None Run 28:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 45.80
Split: 10, Run: 02
None time:  0.6813864109572023
None Run 29:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 39.10
Split: 10, Run: 03
None time:  0.6804493418894708
None Run 30:
Highest Train: 100.00
Highest Valid: 28.20
  Final Train: 100.00
   Final Test: 28.70
run time now: 2.07376766204834
total time:  23.438127746107057
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 34.02 ± 6.34
  Final Train: 97.00 ± 11.49
   Final Test: 33.66 ± 6.78
best run test_acc: 37.929996490478516
[I 2023-06-12 00:25:38,122] Trial 104 finished with value: 34.02000045776367 and parameters: {'Fwd': 0.035097767408865124, 'K': 3, 'alpha': 0.2, 'dropout': 0.2, 'gnnepoch': 0, 'lambda1': 1.0, 'lambda2': 4.155619355737816, 'loop': 2, 'loss': 'CE', 'lr': 0.009102728933004334, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.031227224588342456, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.007467016612147513
weight_decay:  0.04408506107101201
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7986314939334989
None Run 01:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 02
None time:  0.8156395070254803
None Run 02:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  0.7898344008717686
None Run 03:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 59.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8465548339299858
None Run 04:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 52.40
Split: 02, Run: 02
None time:  0.8107029050588608
None Run 05:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 51.30
Split: 02, Run: 03
None time:  1.8377988890279084
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8166388601530343
None Run 07:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.20
Split: 03, Run: 02
None time:  0.8198597969021648
None Run 08:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 54.90
Split: 03, Run: 03
None time:  2.6984539600089192
None Run 09:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 93.33
   Final Test: 58.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7837135370355099
None Run 10:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 48.50
Split: 04, Run: 02
None time:  0.8399418848566711
None Run 11:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 47.50
Split: 04, Run: 03
None time:  0.8195170280523598
None Run 12:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 54.30
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8236780639272183
None Run 13:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 57.80
Split: 05, Run: 02
None time:  2.7307167360559106
None Run 14:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 93.33
   Final Test: 72.10
Split: 05, Run: 03
None time:  2.1724278379697353
None Run 15:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.00
   Final Test: 71.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7906566387973726
None Run 16:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 52.40
Split: 06, Run: 02
None time:  0.7616677901241928
None Run 17:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 56.30
Split: 06, Run: 03
None time:  0.7857752710115165
None Run 18:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 44.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8557468599174172
None Run 19:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 46.00
Split: 07, Run: 02
None time:  0.8927019890397787
None Run 20:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 55.30
Split: 07, Run: 03
None time:  2.0450987899675965
None Run 21:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 90.00
   Final Test: 66.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.130997301079333
None Run 22:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 91.67
   Final Test: 69.20
Split: 08, Run: 02
None time:  0.8253738030325621
None Run 23:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 52.00
Split: 08, Run: 03
None time:  2.291156450053677
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 90.00
   Final Test: 69.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6788335680030286
None Run 25:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.20
Split: 09, Run: 02
None time:  2.4474561791867018
None Run 26:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 86.67
   Final Test: 72.00
Split: 09, Run: 03
None time:  0.7996404930017889
None Run 27:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.265738597838208
None Run 28:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.10
Split: 10, Run: 02
None time:  2.2534911250695586
None Run 29:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 91.67
   Final Test: 64.50
Split: 10, Run: 03
None time:  2.656937725841999
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 64.70
run time now: 6.240871906280518
total time:  41.032013163901865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.79 ± 8.49
  Final Train: 97.50 ± 4.10
   Final Test: 59.20 ± 8.15
best run test_acc: 64.33000183105469
[I 2023-06-12 00:26:19,636] Trial 105 finished with value: 59.7933349609375 and parameters: {'Fwd': 0.016565408572268205, 'K': 3, 'alpha': 0.2, 'dropout': 0.30000000000000004, 'gnnepoch': 10, 'lambda1': 0.9, 'lambda2': 4.471933071996906, 'loop': 2, 'loss': 'CE', 'lr': 0.007467016612147513, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04408506107101201, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.006557813266853422
weight_decay:  0.032994658349431764
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.194120081840083
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 88.33
   Final Test: 67.90
Split: 01, Run: 02
None time:  2.534532596124336
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 65.00
Split: 01, Run: 03
None time:  2.0232729071285576
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 68.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.273992889095098
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 67.40
Split: 02, Run: 02
None time:  3.181491927942261
None Run 05:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 67.50
Split: 02, Run: 03
None time:  2.1082418670412153
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5801388619001955
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.60
Split: 03, Run: 02
None time:  3.280047545908019
None Run 08:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 91.67
   Final Test: 63.20
Split: 03, Run: 03
None time:  3.854342285776511
None Run 09:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 66.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.693222610047087
None Run 10:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 90.00
   Final Test: 63.50
Split: 04, Run: 02
None time:  3.8325812600087374
None Run 11:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 88.33
   Final Test: 63.70
Split: 04, Run: 03
None time:  2.892402551835403
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 83.33
   Final Test: 64.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.3767589810304344
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 70.70
Split: 05, Run: 02
None time:  2.0740805191453546
None Run 14:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 70.70
Split: 05, Run: 03
None time:  2.8834799171891063
None Run 15:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.00
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.951345588080585
None Run 16:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 02
None time:  3.3667256680782884
None Run 17:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 86.67
   Final Test: 68.10
Split: 06, Run: 03
None time:  0.9538774520624429
None Run 18:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 61.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.808147508185357
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 90.00
   Final Test: 65.50
Split: 07, Run: 02
None time:  2.664335392881185
None Run 20:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 88.33
   Final Test: 64.50
Split: 07, Run: 03
None time:  2.23343180003576
None Run 21:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 86.67
   Final Test: 65.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.010386663954705
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 69.50
Split: 08, Run: 02
None time:  2.3364634420722723
None Run 23:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 66.00
Split: 08, Run: 03
None time:  2.878958672983572
None Run 24:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.66800066200085
None Run 25:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 90.00
   Final Test: 70.70
Split: 09, Run: 02
None time:  2.806313564069569
None Run 26:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 72.50
Split: 09, Run: 03
None time:  2.8294833851978183
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 71.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.3926230440847576
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 64.10
Split: 10, Run: 02
None time:  1.575467900140211
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 64.40
Split: 10, Run: 03
None time:  5.1754780248738825
None Run 30:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 86.67
   Final Test: 68.10
run time now: 10.220096826553345
total time:  82.58531232108362
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.20 ± 2.58
  Final Train: 93.28 ± 4.70
   Final Test: 66.64 ± 3.21
best run test_acc: 68.25999450683594
[I 2023-06-12 00:27:42,704] Trial 106 finished with value: 68.19999694824219 and parameters: {'Fwd': 0.024146496180797773, 'K': 2, 'alpha': 0.25, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.729883961900456, 'loop': 2, 'loss': 'CE', 'lr': 0.006557813266853422, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.032994658349431764, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007589520979634971
weight_decay:  0.016581218780541328
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9729987250175327
None Run 01:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 60.10
Split: 01, Run: 02
None time:  1.9119706691708416
None Run 02:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.40
Split: 01, Run: 03
None time:  1.1462333239614964
None Run 03:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4245856411289424
None Run 04:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 63.20
Split: 02, Run: 02
None time:  1.4955987040884793
None Run 05:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.20
Split: 02, Run: 03
None time:  1.1877282469067723
None Run 06:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4896194459870458
None Run 07:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 59.80
Split: 03, Run: 02
None time:  1.6569923667702824
None Run 08:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 59.20
Split: 03, Run: 03
None time:  1.6084974841214716
None Run 09:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 59.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0063905790448189
None Run 10:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.60
Split: 04, Run: 02
None time:  1.0400720571633428
None Run 11:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.30
Split: 04, Run: 03
None time:  1.7528133229352534
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 60.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1226799830328673
None Run 13:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.90
Split: 05, Run: 02
None time:  1.5936839741189033
None Run 14:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.00
Split: 05, Run: 03
None time:  0.9967330570798367
None Run 15:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 67.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8322745671030134
None Run 16:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.60
Split: 06, Run: 02
None time:  1.4243102339096367
None Run 17:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 59.50
Split: 06, Run: 03
None time:  0.9466430470347404
None Run 18:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 57.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.595004937844351
None Run 19:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 59.40
Split: 07, Run: 02
None time:  1.9485589461401105
None Run 20:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 57.00
Split: 07, Run: 03
None time:  1.1534655750729144
None Run 21:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 58.30
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.979724609060213
None Run 22:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.00
Split: 08, Run: 02
None time:  0.9904823119286448
None Run 23:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 63.30
Split: 08, Run: 03
None time:  0.9576386709231883
None Run 24:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 61.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.1165065120439976
None Run 25:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 69.20
Split: 09, Run: 02
None time:  1.8674173359759152
None Run 26:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 68.00
Split: 09, Run: 03
None time:  1.6466705198399723
None Run 27:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 67.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.7154549560509622
None Run 28:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 61.00
Split: 10, Run: 02
None time:  2.0363634740933776
None Run 29:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.80
Split: 10, Run: 03
None time:  1.1786539470776916
None Run 30:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 59.90
run time now: 4.9762208461761475
total time:  44.93724991916679
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.04 ± 2.20
  Final Train: 100.00 ± 0.00
   Final Test: 62.01 ± 3.23
best run test_acc: 63.029998779296875
[I 2023-06-12 00:28:28,075] Trial 107 finished with value: 63.04000473022461 and parameters: {'Fwd': 0.07019383754794137, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 3.486770403219289, 'loop': 2, 'loss': 'MSE', 'lr': 0.007589520979634971, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.016581218780541328, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.006603847143157615
weight_decay:  0.07051038643532816
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5132458398584276
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 91.67
   Final Test: 67.60
Split: 01, Run: 02
None time:  3.4081351049244404
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 83.33
   Final Test: 69.80
Split: 01, Run: 03
None time:  3.629334312165156
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 90.00
   Final Test: 68.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.237284369999543
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 02
None time:  2.0019810248631984
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.00
Split: 02, Run: 03
None time:  2.280732967890799
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  4.055586697999388
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 65.10
Split: 03, Run: 02
None time:  2.627893509110436
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 66.10
Split: 03, Run: 03
None time:  2.407159897033125
None Run 09:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 98.33
   Final Test: 61.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.6086319480091333
None Run 10:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 86.67
   Final Test: 65.60
Split: 04, Run: 02
None time:  2.74208598700352
None Run 11:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 88.33
   Final Test: 66.50
Split: 04, Run: 03
None time:  2.1862923931330442
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 90.00
   Final Test: 67.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.3580682179890573
None Run 13:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 95.00
   Final Test: 71.20
Split: 05, Run: 02
None time:  2.18015005486086
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.40
Split: 05, Run: 03
None time:  1.9072320749983191
None Run 15:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 71.90
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.8059752548579127
None Run 16:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 86.67
   Final Test: 59.10
Split: 06, Run: 02
None time:  1.5656624538823962
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 64.70
Split: 06, Run: 03
None time:  1.546573615865782
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7752061039209366
None Run 19:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 86.67
   Final Test: 64.40
Split: 07, Run: 02
None time:  2.4554047300480306
None Run 20:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 88.33
   Final Test: 65.90
Split: 07, Run: 03
None time:  2.7866232830565423
None Run 21:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 86.67
   Final Test: 64.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.3240940319374204
None Run 22:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.20
Split: 08, Run: 02
None time:  2.4485465618781745
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.70
Split: 08, Run: 03
None time:  2.481590094976127
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 69.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.078751584980637
None Run 25:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 91.67
   Final Test: 71.60
Split: 09, Run: 02
None time:  2.117790315998718
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.00
Split: 09, Run: 03
None time:  1.9976011489052325
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 70.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.329604062018916
None Run 28:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.00
   Final Test: 65.10
Split: 10, Run: 02
None time:  2.210203351220116
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 65.00
Split: 10, Run: 03
None time:  4.520314565859735
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 91.67
   Final Test: 62.90
run time now: 9.105997323989868
total time:  77.91058417898603
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.55 ± 2.44
  Final Train: 94.11 ± 5.27
   Final Test: 67.05 ± 3.05
best run test_acc: 68.1300048828125
[I 2023-06-12 00:29:46,426] Trial 108 finished with value: 68.54666137695312 and parameters: {'Fwd': 0.045875639075892836, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.30000000000000004, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 4.246988271674304, 'loop': 2, 'loss': 'CE', 'lr': 0.006603847143157615, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07051038643532816, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.009066820394419254
weight_decay:  0.06500014655323055
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.410733623895794
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 86.67
   Final Test: 67.30
Split: 01, Run: 02
None time:  0.8280350989662111
None Run 02:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 53.80
Split: 01, Run: 03
None time:  0.8002973499242216
None Run 03:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 54.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8532010579947382
None Run 04:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.70
Split: 02, Run: 02
None time:  1.6819865808356553
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.70
Split: 02, Run: 03
None time:  2.544820622075349
None Run 06:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 83.33
   Final Test: 52.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.349733982933685
None Run 07:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 67.80
Split: 03, Run: 02
None time:  0.8693677831906825
None Run 08:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 48.40
Split: 03, Run: 03
None time:  0.7715380310546607
None Run 09:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 58.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.5423043018672615
None Run 10:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 81.67
   Final Test: 57.60
Split: 04, Run: 02
None time:  2.733937931014225
None Run 11:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 80.00
   Final Test: 57.70
Split: 04, Run: 03, Epoch: 100, Loss: 0.0111, Train: 80.00%, Valid: 62.20% Test: 62.00%
Split: 04, Run: 03
None time:  5.067103727022186
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 81.67
   Final Test: 63.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.0699354358948767
None Run 13:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.20
Split: 05, Run: 02
None time:  2.165378710022196
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.40
Split: 05, Run: 03
None time:  2.4159094060305506
None Run 15:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 71.40
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6863572320435196
None Run 16:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 53.20
Split: 06, Run: 02
None time:  0.5692522299941629
None Run 17:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 54.50
Split: 06, Run: 03
None time:  1.36554339597933
None Run 18:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 57.30
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.828039773972705
None Run 19:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.00
Split: 07, Run: 02
None time:  0.8365814529825002
None Run 20:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 45.70
Split: 07, Run: 03
None time:  0.8235168259125203
None Run 21:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 49.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7811245708726346
None Run 22:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.20
Split: 08, Run: 02
None time:  2.1155529271345586
None Run 23:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.80
Split: 08, Run: 03
None time:  0.7823120618704706
None Run 24:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 58.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.311836851062253
None Run 25:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 88.33
   Final Test: 72.90
Split: 09, Run: 02
None time:  1.6564151390921324
None Run 26:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 72.60
Split: 09, Run: 03
None time:  0.819528236053884
None Run 27:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 49.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8097382721025497
None Run 28:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.50
Split: 10, Run: 02
None time:  0.8090359168127179
None Run 29:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 60.60
Split: 10, Run: 03
None time:  0.7945066029205918
None Run 30:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.80
run time now: 2.459481954574585
total time:  47.206050308886915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.41 ± 7.41
  Final Train: 95.61 ± 6.57
   Final Test: 59.72 ± 7.95
best run test_acc: 65.12999725341797
[I 2023-06-12 00:30:34,184] Trial 109 finished with value: 60.413333892822266 and parameters: {'Fwd': 0.05010862564604725, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.30000000000000004, 'gnnepoch': 10, 'lambda1': 0.9500000000000001, 'lambda2': 4.142417934192982, 'loop': 2, 'loss': 'CE', 'lr': 0.009066820394419254, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06500014655323055, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.007915682203914582
weight_decay:  0.045685476802859636
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9773542280308902
None Run 01:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 57.30
Split: 01, Run: 02
None time:  0.9969141560140997
None Run 02:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 03
None time:  0.9185595589224249
None Run 03:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 58.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9658856589812785
None Run 04:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 62.20
Split: 02, Run: 02
None time:  0.9199906690046191
None Run 05:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.30
Split: 02, Run: 03
None time:  0.9844431870151311
None Run 06:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0102779159788042
None Run 07:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 60.90
Split: 03, Run: 02
None time:  0.9348104919772595
None Run 08:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 57.90
Split: 03, Run: 03
None time:  0.9777320940047503
None Run 09:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9537657201290131
None Run 10:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 56.70
Split: 04, Run: 02
None time:  0.9616798940114677
None Run 11:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 63.20
Split: 04, Run: 03
None time:  0.9334175509866327
None Run 12:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 56.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9639207790605724
None Run 13:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.60
Split: 05, Run: 02
None time:  0.9857228850014508
None Run 14:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.00
Split: 05, Run: 03
None time:  0.9259338320698589
None Run 15:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9282721590716392
None Run 16:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.50
Split: 06, Run: 02
None time:  0.9583984368946403
None Run 17:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 60.10
Split: 06, Run: 03
None time:  0.9649459670763463
None Run 18:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 58.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9098401858936995
None Run 19:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 55.40
Split: 07, Run: 02
None time:  0.9833275969140232
None Run 20:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.00
Split: 07, Run: 03
None time:  1.0090931500308216
None Run 21:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 57.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9621695450041443
None Run 22:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 64.10
Split: 08, Run: 02
None time:  0.8712046500295401
None Run 23:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 63.10
Split: 08, Run: 03
None time:  0.940736026968807
None Run 24:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 63.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9799426239915192
None Run 25:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 66.20
Split: 09, Run: 02
None time:  0.9623279899824411
None Run 26:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 64.10
Split: 09, Run: 03
None time:  0.9766347359400243
None Run 27:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 65.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8861775759141892
None Run 28:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 60.60
Split: 10, Run: 02
None time:  1.0002231218386441
None Run 29:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.20
Split: 10, Run: 03
None time:  0.9961633440107107
None Run 30:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.10
run time now: 2.981149435043335
total time:  29.91490958421491
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.87 ± 3.10
  Final Train: 100.00 ± 0.00
   Final Test: 60.56 ± 3.36
best run test_acc: 62.43999481201172
[I 2023-06-12 00:31:04,642] Trial 110 finished with value: 60.87333297729492 and parameters: {'Fwd': 0.06676205980907912, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.4, 'gnnepoch': 20, 'lambda1': 0.8, 'lambda2': 3.7283824664613414, 'loop': 2, 'loss': 'CE', 'lr': 0.007915682203914582, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.045685476802859636, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006900705729723729
weight_decay:  0.0259475675098836
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.434685849118978
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 91.67
   Final Test: 68.10
Split: 01, Run: 02
None time:  3.8709875689819455
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 90.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  2.5067632901482284
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 68.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.069968902040273
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.10
Split: 02, Run: 02
None time:  2.3162685530260205
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.20
Split: 02, Run: 03
None time:  1.9676696159876883
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.639148326124996
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 95.00
   Final Test: 65.80
Split: 03, Run: 02
None time:  2.2600675728172064
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 66.50
Split: 03, Run: 03
None time:  1.4197045220062137
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.794135289033875
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 88.33
   Final Test: 65.50
Split: 04, Run: 02
None time:  2.0582809201441705
None Run 11:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 64.90
Split: 04, Run: 03
None time:  2.5623139441013336
None Run 12:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 90.00
   Final Test: 64.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.6777434810064733
None Run 13:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 71.10
Split: 05, Run: 02
None time:  2.7386271071154624
None Run 14:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 70.30
Split: 05, Run: 03
None time:  2.1414449110161513
None Run 15:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.7532570781186223
None Run 16:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 93.33
   Final Test: 69.10
Split: 06, Run: 02
None time:  2.727269386872649
None Run 17:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 91.67
   Final Test: 67.50
Split: 06, Run: 03
None time:  3.327346110949293
None Run 18:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 90.00
   Final Test: 67.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3850005350541323
None Run 19:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 59.60
Split: 07, Run: 02
None time:  2.806765842018649
None Run 20:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 93.33
   Final Test: 64.10
Split: 07, Run: 03
None time:  2.102621503872797
None Run 21:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 90.00
   Final Test: 65.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.8212295828852803
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 68.70
Split: 08, Run: 02
None time:  2.675383446039632
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.50
Split: 08, Run: 03
None time:  2.7537204700056463
None Run 24:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.7688660980202258
None Run 25:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 91.67
   Final Test: 71.90
Split: 09, Run: 02
None time:  3.1086837130133063
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 71.40
Split: 09, Run: 03
None time:  2.601901568006724
None Run 27:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.00
   Final Test: 72.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3289530070032924
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 02
None time:  1.4326779250986874
None Run 29:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.30
Split: 10, Run: 03
None time:  1.4416322489269078
None Run 30:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.00
run time now: 4.248300790786743
total time:  72.73005001316778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.85 ± 2.11
  Final Train: 95.33 ± 3.97
   Final Test: 67.31 ± 3.08
best run test_acc: 68.0999984741211
[I 2023-06-12 00:32:17,809] Trial 111 finished with value: 68.85332489013672 and parameters: {'Fwd': 0.044487717458438304, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 4.591732979280825, 'loop': 2, 'loss': 'CE', 'lr': 0.006900705729723729, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0259475675098836, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.009026418641310879
weight_decay:  0.06937159035383396
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7751984170172364
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 66.70
Split: 01, Run: 02
None time:  2.891887210076675
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  2.5359977330081165
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 65.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.7240431141108274
None Run 04:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 67.60
Split: 02, Run: 02
None time:  2.274715653154999
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.30
Split: 02, Run: 03
None time:  2.313063042005524
None Run 06:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.095148016931489
None Run 07:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.30
Split: 03, Run: 02
None time:  2.2514439788646996
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 63.00
Split: 03, Run: 03
None time:  2.559687467990443
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 63.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  4.227794585982338
None Run 10:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 85.00
   Final Test: 65.50
Split: 04, Run: 02
None time:  2.075981565983966
None Run 11:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.90
Split: 04, Run: 03
None time:  2.037918818881735
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.6085474251303822
None Run 13:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.50
Split: 05, Run: 02
None time:  1.69899392593652
None Run 14:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 70.30
Split: 05, Run: 03
None time:  2.028980046045035
None Run 15:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 71.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.6462808509822935
None Run 16:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 66.10
Split: 06, Run: 02
None time:  2.144749595085159
None Run 17:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 93.33
   Final Test: 66.30
Split: 06, Run: 03
None time:  2.3669897608924657
None Run 18:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 93.33
   Final Test: 68.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.3621402480639517
None Run 19:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 63.90
Split: 07, Run: 02
None time:  2.3744762188289315
None Run 20:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 62.90
Split: 07, Run: 03
None time:  2.410022493917495
None Run 21:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 63.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.0116383749991655
None Run 22:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 98.33
   Final Test: 68.60
Split: 08, Run: 02
None time:  2.2662857801187783
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 69.50
Split: 08, Run: 03
None time:  2.924242102075368
None Run 24:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 69.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.55937217711471
None Run 25:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 70.40
Split: 09, Run: 02
None time:  2.5410446559544653
None Run 26:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 71.40
Split: 09, Run: 03
None time:  2.8069938959088176
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 70.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.528708220925182
None Run 28:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.40
Split: 10, Run: 02
None time:  1.8807609700597823
None Run 29:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 03
None time:  1.47531500691548
None Run 30:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 61.60
run time now: 4.931824207305908
total time:  70.61766391806304
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.23 ± 1.98
  Final Train: 96.56 ± 3.69
   Final Test: 66.41 ± 2.91
best run test_acc: 67.05000305175781
[I 2023-06-12 00:33:28,897] Trial 112 finished with value: 68.2266616821289 and parameters: {'Fwd': 0.0335960104041728, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 4.278126644434618, 'loop': 2, 'loss': 'CE', 'lr': 0.009026418641310879, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06937159035383396, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.005086054545284573
weight_decay:  0.039666552211740126
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9930307881440967
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 93.33
   Final Test: 66.10
Split: 01, Run: 02
None time:  2.8779260171577334
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 88.33
   Final Test: 67.00
Split: 01, Run: 03
None time:  2.7375365088228136
None Run 03:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 86.67
   Final Test: 66.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.241975782904774
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.90
Split: 02, Run: 02
None time:  3.9327381048351526
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.60
Split: 02, Run: 03
None time:  2.744615208124742
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.726869123056531
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 64.60
Split: 03, Run: 02
None time:  4.553282683016732
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 62.20
Split: 03, Run: 03
None time:  3.1179722019005567
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 64.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1543209929950535
None Run 10:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.50
Split: 04, Run: 02
None time:  2.7743956379126757
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 65.90
Split: 04, Run: 03
None time:  3.4636484649963677
None Run 12:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 81.67
   Final Test: 66.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.015797537053004
None Run 13:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.20
Split: 05, Run: 02
None time:  2.320134439971298
None Run 14:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.00
   Final Test: 71.70
Split: 05, Run: 03
None time:  2.9085240880958736
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 70.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.901109802071005
None Run 16:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 91.67
   Final Test: 58.20
Split: 06, Run: 02
None time:  1.7027778858318925
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 66.00
Split: 06, Run: 03
None time:  3.1732334920670837
None Run 18:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 86.67
   Final Test: 54.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9489230089820921
None Run 19:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 63.40
Split: 07, Run: 02
None time:  2.735248054843396
None Run 20:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 90.00
   Final Test: 65.60
Split: 07, Run: 03
None time:  3.01230177981779
None Run 21:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 90.00
   Final Test: 66.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.8323739289771765
None Run 22:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.70
Split: 08, Run: 02
None time:  2.2617423192132264
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.90
Split: 08, Run: 03
None time:  3.63666845113039
None Run 24:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.60
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.544735911069438
None Run 25:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 71.80
Split: 09, Run: 02
None time:  2.7163777789101005
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 71.50
Split: 09, Run: 03
None time:  2.7716437980998307
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 71.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.156559339025989
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 95.00
   Final Test: 64.30
Split: 10, Run: 02
None time:  1.8073715749196708
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.30
Split: 10, Run: 03
None time:  1.6506680329330266
None Run 30:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.10
run time now: 6.6627418994903564
total time:  81.64070842112415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.39 ± 3.64
  Final Train: 95.11 ± 4.91
   Final Test: 66.06 ± 4.02
best run test_acc: 67.6300048828125
[I 2023-06-12 00:34:51,055] Trial 113 finished with value: 67.3933334350586 and parameters: {'Fwd': 0.047869967209021175, 'K': 4, 'alpha': 0.0, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 4.703408636967239, 'loop': 2, 'loss': 'CE', 'lr': 0.005086054545284573, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.039666552211740126, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.006520554737974961
weight_decay:  0.028349433472440393
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.432948761153966
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 67.90
Split: 01, Run: 02
None time:  2.577760513871908
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 91.67
   Final Test: 66.60
Split: 01, Run: 03
None time:  2.2910858150571585
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 66.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3271307519171387
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.30
Split: 02, Run: 02
None time:  2.9284013458527625
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.90
Split: 02, Run: 03
None time:  1.8224059098865837
None Run 06:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.559500588104129
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 64.40
Split: 03, Run: 02
None time:  2.2563641688320786
None Run 08:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 03
None time:  3.0842474491801113
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 65.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.1421977567952126
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 88.33
   Final Test: 66.40
Split: 04, Run: 02
None time:  2.977343345992267
None Run 11:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 91.67
   Final Test: 65.90
Split: 04, Run: 03
None time:  2.9284390988759696
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 64.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1195466618519276
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 70.50
Split: 05, Run: 02
None time:  1.9758071568794549
None Run 14:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 70.80
Split: 05, Run: 03
None time:  1.9851684619206935
None Run 15:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 70.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.424448240082711
None Run 16:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 63.70
Split: 06, Run: 02
None time:  2.3009665799327195
None Run 17:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.00
   Final Test: 66.70
Split: 06, Run: 03
None time:  2.977575860917568
None Run 18:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 93.33
   Final Test: 67.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.910480147227645
None Run 19:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 62.50
Split: 07, Run: 02
None time:  2.1646537070628256
None Run 20:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 63.20
Split: 07, Run: 03
None time:  2.1445420768577605
None Run 21:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 62.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.336112661054358
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 68.90
Split: 08, Run: 02
None time:  2.7654481530189514
None Run 23:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 68.50
Split: 08, Run: 03
None time:  2.7935590078122914
None Run 24:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 68.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.524044384015724
None Run 25:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 69.50
Split: 09, Run: 02
None time:  2.0167186809703708
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 70.10
Split: 09, Run: 03
None time:  2.4102254260797054
None Run 27:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 71.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.0745997559279203
None Run 28:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 91.67
   Final Test: 65.80
Split: 10, Run: 02
None time:  1.8805590111296624
None Run 29:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.80
Split: 10, Run: 03
None time:  1.8723504249937832
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.20
run time now: 6.872411489486694
total time:  73.26142481714487
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.36 ± 1.56
  Final Train: 96.56 ± 3.30
   Final Test: 66.59 ± 2.66
best run test_acc: 67.41999816894531
[I 2023-06-12 00:36:04,831] Trial 114 finished with value: 68.35999298095703 and parameters: {'Fwd': 0.016656190726750758, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.30000000000000004, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 4.904671193643093, 'loop': 2, 'loss': 'CE', 'lr': 0.006520554737974961, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.028349433472440393, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.006347366178571234
weight_decay:  0.025819697741482264
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3905224250629544
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  3.1967427991330624
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 86.67
   Final Test: 67.10
Split: 01, Run: 03
None time:  2.8170786378905177
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 88.33
   Final Test: 68.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0791513100266457
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.90
Split: 02, Run: 02
None time:  2.220310753909871
None Run 05:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 67.60
Split: 02, Run: 03
None time:  2.3951754679437727
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.022606099024415
None Run 07:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.80
Split: 03, Run: 02
None time:  2.0071495180018246
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 98.33
   Final Test: 64.90
Split: 03, Run: 03
None time:  2.4738685679621994
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 95.00
   Final Test: 63.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.0321497530676425
None Run 10:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 88.33
   Final Test: 65.80
Split: 04, Run: 02
None time:  2.4737699199467897
None Run 11:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 65.30
Split: 04, Run: 03
None time:  2.4755186901893467
None Run 12:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 91.67
   Final Test: 64.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.4612272081431
None Run 13:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 71.20
Split: 05, Run: 02
None time:  2.0314682200551033
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.10
Split: 05, Run: 03
None time:  2.061706077773124
None Run 15:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 70.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7542188130319118
None Run 16:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.80
Split: 06, Run: 02
None time:  2.3404956799931824
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 63.80
Split: 06, Run: 03
None time:  2.1166796321049333
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 63.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.2426560709718615
None Run 19:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.00
   Final Test: 64.80
Split: 07, Run: 02
None time:  1.9753254619427025
None Run 20:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 62.20
Split: 07, Run: 03
None time:  2.2558697750791907
None Run 21:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.644338294165209
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.70
Split: 08, Run: 02
None time:  2.742927614832297
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 67.90
Split: 08, Run: 03
None time:  2.491353390039876
None Run 24:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 68.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.570683413883671
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 70.60
Split: 09, Run: 02
None time:  1.7727788959164172
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 70.10
Split: 09, Run: 03
None time:  1.8878709902055562
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.7245874681975693
None Run 28:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.40
Split: 10, Run: 02
None time:  1.615942494943738
None Run 29:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.20
Split: 10, Run: 03
None time:  2.3756261309608817
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.10
run time now: 5.759432315826416
total time:  70.82312775496393
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.11 ± 1.77
  Final Train: 96.33 ± 3.78
   Final Test: 66.40 ± 2.74
best run test_acc: 67.06999969482422
[I 2023-06-12 00:37:16,118] Trial 115 finished with value: 68.11333465576172 and parameters: {'Fwd': 0.016272219544044415, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.30000000000000004, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 5.183981078740901, 'loop': 2, 'loss': 'CE', 'lr': 0.006347366178571234, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.025819697741482264, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.25
lr:  0.00786680073445356
weight_decay:  0.03235251661708014
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.863247930072248
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 65.90
Split: 01, Run: 02
None time:  2.2198626280296594
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 66.10
Split: 01, Run: 03
None time:  2.7003692551515996
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 91.67
   Final Test: 67.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3259739028289914
None Run 04:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.10
Split: 02, Run: 02
None time:  2.0577035672031343
None Run 05:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 03
None time:  2.6547810179181397
None Run 06:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 98.33
   Final Test: 63.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.1420988510362804
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 62.10
Split: 03, Run: 02
None time:  3.6187316509895027
None Run 08:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 60.30
Split: 03, Run: 03
None time:  2.9059627829119563
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 62.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.8395890058018267
None Run 10:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 91.67
   Final Test: 65.10
Split: 04, Run: 02
None time:  2.786388651933521
None Run 11:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 88.33
   Final Test: 65.00
Split: 04, Run: 03
None time:  3.3798760750796646
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 88.33
   Final Test: 65.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.137340727960691
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.40
Split: 05, Run: 02
None time:  2.261648308020085
None Run 14:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.20
Split: 05, Run: 03
None time:  1.8921820297837257
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 71.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.6445552411023527
None Run 16:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 93.33
   Final Test: 67.40
Split: 06, Run: 02
None time:  2.341283590067178
None Run 17:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.00
   Final Test: 65.70
Split: 06, Run: 03
None time:  1.8059111880138516
None Run 18:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 61.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0197980729863048
None Run 19:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 62.90
Split: 07, Run: 02
None time:  2.095776502043009
None Run 20:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 98.33
   Final Test: 62.10
Split: 07, Run: 03
None time:  2.073774257209152
None Run 21:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 98.33
   Final Test: 62.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.317972857039422
None Run 22:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 68.20
Split: 08, Run: 02
None time:  2.213314739987254
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 68.10
Split: 08, Run: 03
None time:  2.5769739928655326
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 68.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.186751272995025
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.10
Split: 09, Run: 02
None time:  2.1809246900957078
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 70.60
Split: 09, Run: 03
None time:  2.724832845851779
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 70.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.6331900390796363
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 65.30
Split: 10, Run: 02
None time:  2.964483959134668
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 64.30
Split: 10, Run: 03
None time:  2.0405774349346757
None Run 30:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.40
run time now: 8.682334423065186
total time:  76.8143603799399
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.11 ± 1.73
  Final Train: 96.39 ± 3.31
   Final Test: 65.94 ± 3.15
best run test_acc: 66.95000457763672
[I 2023-06-12 00:38:33,425] Trial 116 finished with value: 68.1066665649414 and parameters: {'Fwd': 0.025039445558979287, 'K': 4, 'alpha': 0.25, 'dropout': 0.30000000000000004, 'gnnepoch': 40, 'lambda1': 0.9500000000000001, 'lambda2': 4.943147660785298, 'loop': 2, 'loss': 'CE', 'lr': 0.00786680073445356, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03235251661708014, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.009165980615504466
weight_decay:  0.08541479498725994
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7735833420883864
None Run 01:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 53.20
Split: 01, Run: 02
None time:  0.7845287038944662
None Run 02:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0147, Train: 88.33%, Valid: 65.60% Test: 67.70%
Split: 01, Run: 03
None time:  5.001329877879471
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 88.33
   Final Test: 67.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.6917452591005713
None Run 04:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 86.67
   Final Test: 53.50
Split: 02, Run: 02
None time:  4.144836836028844
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 67.50
Split: 02, Run: 03
None time:  2.3412135168910027
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.82169185904786
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 66.90
Split: 03, Run: 02
None time:  0.8168713049963117
None Run 08:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.60
Split: 03, Run: 03
None time:  2.254081245046109
None Run 09:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 98.33
   Final Test: 64.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.3813248979859054
None Run 10:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 86.67
   Final Test: 57.10
Split: 04, Run: 02
None time:  1.3178680050186813
None Run 11:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 98.33
   Final Test: 57.20
Split: 04, Run: 03
None time:  3.6166795841418207
None Run 12:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 88.33
   Final Test: 65.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.070898273959756
None Run 13:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 90.00
   Final Test: 58.00
Split: 05, Run: 02
None time:  2.7383580321911722
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 70.30
Split: 05, Run: 03
None time:  2.962994047207758
None Run 15:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 71.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8187583358958364
None Run 16:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 52.00
Split: 06, Run: 02
None time:  0.8362818979658186
None Run 17:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 03
None time:  3.414421055931598
None Run 18:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 86.67
   Final Test: 69.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.6731195298489183
None Run 19:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 65.60
Split: 07, Run: 02
None time:  0.8115594799164683
None Run 20:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 52.40
Split: 07, Run: 03
None time:  0.8046372451353818
None Run 21:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 51.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.3207678999751806
None Run 22:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 98.33
   Final Test: 65.30
Split: 08, Run: 02
None time:  0.8316933067981154
None Run 23:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 61.60
Split: 08, Run: 03
None time:  4.281394683988765
None Run 24:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8068359629251063
None Run 25:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 64.00
Split: 09, Run: 02
None time:  3.5275362140964717
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 72.30
Split: 09, Run: 03
None time:  0.802731421077624
None Run 27:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 60.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4033317698631436
None Run 28:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.10
Split: 10, Run: 02
None time:  3.958908988861367
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 95.00
   Final Test: 63.00
Split: 10, Run: 03
None time:  0.8671950879506767
None Run 30:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.80
run time now: 6.389843940734863
total time:  66.24645726615563
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.25 ± 6.28
  Final Train: 96.06 ± 4.86
   Final Test: 62.35 ± 6.18
best run test_acc: 68.22999572753906
[I 2023-06-12 00:39:40,255] Trial 117 finished with value: 63.25333786010742 and parameters: {'Fwd': 0.06345058253810602, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.30000000000000004, 'gnnepoch': 10, 'lambda1': 0.9, 'lambda2': 4.576673488779688, 'loop': 2, 'loss': 'CE', 'lr': 0.009165980615504466, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.08541479498725994, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.005899730501832405
weight_decay:  0.052289078112730446
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.71839602291584
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.10
Split: 01, Run: 02
None time:  2.7005327839870006
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 66.70
Split: 01, Run: 03
None time:  2.952994009014219
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 67.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.922675261972472
None Run 04:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.30
Split: 02, Run: 02
None time:  3.021645921980962
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 68.20
Split: 02, Run: 03
None time:  2.5110573819838464
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.968269442906603
None Run 07:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 65.30
Split: 03, Run: 02
None time:  2.195618423866108
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 63.60
Split: 03, Run: 03
None time:  3.1883925939910114
None Run 09:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 98.33
   Final Test: 61.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4864612880628556
None Run 10:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 65.50
Split: 04, Run: 02
None time:  2.6297370390966535
None Run 11:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 65.00
Split: 04, Run: 03
None time:  3.285949473036453
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 65.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.0668224811088294
None Run 13:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 71.10
Split: 05, Run: 02
None time:  2.2753130688797683
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 71.00
Split: 05, Run: 03
None time:  2.3312956059817225
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 70.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.1126275779679418
None Run 16:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 65.90
Split: 06, Run: 02
None time:  2.2321349689736962
None Run 17:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 60.80
Split: 06, Run: 03
None time:  2.8312624290119857
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 65.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7267331988550723
None Run 19:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 64.00
Split: 07, Run: 02
None time:  2.2304155530873686
None Run 20:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 64.30
Split: 07, Run: 03
None time:  2.420388045022264
None Run 21:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 65.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.0603967499919236
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 68.70
Split: 08, Run: 02
None time:  3.0092786359600723
None Run 23:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 67.40
Split: 08, Run: 03
None time:  2.1945458201225847
None Run 24:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.5333553650416434
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 71.20
Split: 09, Run: 02
None time:  2.3555284230969846
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 70.60
Split: 09, Run: 03
None time:  3.360054416116327
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 70.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.729827022179961
None Run 28:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 63.60
Split: 10, Run: 02
None time:  2.244933885987848
None Run 29:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 63.90
Split: 10, Run: 03
None time:  1.6724833969492465
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.80
run time now: 6.689911127090454
total time:  81.16457889811136
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.14 ± 1.92
  Final Train: 97.00 ± 2.64
   Final Test: 66.60 ± 2.88
best run test_acc: 67.36000061035156
[I 2023-06-12 00:41:02,064] Trial 118 finished with value: 68.13999938964844 and parameters: {'Fwd': 0.03415900987344613, 'K': 3, 'alpha': 0.25, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 1.0, 'lambda2': 4.793453857592729, 'loop': 2, 'loss': 'CE', 'lr': 0.005899730501832405, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.052289078112730446, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.004909610023795896
weight_decay:  0.010661413845424577
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2011018998455256
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 59.50
Split: 01, Run: 02
None time:  0.9593938100151718
None Run 02:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 59.20
Split: 01, Run: 03
None time:  1.1489828820340335
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 59.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2253364098723978
None Run 04:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 62.70
Split: 02, Run: 02
None time:  1.1853002209682018
None Run 05:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 61.70
Split: 02, Run: 03
None time:  1.192369697848335
None Run 06:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 63.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.100104718003422
None Run 07:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 55.70
Split: 03, Run: 02
None time:  1.133597529027611
None Run 08:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.80
Split: 03, Run: 03
None time:  1.374927335884422
None Run 09:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1354744972195476
None Run 10:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 62.30
Split: 04, Run: 02
None time:  1.1484504889231175
None Run 11:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.40
Split: 04, Run: 03
None time:  1.1333930341061205
None Run 12:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3251873499248177
None Run 13:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.80
Split: 05, Run: 02
None time:  1.1110932279843837
None Run 14:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.00
Split: 05, Run: 03
None time:  1.018401731038466
None Run 15:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0258337780833244
None Run 16:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 60.60
Split: 06, Run: 02
None time:  1.1129217240959406
None Run 17:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 60.90
Split: 06, Run: 03
None time:  0.9841446180362254
None Run 18:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1494018211960793
None Run 19:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 57.60
Split: 07, Run: 02
None time:  1.1044361458625644
None Run 20:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 60.20
Split: 07, Run: 03
None time:  1.0834580049850047
None Run 21:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 57.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9992756459396333
None Run 22:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 62.30
Split: 08, Run: 02
None time:  1.1050211370456964
None Run 23:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 63.90
Split: 08, Run: 03
None time:  1.097476838156581
None Run 24:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 65.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0934418002143502
None Run 25:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 64.40
Split: 09, Run: 02
None time:  1.1685121671762317
None Run 26:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.10
Split: 09, Run: 03
None time:  1.1147099249064922
None Run 27:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 63.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1133947481866926
None Run 28:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.20
Split: 10, Run: 02
None time:  1.0489014429040253
None Run 29:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 61.00
Split: 10, Run: 03
None time:  1.061758005991578
None Run 30:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.60
run time now: 3.2645344734191895
total time:  34.79063045815565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.87 ± 2.54
  Final Train: 100.00 ± 0.00
   Final Test: 61.57 ± 2.65
best run test_acc: 62.51000213623047
[I 2023-06-12 00:41:37,363] Trial 119 finished with value: 61.87333297729492 and parameters: {'Fwd': 0.09960347080535546, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.30000000000000004, 'gnnepoch': 30, 'lambda1': 0.8500000000000001, 'lambda2': 3.8136090499361326, 'loop': 2, 'loss': 'CE', 'lr': 0.004909610023795896, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.010661413845424577, 'weightedloss': False}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.4
lr:  0.007295639895637725
weight_decay:  0.01775753622793732
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.319368924945593
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 95.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  2.3197505031712353
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  2.2924515530467033
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 67.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.1290343580767512
None Run 04:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 69.40
Split: 02, Run: 02
None time:  2.8072469630278647
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
Split: 02, Run: 03
None time:  3.1966169809456915
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 68.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5686763478443027
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.60
Split: 03, Run: 02
None time:  3.031394300982356
None Run 08:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 66.90
Split: 03, Run: 03
None time:  1.6021042568609118
None Run 09:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.739610836142674
None Run 10:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 62.60
Split: 04, Run: 02
None time:  2.694171015173197
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 64.20
Split: 04, Run: 03
None time:  1.8399352428968996
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.6557271310593933
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 69.70
Split: 05, Run: 02
None time:  2.9296081899665296
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 71.10
Split: 05, Run: 03
None time:  2.637863077921793
None Run 15:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 70.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.762353413971141
None Run 16:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 64.20
Split: 06, Run: 02
None time:  2.757098310161382
None Run 17:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 91.67
   Final Test: 69.30
Split: 06, Run: 03
None time:  3.234012129949406
None Run 18:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 90.00
   Final Test: 68.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.592083201976493
None Run 19:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 90.00
   Final Test: 65.00
Split: 07, Run: 02
None time:  2.6482584648765624
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 90.00
   Final Test: 65.70
Split: 07, Run: 03
None time:  2.6491534211672843
None Run 21:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 90.00
   Final Test: 65.90
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.8634248981252313
None Run 22:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 69.30
Split: 08, Run: 02
None time:  2.5705415590200573
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 69.70
Split: 08, Run: 03
None time:  2.716952078975737
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 70.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.950736900093034
None Run 25:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 72.50
Split: 09, Run: 02
None time:  2.9730678321793675
None Run 26:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 71.90
Split: 09, Run: 03
None time:  2.906877839937806
None Run 27:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 98.33
   Final Test: 71.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.1946724720764905
None Run 28:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 66.90
Split: 10, Run: 02
None time:  1.5182400320190936
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.40
Split: 10, Run: 03
None time:  1.417216267902404
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.30
run time now: 5.1774373054504395
total time:  75.80638048215769
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.05 ± 2.17
  Final Train: 96.33 ± 3.49
   Final Test: 67.68 ± 2.70
best run test_acc: 68.55999755859375
[I 2023-06-12 00:42:53,730] Trial 120 finished with value: 69.05333709716797 and parameters: {'Fwd': 0.0731225820175701, 'K': 4, 'alpha': 0.4, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 3.4841667861010563, 'loop': 2, 'loss': 'CE', 'lr': 0.007295639895637725, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01775753622793732, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.5
lr:  0.007435059379815775
weight_decay:  0.01869673404522658
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.259624428115785
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 95.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.3783196108415723
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 98.33
   Final Test: 63.60
Split: 01, Run: 03
None time:  2.375937424134463
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 67.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4313840749673545
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.20
Split: 02, Run: 02
None time:  1.4341427020262927
None Run 05:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.60
Split: 02, Run: 03
None time:  2.1578658390790224
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.890814079903066
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.20
Split: 03, Run: 02
None time:  1.9066386681515723
None Run 08:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.80
Split: 03, Run: 03
None time:  1.5794774841051549
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.0191972150932997
None Run 10:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 64.90
Split: 04, Run: 02
None time:  2.3758975882083178
None Run 11:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 64.30
Split: 04, Run: 03
None time:  2.57531954604201
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 65.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.3215282971505076
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 69.30
Split: 05, Run: 02
None time:  2.126489480957389
None Run 14:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
Split: 05, Run: 03
None time:  2.2328829509206116
None Run 15:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 69.70
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6413231638725847
None Run 16:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.50
Split: 06, Run: 02
None time:  2.4280581809580326
None Run 17:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 68.70
Split: 06, Run: 03
None time:  2.3304028999991715
None Run 18:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 90.00
   Final Test: 67.70
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.336251915199682
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 64.00
Split: 07, Run: 02
None time:  2.644319246057421
None Run 20:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 65.80
Split: 07, Run: 03
None time:  2.2230131898541003
None Run 21:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 90.00
   Final Test: 65.80
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9957961838226765
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 68.40
Split: 08, Run: 02
None time:  2.8126856109593064
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 69.10
Split: 08, Run: 03
None time:  2.436357364989817
None Run 24:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.6712695281021297
None Run 25:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 90.00
   Final Test: 72.60
Split: 09, Run: 02
None time:  1.2481690780259669
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 67.70
Split: 09, Run: 03
None time:  2.320628952002153
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 69.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4914855221286416
None Run 28:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.20
Split: 10, Run: 02
None time:  1.498947988031432
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.00
Split: 10, Run: 03
None time:  1.5252559599466622
None Run 30:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 64.90
run time now: 4.56479811668396
total time:  65.93393841199577
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.38 ± 2.46
  Final Train: 97.00 ± 3.49
   Final Test: 66.90 ± 2.29
best run test_acc: 67.94999694824219
[I 2023-06-12 00:44:00,225] Trial 121 finished with value: 68.37999725341797 and parameters: {'Fwd': 0.07681877559260257, 'K': 4, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 3.4792070410210263, 'loop': 2, 'loss': 'CE', 'lr': 0.007435059379815775, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01869673404522658, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.4
lr:  0.007134142093855809
weight_decay:  0.017760501078065663
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.368483846075833
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 67.20
Split: 01, Run: 02
None time:  2.8732697339728475
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  2.45800314610824
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 91.67
   Final Test: 66.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.2699492850806564
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.50
Split: 02, Run: 02
None time:  2.4102128811646253
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.00
Split: 02, Run: 03
None time:  2.5409463548567146
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.3096364510711282
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.40
Split: 03, Run: 02
None time:  3.9337388451676816
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 66.80
Split: 03, Run: 03
None time:  1.3725897169206291
None Run 09:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.827865146100521
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.30
Split: 04, Run: 02
None time:  2.5872453891206533
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 88.33
   Final Test: 65.20
Split: 04, Run: 03
None time:  2.0643591941334307
None Run 12:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4506303621456027
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 05, Run: 02
None time:  1.78743612812832
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 71.20
Split: 05, Run: 03
None time:  1.889528339030221
None Run 15:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 71.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.490050391992554
None Run 16:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 63.50
Split: 06, Run: 02
None time:  0.8428140729665756
None Run 17:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.20
Split: 06, Run: 03
None time:  1.5158951138146222
None Run 18:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.477548769908026
None Run 19:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 90.00
   Final Test: 64.90
Split: 07, Run: 02
None time:  2.5781574929133058
None Run 20:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 90.00
   Final Test: 65.30
Split: 07, Run: 03
None time:  2.6373345870524645
None Run 21:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 96.67
   Final Test: 65.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.4705251320265234
None Run 22:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 67.30
Split: 08, Run: 02
None time:  2.75137130683288
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 68.60
Split: 08, Run: 03
None time:  2.701741724042222
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 69.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.2755291189532727
None Run 25:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 72.00
Split: 09, Run: 02
None time:  2.6395372489932925
None Run 26:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 72.40
Split: 09, Run: 03
None time:  2.5575653470586985
None Run 27:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 72.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  4.106139873852953
None Run 28:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 63.40
Split: 10, Run: 02
None time:  1.3959763241000473
None Run 29:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 03
None time:  1.515714359935373
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.40
run time now: 7.064313173294067
total time:  70.42117702006362
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.26 ± 2.45
  Final Train: 96.72 ± 3.78
   Final Test: 66.97 ± 3.09
best run test_acc: 67.65999603271484
[I 2023-06-12 00:45:11,170] Trial 122 finished with value: 68.26000213623047 and parameters: {'Fwd': 0.0811276309531331, 'K': 4, 'alpha': 0.4, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9500000000000001, 'lambda2': 3.4596561941673825, 'loop': 2, 'loss': 'CE', 'lr': 0.007134142093855809, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.017760501078065663, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.5
lr:  0.008063540939356765
weight_decay:  0.024086459742593866
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9467848101630807
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 66.50
Split: 01, Run: 02
None time:  1.8758234069682658
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 67.70
Split: 01, Run: 03
None time:  2.151826322078705
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 67.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8172925140243024
None Run 04:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.20
Split: 02, Run: 02
None time:  2.2067754650488496
None Run 05:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.60
Split: 02, Run: 03
None time:  4.08989014220424
None Run 06:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.3792618568986654
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 98.33
   Final Test: 66.30
Split: 03, Run: 02
None time:  3.0715890540741384
None Run 08:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 98.33
   Final Test: 61.50
Split: 03, Run: 03
None time:  1.2911757070105523
None Run 09:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.140603889944032
None Run 10:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 66.20
Split: 04, Run: 02
None time:  2.125695575028658
None Run 11:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.30
Split: 04, Run: 03
None time:  2.5529488688334823
None Run 12:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 65.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.9961959139909595
None Run 13:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 70.50
Split: 05, Run: 02
None time:  1.7233645860105753
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 71.00
Split: 05, Run: 03
None time:  1.8340099721681327
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 70.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7686920519918203
None Run 16:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.80
Split: 06, Run: 02
None time:  2.10760791413486
None Run 17:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 67.30
Split: 06, Run: 03
None time:  1.5353813560213894
None Run 18:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.40
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.1563953161239624
None Run 19:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 64.70
Split: 07, Run: 02
None time:  2.323587967082858
None Run 20:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 98.33
   Final Test: 66.20
Split: 07, Run: 03
None time:  2.4115993049927056
None Run 21:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 65.10
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.615936106070876
None Run 22:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 69.70
Split: 08, Run: 02
None time:  2.667577681131661
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 70.00
Split: 08, Run: 03
None time:  3.0858628060668707
None Run 24:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.184110150905326
None Run 25:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.10
Split: 09, Run: 02
None time:  2.4135721360798925
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 72.30
Split: 09, Run: 03
None time:  3.398949174908921
None Run 27:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 71.40
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4051070269197226
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.20
Split: 10, Run: 02
None time:  1.4392396030016243
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.60
Split: 10, Run: 03
None time:  1.410176785197109
None Run 30:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 62.60
run time now: 4.300448894500732
total time:  67.366382552078
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.41 ± 2.20
  Final Train: 97.78 ± 2.41
   Final Test: 66.91 ± 2.90
best run test_acc: 68.08000183105469
[I 2023-06-12 00:46:19,021] Trial 123 finished with value: 68.40666198730469 and parameters: {'Fwd': 0.07037252114951387, 'K': 4, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.573311811299036, 'loop': 2, 'loss': 'CE', 'lr': 0.008063540939356765, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.024086459742593866, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.5
lr:  0.007905850149421266
weight_decay:  0.02445710052627845
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7214177530258894
None Run 01:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 42.00
Split: 01, Run: 02
None time:  0.6235997730400413
None Run 02:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 29.80
Split: 01, Run: 03
None time:  0.6843431491870433
None Run 03:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 38.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6867719669826329
None Run 04:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 35.30
Split: 02, Run: 02
None time:  0.6910340059548616
None Run 05:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 35.30
Split: 02, Run: 03
None time:  0.6281735950615257
None Run 06:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 35.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6783540479373187
None Run 07:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.50
Split: 03, Run: 02
None time:  0.6610290571115911
None Run 08:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.50
Split: 03, Run: 03
None time:  0.7516021700575948
None Run 09:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 33.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6848847731016576
None Run 10:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 36.50
Split: 04, Run: 02
None time:  0.6897775479592383
None Run 11:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 36.50
Split: 04, Run: 03
None time:  0.7775375701021403
None Run 12:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 40.50
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7501042569056153
None Run 13:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 34.20
Split: 05, Run: 02
None time:  0.8263205620460212
None Run 14:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 40.60
Split: 05, Run: 03
None time:  0.6776500069536269
None Run 15:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 38.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6695916438475251
None Run 16:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 32.90
Split: 06, Run: 02
None time:  0.6588088748976588
None Run 17:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 32.90
Split: 06, Run: 03
None time:  0.6987897388171405
None Run 18:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 32.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6994410180486739
None Run 19:
Highest Train: 100.00
Highest Valid: 26.80
  Final Train: 100.00
   Final Test: 27.50
Split: 07, Run: 02
None time:  0.668590763118118
None Run 20:
Highest Train: 100.00
Highest Valid: 26.80
  Final Train: 100.00
   Final Test: 27.50
Split: 07, Run: 03
None time:  0.7437443269882351
None Run 21:
Highest Train: 100.00
Highest Valid: 27.40
  Final Train: 100.00
   Final Test: 29.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6415914329700172
None Run 22:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 35.80
Split: 08, Run: 02
None time:  0.7350989850237966
None Run 23:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 41.10
Split: 08, Run: 03
None time:  1.182626063004136
None Run 24:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 34.90
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6704100279603153
None Run 25:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.50
Split: 09, Run: 02
None time:  0.7457502360921353
None Run 26:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 35.30
Split: 09, Run: 03
None time:  0.676687141880393
None Run 27:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.50
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8267706481274217
None Run 28:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 37.90
Split: 10, Run: 02
None time:  0.6649051269050688
None Run 29:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 33.50
Split: 10, Run: 03
None time:  0.7892586390953511
None Run 30:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 34.80
run time now: 2.331024408340454
total time:  22.754581674933434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 34.33 ± 3.82
  Final Train: 100.00 ± 0.00
   Final Test: 35.19 ± 3.62
best run test_acc: 37.150001525878906
[I 2023-06-12 00:46:42,443] Trial 124 finished with value: 34.33333206176758 and parameters: {'Fwd': 0.07115375365280734, 'K': 4, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 0, 'lambda1': 0.9500000000000001, 'lambda2': 4.277132174444678, 'loop': 2, 'loss': 'CE', 'lr': 0.007905850149421266, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.02445710052627845, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.5
lr:  0.005410826174288478
weight_decay:  0.03969691893010547
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4405729118734598
None Run 01:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 29.80
Split: 01, Run: 02
None time:  0.461695987964049
None Run 02:
Highest Train: 100.00
Highest Valid: 30.40
  Final Train: 100.00
   Final Test: 29.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0015, Train: 81.67%, Valid: 53.00% Test: 53.60%
Split: 01, Run: 03
None time:  3.1633504710625857
None Run 03:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 81.67
   Final Test: 53.30
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.4954635938629508
None Run 04:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 35.30
Split: 02, Run: 02
None time:  0.43799177603796124
None Run 05:
Highest Train: 100.00
Highest Valid: 35.20
  Final Train: 100.00
   Final Test: 35.30
Split: 02, Run: 03
None time:  2.2719534051138908
None Run 06:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 90.00
   Final Test: 52.80
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4760509261395782
None Run 07:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.50
Split: 03, Run: 02
None time:  0.4308992149308324
None Run 08:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 35.50
Split: 03, Run: 03
None time:  1.7656873951200396
None Run 09:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 86.67
   Final Test: 50.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.4257339769974351
None Run 10:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 36.50
Split: 04, Run: 02
None time:  0.4701716199051589
None Run 11:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 36.50
Split: 04, Run: 03
None time:  1.0875852848403156
None Run 12:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 91.67
   Final Test: 60.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.47219978901557624
None Run 13:
Highest Train: 100.00
Highest Valid: 36.20
  Final Train: 100.00
   Final Test: 37.40
Split: 05, Run: 02
None time:  0.4397454319987446
None Run 14:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 38.30
Split: 05, Run: 03
None time:  1.861738830106333
None Run 15:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 85.00
   Final Test: 49.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.4556052880361676
None Run 16:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 32.90
Split: 06, Run: 02
None time:  0.45625986088998616
None Run 17:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 32.90
Split: 06, Run: 03
None time:  1.0536898639984429
None Run 18:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 85.00
   Final Test: 52.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.44526392593979836
None Run 19:
Highest Train: 100.00
Highest Valid: 26.40
  Final Train: 100.00
   Final Test: 27.30
Split: 07, Run: 02
None time:  0.4417602098546922
None Run 20:
Highest Train: 100.00
Highest Valid: 26.40
  Final Train: 100.00
   Final Test: 27.30
Split: 07, Run: 03, Epoch: 100, Loss: 0.0066, Train: 76.67%, Valid: 55.60% Test: 51.80%
Split: 07, Run: 03
None time:  3.1644333677832037
None Run 21:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 76.67
   Final Test: 51.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4572479531634599
None Run 22:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 35.80
Split: 08, Run: 02
None time:  0.47609429992735386
None Run 23:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 35.80
Split: 08, Run: 03
None time:  0.454092837870121
None Run 24:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 35.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.44974815589375794
None Run 25:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.60
Split: 09, Run: 02
None time:  0.4558849420864135
None Run 26:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.60
Split: 09, Run: 03
None time:  0.46952221798710525
None Run 27:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.4502915949560702
None Run 28:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 33.50
Split: 10, Run: 02, Epoch: 100, Loss: 0.0054, Train: 65.00%, Valid: 48.00% Test: 43.00%
Split: 10, Run: 02
None time:  3.124189881142229
None Run 29:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 65.00
   Final Test: 43.10
Split: 10, Run: 03
None time:  1.9542537769302726
None Run 30:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 93.33
   Final Test: 46.60
run time now: 5.5904624462127686
total time:  30.281626034062356
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 38.88 ± 10.22
  Final Train: 95.17 ± 8.80
   Final Test: 39.38 ± 8.65
best run test_acc: 48.97999954223633
[I 2023-06-12 00:47:13,327] Trial 125 finished with value: 38.880001068115234 and parameters: {'Fwd': 0.05411116080662482, 'K': 4, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 10, 'lambda1': 1.0, 'lambda2': 3.8393877850327303, 'loop': 2, 'loss': 'CE', 'lr': 0.005410826174288478, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03969691893010547, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.007377719980119424
weight_decay:  0.031856336805885885
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2624551937915385
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 88.33
   Final Test: 66.70
Split: 01, Run: 02
None time:  2.4343017919454724
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 86.67
   Final Test: 68.70
Split: 01, Run: 03
None time:  2.1450183039996773
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 66.20
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4067322998307645
None Run 04:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 68.40
Split: 02, Run: 02
None time:  1.1120087699964643
None Run 05:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.10
Split: 02, Run: 03
None time:  2.7668772148899734
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 67.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7503102920018137
None Run 07:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 64.50
Split: 03, Run: 02
None time:  2.4631359020713717
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 91.67
   Final Test: 64.40
Split: 03, Run: 03
None time:  2.679639298003167
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 65.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.217261544894427
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 83.33
   Final Test: 66.00
Split: 04, Run: 02
None time:  2.905163510935381
None Run 11:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 83.33
   Final Test: 67.10
Split: 04, Run: 03
None time:  2.9004576890729368
None Run 12:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 81.67
   Final Test: 67.20
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8886261328589171
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 69.60
Split: 05, Run: 02
None time:  1.2731982700061053
None Run 14:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 69.30
Split: 05, Run: 03
None time:  2.148017347790301
None Run 15:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 71.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.959209298947826
None Run 16:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.90
Split: 06, Run: 02
None time:  2.598863482940942
None Run 17:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 86.67
   Final Test: 68.70
Split: 06, Run: 03
None time:  2.6546940559055656
None Run 18:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 86.67
   Final Test: 69.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.588148406939581
None Run 19:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 95.00
   Final Test: 64.30
Split: 07, Run: 02
None time:  2.2420484330505133
None Run 20:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 86.67
   Final Test: 64.90
Split: 07, Run: 03
None time:  2.0039315121248364
None Run 21:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 86.67
   Final Test: 65.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.310902477009222
None Run 22:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 85.00
   Final Test: 67.80
Split: 08, Run: 02
None time:  2.142369951121509
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.50
Split: 08, Run: 03
None time:  1.5861025638878345
None Run 24:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.262540621915832
None Run 25:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 72.50
Split: 09, Run: 02
None time:  3.217372626066208
None Run 26:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 71.90
Split: 09, Run: 03
None time:  1.998107859864831
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 98.33
   Final Test: 70.80
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.2860250051598996
None Run 28:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 90.00
   Final Test: 62.00
Split: 10, Run: 02, Epoch: 100, Loss: 0.0135, Train: 85.00%, Valid: 69.40% Test: 64.70%
Split: 10, Run: 02
None time:  5.434162327088416
None Run 29:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 85.00
   Final Test: 64.70
Split: 10, Run: 03
None time:  2.994904585182667
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 90.00
   Final Test: 65.70
run time now: 11.772650241851807
total time:  72.95259419409558
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.31 ± 2.53
  Final Train: 92.06 ± 5.83
   Final Test: 67.04 ± 2.95
best run test_acc: 68.29000091552734
[I 2023-06-12 00:48:26,838] Trial 126 finished with value: 68.30667114257812 and parameters: {'Fwd': 0.025089076060125226, 'K': 4, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 3.389409672450577, 'loop': 2, 'loss': 'CE', 'lr': 0.007377719980119424, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.031856336805885885, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.4
lr:  0.005977255145491323
weight_decay:  0.06167762671424467
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2900704240892082
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 60.80
Split: 01, Run: 02
None time:  0.9014075649902225
None Run 02:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 57.10
Split: 01, Run: 03
None time:  0.94220309285447
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 60.50
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3090621440205723
None Run 04:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.30
Split: 02, Run: 02
None time:  0.9172432171180844
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.90
Split: 02, Run: 03
None time:  2.276227871887386
None Run 06:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7453439570963383
None Run 07:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.40
Split: 03, Run: 02
None time:  1.5309047200717032
None Run 08:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.80
Split: 03, Run: 03
None time:  1.9194333699997514
None Run 09:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.40
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.2768197748810053
None Run 10:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.70
Split: 04, Run: 02
None time:  1.0083767760079354
None Run 11:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.40
Split: 04, Run: 03
None time:  0.99613500200212
None Run 12:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.70
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.084513616980985
None Run 13:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.00
Split: 05, Run: 02
None time:  2.574132406152785
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.20
Split: 05, Run: 03
None time:  1.0023654180113226
None Run 15:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.000718988943845
None Run 16:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 54.80
Split: 06, Run: 02
None time:  1.53670824598521
None Run 17:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 60.40
Split: 06, Run: 03
None time:  0.9458693061023951
None Run 18:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.20
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.1082819199655205
None Run 19:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 59.20
Split: 07, Run: 02
None time:  1.8222581970039755
None Run 20:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 56.80
Split: 07, Run: 03
None time:  1.2165544219315052
None Run 21:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 61.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8102083778940141
None Run 22:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 65.50
Split: 08, Run: 02
None time:  1.0255574020557106
None Run 23:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 62.50
Split: 08, Run: 03
None time:  2.495086119044572
None Run 24:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 64.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.643737830920145
None Run 25:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 68.10
Split: 09, Run: 02
None time:  0.9855951401405036
None Run 26:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.70
Split: 09, Run: 03
None time:  1.5467296009883285
None Run 27:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 66.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.2611291999928653
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 60.80
Split: 10, Run: 02
None time:  0.9491232121363282
None Run 29:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.70
Split: 10, Run: 03
None time:  1.0907224758993834
None Run 30:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.10
run time now: 4.347283124923706
total time:  47.42096909787506
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.09 ± 2.59
  Final Train: 100.00 ± 0.00
   Final Test: 62.05 ± 2.99
best run test_acc: 63.42000198364258
[I 2023-06-12 00:49:14,707] Trial 127 finished with value: 63.09333419799805 and parameters: {'Fwd': 0.036577152181846255, 'K': 3, 'alpha': 0.4, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.0846842764693796, 'loop': 2, 'loss': 'MSE', 'lr': 0.005977255145491323, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06167762671424467, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.008193083291227327
weight_decay:  0.023688841291750987
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8132952069863677
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.20
Split: 01, Run: 02
None time:  0.816601769067347
None Run 02:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 59.80
Split: 01, Run: 03
None time:  0.8177557538729161
None Run 03:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 59.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.2868278669193387
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.60
Split: 02, Run: 02
None time:  2.064001557882875
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.50
Split: 02, Run: 03
None time:  2.872084181988612
None Run 06:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7954918800387532
None Run 07:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 57.30
Split: 03, Run: 02
None time:  0.7835197481326759
None Run 08:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 41.50
Split: 03, Run: 03
None time:  3.3584451160859317
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 66.10
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.1120213710237294
None Run 10:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 85.00
   Final Test: 65.50
Split: 04, Run: 02
None time:  3.265779057983309
None Run 11:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 85.00
   Final Test: 64.60
Split: 04, Run: 03
None time:  2.585423834156245
None Run 12:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 88.33
   Final Test: 66.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7633909790311009
None Run 13:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 61.60
Split: 05, Run: 02
None time:  3.0983823160640895
None Run 14:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 95.00
   Final Test: 71.60
Split: 05, Run: 03
None time:  4.3303406778723
None Run 15:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 70.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7651362558826804
None Run 16:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.70
Split: 06, Run: 02
None time:  0.786501184804365
None Run 17:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 59.90
Split: 06, Run: 03
None time:  0.7511922318954021
None Run 18:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.808187380200252
None Run 19:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 91.67
   Final Test: 65.70
Split: 07, Run: 02
None time:  0.8330629649572074
None Run 20:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 58.60
Split: 07, Run: 03
None time:  2.0051882911939174
None Run 21:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 95.00
   Final Test: 68.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.754590175114572
None Run 22:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 57.40
Split: 08, Run: 02
None time:  0.7701717230957001
None Run 23:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 55.20
Split: 08, Run: 03
None time:  0.7471852879971266
None Run 24:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 58.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8248242470435798
None Run 25:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 57.40
Split: 09, Run: 02
None time:  0.7280258219689131
None Run 26:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 62.40
Split: 09, Run: 03
None time:  2.451303355861455
None Run 27:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 91.67
   Final Test: 72.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4209557708818465
None Run 28:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.60
Split: 10, Run: 02
None time:  1.2335091310087591
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 65.90
Split: 10, Run: 03
None time:  2.181176593992859
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.50
run time now: 4.879506826400757
total time:  51.93786603608169
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.61 ± 8.36
  Final Train: 97.33 ± 4.67
   Final Test: 62.18 ± 6.37
best run test_acc: 65.8499984741211
[I 2023-06-12 00:50:07,116] Trial 128 finished with value: 62.61333465576172 and parameters: {'Fwd': 0.07094047860524262, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.30000000000000004, 'gnnepoch': 10, 'lambda1': 0.9500000000000001, 'lambda2': 4.538509703355441, 'loop': 2, 'loss': 'CE', 'lr': 0.008193083291227327, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.023688841291750987, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.45
lr:  0.009877950849732682
weight_decay:  0.019729669471726875
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.253281716024503
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 91.67
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.9369147601537406
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 68.70
Split: 01, Run: 03
None time:  2.8504026520531625
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 90.00
   Final Test: 67.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7233545309863985
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.40
Split: 02, Run: 02
None time:  1.2039793969597667
None Run 05:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.50
Split: 02, Run: 03
None time:  1.7358291919808835
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.70
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2340949710924178
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.30
Split: 03, Run: 02
None time:  2.180901843123138
None Run 08:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.60
Split: 03, Run: 03
None time:  2.572026423178613
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.80
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.0249259718693793
None Run 10:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 64.90
Split: 04, Run: 02
None time:  2.6374134810175747
None Run 11:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 65.50
Split: 04, Run: 03
None time:  1.9445565950591117
None Run 12:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 64.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.6982941660098732
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 70.50
Split: 05, Run: 02
None time:  2.2087684138678014
None Run 14:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 69.80
Split: 05, Run: 03
None time:  1.8582885621581227
None Run 15:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.175552723929286
None Run 16:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 93.33
   Final Test: 69.20
Split: 06, Run: 02
None time:  1.2696788241155446
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 64.30
Split: 06, Run: 03
None time:  2.069212351925671
None Run 18:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 95.00
   Final Test: 59.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0653368870262057
None Run 19:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 64.40
Split: 07, Run: 02
None time:  2.0007240590639412
None Run 20:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 90.00
   Final Test: 65.60
Split: 07, Run: 03
None time:  2.3142667410429567
None Run 21:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 64.20
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.3812798839062452
None Run 22:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.20
Split: 08, Run: 02
None time:  2.557873758021742
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 69.60
Split: 08, Run: 03
None time:  2.666623743949458
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 69.00
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.473939022049308
None Run 25:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 88.33
   Final Test: 72.00
Split: 09, Run: 02
None time:  3.033238328061998
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 71.30
Split: 09, Run: 03
None time:  1.7797376138623804
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 69.10
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2277790990192443
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.80
Split: 10, Run: 02
None time:  1.1620553259272128
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.90
Split: 10, Run: 03
None time:  2.3146919158753008
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 64.80
run time now: 4.74489951133728
total time:  63.73731655604206
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.39 ± 2.10
  Final Train: 96.56 ± 3.69
   Final Test: 66.85 ± 2.96
best run test_acc: 68.11000061035156
[I 2023-06-12 00:51:11,381] Trial 129 finished with value: 68.3933334350586 and parameters: {'Fwd': 0.05510991315982069, 'K': 3, 'alpha': 0.45, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.6615034946492013, 'loop': 2, 'loss': 'CE', 'lr': 0.009877950849732682, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.019729669471726875, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.00938616795955229
weight_decay:  0.018716626948469886
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2070114340167493
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 91.67
   Final Test: 67.60
Split: 01, Run: 02
None time:  4.8953285361640155
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 86.67
   Final Test: 67.80
Split: 01, Run: 03
None time:  2.562184632057324
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 95.00
   Final Test: 68.10
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.239001388894394
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 02
None time:  2.6064086880069226
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 03
None time:  2.063779851188883
None Run 06:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.40
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8066056431271136
None Run 07:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.50
Split: 03, Run: 02
None time:  2.0067528020590544
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 62.20
Split: 03, Run: 03
None time:  1.2670670920051634
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6915380449499935
None Run 10:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.30
Split: 04, Run: 02
None time:  2.2326191291213036
None Run 11:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 65.20
Split: 04, Run: 03
None time:  2.371460256166756
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 64.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.194401326123625
None Run 13:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 71.50
Split: 05, Run: 02
None time:  1.5545444111339748
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.70
Split: 05, Run: 03
None time:  1.8527952379081398
None Run 15:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2155713811516762
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 62.90
Split: 06, Run: 02
None time:  1.8773213308304548
None Run 17:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 67.40
Split: 06, Run: 03
None time:  1.2933246230240911
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.076512190978974
None Run 19:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 62.80
Split: 07, Run: 02
None time:  2.1014148890972137
None Run 20:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 64.30
Split: 07, Run: 03
None time:  2.2931465439032763
None Run 21:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 62.70
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.42361659090966
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 68.50
Split: 08, Run: 02
None time:  2.448847798863426
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.40
Split: 08, Run: 03
None time:  2.192887564189732
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 69.20
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.509838688885793
None Run 25:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 71.20
Split: 09, Run: 02
None time:  2.6934318030253053
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 71.20
Split: 09, Run: 03
None time:  2.17074519302696
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 71.90
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3840577478986233
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 02
None time:  1.0753645491786301
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 63.80
Split: 10, Run: 03
None time:  2.352342266123742
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 64.50
run time now: 4.855806112289429
total time:  64.92435990599915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.64 ± 2.01
  Final Train: 96.94 ± 3.25
   Final Test: 66.69 ± 3.25
best run test_acc: 67.45000457763672
[I 2023-06-12 00:52:16,810] Trial 130 finished with value: 68.63999938964844 and parameters: {'Fwd': 0.05476989417489757, 'K': 4, 'alpha': 0.55, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.6324527893938807, 'loop': 2, 'loss': 'CE', 'lr': 0.00938616795955229, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.018716626948469886, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.009815609674971169
weight_decay:  0.018788534272403637
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1647328219842166
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 67.80
Split: 01, Run: 02
None time:  1.9936353659722954
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 95.00
   Final Test: 64.80
Split: 01, Run: 03
None time:  2.2251709781121463
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 67.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5555294170044363
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.10
Split: 02, Run: 02
None time:  2.8140295511111617
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.30
Split: 02, Run: 03
None time:  1.1506712320260704
None Run 06:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.3797353010158986
None Run 07:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 66.10
Split: 03, Run: 02
None time:  1.902986892964691
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 03
None time:  2.4034250278491527
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7469062299933285
None Run 10:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.30
Split: 04, Run: 02
None time:  1.7761849800590426
None Run 11:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 64.20
Split: 04, Run: 03
None time:  2.4162704388145357
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 91.67
   Final Test: 65.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.347185489954427
None Run 13:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 70.20
Split: 05, Run: 02
None time:  1.637097794096917
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 71.20
Split: 05, Run: 03
None time:  1.5653117110487074
None Run 15:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.20
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.1243730888236314
None Run 16:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 65.10
Split: 06, Run: 02
None time:  1.365319113014266
None Run 17:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.80
Split: 06, Run: 03
None time:  1.1598631171509624
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 65.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.3665719679556787
None Run 19:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 64.00
Split: 07, Run: 02
None time:  2.7816978921182454
None Run 20:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 64.10
Split: 07, Run: 03
None time:  2.5091879381798208
None Run 21:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 65.00
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.233964442042634
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 69.30
Split: 08, Run: 02
None time:  2.693592534167692
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 95.00
   Final Test: 69.30
Split: 08, Run: 03
None time:  2.3663913710042834
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 69.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.786633081967011
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.40
Split: 09, Run: 02
None time:  2.498891440918669
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 72.30
Split: 09, Run: 03
None time:  2.514817717950791
None Run 27:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 71.30
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2934688800014555
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.30
Split: 10, Run: 02
None time:  1.3278674359899014
None Run 29:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 60.80
Split: 10, Run: 03
None time:  1.36362996394746
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 65.00
run time now: 4.037186145782471
total time:  61.74370840494521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.50 ± 1.86
  Final Train: 97.83 ± 2.52
   Final Test: 66.78 ± 2.88
best run test_acc: 67.5999984741211
[I 2023-06-12 00:53:19,095] Trial 131 finished with value: 68.5 and parameters: {'Fwd': 0.06019363019460409, 'K': 4, 'alpha': 0.55, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.885523170476454, 'loop': 2, 'loss': 'CE', 'lr': 0.009815609674971169, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.018788534272403637, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.00910438531123707
weight_decay:  0.012192897304310554
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3910191180184484
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 91.67
   Final Test: 67.40
Split: 01, Run: 02
None time:  2.849740848876536
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  2.4718741960823536
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 66.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8049804880283773
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.20
Split: 02, Run: 02
None time:  2.3146703660022467
None Run 05:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.30
Split: 02, Run: 03
None time:  2.16531324503012
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.30
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.2163623820524663
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.90
Split: 03, Run: 02
None time:  2.0000837550032884
None Run 08:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.20
Split: 03, Run: 03
None time:  1.9054250149056315
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.20
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.051668174797669
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.40
Split: 04, Run: 02
None time:  2.1322522137779742
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 63.40
Split: 04, Run: 03
None time:  2.2302592978812754
None Run 12:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 95.00
   Final Test: 64.00
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.115020771045238
None Run 13:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 70.90
Split: 05, Run: 02
None time:  1.88336437381804
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 70.90
Split: 05, Run: 03
None time:  2.310454570921138
None Run 15:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.60
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.706222916021943
None Run 16:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 65.50
Split: 06, Run: 02
None time:  2.604770732112229
None Run 17:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 93.33
   Final Test: 68.50
Split: 06, Run: 03
None time:  3.2902159569785
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 66.00
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.1780284959822893
None Run 19:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 64.00
Split: 07, Run: 02
None time:  2.5183826761785895
None Run 20:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 65.20
Split: 07, Run: 03
None time:  2.0751161710359156
None Run 21:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 66.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.5801451879087836
None Run 22:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 69.60
Split: 08, Run: 02
None time:  2.558146466035396
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 68.90
Split: 08, Run: 03
None time:  2.589799136854708
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 69.80
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.1409471528604627
None Run 25:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 72.60
Split: 09, Run: 02
None time:  2.5757255780044943
None Run 26:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 71.00
Split: 09, Run: 03
None time:  2.795070179970935
None Run 27:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 71.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3521684689912945
None Run 28:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.30
Split: 10, Run: 02
None time:  1.374400976113975
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.80
Split: 10, Run: 03
None time:  2.9237968418747187
None Run 30:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 64.70
run time now: 5.699599981307983
total time:  69.48914161906578
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.65 ± 1.83
  Final Train: 96.83 ± 2.81
   Final Test: 67.13 ± 2.83
best run test_acc: 68.08999633789062
[I 2023-06-12 00:54:29,083] Trial 132 finished with value: 68.65333557128906 and parameters: {'Fwd': 0.05873480312756382, 'K': 4, 'alpha': 0.55, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 3.686994570689285, 'loop': 2, 'loss': 'CE', 'lr': 0.00910438531123707, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.012192897304310554, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.008976028359294553
weight_decay:  0.012736641433087715
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5994751600082964
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 88.33
   Final Test: 68.10
Split: 01, Run: 02
None time:  2.822122653014958
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 80.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.0330088508781046
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 86.67
   Final Test: 68.70
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3278906939085573
None Run 04:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.60
Split: 02, Run: 02
None time:  2.5343012039083987
None Run 05:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.90
Split: 02, Run: 03
None time:  2.30960019887425
None Run 06:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 65.60
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0288879971485585
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 98.33
   Final Test: 67.40
Split: 03, Run: 02
None time:  2.763207962969318
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 91.67
   Final Test: 65.60
Split: 03, Run: 03
None time:  1.4052937950473279
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.50
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.537059945985675
None Run 10:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 83.33
   Final Test: 65.40
Split: 04, Run: 02
None time:  2.670931210042909
None Run 11:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 81.67
   Final Test: 63.30
Split: 04, Run: 03
None time:  2.3457323980983347
None Run 12:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 80.00
   Final Test: 54.40
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8760288339108229
None Run 13:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 63.10
Split: 05, Run: 02
None time:  2.335072454996407
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 70.80
Split: 05, Run: 03
None time:  2.50761096784845
None Run 15:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 71.30
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8530524871312082
None Run 16:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 57.90
Split: 06, Run: 02
None time:  0.8917098268866539
None Run 17:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 58.30
Split: 06, Run: 03
None time:  0.8584268670529127
None Run 18:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 57.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8134808680042624
None Run 19:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 55.50
Split: 07, Run: 02
None time:  2.226750552887097
None Run 20:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 86.67
   Final Test: 65.70
Split: 07, Run: 03
None time:  0.9327575890347362
None Run 21:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 56.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8947946289554238
None Run 22:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 61.60
Split: 08, Run: 02
None time:  0.9236285060178488
None Run 23:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 60.90
Split: 08, Run: 03
None time:  2.3936368781141937
None Run 24:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 88.33
   Final Test: 66.70
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.989940679864958
None Run 25:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 91.67
   Final Test: 72.40
Split: 09, Run: 02
None time:  2.697438851930201
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 88.33
   Final Test: 71.90
Split: 09, Run: 03
None time:  1.908346327021718
None Run 27:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 71.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.484319879906252
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 65.00
Split: 10, Run: 02
None time:  0.8377817289438099
None Run 29:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.30
Split: 10, Run: 03
None time:  3.529409575043246
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 65.70
run time now: 5.8987016677856445
total time:  58.61837303289212
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.48 ± 4.55
  Final Train: 93.78 ± 6.69
   Final Test: 64.81 ± 5.14
best run test_acc: 67.06999969482422
[I 2023-06-12 00:55:28,166] Trial 133 finished with value: 65.4800033569336 and parameters: {'Fwd': 0.042037441879125066, 'K': 4, 'alpha': 0.55, 'dropout': 0.2, 'gnnepoch': 10, 'lambda1': 0.8500000000000001, 'lambda2': 3.932149522872876, 'loop': 2, 'loss': 'CE', 'lr': 0.008976028359294553, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.012736641433087715, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.00840592201058188
weight_decay:  0.011057264962710754
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.649208314018324
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 02
None time:  2.2922606060747057
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  2.9212550551164895
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 67.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.6516107860952616
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.20
Split: 02, Run: 02
None time:  2.7755005140788853
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.90
Split: 02, Run: 03
None time:  2.793526788940653
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3699066489934921
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 02
None time:  2.6222632490098476
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 95.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  1.847404019907117
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.469295887975022
None Run 10:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 95.00
   Final Test: 64.00
Split: 04, Run: 02
None time:  2.6284070580732077
None Run 11:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 65.70
Split: 04, Run: 03
None time:  2.3619619549717754
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 91.67
   Final Test: 65.10
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.9310980890877545
None Run 13:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 95.00
   Final Test: 71.00
Split: 05, Run: 02
None time:  1.9217681589070708
None Run 14:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 71.50
Split: 05, Run: 03
None time:  1.9321235991083086
None Run 15:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 71.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.4196452680043876
None Run 16:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 91.67
   Final Test: 67.40
Split: 06, Run: 02
None time:  2.243947400012985
None Run 17:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 67.50
Split: 06, Run: 03
None time:  1.9145754240453243
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.10
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9821200771257281
None Run 19:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 64.90
Split: 07, Run: 02
None time:  3.072974134935066
None Run 20:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 58.90
Split: 07, Run: 03
None time:  2.3582408279180527
None Run 21:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 91.67
   Final Test: 65.50
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.576034569879994
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 68.60
Split: 08, Run: 02
None time:  2.892458352027461
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 98.33
   Final Test: 69.50
Split: 08, Run: 03
None time:  2.6997571429237723
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 69.50
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.948649415979162
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.00
   Final Test: 70.60
Split: 09, Run: 02
None time:  2.1153735858388245
None Run 26:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.20
Split: 09, Run: 03
None time:  3.5695901529397815
None Run 27:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 70.70
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.18908606399782
None Run 28:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.10
Split: 10, Run: 02
None time:  2.8562161300797015
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 65.90
Split: 10, Run: 03
None time:  1.367595441872254
None Run 30:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.80
run time now: 5.460330247879028
total time:  72.68303322489373
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.45 ± 2.46
  Final Train: 96.94 ± 3.10
   Final Test: 66.88 ± 2.94
best run test_acc: 67.94000244140625
[I 2023-06-12 00:56:41,485] Trial 134 finished with value: 68.44666290283203 and parameters: {'Fwd': 0.05741609839084528, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.8, 'lambda2': 4.298813849715796, 'loop': 2, 'loss': 'CE', 'lr': 0.00840592201058188, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.011057264962710754, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.00994921233130003
weight_decay:  0.009685960664376408
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.271256348118186
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 91.67
   Final Test: 66.70
Split: 01, Run: 02
None time:  2.3050605261232704
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 67.70
Split: 01, Run: 03
None time:  2.452225279994309
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 88.33
   Final Test: 67.90
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.208280842984095
None Run 04:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.60
Split: 02, Run: 02
None time:  2.1841123779304326
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.70
Split: 02, Run: 03
None time:  2.439070565858856
None Run 06:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 66.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0216782190836966
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 95.00
   Final Test: 64.80
Split: 03, Run: 02
None time:  3.0750434130895883
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 62.10
Split: 03, Run: 03
None time:  1.4305411039385945
None Run 09:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.90
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.032081271056086
None Run 10:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 63.60
Split: 04, Run: 02
None time:  3.6726978889200836
None Run 11:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 85.00
   Final Test: 65.80
Split: 04, Run: 03
None time:  1.7223719619214535
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.3869058350101113
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 71.00
Split: 05, Run: 02
None time:  1.7840097229927778
None Run 14:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 70.70
Split: 05, Run: 03
None time:  1.6420352850109339
None Run 15:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 70.10
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.5941795201506466
None Run 16:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 65.80
Split: 06, Run: 02
None time:  1.4480404250789434
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 63.40
Split: 06, Run: 03
None time:  1.8089700588025153
None Run 18:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.00
   Final Test: 65.50
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8693308571819216
None Run 19:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 63.30
Split: 07, Run: 02
None time:  1.9761285609565675
None Run 20:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 64.50
Split: 07, Run: 03
None time:  1.8348840849939734
None Run 21:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 63.60
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.1835802101995796
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 68.20
Split: 08, Run: 02
None time:  2.2672228070441633
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 95.00
   Final Test: 68.50
Split: 08, Run: 03
None time:  2.4667787968646735
None Run 24:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 86.67
   Final Test: 67.40
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.909146165009588
None Run 25:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 91.67
   Final Test: 69.90
Split: 09, Run: 02
None time:  2.552228471962735
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 70.60
Split: 09, Run: 03
None time:  3.045642828103155
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 70.00
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.2566375450696796
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.60
Split: 10, Run: 02
None time:  1.9155477220192552
None Run 29:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.20
Split: 10, Run: 03
None time:  2.0403137740213424
None Run 30:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.00
run time now: 6.267463445663452
total time:  67.98304418311454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.16 ± 1.97
  Final Train: 95.28 ± 3.92
   Final Test: 66.33 ± 2.85
best run test_acc: 67.30999755859375
[I 2023-06-12 00:57:50,064] Trial 135 finished with value: 68.16000366210938 and parameters: {'Fwd': 0.028268951613188778, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.1, 'gnnepoch': 20, 'lambda1': 0.8, 'lambda2': 4.277143048968826, 'loop': 2, 'loss': 'CE', 'lr': 0.00994921233130003, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.009685960664376408, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.65
lr:  0.008913235809995238
weight_decay:  0.011998464843686253
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8543445589020848
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 55.60
Split: 01, Run: 02
None time:  0.8690161930862814
None Run 02:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 57.50
Split: 01, Run: 03
None time:  0.884729536017403
None Run 03:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 60.80
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8762850479688495
None Run 04:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.10
Split: 02, Run: 02
None time:  0.8785148449242115
None Run 05:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 49.80
Split: 02, Run: 03
None time:  0.9006876319181174
None Run 06:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 59.50
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8722730830777436
None Run 07:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 52.70
Split: 03, Run: 02
None time:  0.8604211560450494
None Run 08:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 53.10
Split: 03, Run: 03
None time:  0.8807022620458156
None Run 09:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 54.60
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8763614310882986
None Run 10:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 49.80
Split: 04, Run: 02
None time:  0.8797166510485113
None Run 11:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 42.50
Split: 04, Run: 03
None time:  0.911537199979648
None Run 12:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 45.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9061170928180218
None Run 13:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 02
None time:  0.8846186439041048
None Run 14:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 60.20
Split: 05, Run: 03
None time:  0.8947973060421646
None Run 15:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.00
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.88055918389
None Run 16:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 58.30
Split: 06, Run: 02
None time:  0.8648813830222934
None Run 17:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 53.70
Split: 06, Run: 03
None time:  0.8878462200518698
None Run 18:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 53.90
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9148497330024838
None Run 19:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 51.80
Split: 07, Run: 02
None time:  0.8978771772235632
None Run 20:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 57.10
Split: 07, Run: 03
None time:  0.8899706311058253
None Run 21:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8702132250182331
None Run 22:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 63.60
Split: 08, Run: 02
None time:  0.7637849480379373
None Run 23:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 56.00
Split: 08, Run: 03
None time:  0.8890304348897189
None Run 24:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 49.30
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8776804830413312
None Run 25:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 55.80
Split: 09, Run: 02
None time:  0.8971983701922
None Run 26:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 62.90
Split: 09, Run: 03
None time:  0.8905858211219311
None Run 27:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 59.20
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8757257831748575
None Run 28:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.30
Split: 10, Run: 02
None time:  0.8688441310077906
None Run 29:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.80
Split: 10, Run: 03
None time:  0.9069263769779354
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 62.30
run time now: 2.696491241455078
total time:  27.600854816148058
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.07 ± 5.92
  Final Train: 100.00 ± 0.00
   Final Test: 56.32 ± 5.77
best run test_acc: 59.59999465942383
[I 2023-06-12 00:58:18,095] Trial 136 finished with value: 56.07333755493164 and parameters: {'Fwd': 0.056962969595738405, 'K': 5, 'alpha': 0.65, 'dropout': 0.2, 'gnnepoch': 10, 'lambda1': 0.8, 'lambda2': 3.9404351550063343, 'loop': 2, 'loss': 'CE', 'lr': 0.008913235809995238, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.011998464843686253, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.6000000000000001
lr:  0.008271380426470694
weight_decay:  0.0159239776794715
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2495985100977123
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 91.67
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.8660972740035504
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 93.33
   Final Test: 64.10
Split: 01, Run: 03
None time:  2.342399541987106
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 91.67
   Final Test: 68.00
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1403295369818807
None Run 04:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 02
None time:  2.003203656990081
None Run 05:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.20
Split: 02, Run: 03
None time:  2.6244665181729943
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 67.90
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2355530480854213
None Run 07:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 61.50
Split: 03, Run: 02
None time:  1.727852761046961
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 03
None time:  1.424338635057211
None Run 09:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.00
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.2436194019392133
None Run 10:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 66.30
Split: 04, Run: 02
None time:  2.156522343866527
None Run 11:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 63.20
Split: 04, Run: 03
None time:  2.4768093060702085
None Run 12:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 65.80
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.887190756155178
None Run 13:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 71.60
Split: 05, Run: 02
None time:  2.3529475908726454
None Run 14:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 71.30
Split: 05, Run: 03
None time:  2.259527918882668
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 70.50
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.1941064009442925
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 95.00
   Final Test: 63.20
Split: 06, Run: 02
None time:  2.1859173751436174
None Run 17:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 64.30
Split: 06, Run: 03
None time:  1.3136607320047915
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.186594809172675
None Run 19:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 63.80
Split: 07, Run: 02
None time:  2.4083348179701716
None Run 20:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 90.00
   Final Test: 64.40
Split: 07, Run: 03
None time:  2.2432199029717594
None Run 21:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 88.33
   Final Test: 64.40
len(train) 60
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.599321114132181
None Run 22:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 68.40
Split: 08, Run: 02
None time:  2.8118718680925667
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 98.33
   Final Test: 68.00
Split: 08, Run: 03
None time:  2.7492101390380412
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 68.10
len(train) 60
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.951209609862417
None Run 25:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 88.33
   Final Test: 70.80
Split: 09, Run: 02
None time:  2.507809794973582
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 98.33
   Final Test: 68.20
Split: 09, Run: 03
None time:  2.425749901216477
None Run 27:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 71.60
len(train) 60
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.148535849992186
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 64.20
Split: 10, Run: 02
None time:  1.9601584440097213
None Run 29:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 95.00
   Final Test: 64.90
Split: 10, Run: 03
None time:  1.2168552230577916
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.10
run time now: 5.3798582553863525
total time:  66.23599333292805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.98 ± 2.53
  Final Train: 95.28 ± 3.77
   Final Test: 66.28 ± 3.08
best run test_acc: 67.2800064086914
[I 2023-06-12 00:59:24,791] Trial 137 finished with value: 67.9800033569336 and parameters: {'Fwd': 0.03353961021403263, 'K': 3, 'alpha': 0.6000000000000001, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 4.221331770525997, 'loop': 2, 'loss': 'CE', 'lr': 0.008271380426470694, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0159239776794715, 'weightedloss': True}. Best is trial 75 with value: 69.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.00710879425179986
weight_decay:  0.017688414255723598
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 60
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2904155789874494
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 91.67
   Final Test: 65.70
Split: 01, Run: 02
None time:  2.0342990388162434
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 88.33
   Final Test: 67.80
Split: 01, Run: 03
None time:  2.272255926160142
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 67.60
len(train) 60
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1193150759208947
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.10
Split: 02, Run: 02
None time:  2.751068254932761
None Run 05:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 03
None time:  1.8711485711392015
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.10
len(train) 60
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.754878804087639
None Run 07:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 98.33
   Final Test: 63.90
Split: 03, Run: 02
None time:  1.438342264154926
None Run 08:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.10
Split: 03, Run: 03
None time:  2.172629321925342
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 98.33
   Final Test: 65.70
len(train) 60
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.5545086429920048
None Run 10:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 66.00
Split: 04, Run: 02
None time:  2.409558366984129
None Run 11:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 64.80
Split: 04, Run: 03
None time:  2.3187012439593673
None Run 12:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.60
len(train) 60
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.3144369751680642
None Run 13:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 69.90
Split: 05, Run: 02
None time:  2.16202992410399
None Run 14:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 95.00
   Final Test: 71.40
Split: 05, Run: 03
None time:  1.8282281069550663
None Run 15:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 70.80
len(train) 60
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5302356779575348
None Run 16:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.30
Split: 06, Run: 02
None time:  1.4699477329850197
None Run 17:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 62.50
Split: 06, Run: 03
None time:  1.807155823102221
None Run 18:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 63.80
len(train) 60
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(60, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.6461130150128156
None Run 19:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 63.60
Split: 07, Run: 02
None time:  2.035885008983314
None Run 20:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 64.00
