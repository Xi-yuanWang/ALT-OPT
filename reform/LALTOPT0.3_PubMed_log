[I 2023-06-12 00:12:20,338] A new study created in RDB with name: PubMed_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.75
lr:  0.00032654476726938194
weight_decay:  0.00048746467650878487
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.264595218002796
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  0.7833468930330127
None Run 02:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 98.33
   Final Test: 75.20
Split: 01, Run: 03
None time:  0.7352364251855761
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.00
run time now: 3.8283615112304688
total time:  5.560311655048281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.67 ± 3.56
  Final Train: 99.44 ± 0.96
   Final Test: 73.50 ± 4.59
[I 2023-06-12 00:12:26,621] Trial 0 finished with value: 76.66666412353516 and parameters: {'Fwd': 0.0480845783760593, 'K': 2, 'alpha': 0.75, 'dropout': 0.1, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 2.972322664282773, 'loop': 1, 'loss': 'CE', 'lr': 0.00032654476726938194, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00048746467650878487, 'weightedloss': False}. Best is trial 0 with value: 76.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0009439725794072175
weight_decay:  7.111924837027935e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.102363830897957
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 02
None time:  1.2480558368843049
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.109355852007866
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 72.80
run time now: 3.5081684589385986
total time:  3.551564493915066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.73 ± 1.89
  Final Train: 100.00 ± 0.00
   Final Test: 72.57 ± 1.56
[I 2023-06-12 00:12:30,549] Trial 1 finished with value: 74.73333740234375 and parameters: {'Fwd': 1.769246504131871e-05, 'K': 6, 'alpha': 0.9, 'dropout': 0.30000000000000004, 'gnnepoch': 20, 'lambda1': 0.35000000000000003, 'lambda2': 1.938302960530316, 'loop': 2, 'loss': 'CE', 'lr': 0.0009439725794072175, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.111924837027935e-05, 'weightedloss': False}. Best is trial 0 with value: 76.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.008545168609968578
weight_decay:  2.335836356434826e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5480213689152151
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.4201662910636514
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.6783006978221238
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.50
run time now: 4.6843955516815186
total time:  4.723289400804788
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.70 ± 0.35
[I 2023-06-12 00:12:35,796] Trial 2 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.00036235314880801804, 'K': 2, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 6.310158358622018, 'loop': 2, 'loss': 'MSE', 'lr': 0.008545168609968578, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.335836356434826e-05, 'weightedloss': False}. Best is trial 2 with value: 78.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0015013796689179381
weight_decay:  0.0032289258400152484
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6379041678737849
None Run 01:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 39.20
Split: 01, Run: 02
None time:  0.5077273899223655
None Run 02:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.90
Split: 01, Run: 03
None time:  0.46612162492237985
None Run 03:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 62.20
run time now: 1.6915233135223389
total time:  1.8557301068212837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.93 ± 11.04
  Final Train: 100.00 ± 0.00
   Final Test: 53.43 ± 12.44
[I 2023-06-12 00:12:38,141] Trial 3 finished with value: 54.93333435058594 and parameters: {'Fwd': 0.056737192279713654, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.45, 'lambda2': 4.620157390623737, 'loop': 1, 'loss': 'CE', 'lr': 0.0015013796689179381, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0032289258400152484, 'weightedloss': True}. Best is trial 2 with value: 78.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.05
lr:  0.0014644840903063206
weight_decay:  3.247769436607129e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.05213882192038
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 02
None time:  2.331137086963281
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.30
Split: 01, Run: 03
None time:  2.0439463590737432
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.20
run time now: 6.469105958938599
total time:  6.521939005004242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.13 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 74.83 ± 1.01
[I 2023-06-12 00:12:45,041] Trial 4 finished with value: 76.13333129882812 and parameters: {'Fwd': 0.00027839105684213583, 'K': 6, 'alpha': 0.05, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.9500000000000001, 'lambda2': 2.306342162430748, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014644840903063206, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.247769436607129e-05, 'weightedloss': False}. Best is trial 2 with value: 78.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.003311360576498977
weight_decay:  8.733555308008001e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7314667801838368
None Run 01:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 02
None time:  2.180079984012991
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 03
None time:  1.8756938281003386
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 5.827571153640747
total time:  5.876336346147582
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 72.23 ± 1.25
[I 2023-06-12 00:12:51,280] Trial 5 finished with value: 74.46666717529297 and parameters: {'Fwd': 0.013944777504523852, 'K': 6, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 20, 'lambda1': 0.30000000000000004, 'lambda2': 4.4379966964741, 'loop': 1, 'loss': 'MSE', 'lr': 0.003311360576498977, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.733555308008001e-06, 'weightedloss': True}. Best is trial 2 with value: 78.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.6000000000000001
lr:  0.007132411991631096
weight_decay:  3.9841938014696096e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8451998971868306
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  0.9511750359088182
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.062813611002639
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 79.60
run time now: 2.8966777324676514
total time:  2.9393440829589963
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.42
  Final Train: 99.44 ± 0.96
   Final Test: 78.17 ± 1.25
[I 2023-06-12 00:12:54,587] Trial 6 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.0032035250488428113, 'K': 3, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 6.024898028191629, 'loop': 1, 'loss': 'CE', 'lr': 0.007132411991631096, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.9841938014696096e-05, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0012141794555542652
weight_decay:  2.6033382555558733e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1258064787834883
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02
None time:  2.0545468381606042
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 03
None time:  2.1343828230164945
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 72.70
run time now: 6.3550124168396
total time:  6.394947847817093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 73.73 ± 1.11
[I 2023-06-12 00:13:01,462] Trial 7 finished with value: 76.46666717529297 and parameters: {'Fwd': 0.0005128378288837541, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 7.041253472380058, 'loop': 2, 'loss': 'MSE', 'lr': 0.0012141794555542652, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6033382555558733e-05, 'weightedloss': False}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.0018857851709247362
weight_decay:  0.006268049889196401
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3677914729341865
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 98.33
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.1437976420857012
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.5881807659752667
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 91.67
   Final Test: 78.20
run time now: 4.140732288360596
total time:  4.189389114966616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.87 ± 0.61
  Final Train: 96.11 ± 3.85
   Final Test: 78.03 ± 0.47
[I 2023-06-12 00:13:06,008] Trial 8 finished with value: 78.86666107177734 and parameters: {'Fwd': 8.01930614415316e-06, 'K': 6, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.235636543467152, 'loop': 1, 'loss': 'CE', 'lr': 0.0018857851709247362, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006268049889196401, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.00017266350934619102
weight_decay:  0.0009745399544533354
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4786242609843612
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 02
None time:  1.381341647123918
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  1.4946898808702826
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.20
run time now: 4.427506923675537
total time:  4.496765926014632
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 72.20 ± 0.00
[I 2023-06-12 00:13:10,963] Trial 9 finished with value: 73.0 and parameters: {'Fwd': 2.570120659695285e-05, 'K': 10, 'alpha': 0.05, 'dropout': 0.0, 'gnnepoch': 110, 'lambda1': 0.0, 'lambda2': 3.9595329204510845, 'loop': 0, 'loss': 'MSE', 'lr': 0.00017266350934619102, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0009745399544533354, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.00897366878869034
weight_decay:  1.2483457632878125e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9988596090115607
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  1.0447523391339928
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 03
None time:  1.100713472114876
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 98.33
   Final Test: 77.40
run time now: 3.189584493637085
total time:  3.2461371009703726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 1.60
  Final Train: 99.44 ± 0.96
   Final Test: 76.73 ± 1.07
[I 2023-06-12 00:13:14,715] Trial 10 finished with value: 78.79999542236328 and parameters: {'Fwd': 1.0399838682695313e-06, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 9.562411062065095, 'loop': 0, 'loss': 'CE', 'lr': 0.00897366878869034, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2483457632878125e-06, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.003949083687408464
weight_decay:  0.04002033269584228
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2457255800254643
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 96.67
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.2655376000329852
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 71.40
Split: 01, Run: 03
None time:  1.2486763219349086
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 75.80
run time now: 3.803647994995117
total time:  3.842749339994043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.33 ± 4.16
  Final Train: 97.78 ± 0.96
   Final Test: 75.13 ± 3.45
[I 2023-06-12 00:13:18,985] Trial 11 finished with value: 77.33333587646484 and parameters: {'Fwd': 0.00922218868291405, 'K': 4, 'alpha': 0.55, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.9283858634810045, 'loop': 0, 'loss': 'CE', 'lr': 0.003949083687408464, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04002033269584228, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0035769534626207407
weight_decay:  0.0076221953111678285
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1332712741568685
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.1338877251837403
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.0109272338449955
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 96.67
   Final Test: 79.20
run time now: 3.7233309745788574
total time:  3.791302477940917
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.58
  Final Train: 97.78 ± 0.96
   Final Test: 78.43 ± 0.68
[I 2023-06-12 00:13:23,385] Trial 12 finished with value: 79.33333587646484 and parameters: {'Fwd': 0.00405470350029055, 'K': 4, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 0.16357691131766128, 'loop': 1, 'loss': 'CE', 'lr': 0.0035769534626207407, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0076221953111678285, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.004752721088070968
weight_decay:  0.06415131258288134
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2155249840579927
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 98.33
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.2648840809706599
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 95.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.1584748281165957
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 79.00
run time now: 3.680987596511841
total time:  3.7234257489908487
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.92
  Final Train: 97.22 ± 1.92
   Final Test: 78.43 ± 1.63
[I 2023-06-12 00:13:27,588] Trial 13 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.0036527090162542983, 'K': 4, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 0.09267866991195994, 'loop': 1, 'loss': 'CE', 'lr': 0.004752721088070968, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06415131258288134, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9500000000000001
lr:  0.005906373174080542
weight_decay:  0.05354564918216036
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.615935605019331
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  0.7514740771148354
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 96.67
   Final Test: 74.00
Split: 01, Run: 03
None time:  0.610616953112185
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 98.33
   Final Test: 73.60
run time now: 2.021515369415283
total time:  2.063000117894262
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.00 ± 1.78
  Final Train: 98.33 ± 1.67
   Final Test: 75.00 ± 2.09
[I 2023-06-12 00:13:30,166] Trial 14 finished with value: 77.0 and parameters: {'Fwd': 0.0024202423054142156, 'K': 4, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 50, 'lambda1': 0.6000000000000001, 'lambda2': 6.010984900638947, 'loop': 0, 'loss': 'CE', 'lr': 0.005906373174080542, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.05354564918216036, 'weightedloss': True}. Best is trial 6 with value: 79.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.8
lr:  0.009476881968628472
weight_decay:  0.00018465109208052995
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0208567790687084
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 77.90
Split: 01, Run: 02
None time:  0.991234719986096
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.0366992531344295
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 98.33
   Final Test: 79.10
run time now: 3.0903584957122803
total time:  3.1407932590227574
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 1.29
  Final Train: 98.89 ± 0.96
   Final Test: 78.83 ± 0.83
[I 2023-06-12 00:13:33,766] Trial 15 finished with value: 79.9333267211914 and parameters: {'Fwd': 0.002119632865370287, 'K': 4, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 0.08652340637796344, 'loop': 2, 'loss': 'CE', 'lr': 0.009476881968628472, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00018465109208052995, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.007919302764413338
weight_decay:  0.0001590543372528944
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8348064089659601
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  0.9271800329443067
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 95.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  0.6990584218874574
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 80.30
run time now: 2.513169527053833
total time:  2.5508672080468386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.87
  Final Train: 97.78 ± 2.55
   Final Test: 79.13 ± 1.85
[I 2023-06-12 00:13:36,732] Trial 16 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.0011465034807914942, 'K': 8, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 40, 'lambda1': 0.55, 'lambda2': 1.39335052610034, 'loop': 2, 'loss': 'CE', 'lr': 0.007919302764413338, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001590543372528944, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8500000000000001
lr:  0.009846207053115164
weight_decay:  0.00014484002347580943
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3927312530577183
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  0.42068156506866217
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.3868745199870318
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 1.2399795055389404
total time:  1.2785521179903299
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 68.30 ± 0.00
[I 2023-06-12 00:13:38,562] Trial 17 finished with value: 67.79999542236328 and parameters: {'Fwd': 0.020178738395149217, 'K': 5, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 0, 'lambda1': 0.8500000000000001, 'lambda2': 3.1206572164651383, 'loop': 2, 'loss': 'CE', 'lr': 0.009846207053115164, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014484002347580943, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.65
lr:  0.002445791632924412
weight_decay:  0.0004361025500934118
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0301532249432057
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 02
None time:  0.8643651930615306
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 03
None time:  0.9794053710065782
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 98.33
   Final Test: 74.50
run time now: 2.9135491847991943
total time:  2.9596102929208428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.53 ± 1.89
  Final Train: 99.44 ± 0.96
   Final Test: 74.80 ± 0.36
[I 2023-06-12 00:13:42,006] Trial 18 finished with value: 75.53333282470703 and parameters: {'Fwd': 0.0011997754492424583, 'K': 3, 'alpha': 0.65, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.64403125406762, 'loop': 2, 'loss': 'CE', 'lr': 0.002445791632924412, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0004361025500934118, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.005336424634415155
weight_decay:  3.685469348682709e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.254077098099515
None Run 01:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 96.67
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.2723876659292728
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  1.2004653059411794
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.60
run time now: 4.7643351554870605
total time:  4.807122848927975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.13 ± 1.33
  Final Train: 98.89 ± 1.92
   Final Test: 76.93 ± 1.14
[I 2023-06-12 00:13:47,238] Trial 19 finished with value: 78.13333129882812 and parameters: {'Fwd': 0.0708442210992038, 'K': 1, 'alpha': 0.25, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.303747330146811, 'loop': 2, 'loss': 'CE', 'lr': 0.005336424634415155, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.685469348682709e-06, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0025850726434257796
weight_decay:  9.976736117992343e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0858817829284817
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 02
None time:  0.9127869950607419
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 98.33
   Final Test: 77.30
Split: 01, Run: 03
None time:  0.9883940408471972
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 98.33
   Final Test: 78.60
run time now: 3.0294442176818848
total time:  3.071165452944115
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.27 ± 0.42
  Final Train: 98.89 ± 0.96
   Final Test: 76.83 ± 2.04
[I 2023-06-12 00:13:50,807] Trial 20 finished with value: 78.26667022705078 and parameters: {'Fwd': 0.00011046006518975485, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 3.1094216489026483, 'loop': 1, 'loss': 'CE', 'lr': 0.0025850726434257796, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.976736117992343e-05, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.005690559175339771
weight_decay:  0.00033230969988464994
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1208918569609523
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 98.33
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.1953422939404845
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 98.33
   Final Test: 77.10
Split: 01, Run: 03
None time:  1.0963270240463316
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
run time now: 3.491178035736084
total time:  3.560018545947969
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 1.33
  Final Train: 98.89 ± 0.96
   Final Test: 77.27 ± 0.76
[I 2023-06-12 00:13:54,897] Trial 21 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.003996008903715536, 'K': 3, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 0.1791402096590312, 'loop': 1, 'loss': 'CE', 'lr': 0.005690559175339771, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00033230969988464994, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.004904759506943063
weight_decay:  0.001366898718585204
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9780396199785173
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 98.33
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.0470297429710627
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.2195187320467085
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 98.33
   Final Test: 77.60
run time now: 3.285024404525757
total time:  3.337540736887604
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 0.35
  Final Train: 98.33 ± 0.00
   Final Test: 77.37 ± 0.49
[I 2023-06-12 00:13:58,670] Trial 22 finished with value: 78.5999984741211 and parameters: {'Fwd': 0.005552498471094549, 'K': 5, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 0.9050034146033017, 'loop': 1, 'loss': 'CE', 'lr': 0.004904759506943063, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001366898718585204, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8
lr:  0.00674856104463016
weight_decay:  0.03882729954737189
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8405980821698904
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  0.9566166799049824
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 03
None time:  0.9444694891571999
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 91.67
   Final Test: 79.90
run time now: 2.780543327331543
total time:  2.8256424099672586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 1.62
  Final Train: 97.22 ± 4.81
   Final Test: 77.40 ± 2.18
[I 2023-06-12 00:14:02,037] Trial 23 finished with value: 79.33333587646484 and parameters: {'Fwd': 0.0018086586668612566, 'K': 3, 'alpha': 0.8, 'dropout': 0.2, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 0.10651234332996719, 'loop': 1, 'loss': 'CE', 'lr': 0.00674856104463016, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03882729954737189, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.65
lr:  0.009787107557245784
weight_decay:  0.013652076736075545
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.001283124787733
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.1923184711486101
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 93.33
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.31093392893672
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 95.00
   Final Test: 79.10
run time now: 3.5385854244232178
total time:  3.585619636811316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.46
  Final Train: 95.56 ± 2.55
   Final Test: 77.97 ± 1.21
[I 2023-06-12 00:14:06,159] Trial 24 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.015420112578580768, 'K': 4, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 1.444858531702867, 'loop': 0, 'loss': 'CE', 'lr': 0.009787107557245784, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013652076736075545, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.65
lr:  0.009503400002407372
weight_decay:  5.604720017085051e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.119039046112448
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 96.67
   Final Test: 76.00
Split: 01, Run: 02
None time:  1.2813327740877867
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 95.00
   Final Test: 73.60
Split: 01, Run: 03
None time:  1.1948637710884213
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.30
run time now: 3.636268138885498
total time:  3.6793920439668
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 5.41
  Final Train: 97.22 ± 2.55
   Final Test: 72.63 ± 3.94
[I 2023-06-12 00:14:10,357] Trial 25 finished with value: 73.9333267211914 and parameters: {'Fwd': 0.01657000220895897, 'K': 5, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 1.6223303590060159, 'loop': 0, 'loss': 'CE', 'lr': 0.009503400002407372, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.604720017085051e-05, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.4
lr:  0.006926865860175819
weight_decay:  0.00019770944588629914
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.20% Test: 74.70%
Split: 01, Run: 01
None time:  1.4959780431818217
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.80% Test: 74.60%
Split: 01, Run: 02
None time:  1.3219954429659992
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.60% Test: 75.20%
Split: 01, Run: 03
None time:  1.6950189850758761
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.40
run time now: 4.55154013633728
total time:  4.589680498000234
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.20 ± 1.83
  Final Train: 100.00 ± 0.00
   Final Test: 74.33 ± 0.12
[I 2023-06-12 00:14:15,408] Trial 26 finished with value: 75.20000457763672 and parameters: {'Fwd': 0.02892036998516285, 'K': 3, 'alpha': 0.4, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 2.5447008637025825, 'loop': 0, 'loss': 'MSE', 'lr': 0.006926865860175819, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019770944588629914, 'weightedloss': False}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.009865573445555468
weight_decay:  0.0008045276856415803
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8660166871268302
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.5641282671131194
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.984634691150859
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 93.33
   Final Test: 77.40
run time now: 5.458789110183716
total time:  5.509733747923747
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.12
  Final Train: 96.67 ± 2.89
   Final Test: 77.20 ± 0.62
[I 2023-06-12 00:14:21,335] Trial 27 finished with value: 79.9333267211914 and parameters: {'Fwd': 0.007725869472169845, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 1.0895737131526633, 'loop': 0, 'loss': 'CE', 'lr': 0.009865573445555468, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0008045276856415803, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.006048400712647938
weight_decay:  0.000987759372566886
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.796554384054616
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 98.33
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.7156845950521529
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 98.33
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.209949275944382
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 96.67
   Final Test: 75.80
run time now: 4.765411615371704
total time:  4.813177094096318
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.00 ± 0.20
  Final Train: 97.78 ± 0.96
   Final Test: 76.80 ± 0.92
[I 2023-06-12 00:14:26,689] Trial 28 finished with value: 79.0 and parameters: {'Fwd': 0.008030092434368386, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 2.146029412193975, 'loop': 2, 'loss': 'CE', 'lr': 0.006048400712647938, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000987759372566886, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.0007539829131659433
weight_decay:  0.00030484347946210756
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.80% Test: 74.70%
Split: 01, Run: 01
None time:  2.5184131460264325
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 02
None time:  0.9597108559682965
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  1.3290152510162443
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.00
run time now: 4.845767259597778
total time:  4.896798599977046
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.53 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 73.27 ± 1.32
[I 2023-06-12 00:14:32,039] Trial 29 finished with value: 75.53333282470703 and parameters: {'Fwd': 0.08447590411852499, 'K': 2, 'alpha': 0.4, 'dropout': 0.0, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 3.2113282669544647, 'loop': 0, 'loss': 'CE', 'lr': 0.0007539829131659433, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00030484347946210756, 'weightedloss': False}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.75
lr:  0.004023141623081002
weight_decay:  0.0006383416694180418
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.005176005186513
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.9643010271247476
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 98.33
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.6839827408548445
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 95.00
   Final Test: 77.90
run time now: 5.728297710418701
total time:  5.763440074166283
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.12
  Final Train: 97.22 ± 1.92
   Final Test: 77.87 ± 0.15
[I 2023-06-12 00:14:38,268] Trial 30 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.007627089634551394, 'K': 3, 'alpha': 0.75, 'dropout': 0.2, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 0.8654866223175073, 'loop': 0, 'loss': 'CE', 'lr': 0.004023141623081002, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006383416694180418, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.65
lr:  0.00964740083431941
weight_decay:  0.0025269629849547677
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8606400289572775
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.7107481101993471
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 98.33
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.99821598501876
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 77.90
run time now: 5.610103130340576
total time:  5.649536586133763
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.12
  Final Train: 98.33 ± 0.00
   Final Test: 77.80 ± 0.36
[I 2023-06-12 00:14:44,388] Trial 31 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.030835953163513792, 'K': 4, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 1.4753540541882901, 'loop': 0, 'loss': 'CE', 'lr': 0.00964740083431941, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0025269629849547677, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.75
lr:  0.00734015854264449
weight_decay:  7.18594479560191e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.913388367043808
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.7312378319911659
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 98.33
   Final Test: 76.90
Split: 01, Run: 03
None time:  2.008132375078276
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 98.33
   Final Test: 78.10
run time now: 5.695281028747559
total time:  5.7385827580001205
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.35
  Final Train: 98.33 ± 0.00
   Final Test: 77.63 ± 0.64
[I 2023-06-12 00:14:50,659] Trial 32 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.014793056982009696, 'K': 5, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 0.9126326605909465, 'loop': 0, 'loss': 'CE', 'lr': 0.00734015854264449, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.18594479560191e-05, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.5
lr:  0.007117915902462968
weight_decay:  0.01722083427213385
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5036091799847782
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 98.33
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.5065583849791437
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.5507290258537978
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 77.30
run time now: 4.628532409667969
total time:  4.678314800839871
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.20
  Final Train: 98.33 ± 0.00
   Final Test: 77.57 ± 0.38
[I 2023-06-12 00:14:55,840] Trial 33 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.036058180950220405, 'K': 4, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.502768633261765, 'loop': 0, 'loss': 'CE', 'lr': 0.007117915902462968, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01722083427213385, 'weightedloss': True}. Best is trial 15 with value: 79.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.00684415685432354
weight_decay:  0.0005187730775510074
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8152883949223906
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 96.67
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.0242702071554959
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 98.33
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.4670351510867476
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 78.00
run time now: 4.343275308609009
total time:  4.383919337997213
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.20
  Final Train: 97.78 ± 0.96
   Final Test: 77.80 ± 0.20
[I 2023-06-12 00:15:00,733] Trial 34 finished with value: 79.99999237060547 and parameters: {'Fwd': 0.043209797768875194, 'K': 2, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.3987600516808802, 'loop': 0, 'loss': 'CE', 'lr': 0.00684415685432354, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005187730775510074, 'weightedloss': False}. Best is trial 34 with value: 79.99999237060547.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.00476741307366426
weight_decay:  0.0005988914458326668
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0669400691986084
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 98.33
   Final Test: 75.50
Split: 01, Run: 02
None time:  1.004539516987279
None Run 02:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 98.33
   Final Test: 74.90
Split: 01, Run: 03
None time:  0.5290933388751
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 98.33
   Final Test: 75.00
run time now: 2.6395552158355713
total time:  2.6888893500436097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.87 ± 0.31
  Final Train: 98.33 ± 0.00
   Final Test: 75.13 ± 0.32
[I 2023-06-12 00:15:03,848] Trial 35 finished with value: 77.86666870117188 and parameters: {'Fwd': 0.03779830528749133, 'K': 1, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 1.0, 'lambda2': 2.156330208604601, 'loop': 0, 'loss': 'CE', 'lr': 0.00476741307366426, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005988914458326668, 'weightedloss': False}. Best is trial 34 with value: 79.99999237060547.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0028974340268514576
weight_decay:  0.0015633076910784984
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.80% Test: 77.80%
Split: 01, Run: 01
None time:  2.7106141787953675
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.00% Test: 76.50%
Split: 01, Run: 02
None time:  2.1897788911592215
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 75.90%
Split: 01, Run: 03
None time:  2.6091637851204723
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.10
run time now: 7.546020030975342
total time:  7.594943865900859
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.00 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 76.60 ± 0.62
[I 2023-06-12 00:15:11,893] Trial 36 finished with value: 78.0 and parameters: {'Fwd': 0.06124633205525911, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 2.59175189512558, 'loop': 0, 'loss': 'MSE', 'lr': 0.0028974340268514576, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015633076910784984, 'weightedloss': False}. Best is trial 34 with value: 79.99999237060547.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.007194432098248542
weight_decay:  0.0031951471388482716
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5187870699446648
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.1859008530154824
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.3226873050443828
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 77.20
run time now: 4.062627077102661
total time:  4.116941647138447
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 99.44 ± 0.96
   Final Test: 77.47 ± 0.25
[I 2023-06-12 00:15:16,450] Trial 37 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.0935116701420525, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 3.6409462738427356, 'loop': 0, 'loss': 'CE', 'lr': 0.007194432098248542, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0031951471388482716, 'weightedloss': False}. Best is trial 37 with value: 80.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0042039671500164865
weight_decay:  0.002034589640529393
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.40% Test: 78.40%
Split: 01, Run: 01
None time:  2.6410694008227438
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.4744330439716578
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.60% Test: 78.40%
Split: 01, Run: 03
None time:  2.6862652401905507
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.8652966022491455
total time:  6.906748278066516
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.21
[I 2023-06-12 00:15:23,805] Trial 38 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.08433159238770355, 'K': 1, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.716387874131716, 'loop': 0, 'loss': 'MSE', 'lr': 0.0042039671500164865, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002034589640529393, 'weightedloss': False}. Best is trial 38 with value: 80.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.003424117124864743
weight_decay:  0.0028236333347228765
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2971253409050405
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.80% Test: 76.00%
Split: 01, Run: 02
None time:  2.421470824861899
None Run 02:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  1.3762404930312186
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.10
run time now: 5.126294136047363
total time:  5.170363903976977
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.07 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 75.93 ± 0.80
[I 2023-06-12 00:15:29,537] Trial 39 finished with value: 78.0666732788086 and parameters: {'Fwd': 0.08968990408042042, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.5355397355341567, 'loop': 0, 'loss': 'MSE', 'lr': 0.003424117124864743, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0028236333347228765, 'weightedloss': False}. Best is trial 38 with value: 80.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.004143515773193799
weight_decay:  0.0045528405957065655
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.248728726990521
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8373070999514312
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9289478529244661
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.0494537353515625
total time:  6.098569395020604
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.12
[I 2023-06-12 00:15:36,100] Trial 40 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.09900259102066386, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 3.7221593593649644, 'loop': 1, 'loss': 'MSE', 'lr': 0.004143515773193799, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0045528405957065655, 'weightedloss': False}. Best is trial 38 with value: 80.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.004739247358118198
weight_decay:  0.0049834311935725555
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.028121776180342
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.6653118028771132
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.7688708300702274
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.533179044723511
total time:  5.613522597122937
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.06
[I 2023-06-12 00:15:42,270] Trial 41 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.09854867376603829, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 3.674482142530148, 'loop': 1, 'loss': 'MSE', 'lr': 0.004739247358118198, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0049834311935725555, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.004318976436083622
weight_decay:  0.004090030425834834
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7528561768122017
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.903714045183733
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  2.059575878083706
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.756632566452026
total time:  5.8073696999344975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.23
[I 2023-06-12 00:15:48,640] Trial 42 finished with value: 80.19998931884766 and parameters: {'Fwd': 0.0941176221582903, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.605924515013974, 'loop': 1, 'loss': 'MSE', 'lr': 0.004318976436083622, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004090030425834834, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0022581891672090707
weight_decay:  0.005099107380482822
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0318, Train: 100.00%, Valid: 78.80% Test: 77.60%
Split: 01, Run: 01
None time:  3.913961948826909
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.511274548014626
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 03
None time:  3.2266076609957963
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.90
run time now: 9.696223020553589
total time:  9.74428261606954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 76.93 ± 0.65
[I 2023-06-12 00:15:58,831] Trial 43 finished with value: 78.46666717529297 and parameters: {'Fwd': 0.057863826577072126, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.826804914637022, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022581891672090707, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005099107380482822, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.004224952396663512
weight_decay:  0.0038674091954850223
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3579416070133448
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 02
None time:  1.6884504968766123
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 03
None time:  1.32041786191985
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.90
run time now: 4.39928126335144
total time:  4.452168927062303
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 75.83 ± 0.31
[I 2023-06-12 00:16:03,830] Trial 44 finished with value: 77.66666412353516 and parameters: {'Fwd': 0.08813702953243477, 'K': 1, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 4.651755680382534, 'loop': 1, 'loss': 'MSE', 'lr': 0.004224952396663512, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0038674091954850223, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.002933470855962289
weight_decay:  0.0019892796112529493
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0004706429317594
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.9567073420621455
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.4563810990657657
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.459139585494995
total time:  6.500972172012553
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.21
[I 2023-06-12 00:16:10,802] Trial 45 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.024648933932486815, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.080600155571157, 'loop': 1, 'loss': 'MSE', 'lr': 0.002933470855962289, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0019892796112529493, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003917153904238049
weight_decay:  0.00942807367547476
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8665269429329783
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.0435139699839056
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.5303818739484996
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.4727630615234375
total time:  6.524350638035685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.40
[I 2023-06-12 00:16:17,819] Trial 46 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.09920367132988618, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.639346988330998, 'loop': 1, 'loss': 'MSE', 'lr': 0.003917153904238049, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00942807367547476, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.003288503786828531
weight_decay:  0.004083983494465825
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5473787959199399
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0242, Train: 100.00%, Valid: 78.80% Test: 77.80%
Split: 01, Run: 02
None time:  3.789819678058848
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.3822872571181506
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.70
run time now: 7.754959344863892
total time:  7.804179684026167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.60 ± 0.10
[I 2023-06-12 00:16:26,090] Trial 47 finished with value: 79.39999389648438 and parameters: {'Fwd': 0.05236153426436048, 'K': 1, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 4.503857947812321, 'loop': 1, 'loss': 'MSE', 'lr': 0.003288503786828531, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004083983494465825, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.002011745408922366
weight_decay:  0.006065306415674659
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9990461240522563
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  2.1438261969015002
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0342, Train: 100.00%, Valid: 75.60% Test: 73.90%
Split: 01, Run: 03
None time:  3.9127543398644775
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.70
run time now: 8.089056015014648
total time:  8.128378548193723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.67 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 75.07 ± 1.31
[I 2023-06-12 00:16:34,656] Trial 48 finished with value: 76.66666412353516 and parameters: {'Fwd': 0.04347023392685042, 'K': 2, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 4.954968481180469, 'loop': 1, 'loss': 'MSE', 'lr': 0.002011745408922366, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006065306415674659, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.004531689940080665
weight_decay:  0.0029953847832998198
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9216410599183291
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.121575074037537
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.907666377024725
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.990651607513428
total time:  6.041596109978855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.00
[I 2023-06-12 00:16:41,133] Trial 49 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.021103088693989327, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.527558864735014, 'loop': 1, 'loss': 'MSE', 'lr': 0.004531689940080665, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0029953847832998198, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.005572892285971202
weight_decay:  0.0023080496072289767
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5984559650532901
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.7029973480384797
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.4144849190488458
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.759408950805664
total time:  5.805203269002959
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.42
[I 2023-06-12 00:16:47,393] Trial 50 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.02028670505035207, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.950433040343298, 'loop': 1, 'loss': 'MSE', 'lr': 0.005572892285971202, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023080496072289767, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.005722417351991711
weight_decay:  0.0024206665662085372
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8319492698647082
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.6456769020296633
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.752588195959106
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.269047498703003
total time:  5.309090618044138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.57
[I 2023-06-12 00:16:53,142] Trial 51 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.03063271383781009, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.8425509736021874, 'loop': 1, 'loss': 'MSE', 'lr': 0.005722417351991711, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0024206665662085372, 'weightedloss': False}. Best is trial 41 with value: 80.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004638408417232006
weight_decay:  0.0018362594373996012
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9806160889565945
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.067161686019972
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.9075523240026087
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.041353464126587
total time:  6.12334438203834
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.35
[I 2023-06-12 00:16:59,726] Trial 52 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.05144613957999857, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.142221347801167, 'loop': 1, 'loss': 'MSE', 'lr': 0.004638408417232006, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0018362594373996012, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.004731385997130289
weight_decay:  0.0014101695770830766
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.915646584937349
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.0238634678535163
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.9751026099547744
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.950998067855835
total time:  5.997655231971294
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.25
[I 2023-06-12 00:17:06,154] Trial 53 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.058562119439675965, 'K': 1, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.135948913742304, 'loop': 1, 'loss': 'MSE', 'lr': 0.004731385997130289, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0014101695770830766, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0034489948912844494
weight_decay:  0.0014127700075928578
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9698687940835953
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  2.1700873628724366
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.945333467097953
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 6.120282888412476
total time:  6.161097874864936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.70 ± 0.26
[I 2023-06-12 00:17:12,810] Trial 54 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.048623522614397674, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.22827075910475, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034489948912844494, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0014127700075928578, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004433786259574062
weight_decay:  0.001235558295371495
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9710836710873991
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.243634652113542
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.9242306880187243
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.178048372268677
total time:  6.221587849082425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.15
[I 2023-06-12 00:17:19,492] Trial 55 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.013151217072507871, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 4.0718494600252555, 'loop': 1, 'loss': 'MSE', 'lr': 0.004433786259574062, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001235558295371495, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0028969008055890763
weight_decay:  0.001038855316494121
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3154751409310848
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0622, Train: 100.00%, Valid: 79.40% Test: 78.00%
Split: 01, Run: 02
None time:  4.652291007107124
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.213138169143349
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.40
run time now: 9.216012001037598
total time:  9.264243653044105
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.29
[I 2023-06-12 00:17:29,240] Trial 56 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.059850000938537234, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.067664810487749, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028969008055890763, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001038855316494121, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004918978855711695
weight_decay:  0.00123882838210647
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3063174728304148
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  2.6647902950644493
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  2.5641226780135185
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
run time now: 7.5706260204315186
total time:  7.609317881986499
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 0.60
[I 2023-06-12 00:17:37,392] Trial 57 finished with value: 79.93333435058594 and parameters: {'Fwd': 0.010900160615882564, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 5.1099181566602665, 'loop': 1, 'loss': 'MSE', 'lr': 0.004918978855711695, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00123882838210647, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.0037865968266461115
weight_decay:  0.00697462693983659
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.521498851943761
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  3.441454465035349
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.1690250858664513
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 8.174217224121094
total time:  8.213581536896527
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.35
[I 2023-06-12 00:17:46,056] Trial 58 finished with value: 80.0 and parameters: {'Fwd': 0.02919222949822277, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 4.4254790312599495, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037865968266461115, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00697462693983659, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.007956642661906568
weight_decay:  0.0007131854489555606
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9307222969364375
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.445735531160608
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.298379187937826
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.724268674850464
total time:  6.7691776000428945
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.29
[I 2023-06-12 00:17:53,240] Trial 59 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.054019384331940645, 'K': 10, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 3.250840249783373, 'loop': 1, 'loss': 'MSE', 'lr': 0.007956642661906568, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007131854489555606, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0015603587398551895
weight_decay:  0.0017582877473359064
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0156, Train: 100.00%, Valid: 51.80% Test: 49.70%
Split: 01, Run: 01
None time:  3.382294340059161
None Run 01:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 49.70
Split: 01, Run: 02
None time:  0.7313281381502748
None Run 02:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 03
None time:  0.728488028049469
None Run 03:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 40.30
run time now: 4.894395351409912
total time:  4.9390754038468
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.33 ± 7.61
  Final Train: 100.00 ± 0.00
   Final Test: 48.37 ± 7.49
[I 2023-06-12 00:17:58,721] Trial 60 finished with value: 49.33333206176758 and parameters: {'Fwd': 0.011090492782832863, 'K': 1, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 4.888448685046114, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015603587398551895, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0017582877473359064, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.004627889974535415
weight_decay:  0.0018152373702872966
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8230978369247168
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.9010888319462538
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  3.3542593251913786
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 8.115664005279541
total time:  8.174833366880193
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.12
[I 2023-06-12 00:18:07,441] Trial 61 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.0228696284764361, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 3.9060867553960623, 'loop': 1, 'loss': 'MSE', 'lr': 0.004627889974535415, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0018152373702872966, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.00489651992203935
weight_decay:  0.0009958948333174465
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.291711056837812
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.075395670020953
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.107811961090192
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.513162612915039
total time:  6.558800492901355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.35
[I 2023-06-12 00:18:14,609] Trial 62 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.0218865390275871, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 3.4157238043789384, 'loop': 1, 'loss': 'MSE', 'lr': 0.00489651992203935, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009958948333174465, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.005843648155409217
weight_decay:  0.004903571285990986
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.40833862381987274
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 02
None time:  1.498463163850829
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 03
None time:  1.0541112921200693
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.9907822608947754
total time:  3.0316470849793404
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.73 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 72.70 ± 1.18
[I 2023-06-12 00:18:18,244] Trial 63 finished with value: 74.73333740234375 and parameters: {'Fwd': 0.06576065809497024, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.6000000000000001, 'gnnepoch': 0, 'lambda1': 0.05, 'lambda2': 4.208497322865442, 'loop': 1, 'loss': 'MSE', 'lr': 0.005843648155409217, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004903571285990986, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004227467217782705
weight_decay:  0.0029359699636793356
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.045954786008224
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.8445738770533353
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  2.152521746000275
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.0794901847839355
total time:  6.120488754007965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.51
[I 2023-06-12 00:18:24,790] Trial 64 finished with value: 80.19999694824219 and parameters: {'Fwd': 0.03774441372996244, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 3.818877002414742, 'loop': 1, 'loss': 'MSE', 'lr': 0.004227467217782705, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0029359699636793356, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.0032198922068275054
weight_decay:  0.009256196602169368
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3584139610175043
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  3.187331472057849
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.3380864749196917
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
run time now: 7.918172597885132
total time:  7.961405009962618
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.15
[I 2023-06-12 00:18:33,312] Trial 65 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.01732216648439604, 'K': 1, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 3.3424550922396588, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032198922068275054, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009256196602169368, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0025817895524190304
weight_decay:  0.0012693416250450925
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.592059175018221
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.268491097027436
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  4.805982870049775
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 11.714192867279053
total time:  11.752960450947285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.15
[I 2023-06-12 00:18:45,516] Trial 66 finished with value: 80.0 and parameters: {'Fwd': 0.06561473560902348, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 4.443525375936237, 'loop': 2, 'loss': 'MSE', 'lr': 0.0025817895524190304, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0012693416250450925, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.0051833556697358785
weight_decay:  0.003312260246677005
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.587102626916021
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.105705711990595
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.0728304667863995
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.805074214935303
total time:  5.842668410856277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.06
[I 2023-06-12 00:18:51,746] Trial 67 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.012595696743075282, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 2.8987402338749937, 'loop': 1, 'loss': 'MSE', 'lr': 0.0051833556697358785, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003312260246677005, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008171251733732775
weight_decay:  0.0020199113560773066
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2252326142042875
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.5337365551386029
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.570807337993756
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
run time now: 4.36482310295105
total time:  4.411560622043908
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 77.57 ± 0.21
[I 2023-06-12 00:18:56,668] Trial 68 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.03792741782326752, 'K': 1, 'alpha': 0.2, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 5.186687076056003, 'loop': 1, 'loss': 'MSE', 'lr': 0.008171251733732775, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0020199113560773066, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.006208931574603551
weight_decay:  0.000831450848348075
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0078912519384176
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.9100294290110469
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  2.1083174019586295
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.60
run time now: 6.058325529098511
total time:  6.119918667944148
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 0.53
[I 2023-06-12 00:19:03,307] Trial 69 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.005321226162118397, 'K': 2, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 3.8105179942927636, 'loop': 1, 'loss': 'MSE', 'lr': 0.006208931574603551, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000831450848348075, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.004056087459472532
weight_decay:  0.00039033933977442384
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0989651679992676
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.015110085019842
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  2.0546843300107867
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.204372882843018
total time:  6.25442345906049
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.59
[I 2023-06-12 00:19:10,097] Trial 70 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.02630804409851549, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 3.2377452601679484, 'loop': 2, 'loss': 'MSE', 'lr': 0.004056087459472532, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00039033933977442384, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.004964820488580096
weight_decay:  0.002918329024371239
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.547275608871132
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.7591884268913418
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.8485787820536643
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.90
run time now: 6.196625709533691
total time:  6.249806168954819
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.40
[I 2023-06-12 00:19:16,839] Trial 71 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.012642171770301126, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 2.751778438330737, 'loop': 1, 'loss': 'MSE', 'lr': 0.004964820488580096, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002918329024371239, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0037219414128981587
weight_decay:  0.005436192101176136
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7384330360218883
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.2147186398506165
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.3731151239480823
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.70
run time now: 6.375982046127319
total time:  6.426220253109932
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.55
[I 2023-06-12 00:19:23,747] Trial 72 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.015577784310792568, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.843227707536758, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037219414128981587, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005436192101176136, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.003673820380309648
weight_decay:  0.005283652692165631
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0239, Train: 100.00%, Valid: 60.20% Test: 56.20%
Split: 01, Run: 01
None time:  3.3166915599722415
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0189, Train: 100.00%, Valid: 72.00% Test: 70.60%
Split: 01, Run: 02
None time:  3.0382414788473397
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.9804245280101895
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.10
run time now: 8.379373550415039
total time:  8.42333309398964
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.07 ± 6.00
  Final Train: 100.00 ± 0.00
   Final Test: 62.97 ± 7.24
[I 2023-06-12 00:19:32,722] Trial 73 finished with value: 66.06666564941406 and parameters: {'Fwd': 0.015053668261247002, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 10, 'lambda1': 0.7000000000000001, 'lambda2': 2.812463765980325, 'loop': 1, 'loss': 'MSE', 'lr': 0.003673820380309648, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005283652692165631, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.45
lr:  0.006420045978373285
weight_decay:  0.0076824982465991095
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2596956461202353
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.5555416238494217
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.6055016280151904
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 4.4585089683532715
total time:  4.4997804360464215
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.42
[I 2023-06-12 00:19:37,661] Trial 74 finished with value: 80.06666564941406 and parameters: {'Fwd': 0.07265326717032232, 'K': 3, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 1.9588729785477055, 'loop': 1, 'loss': 'MSE', 'lr': 0.006420045978373285, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0076824982465991095, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.005189729651963292
weight_decay:  0.01421515864788717
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.847345928195864
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  3.1338862548582256
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.4316176089923829
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.449810028076172
total time:  6.499870840925723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.20
[I 2023-06-12 00:19:44,626] Trial 75 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.042140409769671726, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 3.07701586131758, 'loop': 1, 'loss': 'MSE', 'lr': 0.005189729651963292, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01421515864788717, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.4
lr:  0.0036264682738893486
weight_decay:  0.0016423373481106618
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.401135316118598
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.7372979789506644
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.12908371607773
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.322827339172363
total time:  6.3818800509907305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.20
[I 2023-06-12 00:19:51,567] Trial 76 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.008307666055398429, 'K': 3, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.6786873111538743, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036264682738893486, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0016423373481106618, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.00535659436160468
weight_decay:  0.00434215420348356
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1330299011897296
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.4908814190421253
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.6220698619727045
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.285566329956055
total time:  6.331117543159053
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.66
[I 2023-06-12 00:19:58,454] Trial 77 finished with value: 80.33332824707031 and parameters: {'Fwd': 0.09918505767841265, 'K': 2, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.3585829021277163, 'loop': 1, 'loss': 'MSE', 'lr': 0.00535659436160468, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00434215420348356, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.008410826346250093
weight_decay:  0.0005793715715239421
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7375441261101514
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.0803433400578797
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  0.8960506990551949
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 4.764459848403931
total time:  4.822958952980116
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.47
[I 2023-06-12 00:20:03,766] Trial 78 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.07071539483120848, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 4.156611907194809, 'loop': 1, 'loss': 'MSE', 'lr': 0.008410826346250093, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005793715715239421, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.004407702782878115
weight_decay:  0.002017455794645334
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6279993068892509
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.8775726789608598
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0360, Train: 100.00%, Valid: 80.80% Test: 78.30%
Split: 01, Run: 03
None time:  3.9182570911943913
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 7.488426446914673
total time:  7.539612981956452
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.31
[I 2023-06-12 00:20:11,907] Trial 79 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.030113584310363834, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 3.384889182173265, 'loop': 1, 'loss': 'MSE', 'lr': 0.004407702782878115, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002017455794645334, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.006206721349365771
weight_decay:  0.002223133345561333
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6513479962013662
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.630299337906763
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.4344133229460567
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.752933740615845
total time:  4.8036142969504
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.44
[I 2023-06-12 00:20:17,170] Trial 80 finished with value: 79.99999237060547 and parameters: {'Fwd': 0.012413212646404789, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 3.3376039702364295, 'loop': 1, 'loss': 'MSE', 'lr': 0.006206721349365771, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002223133345561333, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0043715782515629555
weight_decay:  0.0014046048166552704
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.943689232924953
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.789983042050153
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.6397011540830135
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.4054274559021
total time:  5.4486459160689265
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.12
[I 2023-06-12 00:20:23,047] Trial 81 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.03199221601880504, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 3.8631684833057442, 'loop': 1, 'loss': 'MSE', 'lr': 0.0043715782515629555, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0014046048166552704, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00312273354036444
weight_decay:  0.003517623695635881
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5557180210016668
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.5343200650531799
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.794265141012147
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.70
run time now: 4.916292428970337
total time:  4.959040229907259
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 76.70 ± 0.20
[I 2023-06-12 00:20:28,523] Trial 82 finished with value: 78.86666870117188 and parameters: {'Fwd': 0.048539859573313734, 'K': 1, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 3.0900827782702405, 'loop': 1, 'loss': 'MSE', 'lr': 0.00312273354036444, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003517623695635881, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00438024802896888
weight_decay:  0.0024305833783090564
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7641521759796888
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.4975596640724689
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.5150691920425743
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.10
run time now: 4.81623649597168
total time:  4.867563346866518
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 77.57 ± 0.45
[I 2023-06-12 00:20:33,942] Trial 83 finished with value: 79.06666564941406 and parameters: {'Fwd': 0.018128310029905594, 'K': 1, 'alpha': 0.05, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 3.651071331060487, 'loop': 1, 'loss': 'MSE', 'lr': 0.00438024802896888, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0024305833783090564, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.00363182722696322
weight_decay:  0.005847399915905624
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9164024598430842
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.9421526060905308
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.5828841940965503
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.474486589431763
total time:  5.519358139950782
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.26
[I 2023-06-12 00:20:40,018] Trial 84 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0726793985839909, 'K': 2, 'alpha': 0.1, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.4728426047663716, 'loop': 1, 'loss': 'MSE', 'lr': 0.00363182722696322, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005847399915905624, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0037539613608507387
weight_decay:  0.0009723488889060093
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1087434119544923
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7401128369383514
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.831577364122495
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 5.716204643249512
total time:  5.768475027056411
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.25
[I 2023-06-12 00:20:46,337] Trial 85 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.027086311024904736, 'K': 2, 'alpha': 0.1, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 2.7066392857093966, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037539613608507387, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009723488889060093, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0037583953261874172
weight_decay:  0.0009011791636820887
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9081541190389544
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.6367017859593034
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.7774949849117547
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.358878135681152
total time:  6.3986632658634335
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.36
[I 2023-06-12 00:20:53,284] Trial 86 finished with value: 80.0 and parameters: {'Fwd': 0.006162926512693807, 'K': 2, 'alpha': 0.0, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 2.7273453114501653, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037583953261874172, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009011791636820887, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.1
lr:  0.002789992569112679
weight_decay:  0.0007541889940714498
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7213051030412316
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.2093087278772146
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.5291461569722742
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.90
run time now: 6.502003192901611
total time:  6.5446131529752165
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 77.37 ± 0.40
[I 2023-06-12 00:21:00,472] Trial 87 finished with value: 79.4000015258789 and parameters: {'Fwd': 0.026191541780105212, 'K': 6, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.5470301266801845, 'loop': 1, 'loss': 'MSE', 'lr': 0.002789992569112679, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007541889940714498, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.003356489284735744
weight_decay:  0.0011728822797040972
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4226139418315142
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  2.1632141310255975
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0314, Train: 100.00%, Valid: 80.80% Test: 78.50%
Split: 01, Run: 03
None time:  4.955319692147896
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 9.577995777130127
total time:  9.627524854848161
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.35
[I 2023-06-12 00:21:10,611] Trial 88 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.009982020084442838, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.484330349752054, 'loop': 1, 'loss': 'MSE', 'lr': 0.003356489284735744, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011728822797040972, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.002372230598049844
weight_decay:  0.0004988112563323197
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0253, Train: 100.00%, Valid: 80.00% Test: 78.20%
Split: 01, Run: 01
None time:  4.952372465049848
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.992104905191809
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  2.8608681871555746
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 9.847835540771484
total time:  9.897743615088984
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.57 ± 0.57
[I 2023-06-12 00:21:21,009] Trial 89 finished with value: 79.4000015258789 and parameters: {'Fwd': 0.01608399164304627, 'K': 7, 'alpha': 0.05, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.025751949872654, 'loop': 1, 'loss': 'MSE', 'lr': 0.002372230598049844, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004988112563323197, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.1
lr:  0.00498176804198567
weight_decay:  0.0033775122109075246
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8007411670405418
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.998118702089414
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.748235534178093
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.601136922836304
total time:  5.672582510160282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.46
[I 2023-06-12 00:21:27,124] Trial 90 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.03627827428056663, 'K': 3, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 2.2385936307266414, 'loop': 1, 'loss': 'MSE', 'lr': 0.00498176804198567, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0033775122109075246, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0053838936171598396
weight_decay:  0.0017499629105969536
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5167358110193163
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  4.411992237204686
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.7769209269899875
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.20
run time now: 7.7492029666900635
total time:  7.79792020493187
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.47
[I 2023-06-12 00:21:35,511] Trial 91 finished with value: 80.13333129882812 and parameters: {'Fwd': 0.052026710494714065, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 3.910499296442116, 'loop': 1, 'loss': 'MSE', 'lr': 0.0053838936171598396, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0017499629105969536, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0038346371760529054
weight_decay:  0.002859525018197087
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.210100907832384
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.822913391981274
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.642883539898321
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.71275520324707
total time:  6.753010718850419
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.62
[I 2023-06-12 00:21:42,828] Trial 92 finished with value: 80.39999389648438 and parameters: {'Fwd': 0.0736900465987015, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 3.4293029995218474, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038346371760529054, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002859525018197087, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.004546410557452064
weight_decay:  0.006199265068697955
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1232347150798887
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.7282107709906995
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.86771050398238
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.750745534896851
total time:  6.794540632981807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.12
[I 2023-06-12 00:21:50,096] Trial 93 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.045569104954535894, 'K': 1, 'alpha': 0.1, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 4.296688028695732, 'loop': 1, 'loss': 'MSE', 'lr': 0.004546410557452064, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006199265068697955, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.0065953793992614695
weight_decay:  0.002207305924666265
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8848524391651154
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.0356928249821067
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  2.085223173024133
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.038503885269165
total time:  6.078063765075058
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.46
[I 2023-06-12 00:21:56,652] Trial 94 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.028965322334774623, 'K': 2, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.1517341483915486, 'loop': 1, 'loss': 'MSE', 'lr': 0.0065953793992614695, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002207305924666265, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.002972625997538944
weight_decay:  0.0012641629889837056
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.080939843086526
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  2.094458772102371
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  2.6499723598826677
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.857599973678589
total time:  6.9051373491529375
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.23
[I 2023-06-12 00:22:04,060] Trial 95 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.06750352142691951, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 4.034361540689211, 'loop': 1, 'loss': 'MSE', 'lr': 0.002972625997538944, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0012641629889837056, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.003514759171341304
weight_decay:  0.0016595931530940687
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.567666616057977
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  2.082930811913684
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.7210290981456637
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.419647932052612
total time:  6.478330322774127
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 0.21
[I 2023-06-12 00:22:11,115] Trial 96 finished with value: 79.26666259765625 and parameters: {'Fwd': 0.02132874686263124, 'K': 1, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 4.665116222099799, 'loop': 1, 'loss': 'MSE', 'lr': 0.003514759171341304, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0016595931530940687, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.005774992202355275
weight_decay:  0.0038092219899050657
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8755900100804865
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.588573063025251
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.1240415018983185
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.630337715148926
total time:  5.683945182943717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.44
[I 2023-06-12 00:22:17,254] Trial 97 finished with value: 80.13333129882812 and parameters: {'Fwd': 0.03744694356288907, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 2.9226006735465324, 'loop': 1, 'loss': 'MSE', 'lr': 0.005774992202355275, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0038092219899050657, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.007420178888433044
weight_decay:  0.0009912997162954316
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.079286070074886
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 02
None time:  1.1361975569743663
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  1.0779472889844328
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.10
run time now: 3.332611560821533
total time:  3.379067240981385
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 73.40 ± 1.14
[I 2023-06-12 00:22:21,143] Trial 98 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.07974878248765806, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 2.6799936774556983, 'loop': 1, 'loss': 'MSE', 'lr': 0.007420178888433044, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0009912997162954316, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.004619063424566554
weight_decay:  0.0051255082490334085
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.880607653874904
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.7039688320364803
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.827671233098954
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 5.447340488433838
total time:  5.487574968021363
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.25
[I 2023-06-12 00:22:27,043] Trial 99 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.025224733907836812, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 3.61210135347601, 'loop': 1, 'loss': 'MSE', 'lr': 0.004619063424566554, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0051255082490334085, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.004084414675784386
weight_decay:  0.0026444547355062207
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7463682980742306
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.7103730868548155
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.7364792351145297
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.232087135314941
total time:  5.293950521154329
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.10
[I 2023-06-12 00:22:32,774] Trial 100 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.012147502699174346, 'K': 1, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 4.014701841139281, 'loop': 1, 'loss': 'MSE', 'lr': 0.004084414675784386, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0026444547355062207, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0031961723491482712
weight_decay:  0.0040741423664113876
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5372389061376452
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.8644035621546209
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.6983447531238198
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.133005857467651
total time:  6.184466195991263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.36
[I 2023-06-12 00:22:39,415] Trial 101 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.05670480326996494, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 3.2416587370234, 'loop': 1, 'loss': 'MSE', 'lr': 0.0031961723491482712, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0040741423664113876, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0038878131579350547
weight_decay:  0.008825841579700539
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.042192545020953
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.8248608359135687
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.7892045471817255
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.734562397003174
total time:  5.8038816270418465
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.23
[I 2023-06-12 00:22:45,738] Trial 102 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.09637126327565831, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 3.6709086691423405, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038878131579350547, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008825841579700539, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.004942457244303419
weight_decay:  0.005432729071974734
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6674846969544888
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.023890999145806
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.9429767311085016
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.66996169090271
total time:  5.709414832992479
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.40 ± 0.20
[I 2023-06-12 00:22:52,045] Trial 103 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.0505520984220377, 'K': 2, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 3.773746870721014, 'loop': 1, 'loss': 'MSE', 'lr': 0.004942457244303419, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005432729071974734, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0026641418169920214
weight_decay:  0.007336222502183711
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0879921820014715
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  2.1973805758170784
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 03
None time:  2.149226075038314
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 76.40
run time now: 6.489759683609009
total time:  6.542430568952113
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 76.53 ± 0.81
[I 2023-06-12 00:22:59,102] Trial 104 finished with value: 78.4000015258789 and parameters: {'Fwd': 0.07199461038900787, 'K': 1, 'alpha': 0.1, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 4.294909069906266, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026641418169920214, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007336222502183711, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0040576238779004665
weight_decay:  0.00203593439554273
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2673800350166857
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.8908328770194203
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.8294734270311892
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.30
run time now: 6.037055969238281
total time:  6.086127538001165
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.38
[I 2023-06-12 00:23:05,790] Trial 105 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.032267317194259654, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.4591371682554963, 'loop': 1, 'loss': 'MSE', 'lr': 0.0040576238779004665, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00203593439554273, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.005666649090706087
weight_decay:  0.0015133905360204488
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6640784861519933
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.1925355361308903
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.91421719500795
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.808828592300415
total time:  6.89474159409292
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.49
[I 2023-06-12 00:23:13,281] Trial 106 finished with value: 80.19999694824219 and parameters: {'Fwd': 0.0312723208401894, 'K': 2, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 3.460537343859218, 'loop': 1, 'loss': 'MSE', 'lr': 0.005666649090706087, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015133905360204488, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.003499643992357279
weight_decay:  0.0019012466268891225
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0575, Train: 100.00%, Valid: 78.60% Test: 76.90%
Split: 01, Run: 01
None time:  4.37454411201179
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0506, Train: 100.00%, Valid: 78.60% Test: 77.10%
Split: 01, Run: 02
None time:  3.831025298917666
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  2.6110579010564834
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 73.50
run time now: 10.854448556900024
total time:  10.89655083999969
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.87 ± 1.27
  Final Train: 100.00 ± 0.00
   Final Test: 75.73 ± 1.93
[I 2023-06-12 00:23:24,607] Trial 107 finished with value: 77.86666870117188 and parameters: {'Fwd': 0.019984255158159776, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 2.488734609061517, 'loop': 1, 'loss': 'MSE', 'lr': 0.003499643992357279, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0019012466268891225, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.004304414928904544
weight_decay:  0.000773141495794159
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6845553789753467
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.0164348362013698
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9487705931533128
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.69838285446167
total time:  5.736761971842498
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.15
[I 2023-06-12 00:23:30,929] Trial 108 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.0419196060027588, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 3.002687697061629, 'loop': 1, 'loss': 'MSE', 'lr': 0.004304414928904544, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000773141495794159, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004704222966324592
weight_decay:  0.002700665985970238
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5849611500743777
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.136842611944303
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  2.3600653959438205
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.1588826179504395
total time:  6.210365762002766
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.25
[I 2023-06-12 00:23:37,719] Trial 109 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.014113417922088705, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 3.257047917946667, 'loop': 1, 'loss': 'MSE', 'lr': 0.004704222966324592, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002700665985970238, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.003069663166342934
weight_decay:  0.0011633157068030211
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1925404709763825
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.5018128340598196
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 03
None time:  1.4041693529579788
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 75.90
run time now: 4.1466615200042725
total time:  4.191564000910148
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.47 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 75.87 ± 0.25
[I 2023-06-12 00:23:42,473] Trial 110 finished with value: 77.46666717529297 and parameters: {'Fwd': 0.05911981795734626, 'K': 2, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 2.7539758287593115, 'loop': 1, 'loss': 'MSE', 'lr': 0.003069663166342934, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0011633157068030211, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.003998287515017365
weight_decay:  0.0045580545720193604
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.593098227865994
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.9407326730433851
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.73110939306207
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.303346157073975
total time:  5.343133211135864
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.25
[I 2023-06-12 00:23:48,289] Trial 111 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.08068625695541642, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 4.051338069093435, 'loop': 1, 'loss': 'MSE', 'lr': 0.003998287515017365, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0045580545720193604, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.004042597286975843
weight_decay:  0.0020157628463431682
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4089217849541456
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.8418541071005166
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.7725953229237348
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.50
run time now: 5.062625169754028
total time:  5.113860493991524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.40
[I 2023-06-12 00:23:53,838] Trial 112 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.04413034290644958, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.9893383645575113, 'loop': 1, 'loss': 'MSE', 'lr': 0.004042597286975843, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0020157628463431682, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.003641638421209261
weight_decay:  0.00330406719374826
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7967701100278646
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.1301787479314953
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.7988793759141117
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.76042914390564
total time:  5.809298150008544
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.26
[I 2023-06-12 00:24:00,133] Trial 113 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.08126274471780745, 'K': 1, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 3.433618188271743, 'loop': 1, 'loss': 'MSE', 'lr': 0.003641638421209261, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00330406719374826, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.005297968628581724
weight_decay:  0.004543579973698185
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7524604031350464
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.6120427360292524
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.0315364201087505
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.4294397830963135
total time:  5.480028490070254
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.36
[I 2023-06-12 00:24:06,208] Trial 114 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.03327826788908507, 'K': 1, 'alpha': 0.2, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 3.5036129466429493, 'loop': 1, 'loss': 'MSE', 'lr': 0.005297968628581724, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004543579973698185, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.003573885998624271
weight_decay:  0.0035134500425855397
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7709357519634068
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  1.8072398360818624
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.8297172000166029
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.70
run time now: 5.442150592803955
total time:  5.497102627996355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.13 ± 0.51
[I 2023-06-12 00:24:12,160] Trial 115 finished with value: 79.0666732788086 and parameters: {'Fwd': 0.0787829723392337, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 4.238535801968672, 'loop': 1, 'loss': 'MSE', 'lr': 0.003573885998624271, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0035134500425855397, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.006149925101616174
weight_decay:  0.006472052625867975
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.564854380907491
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.6428101928904653
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.7500142911449075
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.993626117706299
total time:  6.040723443031311
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.15
[I 2023-06-12 00:24:18,617] Trial 116 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.0253375924032931, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 3.288972111384412, 'loop': 1, 'loss': 'MSE', 'lr': 0.006149925101616174, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006472052625867975, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0032796901443719714
weight_decay:  0.0029348851040048455
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7183215089607984
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.9321697719860822
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  1.7364197759889066
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.50
run time now: 5.424922943115234
total time:  5.47006272780709
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 76.87 ± 0.35
[I 2023-06-12 00:24:24,539] Trial 117 finished with value: 78.73332977294922 and parameters: {'Fwd': 0.058066193892511796, 'K': 1, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 2.93447347207074, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032796901443719714, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0029348851040048455, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.00492808449059511
weight_decay:  0.0014447795756546357
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8492903111036867
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.8958067628555
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.1707836820278317
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.955536842346191
total time:  6.009789968840778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 78.63 ± 0.21
[I 2023-06-12 00:24:31,067] Trial 118 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.017494608321211844, 'K': 2, 'alpha': 0.1, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 4.571203135125124, 'loop': 1, 'loss': 'MSE', 'lr': 0.00492808449059511, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0014447795756546357, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0038577923029393785
weight_decay:  0.0022422891399399075
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1389393769204617
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.68830354581587
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  4.472522691823542
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
run time now: 9.395245790481567
total time:  9.516539672855288
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.31
[I 2023-06-12 00:24:41,235] Trial 119 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.034275371234788084, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.050039859363808, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038577923029393785, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0022422891399399075, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.0027343587891700038
weight_decay:  0.011054368968929891
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.151618568226695
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0419, Train: 100.00%, Valid: 80.00% Test: 77.30%
Split: 01, Run: 02
None time:  5.578771936008707
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.936625397996977
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.60
run time now: 9.716859102249146
total time:  9.766228946857154
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.57 ± 0.06
[I 2023-06-12 00:24:51,468] Trial 120 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.032884730944150856, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 3.7401535897466776, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027343587891700038, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.011054368968929891, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.30000000000000004
lr:  0.0046273495939129
weight_decay:  0.0037438874774047217
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.021978643955663
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.08107832306996
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.9474860078189522
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.094589471817017
total time:  6.144692349946126
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.12
[I 2023-06-12 00:24:58,062] Trial 121 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.04796244568374289, 'K': 7, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.017691636363191, 'loop': 1, 'loss': 'MSE', 'lr': 0.0046273495939129, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0037438874774047217, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0038244083381988457
weight_decay:  0.0023374580125771955
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.09251322504133
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  3.7465342809446156
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  3.956642911070958
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.20
run time now: 9.841389656066895
total time:  9.893197613069788
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 1.15
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.32
[I 2023-06-12 00:25:08,509] Trial 122 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.0999034278020103, 'K': 9, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 4.330266250681608, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038244083381988457, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023374580125771955, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.35000000000000003
lr:  0.0041282216080289645
weight_decay:  0.005326388389903326
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0335, Train: 100.00%, Valid: 80.80% Test: 78.50%
Split: 01, Run: 01
None time:  5.369702096097171
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  2.4732383370865136
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.224473019130528
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.70
run time now: 10.108138084411621
total time:  10.148565609939396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.46
[I 2023-06-12 00:25:19,120] Trial 123 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.009672409475481241, 'K': 6, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 3.4177001834701928, 'loop': 1, 'loss': 'MSE', 'lr': 0.0041282216080289645, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005326388389903326, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.0043989019938857
weight_decay:  0.006423005279708292
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0610865601338446
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.793459229171276
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  2.17512100096792
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 6.071973085403442
total time:  6.120781558100134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.30
[I 2023-06-12 00:25:25,651] Trial 124 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.02177859023703851, 'K': 5, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.414353712309893, 'loop': 1, 'loss': 'MSE', 'lr': 0.0043989019938857, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006423005279708292, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.45
lr:  0.005236716059584502
weight_decay:  0.0010084119775670814
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8410282779950649
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.4970196639187634
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9510217120405287
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.3348259925842285
total time:  6.387736889068037
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.44
[I 2023-06-12 00:25:32,490] Trial 125 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.008632049950910787, 'K': 5, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.5260203440891007, 'loop': 1, 'loss': 'MSE', 'lr': 0.005236716059584502, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010084119775670814, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.4
lr:  0.004322213228046542
weight_decay:  0.006953029099774347
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9978572898544371
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.9416587860323489
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.100094371009618
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.081303596496582
total time:  6.129152959911153
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.32
[I 2023-06-12 00:25:39,068] Trial 126 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.022006713775259958, 'K': 6, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.1048668368950043, 'loop': 1, 'loss': 'MSE', 'lr': 0.004322213228046542, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006953029099774347, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.005965393580247832
weight_decay:  0.0030567160871553868
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.34468376589939
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.0079456390812993
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.0135709159076214
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.411525249481201
total time:  6.4496277421712875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.20
[I 2023-06-12 00:25:46,103] Trial 127 finished with value: 79.53333282470703 and parameters: {'Fwd': 0.012866722713019049, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.7928764179084444, 'loop': 1, 'loss': 'MSE', 'lr': 0.005965393580247832, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0030567160871553868, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.0030990815079170054
weight_decay:  0.0006640623057246746
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.195134832058102
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.797523827990517
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.6956413320731372
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.728565454483032
total time:  5.772149496013299
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.35
[I 2023-06-12 00:25:52,391] Trial 128 finished with value: 80.13333129882812 and parameters: {'Fwd': 0.009985270565283194, 'K': 5, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 3.373307233793533, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030990815079170054, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006640623057246746, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.35000000000000003
lr:  0.006946440313847785
weight_decay:  0.00170028534282129
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2280245888978243
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  2.1697156049776822
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.8927029359620064
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.334095001220703
total time:  6.377027184003964
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 0.61
[I 2023-06-12 00:25:59,169] Trial 129 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.027461625058969243, 'K': 4, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.9500000000000001, 'lambda2': 4.668601600743773, 'loop': 1, 'loss': 'MSE', 'lr': 0.006946440313847785, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00170028534282129, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.00456454109182436
weight_decay:  0.002311731911314472
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7248196189757437
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  2.1623099809512496
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  2.2411789840552956
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 6.169660806655884
total time:  6.21964621799998
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.53 ± 0.42
[I 2023-06-12 00:26:05,839] Trial 130 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.03677275412284196, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 3.173916816467254, 'loop': 1, 'loss': 'MSE', 'lr': 0.00456454109182436, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.002311731911314472, 'weightedloss': True}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0035030103234815575
weight_decay:  0.005292237257146266
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9591430639848113
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.9748099129647017
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  2.2962126401253045
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.276944637298584
total time:  6.326962891034782
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.35
[I 2023-06-12 00:26:12,606] Trial 131 finished with value: 80.0 and parameters: {'Fwd': 0.015871559277351628, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.537343872165649, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035030103234815575, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005292237257146266, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.003684624274267547
weight_decay:  0.005906015343535849
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.390801426023245
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.572993011912331
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  2.4393848818726838
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 7.445745468139648
total time:  7.491581950802356
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.15
[I 2023-06-12 00:26:20,623] Trial 132 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.006400748062163535, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 2.848058726709625, 'loop': 1, 'loss': 'MSE', 'lr': 0.003684624274267547, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005906015343535849, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.35000000000000003
lr:  0.004179487840847483
weight_decay:  0.011198833652352864
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.846175957005471
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.307345720939338
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  2.391075775027275
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.58543062210083
total time:  6.632380152819678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.12
[I 2023-06-12 00:26:27,679] Trial 133 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.00329439597755941, 'K': 6, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.540569626171079, 'loop': 1, 'loss': 'MSE', 'lr': 0.004179487840847483, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.011198833652352864, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.0051825415640533185
weight_decay:  0.0036299314696002115
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5324212240520865
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.590914203086868
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.0409486379940063
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 6.209233283996582
total time:  6.257773014949635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.10
[I 2023-06-12 00:26:34,444] Trial 134 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.0065770476533245125, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 2.3192970932804977, 'loop': 1, 'loss': 'MSE', 'lr': 0.0051825415640533185, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0036299314696002115, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.00545501459611889
weight_decay:  0.008131994231682564
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8372508629690856
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.2105895979329944
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.101707360940054
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 6.192619562149048
total time:  6.242022634018213
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 1.27
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.23
[I 2023-06-12 00:26:41,123] Trial 135 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.004603192109873873, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 2.0961547833260936, 'loop': 1, 'loss': 'MSE', 'lr': 0.00545501459611889, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008131994231682564, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.4
lr:  0.0024933062496010853
weight_decay:  0.003800219605298611
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.292032211087644
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  1.226243498036638
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 03
None time:  1.5052302910480648
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.80
run time now: 4.065244913101196
total time:  4.105886020930484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.13 ± 2.80
  Final Train: 100.00 ± 0.00
   Final Test: 73.73 ± 1.20
[I 2023-06-12 00:26:45,780] Trial 136 finished with value: 75.13333129882812 and parameters: {'Fwd': 0.007396554170361511, 'K': 6, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 2.3554664043028715, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024933062496010853, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.003800219605298611, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.35000000000000003
lr:  0.004986068713473788
weight_decay:  0.002746309510611783
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2065835690591484
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.8607501941733062
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  2.0001212609931827
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.108347415924072
total time:  6.161848613061011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.06
[I 2023-06-12 00:26:52,385] Trial 137 finished with value: 80.0666732788086 and parameters: {'Fwd': 0.005803622690634199, 'K': 6, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.7464491039210324, 'loop': 1, 'loss': 'MSE', 'lr': 0.004986068713473788, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002746309510611783, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.0029113738613418647
weight_decay:  0.006692720607391768
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.970462312921882
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.19126971391961
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  2.1703563451301306
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 9.370575904846191
total time:  9.421950211049989
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.49
[I 2023-06-12 00:27:02,241] Trial 138 finished with value: 79.33332824707031 and parameters: {'Fwd': 0.019635401052316356, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 1.7991846063103847, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029113738613418647, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006692720607391768, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.35000000000000003
lr:  0.0038268507402684534
weight_decay:  0.005782489316490227
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0267, Train: 100.00%, Valid: 80.80% Test: 78.50%
Split: 01, Run: 01
None time:  4.691662314115092
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0237, Train: 100.00%, Valid: 80.40% Test: 78.20%
Split: 01, Run: 02
None time:  5.268409310141578
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.3049959409981966
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
run time now: 12.304287672042847
total time:  12.347062406828627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.15
[I 2023-06-12 00:27:15,049] Trial 139 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.003827093504908934, 'K': 5, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 3.0154888355601956, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038268507402684534, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005782489316490227, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.25
lr:  0.0064057214914755
weight_decay:  0.004559919303680494
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6196229308843613
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.1269753640517592
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.2135793750640005
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 7.015603542327881
total time:  7.0537668850738555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.36
[I 2023-06-12 00:27:22,634] Trial 140 finished with value: 79.86666107177734 and parameters: {'Fwd': 0.05721972024008258, 'K': 7, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.271219520600789, 'loop': 1, 'loss': 'MSE', 'lr': 0.0064057214914755, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004559919303680494, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.25
lr:  0.004361234828572248
weight_decay:  0.0032957736158293373
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9182034530676901
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.203408665023744
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.9818057720549405
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.143735647201538
total time:  6.184127459069714
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.20
[I 2023-06-12 00:27:29,249] Trial 141 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.006937064362963581, 'K': 6, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.338695400545462, 'loop': 1, 'loss': 'MSE', 'lr': 0.004361234828572248, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0032957736158293373, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.30000000000000004
lr:  0.003304099219025521
weight_decay:  0.002119947669397765
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.932532667182386
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  2.173526572994888
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.0649582610931247
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.218029975891113
total time:  6.261258794926107
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.40
[I 2023-06-12 00:27:35,952] Trial 142 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.009933670457499733, 'K': 4, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 3.782906504394565, 'loop': 1, 'loss': 'MSE', 'lr': 0.003304099219025521, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002119947669397765, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.004807093294817815
weight_decay:  0.001923608913323165
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.943400904070586
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  2.1836613009218127
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.5424179639667273
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.709481954574585
total time:  5.749261082848534
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.57
[I 2023-06-12 00:27:42,182] Trial 143 finished with value: 80.06665802001953 and parameters: {'Fwd': 0.025967051381129556, 'K': 5, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 3.6282401181676005, 'loop': 1, 'loss': 'MSE', 'lr': 0.004807093294817815, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001923608913323165, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.005726845240620973
weight_decay:  0.0012791327013720643
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3689017330762
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.313204159028828
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9502759180031717
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.688604354858398
total time:  6.727715691085905
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.36
[I 2023-06-12 00:27:49,367] Trial 144 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.004976564519000254, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 4.131352187397322, 'loop': 1, 'loss': 'MSE', 'lr': 0.005726845240620973, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0012791327013720643, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.0037968462480303055
weight_decay:  0.0015153557217068786
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4454051540233195
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  4.322365436935797
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.1250823619775474
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 8.934448957443237
total time:  8.987451435998082
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.15
[I 2023-06-12 00:27:58,912] Trial 145 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.01327188775229538, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 2.843139996932528, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037968462480303055, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015153557217068786, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.004469685988236892
weight_decay:  0.009711981318860172
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.517480346141383
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  2.30426244600676
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.718524405034259
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.578058958053589
total time:  5.615775437094271
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.06
[I 2023-06-12 00:28:04,972] Trial 146 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.0026514751483621727, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 1.0, 'lambda2': 3.908285666962876, 'loop': 1, 'loss': 'MSE', 'lr': 0.004469685988236892, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009711981318860172, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.005315111024206148
weight_decay:  0.0025837065609754573
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9243434551171958
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.637421827064827
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.1005859600845724
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.7157301902771
total time:  6.76307646301575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.35
[I 2023-06-12 00:28:12,181] Trial 147 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.039981093810587516, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 2.611385473622332, 'loop': 1, 'loss': 'MSE', 'lr': 0.005315111024206148, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0025837065609754573, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.4
lr:  0.0035347001123607427
weight_decay:  0.0008789492260392071
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.256473303074017
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0436, Train: 100.00%, Valid: 80.00% Test: 78.40%
Split: 01, Run: 02
None time:  4.965814010007307
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  3.3419962781481445
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 10.62573766708374
total time:  10.676625865045935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.40
[I 2023-06-12 00:28:23,406] Trial 148 finished with value: 80.19999694824219 and parameters: {'Fwd': 0.00933153823522487, 'K': 6, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 3.3839645229524535, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035347001123607427, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0008789492260392071, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.25
lr:  0.004280368741818298
weight_decay:  0.003924476334720276
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9111544599290937
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.0047543300315738
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.0638023300562054
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.025773525238037
total time:  6.071432047989219
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 0.23
[I 2023-06-12 00:28:29,979] Trial 149 finished with value: 77.53333282470703 and parameters: {'Fwd': 0.006832910108797516, 'K': 7, 'alpha': 0.25, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 3.1693822047846774, 'loop': 1, 'loss': 'MSE', 'lr': 0.004280368741818298, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003924476334720276, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.004967240264036695
weight_decay:  0.017555446727907927
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1931587108410895
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.9860254370141774
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.7997743799351156
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.40
run time now: 7.03876256942749
total time:  7.091112207854167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.36
[I 2023-06-12 00:28:37,650] Trial 150 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.02013996970830479, 'K': 7, 'alpha': 0.05, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 2.9401276813950723, 'loop': 1, 'loss': 'MSE', 'lr': 0.004967240264036695, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.017555446727907927, 'weightedloss': True}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004009481271969965
weight_decay:  0.005297869852029469
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6161751688923687
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.7641949479002506
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.103738999925554
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.546335935592651
total time:  5.596929654944688
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.30
[I 2023-06-12 00:28:43,851] Trial 151 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.015176960725030594, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.4465405170217895, 'loop': 1, 'loss': 'MSE', 'lr': 0.004009481271969965, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005297869852029469, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004024791365425535
weight_decay:  0.0030928633859720178
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.682008890900761
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.7632549668196589
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.9973814459517598
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.479096174240112
total time:  5.532570397015661
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.31
[I 2023-06-12 00:28:49,993] Trial 152 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.01098549353946867, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.1093722200278164, 'loop': 1, 'loss': 'MSE', 'lr': 0.004024791365425535, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0030928633859720178, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.003998136154742399
weight_decay:  0.00475965369516622
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7044549859128892
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.2598046991042793
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.6392193289939314
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.637700080871582
total time:  5.684933856129646
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.25
[I 2023-06-12 00:28:56,281] Trial 153 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.011823332442234272, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 2.022663029577766, 'loop': 1, 'loss': 'MSE', 'lr': 0.003998136154742399, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00475965369516622, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0032009677384436416
weight_decay:  0.0033818358960851407
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.12014203495346
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.502132175024599
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  2.462755002779886
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.50
run time now: 7.127247333526611
total time:  7.178604620974511
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.23
[I 2023-06-12 00:29:03,931] Trial 154 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.016102766714512964, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 1.939756282742324, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032009677384436416, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0033818358960851407, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.003538093430619376
weight_decay:  0.004290474410773175
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.492646058788523
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  2.4398886000271887
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.7556879550684243
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.80
run time now: 5.739698171615601
total time:  5.791521016974002
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.27 ± 0.57
[I 2023-06-12 00:29:10,205] Trial 155 finished with value: 79.20000457763672 and parameters: {'Fwd': 0.030478605504062513, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 2.0907165508607295, 'loop': 1, 'loss': 'MSE', 'lr': 0.003538093430619376, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004290474410773175, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.003874047228336046
weight_decay:  0.007640458413213022
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7948184739798307
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 98.33
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.5587192010134459
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 98.33
   Final Test: 76.00
Split: 01, Run: 03
None time:  1.781976244179532
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 98.33
   Final Test: 75.80
run time now: 5.182649612426758
total time:  5.229372909059748
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 0.31
  Final Train: 98.33 ± 0.00
   Final Test: 76.13 ± 0.42
[I 2023-06-12 00:29:15,966] Trial 156 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.06342490259942624, 'K': 3, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.7070022665465396, 'loop': 1, 'loss': 'CE', 'lr': 0.003874047228336046, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007640458413213022, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0028222199975443305
weight_decay:  0.006211735470363604
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.101662597153336
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.9245639420114458
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  1.7747513221111149
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.10
run time now: 5.83765172958374
total time:  5.875531574944034
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 77.27 ± 0.21
[I 2023-06-12 00:29:22,329] Trial 157 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.01210167917910164, 'K': 2, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 2.0795733938673884, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028222199975443305, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006211735470363604, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.004727124168412223
weight_decay:  0.0027888029432342723
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0332456938922405
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.657810715958476
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.8788740991149098
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.609215021133423
total time:  5.652873924002051
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.20
[I 2023-06-12 00:29:28,481] Trial 158 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.044479889034894866, 'K': 2, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.3739110199285727, 'loop': 1, 'loss': 'MSE', 'lr': 0.004727124168412223, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0027888029432342723, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.0040424378192346795
weight_decay:  0.002031491821586621
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1841897510457784
None Run 01:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 02
None time:  0.9284528421703726
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 03
None time:  0.8423719210550189
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.50
run time now: 2.9940366744995117
total time:  3.040800889953971
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.13 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 73.33 ± 0.57
[I 2023-06-12 00:29:31,967] Trial 159 finished with value: 75.13333892822266 and parameters: {'Fwd': 0.02343117741723639, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 2.4469066983624868, 'loop': 1, 'loss': 'MSE', 'lr': 0.0040424378192346795, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.002031491821586621, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.003397325123903914
weight_decay:  0.0032057572445129603
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5790471159853041
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.117729099933058
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.5555651830509305
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.292497634887695
total time:  5.341822315938771
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.26
[I 2023-06-12 00:29:37,787] Trial 160 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.07177919724070599, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 2.253150542974332, 'loop': 1, 'loss': 'MSE', 'lr': 0.003397325123903914, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0032057572445129603, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004144552325759771
weight_decay:  0.004780326784544126
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.795354373054579
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.9412006079219282
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  2.0565971101168543
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
run time now: 5.830525159835815
total time:  5.871833754936233
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.21
[I 2023-06-12 00:29:44,097] Trial 161 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.008822501141240717, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.662844619964152, 'loop': 1, 'loss': 'MSE', 'lr': 0.004144552325759771, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004780326784544126, 'weightedloss': False}. Best is trial 52 with value: 80.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.003774106673863361
weight_decay:  0.004789318574454481
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.442238876828924
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.226251312997192
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.0673078149557114
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.768765449523926
total time:  6.819716539001092
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.15
[I 2023-06-12 00:29:51,510] Trial 162 finished with value: 81.0 and parameters: {'Fwd': 0.007663814172571574, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.4396059371883307, 'loop': 1, 'loss': 'MSE', 'lr': 0.003774106673863361, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004789318574454481, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004615165546676527
weight_decay:  0.004549651026478648
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0143076749518514
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.393141900189221
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.7157428730279207
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.155144453048706
total time:  6.204346644924954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.29
[I 2023-06-12 00:29:58,319] Trial 163 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.005754290970763522, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.5881481716588466, 'loop': 1, 'loss': 'MSE', 'lr': 0.004615165546676527, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004549651026478648, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.005458109763631388
weight_decay:  0.004817564768102501
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7439891649410129
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.8396448360290378
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.6199584880378097
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.237905502319336
total time:  5.288791357073933
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.72
[I 2023-06-12 00:30:04,131] Trial 164 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.005771506115060881, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.5507234406085173, 'loop': 1, 'loss': 'MSE', 'lr': 0.005458109763631388, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004817564768102501, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.005090376973066044
weight_decay:  0.006479526383815909
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7081846620421857
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.884819009108469
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.6429767510853708
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.274162292480469
total time:  5.318821512861177
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.44
[I 2023-06-12 00:30:09,939] Trial 165 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.007914886486449547, 'K': 2, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.9181823249038468, 'loop': 1, 'loss': 'MSE', 'lr': 0.005090376973066044, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006479526383815909, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004540883505158087
weight_decay:  0.004594119832473181
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8646440389566123
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.821611117105931
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.6554431128315628
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.387898206710815
total time:  5.432242266833782
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.23
[I 2023-06-12 00:30:15,813] Trial 166 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.004235865118692411, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.2568062482692537, 'loop': 1, 'loss': 'MSE', 'lr': 0.004540883505158087, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004594119832473181, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.004148117748296427
weight_decay:  0.007448582361908308
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6711631298530847
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.8878283880185336
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  3.765904566971585
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 7.361348867416382
total time:  7.400333205005154
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 0.55
[I 2023-06-12 00:30:23,686] Trial 167 finished with value: 79.53333282470703 and parameters: {'Fwd': 0.006226040373515773, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 1.6149984914171513, 'loop': 1, 'loss': 'MSE', 'lr': 0.004148117748296427, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007448582361908308, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.005849579491736048
weight_decay:  0.009051334598027861
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.478841891977936
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8260540049523115
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.8925810609944165
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.239793300628662
total time:  5.280352242989466
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.26
[I 2023-06-12 00:30:29,488] Trial 168 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.010685824359739438, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.7347700180744146, 'loop': 1, 'loss': 'MSE', 'lr': 0.005849579491736048, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009051334598027861, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.0010277282377508538
weight_decay:  0.005550035146621927
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5850141448900104
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 02
None time:  2.3915430561173707
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 03
None time:  1.8803390029352158
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.70
run time now: 5.8914806842803955
total time:  5.937465511029586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.07 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 73.27 ± 1.25
[I 2023-06-12 00:30:35,927] Trial 169 finished with value: 75.0666732788086 and parameters: {'Fwd': 0.008891028711040626, 'K': 1, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.5291745091638558, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010277282377508538, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005550035146621927, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004754833382036438
weight_decay:  0.0037883226026637507
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7145857359282672
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.5550121690612286
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.6720017560292035
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 4.978020429611206
total time:  5.025451555848122
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.10
[I 2023-06-12 00:30:41,430] Trial 170 finished with value: 80.13333892822266 and parameters: {'Fwd': 0.011836054783108762, 'K': 2, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 2.1133613551068287, 'loop': 1, 'loss': 'MSE', 'lr': 0.004754833382036438, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0037883226026637507, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0036965414538813607
weight_decay:  0.0030846988724312504
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.987519991118461
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.000064321095124
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.9148098181467503
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.943183898925781
total time:  5.990562747931108
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.10
[I 2023-06-12 00:30:47,949] Trial 171 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.004878650153357317, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 2.7151588033830723, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036965414538813607, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0030846988724312504, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004261880095401972
weight_decay:  0.0041725628438558
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9024918121285737
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8632703649345785
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.5561652949545532
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.355937480926514
total time:  5.400398571975529
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.15
[I 2023-06-12 00:30:53,832] Trial 172 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.007055867282694547, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.398933886642782, 'loop': 1, 'loss': 'MSE', 'lr': 0.004261880095401972, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0041725628438558, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004348245490379393
weight_decay:  0.004371437283101382
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.896763141034171
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.0642985771410167
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.1991578619927168
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.1972246170043945
total time:  5.237915112869814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.21
[I 2023-06-12 00:30:59,535] Trial 173 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.00719557472431392, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.404828728623975, 'loop': 1, 'loss': 'MSE', 'lr': 0.004348245490379393, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004371437283101382, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.00508340672996427
weight_decay:  0.004726649457805575
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.6705294160638005
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.7657814489211887
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.818263242021203
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
run time now: 7.555589914321899
total time:  7.651052416069433
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.29
[I 2023-06-12 00:31:07,788] Trial 174 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.006841599154823274, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.416617194532117, 'loop': 1, 'loss': 'MSE', 'lr': 0.00508340672996427, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004726649457805575, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.004385405463836439
weight_decay:  0.00382901581809693
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.061433128081262
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.746649817097932
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.884722962975502
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.728528738021851
total time:  6.765757971908897
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.25
[I 2023-06-12 00:31:15,017] Trial 175 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.005499858858107019, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.9497607209639118, 'loop': 1, 'loss': 'MSE', 'lr': 0.004385405463836439, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00382901581809693, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004297830273487179
weight_decay:  0.003928577866108386
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8016714078839868
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.866339444881305
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.1152343838475645
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.857996225357056
total time:  5.9258739850483835
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.26
[I 2023-06-12 00:31:21,480] Trial 176 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.00802527777682187, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.8065264184064511, 'loop': 1, 'loss': 'MSE', 'lr': 0.004297830273487179, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003928577866108386, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.004526944716566082
weight_decay:  0.0037176871391116427
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8465225067920983
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.8074330210220069
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.9564411849714816
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.647643804550171
total time:  5.693890118971467
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.32
[I 2023-06-12 00:31:27,676] Trial 177 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.005367854561063041, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.5253768383505064, 'loop': 1, 'loss': 'MSE', 'lr': 0.004526944716566082, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0037176871391116427, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.0066977029470402134
weight_decay:  0.002741763104197754
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6320257380139083
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.6184155449736863
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.7579923449084163
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.30
run time now: 5.047167778015137
total time:  5.085412529995665
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.60
[I 2023-06-12 00:31:33,277] Trial 178 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.003474349964966638, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.7868213375789537, 'loop': 1, 'loss': 'MSE', 'lr': 0.0066977029470402134, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002741763104197754, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.005712994764757734
weight_decay:  0.003869025499814151
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7467488809488714
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.6395343479234725
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 03
None time:  1.5517040388658643
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 75.60
run time now: 4.974447727203369
total time:  5.0167126569431275
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 76.20 ± 0.56
[I 2023-06-12 00:31:38,762] Trial 179 finished with value: 78.66666412353516 and parameters: {'Fwd': 0.007743596798971706, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.2549441477695473, 'loop': 1, 'loss': 'CE', 'lr': 0.005712994764757734, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003869025499814151, 'weightedloss': True}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.0021660084057718333
weight_decay:  0.007766698143628485
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.221479407977313
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  1.8478262040298432
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  2.0036525861360133
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 7.111633539199829
total time:  7.151609010994434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.33 ± 0.15
[I 2023-06-12 00:31:46,418] Trial 180 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.0025724909105135775, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 1.2625095570667861, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021660084057718333, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007766698143628485, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004196478706261776
weight_decay:  0.005558612104102364
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.726646054070443
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.7515123749617487
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.205521827097982
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.719390392303467
total time:  5.765985806006938
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.15
[I 2023-06-12 00:31:52,809] Trial 181 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.004280245445911807, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.0464111815490527, 'loop': 1, 'loss': 'MSE', 'lr': 0.004196478706261776, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005558612104102364, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.00423215260867498
weight_decay:  0.005859946074167927
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8692488679662347
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.5968421199359
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  3.21773641416803
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.722442626953125
total time:  6.768630811013281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.32
[I 2023-06-12 00:32:00,083] Trial 182 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.0041253920513573735, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 1.9273719344416744, 'loop': 1, 'loss': 'MSE', 'lr': 0.00423215260867498, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005859946074167927, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004806990776842359
weight_decay:  0.004163638845783566
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.820902245119214
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.9954764230642468
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.0320650700014085
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 5.883473873138428
total time:  5.933441173052415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.12
[I 2023-06-12 00:32:06,622] Trial 183 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.006539291495431988, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.3886281195343666, 'loop': 1, 'loss': 'MSE', 'lr': 0.004806990776842359, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004163638845783566, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.005156179745888581
weight_decay:  0.003462317124254388
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.2271577569190413
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.8260099191684276
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.854504724033177
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.947920322418213
total time:  6.985615332843736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.49
[I 2023-06-12 00:32:14,147] Trial 184 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.006314222902952236, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.374250486440028, 'loop': 1, 'loss': 'MSE', 'lr': 0.005156179745888581, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003462317124254388, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004603830429450256
weight_decay:  0.004083493309565353
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9109712468925864
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.9826559741050005
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.90832594409585
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.844857931137085
total time:  5.8836936061270535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.20
[I 2023-06-12 00:32:20,538] Trial 185 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.008324304746044368, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.115008872802034, 'loop': 1, 'loss': 'MSE', 'lr': 0.004603830429450256, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004083493309565353, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004294194544265259
weight_decay:  0.002728105499083643
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5491378800943494
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.932496618013829
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.0953934830613434
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.612494230270386
total time:  5.663101714802906
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.06
[I 2023-06-12 00:32:26,653] Trial 186 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.005239862094336324, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.573746129855091, 'loop': 1, 'loss': 'MSE', 'lr': 0.004294194544265259, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002728105499083643, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.0041553271238978905
weight_decay:  0.002459340418334821
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8147856078576297
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.79217465990223
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.939531304873526
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.585060358047485
total time:  5.630441221874207
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.46
[I 2023-06-12 00:32:32,746] Trial 187 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.004711290187641158, 'K': 3, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 1.7945696269993991, 'loop': 1, 'loss': 'MSE', 'lr': 0.0041553271238978905, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.002459340418334821, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.0032849837061485294
weight_decay:  0.003059370211024066
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.048377903876826
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.7773389159701765
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.8626215939875692
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.725667953491211
total time:  5.774686196120456
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.36
[I 2023-06-12 00:32:39,037] Trial 188 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.005434754427395621, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.563766548059222, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032849837061485294, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003059370211024066, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0037933144927550927
weight_decay:  0.005600555003947302
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8143909808713943
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.9573045030701905
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.160503981867805
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.971884489059448
total time:  7.028163642156869
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.12
[I 2023-06-12 00:32:46,530] Trial 189 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.002939880313416022, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.86381278802589, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037933144927550927, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005600555003947302, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.0042426519511945485
weight_decay:  0.0024007095356583575
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1688366020098329
None Run 01:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.50
Split: 01, Run: 02
None time:  0.9854297540150583
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 03
None time:  1.330566159915179
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.70
run time now: 3.5210044384002686
total time:  3.560611950000748
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 73.43 ± 0.31
[I 2023-06-12 00:32:50,645] Trial 190 finished with value: 74.20000457763672 and parameters: {'Fwd': 0.0019363402202972595, 'K': 3, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.2049460032199484, 'loop': 1, 'loss': 'MSE', 'lr': 0.0042426519511945485, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0024007095356583575, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004771286140200095
weight_decay:  0.004437227231606303
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.72993448888883
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.830967937130481
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.4776693389285356
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.075158596038818
total time:  5.119720606133342
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.21
[I 2023-06-12 00:32:56,408] Trial 191 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.0068339300713635195, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.43486571609545, 'loop': 1, 'loss': 'MSE', 'lr': 0.004771286140200095, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004437227231606303, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.005263644711334279
weight_decay:  0.0061385068624155055
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.896130929933861
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7774249999783933
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.50302739511244
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.259963750839233
total time:  5.302548342850059
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.21
[I 2023-06-12 00:33:02,199] Trial 192 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.0036520316632723533, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.6156143492739976, 'loop': 1, 'loss': 'MSE', 'lr': 0.005263644711334279, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0061385068624155055, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.008753691762185586
weight_decay:  0.003188403277580765
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.078534568892792
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.967231793794781
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.7463277811184525
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.830883979797363
total time:  5.873023382853717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.13 ± 0.46
[I 2023-06-12 00:33:08,530] Trial 193 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.008314929249292793, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 1.9085958179031637, 'loop': 1, 'loss': 'MSE', 'lr': 0.008753691762185586, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003188403277580765, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004522070495167421
weight_decay:  0.00464635453078896
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6579497291240841
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.1388459701556712
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.742860620142892
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.575258731842041
total time:  5.631009676959366
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.40
[I 2023-06-12 00:33:14,676] Trial 194 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.009803694323255925, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 2.467133117118359, 'loop': 1, 'loss': 'MSE', 'lr': 0.004522070495167421, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00464635453078896, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.003984380218224028
weight_decay:  0.007293073585593355
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7875776779837906
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.8200572929345071
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.156808814033866
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.798689365386963
total time:  5.849565285956487
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.30
[I 2023-06-12 00:33:21,152] Trial 195 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.007124868922321299, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.1856315296619746, 'loop': 1, 'loss': 'MSE', 'lr': 0.003984380218224028, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007293073585593355, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0040087150285755945
weight_decay:  0.009279960745972052
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.753759377868846
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.9885051529854536
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.9519775970838964
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.7338547706604
total time:  5.777450229041278
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.32
[I 2023-06-12 00:33:27,503] Trial 196 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.007032036876016063, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.209315809453205, 'loop': 1, 'loss': 'MSE', 'lr': 0.0040087150285755945, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009279960745972052, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.005463194905234177
weight_decay:  0.007205067692922874
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8017817179206759
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.655070313019678
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.7323470320552588
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.228267669677734
total time:  5.269427316030487
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.36
[I 2023-06-12 00:33:33,229] Trial 197 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.004951316802215945, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.0225281517165588, 'loop': 1, 'loss': 'MSE', 'lr': 0.005463194905234177, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007205067692922874, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004726964100341597
weight_decay:  0.01264455102956057
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.935965855838731
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.6879522500094026
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.767065507126972
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.429030418395996
total time:  5.473388264887035
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.15
[I 2023-06-12 00:33:39,125] Trial 198 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.004261913988211465, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.7716706318552589, 'loop': 1, 'loss': 'MSE', 'lr': 0.004726964100341597, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01264455102956057, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.006047818839430989
weight_decay:  0.010236336420595295
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9900112920440733
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  2.1323666640091687
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 03
None time:  1.858914053067565
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.02566123008728
total time:  6.078660047147423
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.70 ± 1.11
[I 2023-06-12 00:33:45,652] Trial 199 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.007711781092534845, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.633817046919174, 'loop': 1, 'loss': 'MSE', 'lr': 0.006047818839430989, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.010236336420595295, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.0017966140992618236
weight_decay:  0.006506085733003442
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7699241410009563
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.763170360121876
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0329, Train: 100.00%, Valid: 75.80% Test: 73.60%
Split: 01, Run: 03
None time:  4.472650564042851
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.60
run time now: 8.044776201248169
total time:  8.090868636965752
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 74.73 ± 1.03
[I 2023-06-12 00:33:54,210] Trial 200 finished with value: 76.4000015258789 and parameters: {'Fwd': 0.006000205787137474, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.342416339020974, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017966140992618236, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006506085733003442, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0034775816465144192
weight_decay:  0.005041112547706667
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7107571728993207
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7589571720454842
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.878705247072503
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.388041734695435
total time:  5.4414254180155694
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.21
[I 2023-06-12 00:34:00,102] Trial 201 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.010648094953872839, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.787989784478926, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034775816465144192, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005041112547706667, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0042693479072226205
weight_decay:  0.003601631237413163
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.976863226853311
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.7317067140247673
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.575084022944793
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.323267698287964
total time:  5.366776490118355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.26
[I 2023-06-12 00:34:05,936] Trial 202 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.014423881870479839, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.9814749181148383, 'loop': 1, 'loss': 'MSE', 'lr': 0.0042693479072226205, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003601631237413163, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0043462055158989335
weight_decay:  0.003924266481646353
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9526543798856437
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8668953208252788
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.1747700511477888
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.040927171707153
total time:  6.101817769929767
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.17
[I 2023-06-12 00:34:12,473] Trial 203 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.014529913983197671, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.999591615885794, 'loop': 1, 'loss': 'MSE', 'lr': 0.0043462055158989335, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003924266481646353, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.00439094609745085
weight_decay:  0.004141548933816127
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9626125718932599
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.822124658850953
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.726355898892507
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.547943592071533
total time:  5.593901114072651
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.40 ± 0.30
[I 2023-06-12 00:34:18,519] Trial 204 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.0137404353012699, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.897884211527981, 'loop': 1, 'loss': 'MSE', 'lr': 0.00439094609745085, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004141548933816127, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004294622355145836
weight_decay:  0.004285986866470093
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9395724348723888
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.9557000680360943
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.65708118211478
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.595468521118164
total time:  5.645921024028212
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.06
[I 2023-06-12 00:34:24,686] Trial 205 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.0153691372332369, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.99738367640766, 'loop': 1, 'loss': 'MSE', 'lr': 0.004294622355145836, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004285986866470093, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.003894903454819295
weight_decay:  0.005245077133013053
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1828451768960804
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.9452612840104848
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.803621457889676
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.979027271270752
total time:  6.017840611981228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.17
[I 2023-06-12 00:34:31,189] Trial 206 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.01670359990258103, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.9665104341289013, 'loop': 1, 'loss': 'MSE', 'lr': 0.003894903454819295, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005245077133013053, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004895206931207279
weight_decay:  0.008049004300272295
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8741160279605538
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  2.850176566047594
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9750105650164187
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.73471474647522
total time:  6.795321287820116
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.49
[I 2023-06-12 00:34:38,598] Trial 207 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.00915569076015261, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.543300969671357, 'loop': 1, 'loss': 'MSE', 'lr': 0.004895206931207279, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008049004300272295, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004410224188659225
weight_decay:  0.0002790237655730022
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.899717709980905
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.5967899861279875
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.9479969891253859
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.510238409042358
total time:  5.551653646863997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.35
[I 2023-06-12 00:34:44,680] Trial 208 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.013745083153905182, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.200640887878114, 'loop': 1, 'loss': 'MSE', 'lr': 0.004410224188659225, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002790237655730022, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0003827025953356235
weight_decay:  0.0040474474021503755
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0071, Train: 100.00%, Valid: 68.40% Test: 67.50%
Split: 01, Run: 01
None time:  4.287353281863034
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0072, Train: 100.00%, Valid: 71.20% Test: 69.70%
Split: 01, Run: 02
None time:  4.566290050977841
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0065, Train: 100.00%, Valid: 64.20% Test: 63.20%
Split: 01, Run: 03
None time:  4.440980668179691
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.10
run time now: 13.472546577453613
total time:  13.532065944047645
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.93 ± 3.52
  Final Train: 100.00 ± 0.00
   Final Test: 66.63 ± 3.29
[I 2023-06-12 00:34:58,776] Trial 209 finished with value: 67.93334197998047 and parameters: {'Fwd': 0.007888485028216995, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 3.0723524464789187, 'loop': 1, 'loss': 'MSE', 'lr': 0.0003827025953356235, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0040474474021503755, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.003614299188366725
weight_decay:  0.006384358481113014
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.109142549103126
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0364, Train: 100.00%, Valid: 80.40% Test: 78.10%
Split: 01, Run: 02
None time:  4.3616914169397205
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.7314332160167396
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 9.240317821502686
total time:  9.286097096977755
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.20
[I 2023-06-12 00:35:08,536] Trial 210 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.01032175323942731, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 1.561299942820709, 'loop': 1, 'loss': 'MSE', 'lr': 0.003614299188366725, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006384358481113014, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0042931511932032
weight_decay:  0.004300562228995494
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8182305959053338
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.9553040619939566
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.8065574001520872
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.619570970535278
total time:  5.662512200884521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.06
[I 2023-06-12 00:35:14,676] Trial 211 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.015457692085612052, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.7074051401809243, 'loop': 1, 'loss': 'MSE', 'lr': 0.0042931511932032, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004300562228995494, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004094866328152855
weight_decay:  0.005004507081024039
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7147459348198026
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.894213363993913
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.1114658981096
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.50
run time now: 5.758764743804932
total time:  5.80762382899411
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.12
[I 2023-06-12 00:35:21,002] Trial 212 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.016619772828264403, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.711319115729216, 'loop': 1, 'loss': 'MSE', 'lr': 0.004094866328152855, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005004507081024039, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.7000000000000001
lr:  0.004426801001840793
weight_decay:  0.003621074063000437
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.941781676840037
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.9790411170106381
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.8744155301246792
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.8397133350372314
total time:  5.886835051001981
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.15
[I 2023-06-12 00:35:27,477] Trial 213 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.005847682805642725, 'K': 2, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.4462279441221373, 'loop': 1, 'loss': 'MSE', 'lr': 0.004426801001840793, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003621074063000437, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.004319094977624872
weight_decay:  0.003204198010204657
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7269044748973101
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.02466034097597
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.1261994778178632
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.915562152862549
total time:  5.9726392878219485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.10
[I 2023-06-12 00:35:33,975] Trial 214 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.005233106901314182, 'K': 2, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.6209165124075415, 'loop': 1, 'loss': 'MSE', 'lr': 0.004319094977624872, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003204198010204657, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0038904701438034093
weight_decay:  0.003244414986959914
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4832675920333713
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.117497401079163
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  2.244383238023147
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.00
run time now: 7.894788980484009
total time:  7.944625315954909
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.50
[I 2023-06-12 00:35:42,549] Trial 215 finished with value: 80.06665802001953 and parameters: {'Fwd': 0.011215912135592256, 'K': 2, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.7945684821066594, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038904701438034093, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003244414986959914, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.004520004589871457
weight_decay:  0.0025975546702740443
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9418097289744765
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.101676625199616
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.8741557819303125
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.983734369277954
total time:  6.031229768879712
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.15
[I 2023-06-12 00:35:49,203] Trial 216 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.005015947714424071, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.5702407076337668, 'loop': 1, 'loss': 'MSE', 'lr': 0.004520004589871457, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0025975546702740443, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.0030325581989193774
weight_decay:  0.0026214327893108926
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9980145459994674
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.9333106011617929
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  2.037530994042754
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.60
run time now: 6.016109466552734
total time:  6.072992678033188
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.93 ± 0.31
[I 2023-06-12 00:35:55,942] Trial 217 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.001334560456717081, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.1, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.0266829308215293, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030325581989193774, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0026214327893108926, 'weightedloss': True}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.6000000000000001
lr:  0.0052261954526688775
weight_decay:  0.0034414414889307934
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9869719201233238
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  1.930037901038304
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  1.7491969419643283
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 77.20
run time now: 5.708535432815552
total time:  5.749883484095335
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 0.31
  Final Train: 99.44 ± 0.96
   Final Test: 77.20 ± 0.00
[I 2023-06-12 00:36:02,330] Trial 218 finished with value: 79.06666564941406 and parameters: {'Fwd': 0.018511379194127202, 'K': 2, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.359904417960004, 'loop': 1, 'loss': 'CE', 'lr': 0.0052261954526688775, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0034414414889307934, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.75
lr:  0.00343919472258456
weight_decay:  0.002605361801463228
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.38426834018901
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  4.236107898876071
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.5963444490917027
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 10.250432252883911
total time:  10.303886657115072
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.40
[I 2023-06-12 00:36:13,143] Trial 219 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0031314818752837792, 'K': 2, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.8638146073421407, 'loop': 1, 'loss': 'MSE', 'lr': 0.00343919472258456, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002605361801463228, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.004371709770243245
weight_decay:  0.0018179119107124512
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.081051785964519
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.219473493983969
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  2.291987967910245
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.628654718399048
total time:  6.679297711933032
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.26
[I 2023-06-12 00:36:20,429] Trial 220 finished with value: 80.33332824707031 and parameters: {'Fwd': 0.014648529514411104, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 2.622007939076782, 'loop': 1, 'loss': 'MSE', 'lr': 0.004371709770243245, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0018179119107124512, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.004614791375954714
weight_decay:  0.003516691327115876
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9460805039852858
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.9026277719531208
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.9039114089682698
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.790510177612305
total time:  5.841197183122858
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.35
[I 2023-06-12 00:36:26,842] Trial 221 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.005437122138194058, 'K': 2, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.5675905376009824, 'loop': 1, 'loss': 'MSE', 'lr': 0.004614791375954714, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003516691327115876, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.7000000000000001
lr:  0.003920641105591598
weight_decay:  0.004201669404287836
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.138887160923332
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.334588529076427
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9381832981016487
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.449112415313721
total time:  6.50090987700969
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.36
[I 2023-06-12 00:36:33,947] Trial 222 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.005744711104133604, 'K': 2, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.3715024687457524, 'loop': 1, 'loss': 'MSE', 'lr': 0.003920641105591598, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004201669404287836, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.004881058692684573
weight_decay:  0.002856829575037829
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.126362195936963
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.9269220819696784
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.035433741984889
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.125567674636841
total time:  6.178922179155052
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.15
[I 2023-06-12 00:36:40,716] Trial 223 finished with value: 80.06666564941406 and parameters: {'Fwd': 0.007876879497342802, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 3.1553275498190168, 'loop': 1, 'loss': 'MSE', 'lr': 0.004881058692684573, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002856829575037829, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.004125881241939914
weight_decay:  0.0037335090453188644
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6307611488737166
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.9794586380012333
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  2.2665970330126584
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.910011529922485
total time:  5.960038237040862
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.29
[I 2023-06-12 00:36:47,261] Trial 224 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.00042448706195200524, 'K': 2, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.6713436127792543, 'loop': 1, 'loss': 'MSE', 'lr': 0.004125881241939914, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0037335090453188644, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8
lr:  0.004460959738868346
weight_decay:  0.0023721453545730827
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5423701170366257
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.080174881964922
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.8896217639558017
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.5613884925842285
total time:  5.622543283039704
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.21
[I 2023-06-12 00:36:53,375] Trial 225 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.009858934770836474, 'K': 2, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.2067501580524618, 'loop': 1, 'loss': 'MSE', 'lr': 0.004460959738868346, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023721453545730827, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0036664804075934154
weight_decay:  0.00499652435469744
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.215798798017204
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.8861551331356168
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.9642010999377817
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.1050169467926025
total time:  6.14466630294919
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.32
[I 2023-06-12 00:37:00,130] Trial 226 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.004948167649279857, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.468498372721846, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036664804075934154, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00499652435469744, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.005090684199321249
weight_decay:  0.003104161244190843
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5835277519654483
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.1588536920025945
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.992309203138575
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.770900011062622
total time:  5.8193356189876795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.25
[I 2023-06-12 00:37:06,515] Trial 227 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.006835297785512742, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.90834599673436, 'loop': 1, 'loss': 'MSE', 'lr': 0.005090684199321249, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003104161244190843, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.7000000000000001
lr:  0.004326937337380943
weight_decay:  0.006763903752671221
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.942977458005771
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.2844157428480685
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  0.818440699018538
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 75.40
run time now: 3.0928235054016113
total time:  3.137227721977979
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 76.70 ± 1.21
[I 2023-06-12 00:37:10,243] Trial 228 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.003519223424051928, 'K': 2, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.6316894347450983, 'loop': 1, 'loss': 'MSE', 'lr': 0.004326937337380943, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.006763903752671221, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.005541471724683321
weight_decay:  8.580624895192614e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0862967749126256
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  2.4097348519135267
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.907658995129168
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.440473556518555
total time:  6.497798326192424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 77.83 ± 0.31
[I 2023-06-12 00:37:17,288] Trial 229 finished with value: 79.53333282470703 and parameters: {'Fwd': 0.01324806138543853, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 3.0934737766140663, 'loop': 1, 'loss': 'MSE', 'lr': 0.005541471724683321, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.580624895192614e-06, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0038741716398862725
weight_decay:  0.004286179564705948
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0739089818671346
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.04263884620741
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.1291289068758488
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.2822349071502686
total time:  6.3412243782076985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.21
[I 2023-06-12 00:37:24,225] Trial 230 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.009091533366763075, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 2.2278588171721387, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038741716398862725, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004286179564705948, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.004248753235640055
weight_decay:  0.005654171648630755
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7243486379738897
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.742135111009702
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  3.034282403998077
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.536677122116089
total time:  6.5873945478815585
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.35
[I 2023-06-12 00:37:31,411] Trial 231 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.0006470993617328191, 'K': 2, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 1.9948801338623583, 'loop': 1, 'loss': 'MSE', 'lr': 0.004248753235640055, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005654171648630755, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.004774866840929743
weight_decay:  0.005929673167926409
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9112470198888332
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7842791739385575
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.824954236857593
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.55899453163147
total time:  5.603150740964338
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.12
[I 2023-06-12 00:37:37,597] Trial 232 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.004002482988480546, 'K': 2, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.0909507085521435, 'loop': 1, 'loss': 'MSE', 'lr': 0.004774866840929743, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005929673167926409, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8
lr:  0.004171726610028414
weight_decay:  0.00808880129395657
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7968502840958536
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.773815228138119
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.011597194010392
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.629997491836548
total time:  5.677883432945237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.26
[I 2023-06-12 00:37:43,824] Trial 233 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.004787155023568445, 'K': 2, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.4186423629459153, 'loop': 1, 'loss': 'MSE', 'lr': 0.004171726610028414, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00808880129395657, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.004537440606735332
weight_decay:  0.0035252113138190054
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8448568109888583
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.1133823900017887
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.063538390211761
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.064417123794556
total time:  6.110008901916444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.30
[I 2023-06-12 00:37:50,368] Trial 234 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.006137881842338725, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.84266259785857, 'loop': 1, 'loss': 'MSE', 'lr': 0.004537440606735332, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0035252113138190054, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0036904208123122876
weight_decay:  0.00012604681833480302
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6657050279900432
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.1494801219087094
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.120104643050581
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.973234415054321
total time:  6.027613845188171
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.23
[I 2023-06-12 00:37:56,977] Trial 235 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.004225277647343195, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 2.7294476295152763, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036904208123122876, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00012604681833480302, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004070401709980823
weight_decay:  0.0047476417703289095
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5545984408818185
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.673646598123014
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.45179434819147
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.717661142349243
total time:  5.766078176908195
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.32
[I 2023-06-12 00:38:03,305] Trial 236 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.007885381354153329, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.105690374911558, 'loop': 1, 'loss': 'MSE', 'lr': 0.004070401709980823, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0047476417703289095, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0032831847265753925
weight_decay:  0.004377015264683964
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.844163996167481
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7111811637878418
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  2.9173864130862057
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.509830951690674
total time:  6.561177992960438
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.40
[I 2023-06-12 00:38:10,399] Trial 237 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.008110092897872291, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.486703902637195, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032831847265753925, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004377015264683964, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.005110218670140537
weight_decay:  0.002844061530525464
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8660245910286903
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.546226170146838
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.3283533530775458
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 6.776538133621216
total time:  6.824327941052616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.61
[I 2023-06-12 00:38:17,714] Trial 238 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.011712002754059852, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.820319155613972, 'loop': 1, 'loss': 'MSE', 'lr': 0.005110218670140537, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002844061530525464, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8500000000000001
lr:  0.0039379427800456225
weight_decay:  0.0022948723440304668
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5573061930481344
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.5582741929683834
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.8139467390719801
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.968870162963867
total time:  5.043335371883586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.15
[I 2023-06-12 00:38:23,245] Trial 239 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.006782892279644485, 'K': 3, 'alpha': 0.8500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.262487505420924, 'loop': 1, 'loss': 'MSE', 'lr': 0.0039379427800456225, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0022948723440304668, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0012411686852496706
weight_decay:  0.003768842811490564
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0139, Train: 100.00%, Valid: 75.00% Test: 73.30%
Split: 01, Run: 01
None time:  3.446350409183651
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.2292049610987306
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.5019034009892493
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.40
run time now: 6.215963840484619
total time:  6.257633467903361
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 72.20 ± 1.21
[I 2023-06-12 00:38:30,169] Trial 240 finished with value: 74.53333282470703 and parameters: {'Fwd': 0.020800714915521552, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 2.9980312617921614, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012411686852496706, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003768842811490564, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.004288031393128045
weight_decay:  0.005430591380835273
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6785152989905328
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.538792229956016
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  2.968021926935762
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.224407911300659
total time:  6.267033869866282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.40
[I 2023-06-12 00:38:36,957] Trial 241 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.005257590798380473, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 1.9872245116561142, 'loop': 1, 'loss': 'MSE', 'lr': 0.004288031393128045, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005430591380835273, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.007814276795708898
weight_decay:  0.004878073311551399
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6574729401618242
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.5101835450623184
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.8232816501986235
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.60
run time now: 5.08803391456604
total time:  5.133058910025284
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.47 ± 0.81
[I 2023-06-12 00:38:42,651] Trial 242 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.00848915606703027, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 5.260129789134233, 'loop': 1, 'loss': 'MSE', 'lr': 0.007814276795708898, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004878073311551399, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004664660129416111
weight_decay:  0.0068566605587419135
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8744808700866997
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.5221247388981283
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9698490879964083
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.80
run time now: 5.399497747421265
total time:  5.4481461169198155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.30
[I 2023-06-12 00:38:48,667] Trial 243 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.006218855738198957, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.6320051407555782, 'loop': 1, 'loss': 'MSE', 'lr': 0.004664660129416111, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0068566605587419135, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004644410547444687
weight_decay:  0.00718269374017554
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1503534831572324
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.6063720451202244
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.759013744071126
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.554100751876831
total time:  5.594370590057224
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.44
[I 2023-06-12 00:38:54,831] Trial 244 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.0002134701164511187, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.6742457346964965, 'loop': 1, 'loss': 'MSE', 'lr': 0.004644410547444687, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00718269374017554, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004795897851193709
weight_decay:  0.007890006917314575
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.792437116149813
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  3.356375833041966
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.101988634094596
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 7.284541845321655
total time:  7.324604503111914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.32
[I 2023-06-12 00:39:02,735] Trial 245 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.014369494372566537, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 1.6642161738373566, 'loop': 1, 'loss': 'MSE', 'lr': 0.004795897851193709, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007890006917314575, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0036110217419212556
weight_decay:  0.010592214971004127
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8273021411150694
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.0681018650066108
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0346, Train: 100.00%, Valid: 79.20% Test: 78.30%
Split: 01, Run: 03
None time:  4.419478255789727
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.50
run time now: 8.349904537200928
total time:  8.394964701961726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.66
[I 2023-06-12 00:39:11,714] Trial 246 finished with value: 80.19999694824219 and parameters: {'Fwd': 0.0001542187545453273, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 1.5010462201982917, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036110217419212556, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.010592214971004127, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.005516531316810559
weight_decay:  0.007225594744589512
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0085299289785326
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.928812535945326
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  2.1809227580670267
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.15734076499939
total time:  6.209376107202843
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.26
[I 2023-06-12 00:39:18,527] Trial 247 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.011220273490251646, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 1.4562136197270772, 'loop': 1, 'loss': 'MSE', 'lr': 0.005516531316810559, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007225594744589512, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004045846397247194
weight_decay:  0.009153354406828339
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0618845459539443
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.527836900902912
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  3.6094826229382306
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 7.251952171325684
total time:  7.31479784892872
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.23
[I 2023-06-12 00:39:26,414] Trial 248 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.0002252683277329267, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.6909184618851132, 'loop': 1, 'loss': 'MSE', 'lr': 0.004045846397247194, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009153354406828339, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  1.0
lr:  0.0045586540004430125
weight_decay:  0.0067513958643418345
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1157779609784484
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.0389790751505643
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.955897559178993
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
run time now: 6.153734922409058
total time:  6.191802044864744
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.25
[I 2023-06-12 00:39:33,116] Trial 249 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.00931945705151744, 'K': 6, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 1.7342953518456676, 'loop': 1, 'loss': 'MSE', 'lr': 0.0045586540004430125, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0067513958643418345, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.005013007089777217
weight_decay:  0.003470601282762128
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9686324240174145
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.317144746892154
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.6762366017792374
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.231303930282593
total time:  6.290429734159261
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.35
[I 2023-06-12 00:39:40,020] Trial 250 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.017876668067815706, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.3163296550282655, 'loop': 1, 'loss': 'MSE', 'lr': 0.005013007089777217, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003470601282762128, 'weightedloss': True}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.0039266726244712
weight_decay:  0.0016800684541694083
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9974999418482184
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.76644675899297
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 03
None time:  1.9035972571000457
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.90
run time now: 5.779173374176025
total time:  5.839331832015887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.03 ± 0.42
[I 2023-06-12 00:39:46,473] Trial 251 finished with value: 78.79999542236328 and parameters: {'Fwd': 0.007002111868062498, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 1.937070523459305, 'loop': 1, 'loss': 'CE', 'lr': 0.0039266726244712, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0016800684541694083, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004444231255316733
weight_decay:  0.005483094610464383
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4400292749051005
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.7506866899784654
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.4748985508922487
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.70
run time now: 4.705907106399536
total time:  4.7536901528947055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.25
[I 2023-06-12 00:39:51,685] Trial 252 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.010907044085495789, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 4.87294964817908, 'loop': 1, 'loss': 'MSE', 'lr': 0.004444231255316733, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005483094610464383, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0034279169870396497
weight_decay:  0.015001516310944528
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.342836641939357
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.7680742829106748
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.381667776964605
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.530101299285889
total time:  5.577300797915086
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.15
[I 2023-06-12 00:39:57,727] Trial 253 finished with value: 80.0 and parameters: {'Fwd': 0.006392929196630039, 'K': 2, 'alpha': 0.9, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.1941048037394975, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034279169870396497, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.015001516310944528, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.006039892016031074
weight_decay:  0.0028983835134030996
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9878925699740648
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  2.3294143909588456
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 03
None time:  1.8472397960722446
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.202585935592651
total time:  6.251181694213301
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 1.11
[I 2023-06-12 00:40:04,514] Trial 254 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.014769996729383006, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.371777341315716, 'loop': 1, 'loss': 'MSE', 'lr': 0.006039892016031074, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0028983835134030996, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.004177762608228719
weight_decay:  0.004080853049656487
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.187718844972551
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.9530267100781202
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  2.5667649968527257
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.744987964630127
total time:  6.790680635953322
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.42
[I 2023-06-12 00:40:11,843] Trial 255 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.008839912757819857, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 3.2191128296894242, 'loop': 1, 'loss': 'MSE', 'lr': 0.004177762608228719, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004080853049656487, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.7000000000000001
lr:  0.005069527202887695
weight_decay:  0.0005323638373530446
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0195024008862674
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.8437882068101317
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.883401694940403
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 5.7845847606658936
total time:  5.831068221945316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.60 ± 0.10
[I 2023-06-12 00:40:18,164] Trial 256 finished with value: 80.80000305175781 and parameters: {'Fwd': 3.877630618408845e-05, 'K': 3, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.837504076605501, 'loop': 1, 'loss': 'MSE', 'lr': 0.005069527202887695, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005323638373530446, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0048089791553213275
weight_decay:  0.00039708889337179416
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.097952852025628
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 74.10
Split: 01, Run: 02
None time:  0.8968777018599212
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 03
None time:  0.9638207550160587
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.30
run time now: 2.9988880157470703
total time:  3.043856524862349
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 75.53 ± 1.24
[I 2023-06-12 00:40:21,786] Trial 257 finished with value: 77.80001068115234 and parameters: {'Fwd': 9.499008202614426e-05, 'K': 4, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 1.7385760513749706, 'loop': 1, 'loss': 'MSE', 'lr': 0.0048089791553213275, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00039708889337179416, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.6000000000000001
lr:  0.009652926499961908
weight_decay:  0.0019838006374130967
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.674962165998295
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.4749360089190304
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.7710434840992093
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.00
run time now: 4.957659482955933
total time:  4.9953589148353785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 77.30 ± 0.44
[I 2023-06-12 00:40:27,239] Trial 258 finished with value: 78.4000015258789 and parameters: {'Fwd': 0.0021455480944844686, 'K': 3, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 1.086909231346163, 'loop': 1, 'loss': 'MSE', 'lr': 0.009652926499961908, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0019838006374130967, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.75
lr:  0.0037170168364213155
weight_decay:  0.0005754496319352096
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.352489701937884
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.6423752310220152
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0366, Train: 100.00%, Valid: 80.20% Test: 78.00%
Split: 01, Run: 03
None time:  4.4371988859493285
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 8.468597888946533
total time:  8.506415923126042
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.06
[I 2023-06-12 00:40:36,362] Trial 259 finished with value: 80.4000015258789 and parameters: {'Fwd': 4.588179015649305e-05, 'K': 3, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.847284460026039, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037170168364213155, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005754496319352096, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8
lr:  0.004468699626514462
weight_decay:  0.006264515684176997
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.786197845125571
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.8137219049967825
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.5591923689935356
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.1927266120910645
total time:  5.245704251108691
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.26
[I 2023-06-12 00:40:42,131] Trial 260 finished with value: 80.53333282470703 and parameters: {'Fwd': 3.828852048348097e-06, 'K': 1, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 6.827205874586768, 'loop': 1, 'loss': 'MSE', 'lr': 0.004468699626514462, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006264515684176997, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.0014945714402198188
weight_decay:  0.0007950392577356247
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.419293740997091
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  1.8796782880090177
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0206, Train: 100.00%, Valid: 75.00% Test: 72.40%
Split: 01, Run: 03
None time:  4.158240031916648
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.50
run time now: 8.500575065612793
total time:  8.55654549994506
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.93 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 73.80 ± 1.68
[I 2023-06-12 00:40:51,135] Trial 261 finished with value: 75.93333435058594 and parameters: {'Fwd': 0.0031168931511257533, 'K': 2, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 1.4113252650206691, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014945714402198188, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007950392577356247, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004019748188510682
weight_decay:  0.00029266812575859277
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8463447550311685
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.6649100850336254
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.6047693321015686
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.160557746887207
total time:  5.267665022984147
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.44
[I 2023-06-12 00:40:56,878] Trial 262 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.022090427768761873, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 8.460086407261326, 'loop': 1, 'loss': 'MSE', 'lr': 0.004019748188510682, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00029266812575859277, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.005467399115904744
weight_decay:  0.0004612185259439262
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.028601780999452
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.499824529979378
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.6795471711084247
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.295666456222534
total time:  5.342095124069601
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.35
[I 2023-06-12 00:41:02,756] Trial 263 finished with value: 80.66666412353516 and parameters: {'Fwd': 1.0905156642010782e-05, 'K': 2, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.0577448461410404, 'loop': 1, 'loss': 'MSE', 'lr': 0.005467399115904744, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004612185259439262, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.7000000000000001
lr:  0.0018109941927459735
weight_decay:  0.0002607883474934652
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.810598913114518
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.7480724649503827
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  1.93420644197613
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.80
run time now: 5.528696298599243
total time:  5.574979624012485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.73 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 74.63 ± 1.36
[I 2023-06-12 00:41:08,842] Trial 264 finished with value: 76.73333740234375 and parameters: {'Fwd': 0.0003092092543835958, 'K': 1, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 4.452130870356878, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018109941927459735, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002607883474934652, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8500000000000001
lr:  0.002483278600846899
weight_decay:  0.001329782330637938
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6894574100151658
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  1.763376760063693
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0310, Train: 100.00%, Valid: 77.80% Test: 76.20%
Split: 01, Run: 03
None time:  4.465597524074838
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.40
run time now: 7.961164951324463
total time:  7.998680867953226
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 76.87 ± 0.42
[I 2023-06-12 00:41:17,360] Trial 265 finished with value: 78.26667022705078 and parameters: {'Fwd': 0.017339471434849846, 'K': 3, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.8610436266803863, 'loop': 1, 'loss': 'MSE', 'lr': 0.002483278600846899, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001329782330637938, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.003282997783849792
weight_decay:  0.00035200992016567995
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.849311392987147
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.329691231949255
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.2070793120656163
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.424527168273926
total time:  6.473990371916443
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.10
[I 2023-06-12 00:41:24,341] Trial 266 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.0006353514461723012, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 2.6515198524686285, 'loop': 1, 'loss': 'MSE', 'lr': 0.003282997783849792, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00035200992016567995, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.6000000000000001
lr:  0.00011292139894061287
weight_decay:  0.0023491445825052676
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6067246180027723
None Run 01:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 37.50
Split: 01, Run: 02
None time:  1.5475442970637232
None Run 02:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 27.30
Split: 01, Run: 03
None time:  1.4084237709175795
None Run 03:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 54.70
run time now: 4.599479675292969
total time:  4.642354106996208
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 39.73 ± 11.10
  Final Train: 100.00 ± 0.00
   Final Test: 39.83 ± 13.85
[I 2023-06-12 00:41:29,526] Trial 267 finished with value: 39.733333587646484 and parameters: {'Fwd': 0.012890710860624991, 'K': 2, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 1.6340726827019931, 'loop': 1, 'loss': 'MSE', 'lr': 0.00011292139894061287, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023491445825052676, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.0005918123020182696
weight_decay:  0.004693906918907865
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0116, Train: 100.00%, Valid: 74.60% Test: 72.90%
Split: 01, Run: 01
None time:  4.2996972820255905
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 02
None time:  2.1081897059921175
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 03
None time:  2.036189866019413
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.00
run time now: 8.478638172149658
total time:  8.516886814963073
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 72.63 ± 0.35
[I 2023-06-12 00:41:38,532] Trial 268 finished with value: 74.66666412353516 and parameters: {'Fwd': 0.0050433458971844486, 'K': 1, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 2.1570385536738463, 'loop': 1, 'loss': 'MSE', 'lr': 0.0005918123020182696, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004693906918907865, 'weightedloss': False}. Best is trial 162 with value: 81.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004869553558751366
weight_decay:  0.09502327735540175
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.889504542807117
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.9815425290726125
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  2.091275254962966
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.999549627304077
total time:  6.0482058429624885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.40
[I 2023-06-12 00:41:45,006] Trial 269 finished with value: 81.13333129882812 and parameters: {'Fwd': 4.870086003400744e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.500873695156944, 'loop': 1, 'loss': 'MSE', 'lr': 0.004869553558751366, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.09502327735540175, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004979464483811521
weight_decay:  0.015461599556985133
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9530179791618139
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.6199309988878667
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.5981859150342643
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.207583904266357
total time:  6.246028800029308
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.21
[I 2023-06-12 00:41:51,777] Trial 270 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.00045089520836980897, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.4959084464640116, 'loop': 1, 'loss': 'MSE', 'lr': 0.004979464483811521, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.015461599556985133, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004581360718985612
weight_decay:  0.0010729253698876153
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8389976569451392
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 98.33
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.6708311270922422
None Run 02:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 03
None time:  1.7620705580338836
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 98.33
   Final Test: 75.80
run time now: 5.312264442443848
total time:  5.350225056055933
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.07 ± 0.31
  Final Train: 98.89 ± 0.96
   Final Test: 75.67 ± 0.12
[I 2023-06-12 00:41:57,591] Trial 271 finished with value: 78.0666732788086 and parameters: {'Fwd': 3.3820772552952266e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 1.9061203621571596, 'loop': 1, 'loss': 'CE', 'lr': 0.004581360718985612, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010729253698876153, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.006212662667854848
weight_decay:  0.046689007408394385
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6085056879092008
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.696789360139519
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.795409576036036
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.135810375213623
total time:  5.186055155005306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.36
[I 2023-06-12 00:42:03,390] Trial 272 finished with value: 80.80000305175781 and parameters: {'Fwd': 3.580895493125223e-05, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 2.41444888201058, 'loop': 1, 'loss': 'MSE', 'lr': 0.006212662667854848, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.046689007408394385, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.005415677554806228
weight_decay:  0.07283267309710151
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7372126509435475
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.8689632599707693
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.5264432579278946
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.2129151821136475
total time:  6.263440011069179
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.42
[I 2023-06-12 00:42:10,260] Trial 273 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.001621596570316587, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.0470834575504138, 'loop': 1, 'loss': 'MSE', 'lr': 0.005415677554806228, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.07283267309710151, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.004358607005545249
weight_decay:  0.0016104651295676777
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5447113090194762
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.7652373989112675
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.8141334529500455
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.160160541534424
total time:  6.209415567107499
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.26
[I 2023-06-12 00:42:16,986] Trial 274 finished with value: 80.06666564941406 and parameters: {'Fwd': 5.293947896721715e-05, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 2.2467166972828, 'loop': 1, 'loss': 'MSE', 'lr': 0.004358607005545249, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0016104651295676777, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0049699585679364435
weight_decay:  0.07026375935342072
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1184843939263374
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.8571344760712236
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.8325600589159876
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.70
run time now: 5.8482043743133545
total time:  5.895105554023758
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.49
[I 2023-06-12 00:42:23,374] Trial 275 finished with value: 80.5999984741211 and parameters: {'Fwd': 8.230654423771806e-05, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 0.39254735666264473, 'loop': 1, 'loss': 'MSE', 'lr': 0.0049699585679364435, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07026375935342072, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.00414637655386094
weight_decay:  0.012365881145525533
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9583592421840876
None Run 01:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 02
None time:  0.8603400040883571
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 03
None time:  1.1247314410284162
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.50
run time now: 2.9785048961639404
total time:  3.028340686811134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 74.93 ± 0.81
[I 2023-06-12 00:42:26,949] Trial 276 finished with value: 76.46666717529297 and parameters: {'Fwd': 0.00017409055775589757, 'K': 3, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 2.6190982532152205, 'loop': 1, 'loss': 'MSE', 'lr': 0.00414637655386094, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.012365881145525533, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.65
lr:  0.004675118420223105
weight_decay:  0.00961416405428499
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9609399670735002
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 02
None time:  1.4550392748788
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  1.0189154201652855
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 3.472886562347412
total time:  3.5137184970080853
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 72.43 ± 1.27
[I 2023-06-12 00:42:31,049] Trial 277 finished with value: 74.53333282470703 and parameters: {'Fwd': 0.0003080103938749327, 'K': 4, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 20, 'lambda1': 0.7000000000000001, 'lambda2': 2.9750213110943777, 'loop': 1, 'loss': 'MSE', 'lr': 0.004675118420223105, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00961416405428499, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.0037519012956758815
weight_decay:  9.588468377244683e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0284, Train: 100.00%, Valid: 81.20% Test: 78.40%
Split: 01, Run: 01
None time:  4.324272359954193
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.1874575740657747
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.6311694108881056
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.80
run time now: 8.17911696434021
total time:  8.22139296378009
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.29
[I 2023-06-12 00:42:39,917] Trial 278 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0008070270600231389, 'K': 2, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.258621350331018, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037519012956758815, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.588468377244683e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.006585606515261071
weight_decay:  0.024944807787718157
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.916934120003134
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.838403204921633
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.5095513591077179
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.301400661468506
total time:  5.344011941924691
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.85
[I 2023-06-12 00:42:45,765] Trial 279 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.0009631719024956197, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 5.825194374882017, 'loop': 1, 'loss': 'MSE', 'lr': 0.006585606515261071, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.024944807787718157, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9
lr:  0.005547223719136421
weight_decay:  0.01721351091877047
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.723205619957298
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.3321473950054497
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.5099060519132763
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.10
run time now: 4.597638368606567
total time:  4.637373036937788
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 76.97 ± 0.75
[I 2023-06-12 00:42:50,955] Trial 280 finished with value: 78.79999542236328 and parameters: {'Fwd': 7.837305258141451e-05, 'K': 1, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 4.360715164552234, 'loop': 1, 'loss': 'MSE', 'lr': 0.005547223719136421, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01721351091877047, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.004228677797815565
weight_decay:  0.026691549406717554
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.416958458023146
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 02
None time:  0.7309501199051738
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03
None time:  2.0118737719021738
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.50
run time now: 5.200563192367554
total time:  5.236862921155989
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 4.99
  Final Train: 100.00 ± 0.00
   Final Test: 68.93 ± 4.27
[I 2023-06-12 00:42:56,690] Trial 281 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.0025192336811371485, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 10, 'lambda1': 0.8500000000000001, 'lambda2': 1.8828556715433122, 'loop': 1, 'loss': 'MSE', 'lr': 0.004228677797815565, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.026691549406717554, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0030160125088401156
weight_decay:  0.08290151179284957
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7531830270309001
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  2.0425547829363495
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.4109470101539046
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.2434916496276855
total time:  6.285384286893532
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.15
[I 2023-06-12 00:43:03,524] Trial 282 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.00985067893246864, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.738928965724029, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030160125088401156, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08290151179284957, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.0048019576034132655
weight_decay:  0.08337885550114002
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2120847611222416
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.769403463229537
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.8011160041205585
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.81877589225769
total time:  5.861489553935826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.23
[I 2023-06-12 00:43:09,876] Trial 283 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.00013857508175786165, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 2.303935737336696, 'loop': 1, 'loss': 'MSE', 'lr': 0.0048019576034132655, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08337885550114002, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.75
lr:  0.0017169561096961861
weight_decay:  0.012260224523775516
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.498008963186294
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02
None time:  1.8996972301974893
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 03
None time:  1.8446912940125912
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.30
run time now: 8.279019117355347
total time:  8.32746176701039
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 74.70 ± 1.31
[I 2023-06-12 00:43:18,654] Trial 284 finished with value: 76.46666717529297 and parameters: {'Fwd': 0.000226487024884038, 'K': 2, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 1.5820640448236318, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017169561096961861, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.012260224523775516, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.003982845872913996
weight_decay:  0.043265152684400274
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8855444199871272
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  4.5019489179831
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  2.291896992130205
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
run time now: 8.712827444076538
total time:  8.765310405986384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.40 ± 0.20
[I 2023-06-12 00:43:27,992] Trial 285 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.024785432324123453, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 4.753308192991179, 'loop': 1, 'loss': 'MSE', 'lr': 0.003982845872913996, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.043265152684400274, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.007534510279473038
weight_decay:  0.028007519194851217
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.805361589184031
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.9280832060612738
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.8324402868747711
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.605623245239258
total time:  5.647389966994524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 0.10
[I 2023-06-12 00:43:34,192] Trial 286 finished with value: 79.06666564941406 and parameters: {'Fwd': 0.01206304243922661, 'K': 2, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.5034913760873954, 'loop': 1, 'loss': 'MSE', 'lr': 0.007534510279473038, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.028007519194851217, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.005077573955584698
weight_decay:  0.048245948471786045
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4366077149752527
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.2232232929673046
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.4588575169909745
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.160165786743164
total time:  5.209273834945634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.15
[I 2023-06-12 00:43:39,994] Trial 287 finished with value: 80.66666412353516 and parameters: {'Fwd': 2.112123459973164e-05, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 2.127792103753839, 'loop': 1, 'loss': 'MSE', 'lr': 0.005077573955584698, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.048245948471786045, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004453262066400657
weight_decay:  0.09352509340441378
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.346108135068789
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.2462640900630504
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.696741851978004
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.327739477157593
total time:  6.374288434861228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.26
[I 2023-06-12 00:43:46,829] Trial 288 finished with value: 80.13333892822266 and parameters: {'Fwd': 0.017197116864334172, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 1.239797868611855, 'loop': 2, 'loss': 'MSE', 'lr': 0.004453262066400657, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.09352509340441378, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.0026812093618089083
weight_decay:  0.0006193801069955045
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.835879767080769
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.40
Split: 01, Run: 02
None time:  1.8292158748954535
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 03
None time:  1.7788058549631387
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.80
run time now: 5.483868360519409
total time:  5.522625311044976
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 74.77 ± 0.85
[I 2023-06-12 00:43:52,852] Trial 289 finished with value: 76.86666870117188 and parameters: {'Fwd': 0.007921291627524387, 'K': 3, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 4.558646996378433, 'loop': 1, 'loss': 'CE', 'lr': 0.0026812093618089083, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006193801069955045, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.003481802289865729
weight_decay:  0.0026965837207149597
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9795353489462286
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  3.526049847016111
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  2.9817819010932
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 8.699618816375732
total time:  8.750921971863136
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.51
[I 2023-06-12 00:44:02,217] Trial 290 finished with value: 80.13333892822266 and parameters: {'Fwd': 0.003811587981688016, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.0486691379926616, 'loop': 1, 'loss': 'MSE', 'lr': 0.003481802289865729, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0026965837207149597, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.005833549097470253
weight_decay:  0.0015454813484300466
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0341, Train: 100.00%, Valid: 76.00% Test: 74.60%
Split: 01, Run: 01
None time:  3.469445482129231
None Run 01:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 74.50
Split: 01, Run: 02
None time:  0.939792875899002
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 03
None time:  0.9489832192193717
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.40
run time now: 5.393118143081665
total time:  5.4448472110088915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.67 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 73.53 ± 1.06
[I 2023-06-12 00:44:08,305] Trial 291 finished with value: 75.66667175292969 and parameters: {'Fwd': 0.014639842083113825, 'K': 2, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.75, 'lambda2': 2.7067818500803233, 'loop': 1, 'loss': 'MSE', 'lr': 0.005833549097470253, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015454813484300466, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.7000000000000001
lr:  0.0038916335525386704
weight_decay:  0.06430177074292902
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8149480868596584
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.008374529890716
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.032571795862168
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.888887166976929
total time:  5.941386841004714
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.15
[I 2023-06-12 00:44:14,815] Trial 292 finished with value: 80.46666717529297 and parameters: {'Fwd': 6.530873768160262e-05, 'K': 1, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.404670160204796, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038916335525386704, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.06430177074292902, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0045042057021620506
weight_decay:  0.0032026364022491103
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.938324882183224
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.9695737848524004
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.5407564849592745
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.70
run time now: 5.486773490905762
total time:  5.5751821249723434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.47
[I 2023-06-12 00:44:20,980] Trial 293 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.0011952190031814622, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 1.9903930883457064, 'loop': 1, 'loss': 'MSE', 'lr': 0.0045042057021620506, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0032026364022491103, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.002074612868283352
weight_decay:  0.0002117142189160938
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.120787443825975
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  3.341871371027082
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  3.148514101980254
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.20
run time now: 8.64866304397583
total time:  8.698191331000999
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.23 ± 0.06
[I 2023-06-12 00:44:30,171] Trial 294 finished with value: 78.86666870117188 and parameters: {'Fwd': 0.00012867025269342939, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.834013307328793, 'loop': 1, 'loss': 'MSE', 'lr': 0.002074612868283352, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002117142189160938, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.009069716559527305
weight_decay:  0.008757407954220418
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8018320470582694
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7338537550531328
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  1.808561075013131
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.00
run time now: 5.382952928543091
total time:  5.427212685113773
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.37 ± 0.72
[I 2023-06-12 00:44:36,120] Trial 295 finished with value: 78.66666412353516 and parameters: {'Fwd': 2.9002549548336045e-05, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 3.1995437316287223, 'loop': 1, 'loss': 'MSE', 'lr': 0.009069716559527305, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008757407954220418, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.005221593042910918
weight_decay:  0.0004608744128588098
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.175503398058936
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 02
None time:  1.0868360849563032
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 03
None time:  0.8622689449694008
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.30
run time now: 3.1557791233062744
total time:  3.2026470419950783
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.00 ± 1.59
  Final Train: 100.00 ± 0.00
   Final Test: 74.03 ± 0.87
[I 2023-06-12 00:44:39,817] Trial 296 finished with value: 77.0 and parameters: {'Fwd': 0.007779333725665108, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 4.235417094619695, 'loop': 1, 'loss': 'MSE', 'lr': 0.005221593042910918, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0004608744128588098, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.0012141530223583783
weight_decay:  0.09772052787832995
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0191, Train: 100.00%, Valid: 76.60% Test: 75.40%
Split: 01, Run: 01
None time:  4.302192728035152
None Run 01:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 02
None time:  2.0025468468666077
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 03
None time:  1.9732733371201903
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 73.80
run time now: 8.314943313598633
total time:  8.375167336082086
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 74.10 ± 1.28
[I 2023-06-12 00:44:48,798] Trial 297 finished with value: 76.33333587646484 and parameters: {'Fwd': 5.7117229172266026e-05, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.5695710508546212, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012141530223583783, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.09772052787832995, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004113007146545174
weight_decay:  0.0020188748435785125
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0270546718966216
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.5388772988226265
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.7731631570495665
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.376899480819702
total time:  5.422750279074535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 0.35
[I 2023-06-12 00:44:54,708] Trial 298 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.00011322822234926149, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.718328779173888, 'loop': 1, 'loss': 'MSE', 'lr': 0.004113007146545174, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0020188748435785125, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0021529604748762284
weight_decay:  0.021745654624750036
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8858764900360256
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.7715808269567788
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  2.8681005551479757
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.20
run time now: 6.564992904663086
total time:  6.619830087060109
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 76.43 ± 0.59
[I 2023-06-12 00:45:01,810] Trial 299 finished with value: 78.5999984741211 and parameters: {'Fwd': 0.020634656113361627, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.2547901389595992, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021529604748762284, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.021745654624750036, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0036434358287382534
weight_decay:  0.03422740116499214
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7669949631672353
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.7274806660134345
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.908419918967411
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.43790864944458
total time:  5.482865059981123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 0.15
[I 2023-06-12 00:45:07,784] Trial 300 finished with value: 80.06665802001953 and parameters: {'Fwd': 0.010942400918210976, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 3.7315706975859335, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036434358287382534, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.03422740116499214, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004182383287084033
weight_decay:  0.0020683861008066596
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8458546588663012
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  2.023316196864471
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.298788998974487
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.2025675773620605
total time:  6.253005349775776
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.36
[I 2023-06-12 00:45:14,579] Trial 301 finished with value: 80.39999389648438 and parameters: {'Fwd': 0.005582163646676013, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 5.059403967306498, 'loop': 1, 'loss': 'MSE', 'lr': 0.004182383287084033, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0020683861008066596, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0038655939063977967
weight_decay:  0.0027371526824543435
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.722745131002739
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.768907338147983
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  3.480493283132091
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.80
run time now: 7.006693601608276
total time:  7.0608357531018555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 77.60 ± 0.17
[I 2023-06-12 00:45:22,247] Trial 302 finished with value: 79.5999984741211 and parameters: {'Fwd': 9.750780347503774e-05, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 1.5480558112453322, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038655939063977967, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0027371526824543435, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0034107725817000044
weight_decay:  0.003857180505803504
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3905595990363508
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.90861478401348
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.8772770608775318
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.216090440750122
total time:  5.266813663998619
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.70 ± 0.30
[I 2023-06-12 00:45:28,051] Trial 303 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.009198265866682372, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.952668294988731, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034107725817000044, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003857180505803504, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0023341585516533014
weight_decay:  0.011528499840886811
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.065093111013994
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0424, Train: 100.00%, Valid: 78.40% Test: 77.00%
Split: 01, Run: 02
None time:  4.405695675173774
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.8703967849723995
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.20
run time now: 10.379637241363525
total time:  10.417461722856387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.00 ± 0.80
[I 2023-06-12 00:45:39,128] Trial 304 finished with value: 78.86666107177734 and parameters: {'Fwd': 0.00015980204421499631, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 2.1391648812631447, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023341585516533014, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.011528499840886811, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004328239574038936
weight_decay:  0.002040008064092282
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0261472151614726
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.8460562720429152
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  3.0846821928862482
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.00
run time now: 7.013940811157227
total time:  7.1037881770171225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 77.60 ± 0.53
[I 2023-06-12 00:45:46,848] Trial 305 finished with value: 79.93333435058594 and parameters: {'Fwd': 0.00011851814532268666, 'K': 2, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 2.519727304347514, 'loop': 1, 'loss': 'MSE', 'lr': 0.004328239574038936, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002040008064092282, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004704659502259732
weight_decay:  0.0324205853409006
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8456412740051746
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.6420813479926437
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.9477390409447253
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.474833250045776
total time:  6.529939650092274
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.17
[I 2023-06-12 00:45:53,853] Trial 306 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.004780686718166766, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.7406524093087676, 'loop': 1, 'loss': 'MSE', 'lr': 0.004704659502259732, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0324205853409006, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.003038832504671826
weight_decay:  0.007381491215958476
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.909827221184969
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  2.0661258830223233
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  2.473420836031437
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.484692335128784
total time:  6.533038119086996
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.55
[I 2023-06-12 00:46:00,850] Trial 307 finished with value: 80.39999389648438 and parameters: {'Fwd': 0.0002071067954744358, 'K': 2, 'alpha': 0.25, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 1.352338146551476, 'loop': 1, 'loss': 'MSE', 'lr': 0.003038832504671826, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007381491215958476, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0020104579470213526
weight_decay:  0.004799606049284739
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0410657927859575
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 02
None time:  2.039154889062047
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 03
None time:  1.9120383290573955
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 76.20
run time now: 6.0370032787323
total time:  6.0866501240525395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 76.00 ± 0.62
[I 2023-06-12 00:46:07,417] Trial 308 finished with value: 77.46666717529297 and parameters: {'Fwd': 0.00025517925983895847, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 5.215783625880674, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020104579470213526, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004799606049284739, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.0040791038775699045
weight_decay:  0.02088774657882098
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9335431170184165
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.755650304025039
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.9037446060683578
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.10
run time now: 5.628747940063477
total time:  5.7115462210495025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 76.33 ± 0.21
[I 2023-06-12 00:46:13,650] Trial 309 finished with value: 78.33333587646484 and parameters: {'Fwd': 0.0004176940834600094, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 3.8963984627778068, 'loop': 1, 'loss': 'CE', 'lr': 0.0040791038775699045, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02088774657882098, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.0036486004706866733
weight_decay:  0.0033744080994711394
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0955007299780846
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.391833895118907
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.5838767911773175
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.70
run time now: 5.109783887863159
total time:  5.1568846851587296
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.45
[I 2023-06-12 00:46:19,285] Trial 310 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.00011296509115403727, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 1.7977066102797443, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036486004706866733, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0033744080994711394, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004576179634248926
weight_decay:  0.01415959709138544
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.60262735420838
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.7447226499207318
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.8159863820765167
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.206337928771973
total time:  5.248778040986508
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.23
[I 2023-06-12 00:46:25,164] Trial 311 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.00019508501140166337, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.42015341035949, 'loop': 1, 'loss': 'MSE', 'lr': 0.004576179634248926, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01415959709138544, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.0042064994459000615
weight_decay:  0.0026296064609914517
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7511242718901485
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.1887755640782416
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.087182329967618
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.084798812866211
total time:  6.1434147991240025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.15
[I 2023-06-12 00:46:31,785] Trial 312 finished with value: 80.39999389648438 and parameters: {'Fwd': 0.013763337610635924, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 3.1116530850703303, 'loop': 1, 'loss': 'MSE', 'lr': 0.0042064994459000615, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0026296064609914517, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0032119829538177617
weight_decay:  0.0013297771207010835
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9579218111466616
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7554457120131701
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.9461316070519388
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.6962785720825195
total time:  5.735302455024794
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.21
[I 2023-06-12 00:46:38,064] Trial 313 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.0002647137237802408, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.2909499199912493, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032119829538177617, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0013297771207010835, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0007306616283255931
weight_decay:  0.006172282782550713
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7239946420304477
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0108, Train: 100.00%, Valid: 74.20% Test: 72.50%
Split: 01, Run: 02
None time:  4.464960883837193
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  2.441197288921103
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.40
run time now: 8.669157981872559
total time:  8.715046453056857
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.20 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 73.00 ± 0.46
[I 2023-06-12 00:46:47,353] Trial 314 finished with value: 75.20000457763672 and parameters: {'Fwd': 0.04857719838505165, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 1.6871964252000575, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007306616283255931, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006172282782550713, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0038894361172085914
weight_decay:  0.04081188528566152
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9676792121026665
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  1.1822141788434237
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 03
None time:  1.0607139279600233
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.60
run time now: 3.250626802444458
total time:  3.308178496081382
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 76.30 ± 0.52
[I 2023-06-12 00:46:51,153] Trial 315 finished with value: 78.5999984741211 and parameters: {'Fwd': 0.007265037872873302, 'K': 2, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 3.593647417269475, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038894361172085914, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.04081188528566152, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.004767593760527926
weight_decay:  0.004813939117076355
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.05933595309034
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  3.8430943230632693
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  2.2532738528680056
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.00
run time now: 8.197188377380371
total time:  8.250568045070395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.50
[I 2023-06-12 00:46:59,861] Trial 316 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.00625904882772822, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.1147870625354623, 'loop': 1, 'loss': 'MSE', 'lr': 0.004767593760527926, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004813939117076355, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8
lr:  0.005330801290095674
weight_decay:  0.04889741671031916
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9072328279726207
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.9125595150981098
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.896272171055898
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.749383926391602
total time:  5.798393738921732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.10
[I 2023-06-12 00:47:06,202] Trial 317 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.018446158551483755, 'K': 2, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.615714905101685, 'loop': 1, 'loss': 'MSE', 'lr': 0.005330801290095674, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.04889741671031916, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004340536159579849
weight_decay:  0.003953265224976542
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3983717479277402
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0314, Train: 100.00%, Valid: 80.60% Test: 78.00%
Split: 01, Run: 02
None time:  4.618833628017455
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.5809081299230456
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.00
run time now: 7.637571811676025
total time:  7.679031024919823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.15
[I 2023-06-12 00:47:14,368] Trial 318 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.00035668615982473607, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 2.810354907515173, 'loop': 1, 'loss': 'MSE', 'lr': 0.004340536159579849, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003953265224976542, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0016675401250353333
weight_decay:  0.0595992736354922
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.498117264127359
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  3.6167186121456325
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 03
None time:  1.8688392050098628
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.50
run time now: 8.020864248275757
total time:  8.065691410098225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 75.70 ± 0.53
[I 2023-06-12 00:47:23,058] Trial 319 finished with value: 77.13333892822266 and parameters: {'Fwd': 0.011681005191643536, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 5.412808872926011, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016675401250353333, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0595992736354922, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.007145173620225756
weight_decay:  0.0018367225217051522
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8243245808407664
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.4913047139998525
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.7148682980332524
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.0698630809783936
total time:  5.115786181064323
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.32
[I 2023-06-12 00:47:28,775] Trial 320 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.003373176647996098, 'K': 1, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 3.29614872284747, 'loop': 1, 'loss': 'MSE', 'lr': 0.007145173620225756, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0018367225217051522, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.003631080152435316
weight_decay:  0.008363387056326093
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.237835875013843
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.46225642808713
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.9825002138968557
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 7.729889392852783
total time:  7.778893515933305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.31
[I 2023-06-12 00:47:37,043] Trial 321 finished with value: 79.86666107177734 and parameters: {'Fwd': 0.02572772921120806, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.0312456932734175, 'loop': 1, 'loss': 'MSE', 'lr': 0.003631080152435316, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008363387056326093, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.005802985103363749
weight_decay:  0.0023831498795173094
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.018119053915143
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.623829626943916
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.5634235218167305
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.242902040481567
total time:  5.286078233039007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.36
[I 2023-06-12 00:47:42,941] Trial 322 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.00938954906998084, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 9.933198679731362, 'loop': 1, 'loss': 'MSE', 'lr': 0.005802985103363749, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023831498795173094, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.00492312546173006
weight_decay:  0.003171602365088456
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.080386263085529
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.9641076570842415
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.265267379814759
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.366832256317139
total time:  5.424915835959837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.12
[I 2023-06-12 00:47:48,957] Trial 323 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.004204914058107113, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.4384506033502773, 'loop': 1, 'loss': 'MSE', 'lr': 0.00492312546173006, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003171602365088456, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.004914209337058183
weight_decay:  0.00586398971599053
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.908009205944836
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.4382010700646788
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.8101871709804982
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.50
run time now: 7.196280479431152
total time:  7.246716047869995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.35
[I 2023-06-12 00:47:56,652] Trial 324 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.0001667509485993267, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.313347698479702, 'loop': 1, 'loss': 'MSE', 'lr': 0.004914209337058183, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00586398971599053, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.005157058660562165
weight_decay:  0.004224096635075997
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.6803757078014314
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.6934864001814276
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.7853834410198033
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 7.203770160675049
total time:  7.245987805072218
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.45
[I 2023-06-12 00:48:04,402] Trial 325 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.004484172397106696, 'K': 5, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.896968653876067, 'loop': 1, 'loss': 'MSE', 'lr': 0.005157058660562165, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004224096635075997, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.00021237667831659968
weight_decay:  0.001136654526275466
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6193073911126703
None Run 01:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 41.40
Split: 01, Run: 02
None time:  1.6688538468442857
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03
None time:  2.0681989770382643
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 5.406365633010864
total time:  5.465972302947193
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.67 ± 14.85
  Final Train: 100.00 ± 0.00
   Final Test: 58.93 ± 15.22
[I 2023-06-12 00:48:10,361] Trial 326 finished with value: 61.66666793823242 and parameters: {'Fwd': 0.015703532382048125, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 4.8412015262380885, 'loop': 1, 'loss': 'MSE', 'lr': 0.00021237667831659968, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001136654526275466, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.001904779896190366
weight_decay:  0.0032149612560379744
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.182434828951955
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 02
None time:  1.5833530109375715
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 03
None time:  2.199243747163564
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 76.10
run time now: 6.003028631210327
total time:  6.051757064880803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 75.77 ± 0.95
[I 2023-06-12 00:48:16,931] Trial 327 finished with value: 77.20000457763672 and parameters: {'Fwd': 7.731147815237602e-05, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 4.081129426843971, 'loop': 1, 'loss': 'MSE', 'lr': 0.001904779896190366, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0032149612560379744, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.35000000000000003
lr:  0.003979553704964256
weight_decay:  0.007255637615013267
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3175041868817061
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.5601672509219497
None Run 02:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 96.67
   Final Test: 75.30
Split: 01, Run: 03
None time:  1.4520316298585385
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.30
run time now: 4.378164291381836
total time:  4.42601199215278
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.87 ± 0.50
  Final Train: 98.89 ± 1.92
   Final Test: 75.63 ± 0.58
[I 2023-06-12 00:48:21,949] Trial 328 finished with value: 77.86666870117188 and parameters: {'Fwd': 0.00590100586439822, 'K': 4, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 1.4662939478396881, 'loop': 1, 'loss': 'CE', 'lr': 0.003979553704964256, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007255637615013267, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.004607452115662498
weight_decay:  0.060591839982059845
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6030332408845425
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.8623614460229874
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.825148768024519
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.32537841796875
total time:  5.377867378061637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.25
[I 2023-06-12 00:48:27,835] Trial 329 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.007434751801933454, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.45805965963517, 'loop': 1, 'loss': 'MSE', 'lr': 0.004607452115662498, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.060591839982059845, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.006161593640092693
weight_decay:  0.010314578832635868
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9569488840643317
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  2.7193766301497817
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 03
None time:  2.5707240849733353
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.70
run time now: 7.285237789154053
total time:  7.337364617967978
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 76.60 ± 0.90
[I 2023-06-12 00:48:35,635] Trial 330 finished with value: 78.0 and parameters: {'Fwd': 0.03340856949829125, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 2.924752388836074, 'loop': 1, 'loss': 'MSE', 'lr': 0.006161593640092693, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.010314578832635868, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0013709525520114682
weight_decay:  0.00460257833367226
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.281960888998583
None Run 01:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 02
None time:  2.493182167876512
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03
None time:  2.264486555941403
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.00
run time now: 7.076134920120239
total time:  7.121274047065526
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 73.37 ± 1.35
[I 2023-06-12 00:48:43,399] Trial 331 finished with value: 75.73333740234375 and parameters: {'Fwd': 0.01061172289991763, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 4.697829745144359, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013709525520114682, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00460257833367226, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.4
lr:  0.0027255686312675424
weight_decay:  0.0023692066653547925
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.272033793851733
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  3.4903232369106263
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  1.9666347799357027
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.70
run time now: 9.771158695220947
total time:  9.822407494997606
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.00 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 77.07 ± 0.47
[I 2023-06-12 00:48:53,804] Trial 332 finished with value: 79.0 and parameters: {'Fwd': 0.007973388800737207, 'K': 3, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.191254606827523, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027255686312675424, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023692066653547925, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.005551842244894786
weight_decay:  0.0016032951244431249
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5845077221747488
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0326, Train: 100.00%, Valid: 81.20% Test: 78.70%
Split: 01, Run: 02
None time:  3.6433024348225445
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.6832943258341402
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.94796895980835
total time:  6.996765204006806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.36
[I 2023-06-12 00:49:01,332] Trial 333 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.0027769262024232573, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 1.2232985252254487, 'loop': 1, 'loss': 'MSE', 'lr': 0.005551842244894786, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0016032951244431249, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004741166139660963
weight_decay:  0.005496793097837923
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7442028389777988
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.788678424898535
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  2.790169039973989
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.360772371292114
total time:  6.402225058991462
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.29
[I 2023-06-12 00:49:08,376] Trial 334 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.020187480540731276, 'K': 2, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 1.6206886308034316, 'loop': 1, 'loss': 'MSE', 'lr': 0.004741166139660963, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005496793097837923, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.003418937960413645
weight_decay:  0.039688902549632095
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9625777010805905
None Run 01:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 02
None time:  0.9817755990661681
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 03
None time:  1.1760171751957387
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 74.90
run time now: 4.161071062088013
total time:  4.2140855779871345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 74.43 ± 0.72
[I 2023-06-12 00:49:13,165] Trial 335 finished with value: 75.53333282470703 and parameters: {'Fwd': 0.004333231185018173, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 4.365878114194128, 'loop': 1, 'loss': 'MSE', 'lr': 0.003418937960413645, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.039688902549632095, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.003992505293941665
weight_decay:  0.003648874712511736
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9629456449765712
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.9467501461040229
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.746779402019456
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.703337669372559
total time:  5.754308074014261
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.31
[I 2023-06-12 00:49:19,376] Trial 336 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.013198829821490224, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.4768224954752296, 'loop': 1, 'loss': 'MSE', 'lr': 0.003992505293941665, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003648874712511736, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.003828584811503892
weight_decay:  0.0035774607628812133
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0801479800138623
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.0065654050558805
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.8675189230125397
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.60
run time now: 6.027333974838257
total time:  6.104910274967551
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.06
[I 2023-06-12 00:49:26,011] Trial 337 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.013791902919654977, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 6.2966967058260455, 'loop': 1, 'loss': 'MSE', 'lr': 0.003828584811503892, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0035774607628812133, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004150926795663882
weight_decay:  0.0068239736910963
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.162513533141464
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8032980689313263
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.8702541070524603
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.877376556396484
total time:  5.923186851898208
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.26
[I 2023-06-12 00:49:32,390] Trial 338 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.001598019779431971, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.445480828800691, 'loop': 1, 'loss': 'MSE', 'lr': 0.004150926795663882, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0068239736910963, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.00320024724548725
weight_decay:  0.033934561771093205
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6091736368834972
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.9948700917884707
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.900445143925026
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.540722846984863
total time:  6.593431530985981
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.21
[I 2023-06-12 00:49:39,478] Trial 339 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.059647407479458875, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 3.6208356383613607, 'loop': 1, 'loss': 'MSE', 'lr': 0.00320024724548725, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.033934561771093205, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0035533864567114247
weight_decay:  0.0007449877608212595
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7827073321677744
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.9537556930445135
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.7876160291489214
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.562446594238281
total time:  5.607932356884703
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.40 ± 0.20
[I 2023-06-12 00:49:45,526] Trial 340 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.012555870191395115, 'K': 2, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 3.289921110276742, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035533864567114247, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007449877608212595, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004412311907687576
weight_decay:  0.004915449671585863
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5622892971150577
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  3.2319796478841454
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.762029716046527
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
run time now: 7.652959585189819
total time:  7.703999451827258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.26
[I 2023-06-12 00:49:53,724] Trial 341 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.015967213061087254, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 3.1435689231225283, 'loop': 1, 'loss': 'MSE', 'lr': 0.004412311907687576, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004915449671585863, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.003949336746863717
weight_decay:  0.013927762741886113
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1509956340305507
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.5540538209024817
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.4257794241420925
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.171505451202393
total time:  6.2146366911474615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.40
[I 2023-06-12 00:50:00,420] Trial 342 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.025764608806788984, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 1.9235416068417315, 'loop': 1, 'loss': 'MSE', 'lr': 0.003949336746863717, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.013927762741886113, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.004270246878285806
weight_decay:  0.003954616089281884
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9790698699653149
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.488284041872248
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.7715452110860497
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.271963357925415
total time:  6.311500813812017
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.20
[I 2023-06-12 00:50:07,335] Trial 343 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.042112054844394, 'K': 1, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.7448526237129394, 'loop': 1, 'loss': 'MSE', 'lr': 0.004270246878285806, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003954616089281884, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.003767738998192669
weight_decay:  0.01886104062526684
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.119081747950986
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.9825000339187682
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.8217010458465666
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.991350173950195
total time:  6.047871235990897
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.23
[I 2023-06-12 00:50:13,931] Trial 344 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.009593464922544299, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.936605564242777, 'loop': 1, 'loss': 'MSE', 'lr': 0.003767738998192669, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01886104062526684, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004612308269210386
weight_decay:  0.02137758450319439
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1578074370045215
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.2087844628840685
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.6642736929934472
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.069742202758789
total time:  6.1084210521075875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.38
[I 2023-06-12 00:50:20,534] Trial 345 finished with value: 80.0 and parameters: {'Fwd': 4.645001431960773e-05, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 3.0132229861251205, 'loop': 1, 'loss': 'MSE', 'lr': 0.004612308269210386, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02137758450319439, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0067031698393881034
weight_decay:  4.298033167800852e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.189671788131818
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.8873637760989368
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  2.1318260540720075
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.24695611000061
total time:  6.2909628679044545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.83 ± 0.45
[I 2023-06-12 00:50:27,328] Trial 346 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.01092208761964486, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 4.492246303916923, 'loop': 1, 'loss': 'MSE', 'lr': 0.0067031698393881034, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.298033167800852e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0077809825777754105
weight_decay:  0.002248793790085269
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.784443762153387
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.6357636437751353
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.7956510127987713
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.25590443611145
total time:  5.303898870013654
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.27 ± 0.15
[I 2023-06-12 00:50:33,173] Trial 347 finished with value: 78.0 and parameters: {'Fwd': 0.016392212074623977, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 3.4241753413814005, 'loop': 1, 'loss': 'MSE', 'lr': 0.0077809825777754105, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002248793790085269, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.0016117226555394562
weight_decay:  0.009486734665547334
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6677913791500032
None Run 01:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.50
Split: 01, Run: 02
None time:  1.7039643481839448
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 72.90
Split: 01, Run: 03
None time:  1.245082776993513
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.10
run time now: 4.655329704284668
total time:  4.707077234983444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 73.50 ± 0.87
[I 2023-06-12 00:50:38,356] Trial 348 finished with value: 76.0 and parameters: {'Fwd': 0.021674773557063008, 'K': 2, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.15000000000000002, 'lambda2': 3.894779198827031, 'loop': 1, 'loss': 'CE', 'lr': 0.0016117226555394562, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009486734665547334, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.002434711759696729
weight_decay:  0.0009537482453353994
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.986840857891366
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  2.176472353981808
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 03
None time:  1.6263410339597613
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.80
run time now: 7.825303554534912
total time:  7.867875509895384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 76.63 ± 0.96
[I 2023-06-12 00:50:46,764] Trial 349 finished with value: 78.4000015258789 and parameters: {'Fwd': 6.651188108870875e-05, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 2.6739939896762723, 'loop': 1, 'loss': 'MSE', 'lr': 0.002434711759696729, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009537482453353994, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0029373907726168227
weight_decay:  1.3330893828620636e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7632015550043434
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  3.388764973031357
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.8327171090058982
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.70
run time now: 9.019847869873047
total time:  9.073520398931578
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.38
[I 2023-06-12 00:50:56,330] Trial 350 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.008993228554345869, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 2.8398517444749833, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029373907726168227, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3330893828620636e-06, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.004104092456783378
weight_decay:  0.002880045594190337
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9279584761243314
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.3852439299225807
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  2.7544889030978084
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
run time now: 7.122950792312622
total time:  7.167383793974295
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.12
[I 2023-06-12 00:51:04,159] Trial 351 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.0003239279016358017, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 7.898619346335851, 'loop': 1, 'loss': 'MSE', 'lr': 0.004104092456783378, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002880045594190337, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0034792891389300268
weight_decay:  0.005732296484875425
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5230601029470563
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7409609449096024
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.9393479030113667
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.240509271621704
total time:  6.2865348351188
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.42
[I 2023-06-12 00:51:11,024] Trial 352 finished with value: 81.0 and parameters: {'Fwd': 0.007315559535838815, 'K': 2, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 1.8139525855408634, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034792891389300268, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005732296484875425, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0033324270369657727
weight_decay:  0.005911188329428987
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.171889968914911
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.2734221268910915
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.8992617221083492
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
run time now: 6.38455605506897
total time:  6.4416890379507095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.12
[I 2023-06-12 00:51:18,017] Trial 353 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.006297491719150131, 'K': 2, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 4.218595911517073, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033324270369657727, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005911188329428987, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0035881330584600513
weight_decay:  0.0076818189723991395
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.016719447914511
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  2.449570333119482
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  2.0696677081286907
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.571629762649536
total time:  6.612164058955386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.10
[I 2023-06-12 00:51:25,178] Trial 354 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.007754704326490373, 'K': 2, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.0107215227620947, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035881330584600513, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0076818189723991395, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.005118258178780972
weight_decay:  0.005174822154004151
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3822485979180783
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.3306608798447996
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 03
None time:  1.0004877110477537
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 75.30
run time now: 3.7459301948547363
total time:  3.789150276919827
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.80 ± 1.97
  Final Train: 100.00 ± 0.00
   Final Test: 76.27 ± 1.19
[I 2023-06-12 00:51:29,567] Trial 355 finished with value: 77.80001068115234 and parameters: {'Fwd': 1.4650807633744582e-05, 'K': 2, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.2065052181032447, 'loop': 1, 'loss': 'MSE', 'lr': 0.005118258178780972, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.005174822154004151, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  1.0
lr:  0.004482622576519799
weight_decay:  0.0042083450363818945
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.71549965813756
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.8304191250354052
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  2.1694378731772304
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 7.750786781311035
total time:  7.791844064136967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.29
[I 2023-06-12 00:51:37,861] Trial 356 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0004822904860516002, 'K': 1, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.0598345683425134, 'loop': 2, 'loss': 'MSE', 'lr': 0.004482622576519799, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0042083450363818945, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0009204699187069518
weight_decay:  0.008194084872493825
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.80% Test: 71.80%
Split: 01, Run: 01
None time:  2.1265457938425243
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 02
None time:  1.0726388080511242
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.9373012972064316
None Run 03:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 53.20
run time now: 4.173344612121582
total time:  4.216255498118699
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.07 ± 11.83
  Final Train: 100.00 ± 0.00
   Final Test: 64.57 ± 9.97
[I 2023-06-12 00:51:42,591] Trial 357 finished with value: 65.0666732788086 and parameters: {'Fwd': 0.000711496883388926, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.1, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 1.0861367449059556, 'loop': 0, 'loss': 'MSE', 'lr': 0.0009204699187069518, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008194084872493825, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.008898908170811353
weight_decay:  0.005668522390716811
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1290304788853973
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 02
None time:  2.0203675020020455
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  2.063031282974407
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.10
run time now: 6.25120735168457
total time:  6.312963440082967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.93 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 76.77 ± 0.67
[I 2023-06-12 00:51:49,412] Trial 358 finished with value: 76.93334197998047 and parameters: {'Fwd': 0.005882633591540196, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 2.5387551766714074, 'loop': 1, 'loss': 'MSE', 'lr': 0.008898908170811353, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005668522390716811, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.0037593179488510067
weight_decay:  0.0108924503203771
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2836901389528066
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.8464963929727674
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.946771569084376
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.60
run time now: 6.115909099578857
total time:  6.167195551097393
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.15
[I 2023-06-12 00:51:56,139] Trial 359 finished with value: 80.06666564941406 and parameters: {'Fwd': 0.002263569997072555, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.356558509207548, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037593179488510067, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0108924503203771, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.00553048429958122
weight_decay:  0.003933552268920811
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4408301450312138
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.6551264440640807
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.971098719863221
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.102710008621216
total time:  6.146266881842166
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.06
[I 2023-06-12 00:52:02,776] Trial 360 finished with value: 80.06666564941406 and parameters: {'Fwd': 0.0009147398181743499, 'K': 2, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.738260340673946, 'loop': 1, 'loss': 'MSE', 'lr': 0.00553048429958122, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003933552268920811, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.00475605280198432
weight_decay:  0.006286303189370633
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6668502429965883
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  2.2284349959809333
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.386255311081186
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 7.313977956771851
total time:  7.352392083965242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.53 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 77.50 ± 0.30
[I 2023-06-12 00:52:10,675] Trial 361 finished with value: 77.53333282470703 and parameters: {'Fwd': 0.011822497679341876, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 3.5547041409924236, 'loop': 1, 'loss': 'MSE', 'lr': 0.00475605280198432, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006286303189370633, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.00320236736742711
weight_decay:  0.003281090903290271
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1971801740583032
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.6849431288428605
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.8969160181004554
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.814564228057861
total time:  5.8642089501954615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 77.67 ± 0.12
[I 2023-06-12 00:52:17,047] Trial 362 finished with value: 80.19998931884766 and parameters: {'Fwd': 0.00889372478256391, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 0.6038820402316194, 'loop': 1, 'loss': 'MSE', 'lr': 0.00320236736742711, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003281090903290271, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.004017347913813391
weight_decay:  0.004201033734215574
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9588805409148335
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8241923430468887
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.76498043211177
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.584705591201782
total time:  5.626068618148565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.21
[I 2023-06-12 00:52:23,323] Trial 363 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.012576077422705537, 'K': 2, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 3.2211935039071906, 'loop': 1, 'loss': 'MSE', 'lr': 0.004017347913813391, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004201033734215574, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9
lr:  0.004515743611307299
weight_decay:  0.02819377430599528
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.211654475191608
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  2.0109158670529723
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.5923045291565359
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.850368022918701
total time:  5.896493339212611
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.44
[I 2023-06-12 00:52:29,795] Trial 364 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.02953894123588223, 'K': 3, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 1.8335207260875546, 'loop': 1, 'loss': 'MSE', 'lr': 0.004515743611307299, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02819377430599528, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0035629298057817172
weight_decay:  0.015110339485672085
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5145894889719784
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.7141600160393864
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.8543588030152023
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.119044542312622
total time:  6.166008290834725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.32
[I 2023-06-12 00:52:36,549] Trial 365 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0849041451894558, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.1262303520587498, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035629298057817172, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.015110339485672085, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.00525801625098797
weight_decay:  0.0049009706404887525
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9484392940066755
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.0462301820516586
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.8451390659902245
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.876507043838501
total time:  5.913127531064674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.36
[I 2023-06-12 00:52:42,979] Trial 366 finished with value: 80.06665802001953 and parameters: {'Fwd': 0.007317815936323274, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 1.4511990573881821, 'loop': 1, 'loss': 'MSE', 'lr': 0.00525801625098797, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0049009706404887525, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.004312267572353001
weight_decay:  0.0026645324276959276
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7095185660291463
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.6178415641188622
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 03
None time:  1.8982335950713605
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.70
run time now: 5.266139030456543
total time:  5.315949033014476
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 75.90 ± 0.35
[I 2023-06-12 00:52:48,759] Trial 367 finished with value: 77.79999542236328 and parameters: {'Fwd': 2.3122840868783067e-05, 'K': 1, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 2.563297915895224, 'loop': 1, 'loss': 'CE', 'lr': 0.004312267572353001, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0026645324276959276, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.00043435478168965584
weight_decay:  0.0657129188490217
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9720906768925488
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0026, Train: 100.00%, Valid: 68.60% Test: 67.80%
Split: 01, Run: 02
None time:  3.934918373124674
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.9856650810688734
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.60
run time now: 7.926032781600952
total time:  7.973042767960578
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 0.87
[I 2023-06-12 00:52:57,306] Trial 368 finished with value: 69.9333267211914 and parameters: {'Fwd': 0.0006099536881033166, 'K': 2, 'alpha': 0.25, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 2.969633226704376, 'loop': 1, 'loss': 'MSE', 'lr': 0.00043435478168965584, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0657129188490217, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.003835880935351897
weight_decay:  0.006848662721144472
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8951155059039593
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.2586231131572276
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.9595934299286455
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.149896860122681
total time:  6.203727590152994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.31
[I 2023-06-12 00:53:04,020] Trial 369 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.01753029919710322, 'K': 2, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.296544662987221, 'loop': 1, 'loss': 'MSE', 'lr': 0.003835880935351897, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006848662721144472, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8500000000000001
lr:  0.008365116566315183
weight_decay:  0.003625544248146305
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6162582519464195
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8545624709222466
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.8387032120954245
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.80
run time now: 5.345490455627441
total time:  5.393975147977471
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.47 ± 0.70
[I 2023-06-12 00:53:10,036] Trial 370 finished with value: 79.33333587646484 and parameters: {'Fwd': 0.0018908650192476777, 'K': 3, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 5.477365044145386, 'loop': 1, 'loss': 'MSE', 'lr': 0.008365116566315183, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003625544248146305, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  1.0
lr:  0.0028881930243022935
weight_decay:  0.004998279127095073
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.298905136063695
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.9432461990509182
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  2.2210286408662796
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
run time now: 7.503302097320557
total time:  7.54431987600401
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.61
[I 2023-06-12 00:53:18,215] Trial 371 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.005381187924566899, 'K': 2, 'alpha': 1.0, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 1.7419681915506362, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028881930243022935, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004998279127095073, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004938940823769087
weight_decay:  8.110769387839209e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.090535234892741
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.8141132399905473
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.2534772518556565
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.60
run time now: 6.405616521835327
total time:  6.45341578591615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.57
[I 2023-06-12 00:53:25,314] Trial 372 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.010145876364305658, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 0.8136858608149723, 'loop': 1, 'loss': 'MSE', 'lr': 0.004938940823769087, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.110769387839209e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004226725875543672
weight_decay:  0.01889273626280625
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0246583349071443
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 02
None time:  1.3494103599805385
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.50
Split: 01, Run: 03
None time:  1.4627635008655488
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.60
run time now: 3.877687692642212
total time:  3.9161472800187767
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 73.17 ± 0.49
[I 2023-06-12 00:53:29,845] Trial 373 finished with value: 74.86666870117188 and parameters: {'Fwd': 0.0009619029944546166, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 5.011600667340226, 'loop': 1, 'loss': 'MSE', 'lr': 0.004226725875543672, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.01889273626280625, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0033657957442204543
weight_decay:  0.008171901917013991
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.187968151178211
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0306, Train: 100.00%, Valid: 79.80% Test: 78.30%
Split: 01, Run: 02
None time:  4.563349670963362
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.130653388798237
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 8.91530156135559
total time:  8.966836381005123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.26
[I 2023-06-12 00:53:39,402] Trial 374 finished with value: 80.06665802001953 and parameters: {'Fwd': 0.05290899060966564, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.7760415822774984, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033657957442204543, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008171901917013991, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.009740633601206786
weight_decay:  0.0029216951171454454
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0532043070998043
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 02
None time:  1.9273565569892526
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  2.0353761499281973
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.30
run time now: 6.076612234115601
total time:  6.152207892853767
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 76.77 ± 0.64
[I 2023-06-12 00:53:46,219] Trial 375 finished with value: 78.06665802001953 and parameters: {'Fwd': 2.7971752756169383e-05, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 4.159215409858614, 'loop': 1, 'loss': 'MSE', 'lr': 0.009740633601206786, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0029216951171454454, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.005655794239526733
weight_decay:  0.011980404326934396
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.864794644061476
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.1595262170303613
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.596720936940983
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.661160230636597
total time:  5.703362207859755
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.15
[I 2023-06-12 00:53:52,584] Trial 376 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.014080569383717587, 'K': 2, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.9136139305119872, 'loop': 1, 'loss': 'MSE', 'lr': 0.005655794239526733, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.011980404326934396, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004699849723292753
weight_decay:  0.0016980701696438475
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.848134043160826
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.062373808817938
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.7374365660361946
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.693639039993286
total time:  5.7483075589407235
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.32
[I 2023-06-12 00:53:58,832] Trial 377 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.006728488892538724, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 3.351720452684376, 'loop': 1, 'loss': 'MSE', 'lr': 0.004699849723292753, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0016980701696438475, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.006316634089838161
weight_decay:  0.05589188737389589
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7761581011582166
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.951167134102434
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.6181420208886266
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.383150339126587
total time:  5.435848864959553
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.35
[I 2023-06-12 00:54:04,745] Trial 378 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.021305644229536163, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 2.0188421895656883, 'loop': 1, 'loss': 'MSE', 'lr': 0.006316634089838161, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.05589188737389589, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9
lr:  0.0025289408458620917
weight_decay:  0.0838156829270411
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.068660045042634
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0273, Train: 100.00%, Valid: 79.00% Test: 77.10%
Split: 01, Run: 02
None time:  4.31299371086061
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  1.655358965974301
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.10
run time now: 8.071021795272827
total time:  8.117974892957136
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.37 ± 0.46
[I 2023-06-12 00:54:13,353] Trial 379 finished with value: 78.79999542236328 and parameters: {'Fwd': 0.03912876244332459, 'K': 1, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 2.4191954748596034, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025289408458620917, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0838156829270411, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0038972841930176943
weight_decay:  0.00014297494653747321
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.746317005949095
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  2.634976041968912
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.642109425039962
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.063826560974121
total time:  6.109458214836195
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.67 ± 0.25
[I 2023-06-12 00:54:19,993] Trial 380 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.00361034925812584, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 1.5735128373958132, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038972841930176943, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00014297494653747321, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.004392006256587532
weight_decay:  0.006392727330680537
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6756009389646351
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.7784151048399508
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.719991201069206
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.2508769035339355
total time:  5.309235495049506
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.40
[I 2023-06-12 00:54:25,876] Trial 381 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.06893412655118492, 'K': 2, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.6546963834135324, 'loop': 1, 'loss': 'MSE', 'lr': 0.004392006256587532, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006392727330680537, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.0015551287582619808
weight_decay:  0.00017008199896378952
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0400989551562816
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.4895388619042933
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.40
Split: 01, Run: 03
None time:  2.592711185105145
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.60
run time now: 6.159476280212402
total time:  6.201823385898024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 75.20 ± 0.69
[I 2023-06-12 00:54:32,637] Trial 382 finished with value: 76.73333740234375 and parameters: {'Fwd': 0.0005490236381631475, 'K': 3, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 4.716812393740616, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015551287582619808, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00017008199896378952, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.005118980997921269
weight_decay:  0.004045157346147216
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9449631511233747
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.9987491180654615
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.9590022119227797
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.9406726360321045
total time:  5.99136747000739
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.20
[I 2023-06-12 00:54:39,191] Trial 383 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.00822132347895907, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 3.1392418671100697, 'loop': 1, 'loss': 'MSE', 'lr': 0.005118980997921269, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004045157346147216, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.003688646370291637
weight_decay:  2.829831062057569e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4216079800389707
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.5126268349122256
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.74720566207543
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.20
run time now: 6.733552932739258
total time:  6.785109887830913
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 0.35
[I 2023-06-12 00:54:46,549] Trial 384 finished with value: 81.0 and parameters: {'Fwd': 0.00036654857931627574, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.1199303709477846, 'loop': 1, 'loss': 'MSE', 'lr': 0.003688646370291637, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.829831062057569e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.003212061117171017
weight_decay:  0.00011759186663926348
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1617946280166507
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  2.1826677550561726
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.9788296441547573
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.363796710968018
total time:  6.406114567071199
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.38
[I 2023-06-12 00:54:53,607] Trial 385 finished with value: 80.13333129882812 and parameters: {'Fwd': 1.094257961575104e-06, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 2.258564220071117, 'loop': 1, 'loss': 'MSE', 'lr': 0.003212061117171017, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00011759186663926348, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.003620097759816047
weight_decay:  0.0004430305542311487
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9471231629140675
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 98.33
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.833170616067946
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 03
None time:  1.842782145133242
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.10
run time now: 5.659390211105347
total time:  5.7086814870126545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 0.20
  Final Train: 99.44 ± 0.96
   Final Test: 76.40 ± 0.44
[I 2023-06-12 00:54:59,906] Trial 386 finished with value: 78.20000457763672 and parameters: {'Fwd': 1.5221911502217905e-05, 'K': 1, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 2.168756032873615, 'loop': 1, 'loss': 'CE', 'lr': 0.003620097759816047, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004430305542311487, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.003985694791254634
weight_decay:  0.0003220578864880367
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8394104288890958
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.558722339803353
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  2.214116983115673
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.6537275314331055
total time:  5.703055441845208
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.30
[I 2023-06-12 00:55:06,147] Trial 387 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.0003793659202254868, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.7111643371264114, 'loop': 1, 'loss': 'MSE', 'lr': 0.003985694791254634, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0003220578864880367, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0036496022694938826
weight_decay:  0.001125002517320761
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.410229306202382
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0325, Train: 100.00%, Valid: 80.40% Test: 78.70%
Split: 01, Run: 02
None time:  4.67729657702148
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  2.076158653013408
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 9.203460216522217
total time:  9.24706648895517
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.60 ± 0.26
[I 2023-06-12 00:55:15,883] Trial 388 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.002215591348014804, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 2.891679207173474, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036496022694938826, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001125002517320761, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.0028937592682316145
weight_decay:  4.700405366933602e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.583431978011504
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.9530558930709958
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  3.7641809550113976
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 8.339980125427246
total time:  8.390919467899948
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 77.57 ± 0.38
[I 2023-06-12 00:55:24,751] Trial 389 finished with value: 79.26666259765625 and parameters: {'Fwd': 0.0033519899679713464, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.528123530490832, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028937592682316145, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.700405366933602e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004116395108420806
weight_decay:  9.68955527703755e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9186614321079105
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.7252618849743158
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 03
None time:  1.9791663619689643
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.00
run time now: 5.663465976715088
total time:  5.7073136498220265
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 77.03 ± 0.65
[I 2023-06-12 00:55:30,936] Trial 390 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.004955927271549916, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 1.975181958609392, 'loop': 1, 'loss': 'MSE', 'lr': 0.004116395108420806, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.68955527703755e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.003402676497730562
weight_decay:  9.94552730956438e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9743072059936821
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.9664045930840075
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.9726739549078047
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.9540276527404785
total time:  6.008649069815874
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.53
[I 2023-06-12 00:55:37,509] Trial 391 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.0007417759971760256, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 5.747406667457333, 'loop': 1, 'loss': 'MSE', 'lr': 0.003402676497730562, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.94552730956438e-06, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.0019176956191670528
weight_decay:  0.00023604006547782737
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.8882745979353786
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.218776686117053
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 03
None time:  3.265786634059623
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 76.60
run time now: 9.425419807434082
total time:  9.476251481100917
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 76.87 ± 0.64
[I 2023-06-12 00:55:47,568] Trial 392 finished with value: 78.19999694824219 and parameters: {'Fwd': 0.010521014473262497, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.451538776353082, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019176956191670528, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00023604006547782737, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.0014254675857249932
weight_decay:  4.8929536807603365e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7942123610991985
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0939718969166279
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 03
None time:  0.9263183549046516
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.60
run time now: 2.8520450592041016
total time:  2.899374089902267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.40 ± 2.96
  Final Train: 100.00 ± 0.00
   Final Test: 73.60 ± 3.75
[I 2023-06-12 00:55:50,971] Trial 393 finished with value: 75.4000015258789 and parameters: {'Fwd': 0.0002661292109542021, 'K': 2, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 2.3762509129740765, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014254675857249932, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.8929536807603365e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.002363592137050606
weight_decay:  2.8917061712004536e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.2496609361842275
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0323, Train: 100.00%, Valid: 79.20% Test: 77.00%
Split: 01, Run: 02
None time:  4.256310320226476
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  3.2597889720927924
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.60
run time now: 11.805054664611816
total time:  11.8586073089391
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 76.97 ± 0.35
[I 2023-06-12 00:56:03,385] Trial 394 finished with value: 78.5999984741211 and parameters: {'Fwd': 0.013517510586783998, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 4.03062240778948, 'loop': 1, 'loss': 'MSE', 'lr': 0.002363592137050606, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8917061712004536e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.004351602992542205
weight_decay:  0.0006666873778341818
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.317898422945291
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.8104294228833169
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.8961736250203103
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
run time now: 6.064633131027222
total time:  6.110458713024855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.10
[I 2023-06-12 00:56:10,138] Trial 395 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.006514453895276648, 'K': 1, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 2.7529495714853893, 'loop': 1, 'loss': 'MSE', 'lr': 0.004351602992542205, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006666873778341818, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0038695331611350568
weight_decay:  0.0026015797112976303
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.532203015871346
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.7971762521192431
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.0486429559532553
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.10
run time now: 5.447965383529663
total time:  5.640066836029291
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.35
[I 2023-06-12 00:56:16,381] Trial 396 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.0013956038216995884, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.0, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 2.042984852115533, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038695331611350568, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0026015797112976303, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004884026601162378
weight_decay:  6.65843652695339e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8880072820466012
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0378, Train: 100.00%, Valid: 80.60% Test: 77.90%
Split: 01, Run: 02
None time:  4.230059581110254
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.8674487241078168
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 8.02267074584961
total time:  8.06548179499805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.12
[I 2023-06-12 00:56:24,893] Trial 397 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.0005247668853230233, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.539342485347709, 'loop': 1, 'loss': 'MSE', 'lr': 0.004884026601162378, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.65843652695339e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007028979222656991
weight_decay:  5.5472076204738314e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2487052590586245
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.1891708550974727
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.9677143420558423
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 6.481616973876953
total time:  6.53727758792229
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.35
[I 2023-06-12 00:56:32,047] Trial 398 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.000305841495049168, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 2.570702077457428, 'loop': 1, 'loss': 'MSE', 'lr': 0.007028979222656991, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.5472076204738314e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.006013191466263327
weight_decay:  1.5637423084395263e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.016299600014463
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.6224109600298107
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.9506978071294725
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.70
run time now: 5.63172459602356
total time:  5.684564291033894
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 0.46
[I 2023-06-12 00:56:38,382] Trial 399 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.0010996835034350633, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.947076577884638, 'loop': 1, 'loss': 'MSE', 'lr': 0.006013191466263327, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5637423084395263e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00505437662047845
weight_decay:  3.92810425831058e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9187873429618776
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7179306969046593
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.5882078919094056
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.2577619552612305
total time:  5.308276618132368
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.21
[I 2023-06-12 00:56:44,226] Trial 400 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.0012903696128517723, 'K': 1, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 3.4746459424960148, 'loop': 1, 'loss': 'MSE', 'lr': 0.00505437662047845, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.92810425831058e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.004675004767734696
weight_decay:  1.4915945166707977e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.142416551010683
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.6131577910855412
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.4310495180543512
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.230062484741211
total time:  6.273739782860503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.47
[I 2023-06-12 00:56:51,012] Trial 401 finished with value: 80.60000610351562 and parameters: {'Fwd': 0.0004074727089508182, 'K': 3, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 3.262842221594438, 'loop': 1, 'loss': 'MSE', 'lr': 0.004675004767734696, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4915945166707977e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0011287039503519905
weight_decay:  0.0013739831890294198
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7296137469820678
None Run 01:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02
None time:  3.005150903016329
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.10
Split: 01, Run: 03
None time:  1.869090948952362
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.90
run time now: 6.92197322845459
total time:  7.032513831043616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.67 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 73.97 ± 1.01
[I 2023-06-12 00:56:58,640] Trial 402 finished with value: 75.66666412353516 and parameters: {'Fwd': 0.02566932528830093, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.727087602915928, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011287039503519905, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0013739831890294198, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0055880496588585835
weight_decay:  0.00019666456658089972
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0438508230727166
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.769952017115429
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.9134622861165553
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.773837566375732
total time:  5.821881578071043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.23
[I 2023-06-12 00:57:05,034] Trial 403 finished with value: 80.60000610351562 and parameters: {'Fwd': 0.0005422125925443411, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.426691043494801, 'loop': 1, 'loss': 'MSE', 'lr': 0.0055880496588585835, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00019666456658089972, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0021502287829974925
weight_decay:  3.1738525758413294e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8175410989206284
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02
None time:  2.8733161739073694
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 03
None time:  2.988722149981186
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.10
run time now: 7.715575456619263
total time:  7.760638613021001
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 75.17 ± 0.95
[I 2023-06-12 00:57:13,282] Trial 404 finished with value: 77.0666732788086 and parameters: {'Fwd': 0.017333163060953793, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 3.080875626311576, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021502287829974925, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.1738525758413294e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0005366215430639569
weight_decay:  0.00031528067707801494
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.389802152989432
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0040, Train: 100.00%, Valid: 75.00% Test: 71.00%
Split: 01, Run: 02
None time:  4.209581813076511
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  1.9686812630388886
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 8.605879783630371
total time:  8.648349626921117
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.00 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.67 ± 1.59
[I 2023-06-12 00:57:22,414] Trial 405 finished with value: 74.0 and parameters: {'Fwd': 0.000544694071127906, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.3070403677731814, 'loop': 1, 'loss': 'MSE', 'lr': 0.0005366215430639569, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00031528067707801494, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8
lr:  0.004428937865562391
weight_decay:  0.0021176077603760886
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9615789961535484
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 98.33
   Final Test: 76.10
Split: 01, Run: 02
None time:  1.7613868489861488
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 98.33
   Final Test: 75.60
Split: 01, Run: 03
None time:  1.9012068170122802
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.60
run time now: 5.664093017578125
total time:  5.782407286809757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 0.60
  Final Train: 98.89 ± 0.96
   Final Test: 75.77 ± 0.29
[I 2023-06-12 00:57:28,677] Trial 406 finished with value: 78.20000457763672 and parameters: {'Fwd': 0.0025483255759130236, 'K': 2, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.85856611446025, 'loop': 1, 'loss': 'CE', 'lr': 0.004428937865562391, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0021176077603760886, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.004988328972867866
weight_decay:  4.0310901415192515e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9757606440689415
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.797696908004582
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  2.157087109051645
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.967580080032349
total time:  6.016928625991568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.21
[I 2023-06-12 00:57:35,192] Trial 407 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.004475727906601532, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 2.5986885919228038, 'loop': 1, 'loss': 'MSE', 'lr': 0.004988328972867866, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.0310901415192515e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.003540498875606175
weight_decay:  7.894313146462522e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1742596300318837
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0171, Train: 100.00%, Valid: 80.60% Test: 77.80%
Split: 01, Run: 02
None time:  4.940910737961531
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.06429098197259
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 9.404383182525635
total time:  9.481328920926899
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 0.26
[I 2023-06-12 00:57:45,308] Trial 408 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.0001387508814318765, 'K': 5, 'alpha': 0.25, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 3.7769962211593233, 'loop': 1, 'loss': 'MSE', 'lr': 0.003540498875606175, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.894313146462522e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.003054929537826469
weight_decay:  2.7223684812055526e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3335464370902628
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.6566051971167326
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  2.193691864842549
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.80
run time now: 6.22001838684082
total time:  6.2702611540444195
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.27 ± 0.40
[I 2023-06-12 00:57:52,126] Trial 409 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.03327691308227288, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 2.4936374687258076, 'loop': 1, 'loss': 'MSE', 'lr': 0.003054929537826469, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.7223684812055526e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0013562347393098425
weight_decay:  6.026970876660495e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0297, Train: 100.00%, Valid: 77.00% Test: 75.60%
Split: 01, Run: 01
None time:  4.288204766111448
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  3.0908180018886924
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0271, Train: 100.00%, Valid: 75.80% Test: 73.60%
Split: 01, Run: 03
None time:  4.543762657092884
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.50
run time now: 11.961555004119873
total time:  12.019441443029791
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 74.17 ± 1.24
[I 2023-06-12 00:58:04,692] Trial 410 finished with value: 76.20000457763672 and parameters: {'Fwd': 0.0001820956584246292, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.9804911974001893, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013562347393098425, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.026970876660495e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004160150784031069
weight_decay:  0.030577482907174103
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3708827609661967
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  3.2250805988442153
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.4423079499974847
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 8.07771635055542
total time:  8.129325535148382
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 0.25
[I 2023-06-12 00:58:13,266] Trial 411 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.0003678947842535941, 'K': 2, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 2.240775551735143, 'loop': 1, 'loss': 'MSE', 'lr': 0.004160150784031069, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.030577482907174103, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.004709624515265037
weight_decay:  6.918898094485405e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0430190351326019
None Run 01:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 02
None time:  1.2636660290881991
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 03
None time:  0.9014467580709606
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 74.70
run time now: 3.2429583072662354
total time:  3.2863671521190554
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.80 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 73.93 ± 0.71
[I 2023-06-12 00:58:17,178] Trial 412 finished with value: 75.80000305175781 and parameters: {'Fwd': 0.014736187918992127, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 4.570618774115521, 'loop': 1, 'loss': 'MSE', 'lr': 0.004709624515265037, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.918898094485405e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8500000000000001
lr:  0.0008039763981410752
weight_decay:  0.0031491670816898203
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8001796409953386
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02
None time:  2.7668395061045885
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0133, Train: 100.00%, Valid: 75.60% Test: 73.20%
Split: 01, Run: 03
None time:  4.2484117220155895
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.00
run time now: 8.858850955963135
total time:  8.909382684156299
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 72.73 ± 0.64
[I 2023-06-12 00:58:26,642] Trial 413 finished with value: 75.53333282470703 and parameters: {'Fwd': 0.0015194460106700625, 'K': 3, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.705340463800423, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008039763981410752, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0031491670816898203, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0016711576535090532
weight_decay:  0.09719862685865323
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.27013663505204
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 02
None time:  1.4826652149204165
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 74.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0250, Train: 100.00%, Valid: 76.40% Test: 73.80%
Split: 01, Run: 03
None time:  4.67250951891765
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 73.80
run time now: 8.479522943496704
total time:  8.526386049110442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 74.80 ± 1.18
[I 2023-06-12 00:58:35,696] Trial 414 finished with value: 77.0 and parameters: {'Fwd': 0.02051089775243024, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 4.2975399576468405, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016711576535090532, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.09719862685865323, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.005229446473816757
weight_decay:  2.0076948847579896e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4638651141431183
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  2.320927350083366
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.7576781220268458
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.5756165981292725
total time:  5.622608287958428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.32
[I 2023-06-12 00:58:41,843] Trial 415 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0481942745637689, 'K': 1, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 1.8461765750663315, 'loop': 1, 'loss': 'MSE', 'lr': 0.005229446473816757, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0076948847579896e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0010360607553739163
weight_decay:  0.0002588284145291415
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0253, Train: 100.00%, Valid: 76.00% Test: 75.80%
Split: 01, Run: 01
None time:  4.190171791939065
None Run 01:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  1.313399428036064
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03
None time:  2.0911627118475735
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.30
run time now: 7.628068685531616
total time:  7.680411445908248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 73.80 ± 1.73
[I 2023-06-12 00:58:50,041] Trial 416 finished with value: 75.66666412353516 and parameters: {'Fwd': 0.009441044611909427, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 5.2839426779136165, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010360607553739163, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002588284145291415, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0037828316031124675
weight_decay:  0.00020938713008607026
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.229139693081379
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.5368378800339997
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.9990490349009633
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.90
run time now: 5.811208963394165
total time:  5.862065224908292
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.21
[I 2023-06-12 00:58:56,491] Trial 417 finished with value: 80.39999389648438 and parameters: {'Fwd': 0.005560276389882031, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 3.548423313216945, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037828316031124675, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00020938713008607026, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.30000000000000004
lr:  0.0002070736342200256
weight_decay:  0.03777822445037126
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.880456473911181
None Run 01:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0031, Train: 100.00%, Valid: 65.60% Test: 61.90%
Split: 01, Run: 02
None time:  4.291602415964007
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 61.90
Split: 01, Run: 03
None time:  2.5847737649455667
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 8.800204515457153
total time:  8.8537928101141
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.60 ± 3.99
  Final Train: 100.00 ± 0.00
   Final Test: 65.23 ± 4.02
[I 2023-06-12 00:59:05,841] Trial 418 finished with value: 66.5999984741211 and parameters: {'Fwd': 0.011727767097745853, 'K': 4, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.1950594888445822, 'loop': 1, 'loss': 'MSE', 'lr': 0.0002070736342200256, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.03777822445037126, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.00433896168774947
weight_decay:  0.00014251382644890696
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3056607509497553
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.8406237149611115
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.728878152091056
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.90
run time now: 5.913384914398193
total time:  5.953239670023322
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.40
[I 2023-06-12 00:59:12,268] Trial 419 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.0071708165571818866, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 5.0814719137831945, 'loop': 1, 'loss': 'MSE', 'lr': 0.00433896168774947, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00014251382644890696, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.002697550736177675
weight_decay:  0.0034308223790375275
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.366324364906177
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.5561856869608164
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  3.905499197077006
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.10
run time now: 7.8718225955963135
total time:  7.92029529903084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 77.23 ± 0.42
[I 2023-06-12 00:59:20,676] Trial 420 finished with value: 79.26666259765625 and parameters: {'Fwd': 0.002933849946067439, 'K': 2, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.4113421548130973, 'loop': 1, 'loss': 'MSE', 'lr': 0.002697550736177675, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0034308223790375275, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.0057703012132214754
weight_decay:  0.000754695843523309
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5392608379479498
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.1609766450710595
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.3608651550021023
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.40
run time now: 4.097364664077759
total time:  4.1454589639324695
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 77.77 ± 0.32
[I 2023-06-12 00:59:25,264] Trial 421 finished with value: 80.0 and parameters: {'Fwd': 0.09854297419415488, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 5.47573587659695, 'loop': 1, 'loss': 'MSE', 'lr': 0.0057703012132214754, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000754695843523309, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.0018501175896951064
weight_decay:  0.0018116087742265784
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0999104818329215
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  2.0215067551471293
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 03
None time:  2.33784972387366
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.20
run time now: 6.497635364532471
total time:  6.544158044969663
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 75.73 ± 0.61
[I 2023-06-12 00:59:32,289] Trial 422 finished with value: 77.20000457763672 and parameters: {'Fwd': 0.009255202132174052, 'K': 2, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 2.12782604077748, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018501175896951064, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0018116087742265784, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.003978616582883352
weight_decay:  0.023505579857641005
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.89603754109703
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.8635138948448002
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.7232153068762273
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.80
run time now: 5.52031946182251
total time:  5.565707636065781
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.36
[I 2023-06-12 00:59:38,325] Trial 423 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.018457233887343553, 'K': 2, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 3.3112064767667664, 'loop': 1, 'loss': 'MSE', 'lr': 0.003978616582883352, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.023505579857641005, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.003341792858337556
weight_decay:  2.4556081464438897e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0691013508476317
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.5711684960406274
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.3667353000491858
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.60
run time now: 6.043976783752441
total time:  6.0912443089764565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.00 ± 1.71
  Final Train: 100.00 ± 0.00
   Final Test: 72.60 ± 1.48
[I 2023-06-12 00:59:44,895] Trial 424 finished with value: 75.00000762939453 and parameters: {'Fwd': 0.0007030458294216119, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 0, 'lambda1': 0.75, 'lambda2': 2.8857626579174385, 'loop': 1, 'loss': 'MSE', 'lr': 0.003341792858337556, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.4556081464438897e-05, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.004755065109368597
weight_decay:  0.004543258064229597
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3293913011439145
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.5961406589485705
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.6814160749781877
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.690879583358765
total time:  5.821762616978958
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.25
[I 2023-06-12 00:59:51,314] Trial 425 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.05879807105110586, 'K': 2, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.7036298655603743, 'loop': 1, 'loss': 'MSE', 'lr': 0.004755065109368597, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004543258064229597, 'weightedloss': True}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.0043733309345597065
weight_decay:  0.0026656561595968624
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.203266959870234
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 02
None time:  2.811362226959318
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 03
None time:  1.4447784330695868
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 72.20
run time now: 7.501555681228638
total time:  7.54759670002386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.20 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 73.57 ± 1.31
[I 2023-06-12 00:59:59,419] Trial 426 finished with value: 76.20000457763672 and parameters: {'Fwd': 0.0017702338082601808, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 30, 'lambda1': 0.8500000000000001, 'lambda2': 1.8930799096140865, 'loop': 1, 'loss': 'MSE', 'lr': 0.0043733309345597065, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0026656561595968624, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00031543958874310227
weight_decay:  0.054508350771323634
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0852571700233966
None Run 01:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 02
None time:  1.6425025649368763
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.6475516259670258
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.20
run time now: 5.408377408981323
total time:  5.46648936602287
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 72.50 ± 1.97
[I 2023-06-12 01:00:05,457] Trial 427 finished with value: 74.46666717529297 and parameters: {'Fwd': 0.003796128285612803, 'K': 1, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.3017137705508937, 'loop': 1, 'loss': 'CE', 'lr': 0.00031543958874310227, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.054508350771323634, 'weightedloss': False}. Best is trial 269 with value: 81.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.005304044921740005
weight_decay:  0.0038356635201946573
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7361338750924915
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.5532824050169438
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.50
