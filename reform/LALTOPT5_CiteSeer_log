[I 2023-06-11 23:21:26,057] A new study created in RDB with name: CiteSeer_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.15000000000000002
lr:  0.003120933628742172
weight_decay:  0.0006188619911440787
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.00% Test: 42.60%
Split: 01, Run: 01
None time:  2.2084680958651006
None Run 01:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 42.60
Split: 01, Run: 02
None time:  0.7892209920100868
None Run 02:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 39.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.00% Test: 42.50%
Split: 01, Run: 03
None time:  1.3884195829741657
None Run 03:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 42.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.80% Test: 52.80%
Split: 02, Run: 01
None time:  1.3966992490459234
None Run 04:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 52.80
Split: 02, Run: 02
None time:  0.8143898609559983
None Run 05:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 57.80
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.00% Test: 55.70%
Split: 02, Run: 03
None time:  1.3892452518921345
None Run 06:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.80% Test: 42.90%
Split: 03, Run: 01
None time:  1.3776866048574448
None Run 07:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 43.00
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.20% Test: 42.00%
Split: 03, Run: 02
None time:  1.4228495419956744
None Run 08:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 41.80
Split: 03, Run: 03
None time:  0.845956354867667
None Run 09:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 43.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.20% Test: 52.50%
Split: 04, Run: 01
None time:  1.403967077145353
None Run 10:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 52.50
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.20% Test: 51.60%
Split: 04, Run: 02
None time:  1.4257124171126634
None Run 11:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 51.60
Split: 04, Run: 03
None time:  0.7383198540192097
None Run 12:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 53.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.00% Test: 56.30%
Split: 05, Run: 01
None time:  1.4692585091106594
None Run 13:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 56.30
Split: 05, Run: 02
None time:  0.7906269978266209
None Run 14:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.00
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.60% Test: 54.80%
Split: 05, Run: 03
None time:  1.4326912581454962
None Run 15:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 54.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.20% Test: 49.50%
Split: 06, Run: 01
None time:  1.3311172248795629
None Run 16:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 49.50
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 58.20% Test: 52.40%
Split: 06, Run: 02
None time:  1.471513716969639
None Run 17:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 52.40
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.80% Test: 51.20%
Split: 06, Run: 03
None time:  1.4175342211965472
None Run 18:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 51.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.80% Test: 50.20%
Split: 07, Run: 01
None time:  1.412892669904977
None Run 19:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 50.40
Split: 07, Run: 02
None time:  0.8195864639710635
None Run 20:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 50.60
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.40% Test: 51.20%
Split: 07, Run: 03
None time:  1.3627113210968673
None Run 21:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 51.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.40% Test: 51.80%
Split: 08, Run: 01
None time:  1.4788513691164553
None Run 22:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 51.90
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 52.00% Test: 51.30%
Split: 08, Run: 02
None time:  1.408613566076383
None Run 23:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.30
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.40% Test: 53.50%
Split: 08, Run: 03
None time:  1.377549187047407
None Run 24:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 53.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.00% Test: 55.30%
Split: 09, Run: 01
None time:  1.4098893960472196
None Run 25:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.30
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.60% Test: 55.20%
Split: 09, Run: 02
None time:  1.3845789139159024
None Run 26:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 55.20
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.00% Test: 54.20%
Split: 09, Run: 03
None time:  1.3691835750360042
None Run 27:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 54.20
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.80% Test: 56.50%
Split: 10, Run: 01
None time:  1.3403559071011841
None Run 28:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 56.60
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.00% Test: 52.10%
Split: 10, Run: 02
None time:  1.4672359209507704
None Run 29:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 52.10
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.20% Test: 52.20%
Split: 10, Run: 03
None time:  1.3431996828876436
None Run 30:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.20
run time now: 4.189921855926514
total time:  41.84898138791323
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.27 ± 6.49
  Final Train: 100.00 ± 0.00
   Final Test: 50.98 ± 4.99
best run test_acc: 52.20000076293945
[I 2023-06-11 23:22:08,454] Trial 0 finished with value: 51.26667022705078 and parameters: {'Fwd': 7.132853852386155e-05, 'K': 6, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8500000000000001, 'lambda2': 8.621697004609727, 'loop': 0, 'loss': 'MSE', 'lr': 0.003120933628742172, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0006188619911440787, 'weightedloss': True}. Best is trial 0 with value: 51.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.35000000000000003
lr:  0.005221914972077076
weight_decay:  0.0002751353553596068
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 31.60% Test: 33.90%
Split: 01, Run: 01
None time:  0.5888115088455379
None Run 01:
Highest Train: 100.00
Highest Valid: 31.60
  Final Train: 100.00
   Final Test: 33.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.40% Test: 51.70%
Split: 01, Run: 02
None time:  0.6321356180123985
None Run 02:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 51.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.80% Test: 56.50%
Split: 01, Run: 03
None time:  0.5613959319889545
None Run 03:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 56.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.2708848889451474
None Run 04:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 32.90
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.80% Test: 62.30%
Split: 02, Run: 02
None time:  0.6160750240087509
None Run 05:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.20
Split: 02, Run: 03
None time:  0.29234825004823506
None Run 06:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 60.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.2484216911252588
None Run 07:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 32.30
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.00% Test: 56.00%
Split: 03, Run: 02
None time:  0.5931538708973676
None Run 08:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.00
Split: 03, Run: 03
None time:  0.3276251091156155
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.2717709490098059
None Run 10:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 29.70
Split: 04, Run: 02
None time:  0.24065389204770327
None Run 11:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 45.50
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.00% Test: 51.40%
Split: 04, Run: 03
None time:  0.5950236849021167
None Run 12:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 51.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.2728475257754326
None Run 13:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 39.30
Split: 05, Run: 02
None time:  0.3069362649694085
None Run 14:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.70
Split: 05, Run: 03
None time:  0.25166760897263885
None Run 15:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 55.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.24674043408595026
None Run 16:
Highest Train: 100.00
Highest Valid: 31.00
  Final Train: 100.00
   Final Test: 28.80
Split: 06, Run: 02
None time:  0.2740804741624743
None Run 17:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 56.00
Split: 06, Run: 03
None time:  0.2578131831251085
None Run 18:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 58.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.2565304711461067
None Run 19:
Highest Train: 100.00
Highest Valid: 21.60
  Final Train: 100.00
   Final Test: 23.40
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.20% Test: 49.70%
Split: 07, Run: 02
None time:  0.5667994699906558
None Run 20:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 49.50
Split: 07, Run: 03
None time:  0.2728548878803849
None Run 21:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 45.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.2294708590488881
None Run 22:
Highest Train: 100.00
Highest Valid: 31.60
  Final Train: 100.00
   Final Test: 30.10
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.00% Test: 61.10%
Split: 08, Run: 02
None time:  0.5928376698866487
None Run 23:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.90
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 63.80% Test: 60.00%
Split: 08, Run: 03
None time:  0.5416305200196803
None Run 24:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 60.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.272977523971349
None Run 25:
Highest Train: 100.00
Highest Valid: 28.60
  Final Train: 100.00
   Final Test: 27.00
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.40% Test: 58.00%
Split: 09, Run: 02
None time:  0.5626069649588317
None Run 26:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 57.80
Split: 09, Run: 03
None time:  0.29992696014232934
None Run 27:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.281894767889753
None Run 28:
Highest Train: 100.00
Highest Valid: 28.20
  Final Train: 100.00
   Final Test: 24.00
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 52.40%
Split: 10, Run: 02
None time:  0.5901932360138744
None Run 29:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 52.50
Split: 10, Run: 03
None time:  0.3077611098997295
None Run 30:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.80
run time now: 1.2167234420776367
total time:  12.594223607797176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 47.33 ± 13.49
  Final Train: 100.00 ± 0.00
   Final Test: 47.36 ± 13.46
best run test_acc: 57.910003662109375
[I 2023-06-11 23:22:21,402] Trial 1 finished with value: 47.32666778564453 and parameters: {'Fwd': 0.0017965687688610403, 'K': 4, 'alpha': 0.35000000000000003, 'dropout': 0.4, 'gnnepoch': 40, 'lambda1': 0.15000000000000002, 'lambda2': 8.04295321572286, 'loop': 0, 'loss': 'MSE', 'lr': 0.005221914972077076, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002751353553596068, 'weightedloss': True}. Best is trial 0 with value: 51.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.65
lr:  0.007326632699633499
weight_decay:  0.0017425384374178407
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.20579186407849193
None Run 01:
Highest Train: 100.00
Highest Valid: 29.60
  Final Train: 100.00
   Final Test: 29.10
Split: 01, Run: 02
None time:  0.16050363890826702
None Run 02:
Highest Train: 100.00
Highest Valid: 28.60
  Final Train: 100.00
   Final Test: 26.20
Split: 01, Run: 03
None time:  0.1917888920288533
None Run 03:
Highest Train: 100.00
Highest Valid: 28.60
  Final Train: 100.00
   Final Test: 26.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.17841391009278595
None Run 04:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 36.00
Split: 02, Run: 02
None time:  0.21265441505238414
None Run 05:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 41.00
Split: 02, Run: 03
None time:  0.1950321481563151
None Run 06:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 45.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.2062456018757075
None Run 07:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 39.10
Split: 03, Run: 02
None time:  0.18711420614272356
None Run 08:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 35.20
Split: 03, Run: 03
None time:  0.1993845880497247
None Run 09:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 35.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.2389212951529771
None Run 10:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 40.20
Split: 04, Run: 02
None time:  0.25695913285017014
None Run 11:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 45.10
Split: 04, Run: 03
None time:  0.18960041902028024
None Run 12:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 34.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.20595477195456624
None Run 13:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 36.30
Split: 05, Run: 02
None time:  0.21460225409828126
None Run 14:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 39.20
Split: 05, Run: 03
None time:  0.18708820082247257
None Run 15:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 37.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.21348210517317057
None Run 16:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 36.60
Split: 06, Run: 02
None time:  0.2022933759726584
None Run 17:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 42.50
Split: 06, Run: 03
None time:  0.19056296185590327
None Run 18:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 36.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.24416371481493115
None Run 19:
Highest Train: 100.00
Highest Valid: 31.40
  Final Train: 100.00
   Final Test: 33.70
Split: 07, Run: 02
None time:  0.2223278139717877
None Run 20:
Highest Train: 100.00
Highest Valid: 31.40
  Final Train: 100.00
   Final Test: 34.70
Split: 07, Run: 03
None time:  0.22359766787849367
None Run 21:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 44.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.2101981749292463
None Run 22:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 49.30
Split: 08, Run: 02
None time:  0.23476012400351465
None Run 23:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 43.00
Split: 08, Run: 03
None time:  0.2253789349924773
None Run 24:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.18340119905769825
None Run 25:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 31.00
Split: 09, Run: 02
None time:  0.16108751203864813
None Run 26:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 31.00
Split: 09, Run: 03
None time:  0.1818000329658389
None Run 27:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 27.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.19379321206361055
None Run 28:
Highest Train: 100.00
Highest Valid: 29.20
  Final Train: 100.00
   Final Test: 29.20
Split: 10, Run: 02
None time:  0.1731731181498617
None Run 29:
Highest Train: 100.00
Highest Valid: 29.20
  Final Train: 100.00
   Final Test: 29.20
Split: 10, Run: 03
None time:  0.18142797681502998
None Run 30:
Highest Train: 100.00
Highest Valid: 29.20
  Final Train: 100.00
   Final Test: 29.20
run time now: 0.5855634212493896
total time:  7.115189319010824
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 36.73 ± 6.00
  Final Train: 100.00 ± 0.00
   Final Test: 36.32 ± 6.37
best run test_acc: 39.48999786376953
[I 2023-06-11 23:22:28,886] Trial 2 finished with value: 36.72666931152344 and parameters: {'Fwd': 0.015538696203391555, 'K': 5, 'alpha': 0.65, 'dropout': 0.1, 'gnnepoch': 0, 'lambda1': 0.25, 'lambda2': 9.594435828679163, 'loop': 1, 'loss': 'CE', 'lr': 0.007326632699633499, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0017425384374178407, 'weightedloss': False}. Best is trial 0 with value: 51.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.005538491641378637
weight_decay:  3.3628681058714704e-05
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.20% Test: 42.90%
Split: 01, Run: 01
None time:  1.1513997099827975
None Run 01:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 42.80
Split: 01, Run: 02
None time:  0.510430907830596
None Run 02:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 41.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 39.00% Test: 39.50%
Split: 01, Run: 03
None time:  1.1636134788859636
None Run 03:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 39.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5240524210967124
None Run 04:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 50.60
Split: 02, Run: 02
None time:  0.45301424991339445
None Run 05:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.30
Split: 02, Run: 03
None time:  0.5244337299373001
None Run 06:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 52.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4968918268568814
None Run 07:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 43.30
Split: 03, Run: 02
None time:  0.5474362769164145
None Run 08:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 40.40
Split: 03, Run: 03
None time:  0.5005835420452058
None Run 09:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 39.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.47834175592288375
None Run 10:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 55.90
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.00% Test: 50.90%
Split: 04, Run: 02
None time:  1.1829901321325451
None Run 11:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 51.00
Split: 04, Run: 03
None time:  0.5142811529804021
None Run 12:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 53.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.462588386842981
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 57.20
Split: 05, Run: 02
None time:  0.5172907011583447
None Run 14:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 53.40
Split: 05, Run: 03
None time:  0.5118055939674377
None Run 15:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 56.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.47086953511461616
None Run 16:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 52.80
Split: 06, Run: 02
None time:  0.5574438441544771
None Run 17:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 52.20
Split: 06, Run: 03
None time:  0.5290227921213955
None Run 18:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 53.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.4576938359532505
None Run 19:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 51.90
Split: 07, Run: 02
None time:  0.5432282059919089
None Run 20:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 51.30
Split: 07, Run: 03
None time:  0.4773212638683617
None Run 21:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 52.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5065113618038595
None Run 22:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 51.20
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 52.80% Test: 50.30%
Split: 08, Run: 02
None time:  1.172644275939092
None Run 23:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 50.40
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 58.00% Test: 56.00%
Split: 08, Run: 03
None time:  1.155845311935991
None Run 24:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 52.80% Test: 52.50%
Split: 09, Run: 01
None time:  1.1772899858187884
None Run 25:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 52.50
Split: 09, Run: 02
None time:  0.509184000082314
None Run 26:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.80
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 53.20%
Split: 09, Run: 03
None time:  1.1943237490486354
None Run 27:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 53.20
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.00% Test: 53.60%
Split: 10, Run: 01
None time:  1.1479870500043035
None Run 28:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 53.40
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.80% Test: 51.30%
Split: 10, Run: 02
None time:  1.2164335658308119
None Run 29:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 52.40
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.20% Test: 53.80%
Split: 10, Run: 03
None time:  1.2251759921200573
None Run 30:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 53.30
run time now: 3.631333589553833
total time:  22.928433178924024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.10 ± 6.64
  Final Train: 100.00 ± 0.00
   Final Test: 50.89 ± 5.22
best run test_acc: 52.6300048828125
[I 2023-06-11 23:22:52,188] Trial 3 finished with value: 51.099998474121094 and parameters: {'Fwd': 0.030812866840447355, 'K': 8, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 8.446653399366232, 'loop': 0, 'loss': 'MSE', 'lr': 0.005538491641378637, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.3628681058714704e-05, 'weightedloss': False}. Best is trial 0 with value: 51.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.00039988933180104585
weight_decay:  4.3643809068325664e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.00% Test: 41.70%
Split: 01, Run: 01
None time:  1.357884380966425
None Run 01:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.70
Split: 01, Run: 02
None time:  0.9586920028086752
None Run 02:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 32.10
Split: 01, Run: 03
None time:  0.8592325812205672
None Run 03:
Highest Train: 100.00
Highest Valid: 34.60
  Final Train: 100.00
   Final Test: 36.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9265958010219038
None Run 04:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 42.10
Split: 02, Run: 02
None time:  0.9375119612086564
None Run 05:
Highest Train: 100.00
Highest Valid: 26.20
  Final Train: 100.00
   Final Test: 26.60
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.80% Test: 53.50%
Split: 02, Run: 03
None time:  1.3751749380026013
None Run 06:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 53.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8771188801620156
None Run 07:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 50.20
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 30.80% Test: 32.40%
Split: 03, Run: 02
None time:  1.347839908208698
None Run 08:
Highest Train: 100.00
Highest Valid: 30.80
  Final Train: 100.00
   Final Test: 32.60
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.40% Test: 51.00%
Split: 03, Run: 03
None time:  1.3318140560295433
None Run 09:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 51.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.60% Test: 43.20%
Split: 04, Run: 01
None time:  1.3789012168999761
None Run 10:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 44.70
Split: 04, Run: 02
None time:  0.9123193549457937
None Run 11:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 51.30
Split: 04, Run: 03
None time:  1.0346997389569879
None Run 12:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 48.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.40% Test: 56.20%
Split: 05, Run: 01
None time:  1.4220402091741562
None Run 13:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 56.20
Split: 05, Run: 02
None time:  1.079333039931953
None Run 14:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 47.40
Split: 05, Run: 03
None time:  0.908674038015306
None Run 15:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 48.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.92425622115843
None Run 16:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 52.80
Split: 06, Run: 02
None time:  0.9608971960842609
None Run 17:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 47.60
Split: 06, Run: 03
None time:  0.9776795150246471
None Run 18:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 39.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9708582339808345
None Run 19:
Highest Train: 100.00
Highest Valid: 33.40
  Final Train: 100.00
   Final Test: 39.90
Split: 07, Run: 02
None time:  0.9205995451193303
None Run 20:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 52.10
Split: 07, Run: 03
None time:  0.9737444780766964
None Run 21:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 35.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.911608459893614
None Run 22:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 38.20
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.20% Test: 53.50%
Split: 08, Run: 02
None time:  1.422233308898285
None Run 23:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 53.50
Split: 08, Run: 03
None time:  0.8372875638306141
None Run 24:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 45.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8841985850594938
None Run 25:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 53.60
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.60% Test: 56.20%
Split: 09, Run: 02
None time:  1.4101795530878007
None Run 26:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 56.20
Split: 09, Run: 03
None time:  0.9312355211004615
None Run 27:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 38.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8611240230966359
None Run 28:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 46.30
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 43.80% Test: 42.10%
Split: 10, Run: 02
None time:  1.396929050795734
None Run 29:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 42.10
Split: 10, Run: 03
None time:  0.865643183933571
None Run 30:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 51.90
run time now: 3.158355236053467
total time:  32.97212337702513
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.43 ± 8.88
  Final Train: 100.00 ± 0.00
   Final Test: 45.20 ± 7.81
best run test_acc: 52.06000518798828
[I 2023-06-11 23:23:25,502] Trial 4 finished with value: 45.42666244506836 and parameters: {'Fwd': 0.00013955963658572075, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 5.567330896911486, 'loop': 0, 'loss': 'MSE', 'lr': 0.00039988933180104585, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.3643809068325664e-05, 'weightedloss': False}. Best is trial 0 with value: 51.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.001123084492499817
weight_decay:  0.004426845710788424
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.80% Test: 47.50%
Split: 01, Run: 01
None time:  1.462638558121398
None Run 01:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 47.30
Split: 01, Run: 02
None time:  0.8871825039386749
None Run 02:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 46.10
Split: 01, Run: 03
None time:  0.8804667899385095
None Run 03:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 44.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8932206290774047
None Run 04:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.20
Split: 02, Run: 02
None time:  0.8982828459702432
None Run 05:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.80
Split: 02, Run: 03
None time:  0.8122835708782077
None Run 06:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 57.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.40% Test: 46.90%
Split: 03, Run: 01
None time:  1.4439376550726593
None Run 07:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 46.70
Split: 03, Run: 02
None time:  0.8656533800531179
None Run 08:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 44.40
Split: 03, Run: 03
None time:  0.9246650079730898
None Run 09:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 44.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8355844400357455
None Run 10:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 52.90
Split: 04, Run: 02
None time:  0.8966208358760923
None Run 11:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 52.60
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.60% Test: 52.40%
Split: 04, Run: 03
None time:  1.4107928390149027
None Run 12:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 52.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.80% Test: 55.40%
Split: 05, Run: 01
None time:  1.4535998629871756
None Run 13:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 55.20
Split: 05, Run: 02
None time:  0.8759015889372677
None Run 14:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 54.20
Split: 05, Run: 03
None time:  1.0036405781283975
None Run 15:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.20% Test: 54.80%
Split: 06, Run: 01
None time:  1.4429440000094473
None Run 16:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.70
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 63.60% Test: 58.80%
Split: 06, Run: 02
None time:  1.411019206047058
None Run 17:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 58.30
Split: 06, Run: 03
None time:  0.8803681458812207
None Run 18:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 55.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9056370779871941
None Run 19:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 49.60
Split: 07, Run: 02
None time:  0.8396520528476685
None Run 20:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 51.60
Split: 07, Run: 03
None time:  0.8843386839143932
None Run 21:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 48.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8123351489193738
None Run 22:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 55.30
Split: 08, Run: 02
None time:  0.8319096320774406
None Run 23:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 54.10
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 51.60%
Split: 08, Run: 03
None time:  1.462751777144149
None Run 24:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 51.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.20% Test: 57.90%
Split: 09, Run: 01
None time:  1.4623064608313143
None Run 25:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.80
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.40% Test: 58.60%
Split: 09, Run: 02
None time:  1.392482838826254
None Run 26:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.50
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.00% Test: 58.00%
Split: 09, Run: 03
None time:  1.4023491810075939
None Run 27:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8145315609872341
None Run 28:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 55.50
Split: 10, Run: 02
None time:  0.8688068680930883
None Run 29:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 53.60
Split: 10, Run: 03
None time:  0.8857647359836847
None Run 30:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 52.50
run time now: 2.6068522930145264
total time:  32.85315293795429
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.78 ± 6.65
  Final Train: 100.00 ± 0.00
   Final Test: 52.61 ± 4.33
best run test_acc: 53.900001525878906
[I 2023-06-11 23:23:58,721] Trial 5 finished with value: 52.78000259399414 and parameters: {'Fwd': 0.002417350517568391, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.8356826303170357, 'loop': 0, 'loss': 'MSE', 'lr': 0.001123084492499817, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004426845710788424, 'weightedloss': False}. Best is trial 5 with value: 52.78000259399414.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.30000000000000004
lr:  0.00014992003552124879
weight_decay:  0.007370774052374189
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6973505842033774
None Run 01:
Highest Train: 100.00
Highest Valid: 36.00
  Final Train: 100.00
   Final Test: 32.20
Split: 01, Run: 02
None time:  0.9961924718227237
None Run 02:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 93.33
   Final Test: 45.70
Split: 01, Run: 03
None time:  0.7968628969974816
None Run 03:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 45.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3942571650259197
None Run 04:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 93.33
   Final Test: 59.90
Split: 02, Run: 02
None time:  1.1236759030725807
None Run 05:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 60.50
Split: 02, Run: 03, Epoch: 100, Loss: 0.3866, Train: 90.00%, Valid: 62.60% Test: 59.80%
Split: 02, Run: 03
None time:  1.8075932499486953
None Run 06:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 93.33
   Final Test: 60.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.8278, Train: 86.67%, Valid: 47.40% Test: 47.40%
Split: 03, Run: 01
None time:  1.8312974700238556
None Run 07:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 86.67
   Final Test: 47.20
Split: 03, Run: 02
None time:  0.9076436189934611
None Run 08:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 90.00
   Final Test: 47.60
Split: 03, Run: 03
None time:  0.9013415360823274
None Run 09:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 96.67
   Final Test: 47.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7847672200296074
None Run 10:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 96.67
   Final Test: 43.20
Split: 04, Run: 02
None time:  0.6923479570541531
None Run 11:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 43.50
Split: 04, Run: 03
None time:  0.7262174019124359
None Run 12:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 45.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0747641429770738
None Run 13:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 96.67
   Final Test: 41.90
Split: 05, Run: 02
None time:  0.8020111510995775
None Run 14:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 43.10
Split: 05, Run: 03
None time:  1.6930224979296327
None Run 15:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 90.00
   Final Test: 44.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9526802070904523
None Run 16:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 54.60
Split: 06, Run: 02
None time:  0.9790562042035162
None Run 17:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 57.30
Split: 06, Run: 03
None time:  0.9256622311659157
None Run 18:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 58.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0685543650761247
None Run 19:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 80.00
   Final Test: 41.10
Split: 07, Run: 02
None time:  0.7280907609965652
None Run 20:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 42.70
Split: 07, Run: 03
None time:  0.688634563004598
None Run 21:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 43.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0440806620754302
None Run 22:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 90.00
   Final Test: 53.40
Split: 08, Run: 02
None time:  0.7592913468834013
None Run 23:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 54.90
Split: 08, Run: 03
None time:  0.7134015308693051
None Run 24:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 55.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.564637087052688
None Run 25:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 90.00
   Final Test: 50.60
Split: 09, Run: 02
None time:  0.7633763041812927
None Run 26:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 51.00
Split: 09, Run: 03
None time:  0.8546822848729789
None Run 27:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 96.67
   Final Test: 50.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.991161969024688
None Run 28:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 96.67
   Final Test: 55.30
Split: 10, Run: 02
None time:  0.7363280958961695
None Run 29:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 57.40
Split: 10, Run: 03
None time:  0.7325854068621993
None Run 30:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 57.70
run time now: 2.4997718334198
total time:  30.757838724879548
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.77 ± 8.45
  Final Train: 96.00 ± 4.98
   Final Test: 49.75 ± 7.11
best run test_acc: 51.029998779296875
[I 2023-06-11 23:24:29,813] Trial 6 finished with value: 50.766666412353516 and parameters: {'Fwd': 0.016962262760334218, 'K': 7, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 0.31084081278305087, 'loop': 1, 'loss': 'CE', 'lr': 0.00014992003552124879, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007370774052374189, 'weightedloss': False}. Best is trial 5 with value: 52.78000259399414.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.75
lr:  0.00048585358930747355
weight_decay:  2.0108570415705944e-06
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0566036540549248
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 90.00
   Final Test: 59.00
Split: 01, Run: 02
None time:  0.5761409851256758
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.90
Split: 01, Run: 03
None time:  0.6224447509739548
None Run 03:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1369334768969566
None Run 04:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 86.67
   Final Test: 60.50
Split: 02, Run: 02
None time:  0.5927394619211555
None Run 05:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 63.60
Split: 02, Run: 03
None time:  0.6903763019945472
None Run 06:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8603524621576071
None Run 07:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 53.50
Split: 03, Run: 02
None time:  0.6222614028956741
None Run 08:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 55.80
Split: 03, Run: 03
None time:  0.7821555058471859
None Run 09:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 56.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.374304372118786
None Run 10:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 86.67
   Final Test: 51.50
Split: 04, Run: 02
None time:  0.6171362020540982
None Run 11:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 50.70
Split: 04, Run: 03
None time:  0.603243940975517
None Run 12:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 50.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9639663670677692
None Run 13:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 96.67
   Final Test: 55.70
Split: 05, Run: 02
None time:  0.848930048989132
None Run 14:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.70
Split: 05, Run: 03
None time:  0.6515708160586655
None Run 15:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7205946510657668
None Run 16:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 59.30
Split: 06, Run: 02
None time:  0.7701760351192206
None Run 17:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 59.30
Split: 06, Run: 03
None time:  0.6616410058923066
None Run 18:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.1692, Train: 86.67%, Valid: 51.80% Test: 57.70%
Split: 07, Run: 01
None time:  1.5028842091560364
None Run 19:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 86.67
   Final Test: 57.40
Split: 07, Run: 02
None time:  0.5107558160088956
None Run 20:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 58.00
Split: 07, Run: 03
None time:  0.606238333042711
None Run 21:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 57.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7691069280263036
None Run 22:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 64.00
Split: 08, Run: 02
None time:  0.61773935216479
None Run 23:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.70
Split: 08, Run: 03
None time:  0.5619112299755216
None Run 24:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.1451, Train: 73.33%, Valid: 57.00% Test: 57.50%
Split: 09, Run: 01
None time:  1.4023250790778548
None Run 25:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 80.00
   Final Test: 57.40
Split: 09, Run: 02
None time:  0.609482116997242
None Run 26:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.10
Split: 09, Run: 03
None time:  0.7221206431277096
None Run 27:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 96.67
   Final Test: 58.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8531259871087968
None Run 28:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 96.67
   Final Test: 56.70
Split: 10, Run: 02
None time:  0.5410879459232092
None Run 29:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.40
Split: 10, Run: 03
None time:  0.5674310671165586
None Run 30:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 55.50
run time now: 1.99806809425354
total time:  24.41829385003075
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.19 ± 5.93
  Final Train: 97.00 ± 5.35
   Final Test: 58.68 ± 4.22
best run test_acc: 60.0099983215332
[I 2023-06-11 23:24:54,572] Trial 7 finished with value: 58.19333267211914 and parameters: {'Fwd': 0.0006639311669283853, 'K': 5, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.2721608106828706, 'loop': 1, 'loss': 'CE', 'lr': 0.00048585358930747355, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.0108570415705944e-06, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00032048444440063815
weight_decay:  0.0009170547591533112
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9648844201583415
None Run 01:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 31.70
Split: 01, Run: 02
None time:  0.7930924140382558
None Run 02:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 32.10
Split: 01, Run: 03
None time:  0.8044120499398559
None Run 03:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 32.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1271136121358722
None Run 04:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.90
Split: 02, Run: 02
None time:  0.8436728708911687
None Run 05:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.90
Split: 02, Run: 03
None time:  0.7888379571959376
None Run 06:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4077982890885323
None Run 07:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 49.30
Split: 03, Run: 02
None time:  0.7856027081143111
None Run 08:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 49.50
Split: 03, Run: 03
None time:  0.903882151003927
None Run 09:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 49.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0910803631413728
None Run 10:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 46.00
Split: 04, Run: 02
None time:  0.7887522371020168
None Run 11:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 47.60
Split: 04, Run: 03
None time:  0.7892072058748454
None Run 12:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 47.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9253336370456964
None Run 13:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 48.40
Split: 05, Run: 02
None time:  0.778060182929039
None Run 14:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 48.40
Split: 05, Run: 03
None time:  0.7049698969349265
None Run 15:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 48.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0844, Train: 96.67%, Valid: 63.00% Test: 59.00%
Split: 06, Run: 01
None time:  1.6727700971532613
None Run 16:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 59.00
Split: 06, Run: 02
None time:  1.1190611410420388
None Run 17:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 59.20
Split: 06, Run: 03
None time:  1.240793899865821
None Run 18:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 59.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9556578111369163
None Run 19:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 42.90
Split: 07, Run: 02
None time:  0.7610687529668212
None Run 20:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 43.20
Split: 07, Run: 03
None time:  0.8830774140078574
None Run 21:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 43.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2983945729210973
None Run 22:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 90.00
   Final Test: 61.30
Split: 08, Run: 02
None time:  0.8396574459038675
None Run 23:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.00
Split: 08, Run: 03
None time:  0.792562018847093
None Run 24:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5524119730107486
None Run 25:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.00
Split: 09, Run: 02
None time:  1.272764969151467
None Run 26:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.10
Split: 09, Run: 03
None time:  1.3615335498470813
None Run 27:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 83.33
   Final Test: 50.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4176283669658005
None Run 28:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 96.67
   Final Test: 53.90
Split: 10, Run: 02
None time:  1.2013042022008449
None Run 29:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 54.60
Split: 10, Run: 03
None time:  0.7779699151869863
None Run 30:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 54.90
run time now: 3.4301981925964355
total time:  31.632337437942624
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.53 ± 9.61
  Final Train: 98.78 ± 3.55
   Final Test: 50.67 ± 8.66
best run test_acc: 51.02000045776367
[I 2023-06-11 23:25:26,586] Trial 8 finished with value: 51.526668548583984 and parameters: {'Fwd': 0.01859820560655443, 'K': 1, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 5.22145662301079, 'loop': 2, 'loss': 'CE', 'lr': 0.00032048444440063815, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009170547591533112, 'weightedloss': False}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.0048481090769360745
weight_decay:  0.00016085416970084375
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.28633893886581063
None Run 01:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 33.80
Split: 01, Run: 02
None time:  0.259206305956468
None Run 02:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 33.80
Split: 01, Run: 03
None time:  0.24981366517022252
None Run 03:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 33.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.26196773792617023
None Run 04:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 40.40
Split: 02, Run: 02
None time:  0.26771743781864643
None Run 05:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 40.40
Split: 02, Run: 03
None time:  0.2695991829968989
None Run 06:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 40.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.2643349759746343
None Run 07:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.30
Split: 03, Run: 02
None time:  0.26961129787378013
None Run 08:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.30
Split: 03, Run: 03
None time:  0.2507041790522635
None Run 09:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.23749806405976415
None Run 10:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 40.50
Split: 04, Run: 02
None time:  0.2403506929986179
None Run 11:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 40.50
Split: 04, Run: 03
None time:  0.24752745684236288
None Run 12:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 40.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.22489057295024395
None Run 13:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 42.00
Split: 05, Run: 02
None time:  0.2122176440898329
None Run 14:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 42.00
Split: 05, Run: 03
None time:  0.25653908494859934
None Run 15:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 42.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.32745137298479676
None Run 16:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.80
Split: 06, Run: 02
None time:  0.2763940170407295
None Run 17:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.80
Split: 06, Run: 03
None time:  0.295829659095034
None Run 18:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.2569400069769472
None Run 19:
Highest Train: 100.00
Highest Valid: 26.60
  Final Train: 100.00
   Final Test: 31.20
Split: 07, Run: 02
None time:  0.27735551190562546
None Run 20:
Highest Train: 100.00
Highest Valid: 26.60
  Final Train: 100.00
   Final Test: 31.20
Split: 07, Run: 03
None time:  0.24302910594269633
None Run 21:
Highest Train: 100.00
Highest Valid: 26.60
  Final Train: 100.00
   Final Test: 31.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.24092312203720212
None Run 22:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.20
Split: 08, Run: 02
None time:  0.2799042130354792
None Run 23:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.20
Split: 08, Run: 03
None time:  0.29316194797866046
None Run 24:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 41.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.23783427011221647
None Run 25:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 35.90
Split: 09, Run: 02
None time:  0.23107977001927793
None Run 26:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 35.90
Split: 09, Run: 03
None time:  0.2608284221496433
None Run 27:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 35.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.2519275709055364
None Run 28:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 34.30
Split: 10, Run: 02
None time:  0.26960470504127443
None Run 29:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 34.30
Split: 10, Run: 03
None time:  0.282999254995957
None Run 30:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 34.30
run time now: 0.8450992107391357
total time:  8.856287728063762
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 37.82 ± 5.02
  Final Train: 100.00 ± 0.00
   Final Test: 37.84 ± 3.59
best run test_acc: 37.840003967285156
[I 2023-06-11 23:25:35,795] Trial 9 finished with value: 37.81999969482422 and parameters: {'Fwd': 2.474191163989436e-06, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 10, 'lambda1': 0.75, 'lambda2': 4.9454355095158995, 'loop': 2, 'loss': 'CE', 'lr': 0.0048481090769360745, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016085416970084375, 'weightedloss': False}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.001231263345972029
weight_decay:  1.3603519097357087e-06
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7021930979099125
None Run 01:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 93.33
   Final Test: 50.30
Split: 01, Run: 02
None time:  0.6973777399398386
None Run 02:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 90.00
   Final Test: 50.00
Split: 01, Run: 03
None time:  0.6146945341024548
None Run 03:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 93.33
   Final Test: 48.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5474113579839468
None Run 04:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 55.30
Split: 02, Run: 02
None time:  0.624974163947627
None Run 05:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 96.67
   Final Test: 54.80
Split: 02, Run: 03
None time:  0.6535507589578629
None Run 06:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 53.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6384300559293479
None Run 07:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 96.67
   Final Test: 48.10
Split: 03, Run: 02
None time:  0.7887623610440642
None Run 08:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 96.67
   Final Test: 53.50
Split: 03, Run: 03
None time:  0.5524181891232729
None Run 09:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 49.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6427095041144639
None Run 10:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 86.67
   Final Test: 50.10
Split: 04, Run: 02
None time:  0.5890377049800009
None Run 11:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 54.40
Split: 04, Run: 03
None time:  0.5534083598759025
None Run 12:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 96.67
   Final Test: 47.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7914763081353158
None Run 13:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 93.33
   Final Test: 58.20
Split: 05, Run: 02
None time:  0.6006262921728194
None Run 14:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 55.20
Split: 05, Run: 03
None time:  0.589966821949929
None Run 15:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 52.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5529894130304456
None Run 16:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 56.20
Split: 06, Run: 02
None time:  0.6379806050099432
None Run 17:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 55.10
Split: 06, Run: 03
None time:  0.5595907759852707
None Run 18:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 96.67
   Final Test: 51.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7222544690594077
None Run 19:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 90.00
   Final Test: 53.80
Split: 07, Run: 02
None time:  0.5447336619254202
None Run 20:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 49.00
Split: 07, Run: 03
None time:  0.5734821669757366
None Run 21:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 96.67
   Final Test: 44.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7299833360593766
None Run 22:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 90.00
   Final Test: 61.70
Split: 08, Run: 02
None time:  0.7045515500940382
None Run 23:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 93.33
   Final Test: 57.30
Split: 08, Run: 03
None time:  0.6236089870799333
None Run 24:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 93.33
   Final Test: 49.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7208364990074188
None Run 25:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 90.00
   Final Test: 46.00
Split: 09, Run: 02
None time:  0.557917915051803
None Run 26:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 45.80
Split: 09, Run: 03
None time:  0.5472368509508669
None Run 27:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 46.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7227553811389953
None Run 28:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 90.00
   Final Test: 52.40
Split: 10, Run: 02
None time:  0.5966763901524246
None Run 29:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 51.70
Split: 10, Run: 03
None time:  0.5485651670023799
None Run 30:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 49.30
run time now: 1.916074275970459
total time:  20.01081454800442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.23 ± 5.41
  Final Train: 95.89 ± 4.08
   Final Test: 51.69 ± 4.06
best run test_acc: 54.220001220703125
[I 2023-06-11 23:25:56,337] Trial 10 finished with value: 52.22666931152344 and parameters: {'Fwd': 1.0633013834268239e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 0.3645513966551057, 'loop': 1, 'loss': 'CE', 'lr': 0.001231263345972029, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.3603519097357087e-06, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.7000000000000001
lr:  0.0013558652201712193
weight_decay:  0.0801444137366439
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9747481448575854
None Run 01:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 46.00
Split: 01, Run: 02
None time:  0.9422349059022963
None Run 02:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 44.70
Split: 01, Run: 03
None time:  0.8359551350586116
None Run 03:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 44.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0204858488868922
None Run 04:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 56.80
Split: 02, Run: 02
None time:  0.9344106649514288
None Run 05:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.10
Split: 02, Run: 03
None time:  0.8658232369925827
None Run 06:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8846177230589092
None Run 07:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 43.30
Split: 03, Run: 02
None time:  0.93362200492993
None Run 08:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 47.20
Split: 03, Run: 03
None time:  0.9604310670401901
None Run 09:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 47.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4447940099053085
None Run 10:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 53.40
Split: 04, Run: 02
None time:  0.8951099538244307
None Run 11:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 53.70
Split: 04, Run: 03
None time:  1.2232633049134165
None Run 12:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 54.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0737614289391786
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 57.40
Split: 05, Run: 02
None time:  1.0894119590520859
None Run 14:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 56.50
Split: 05, Run: 03
None time:  0.9523440899793059
None Run 15:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 58.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9268769670743495
None Run 16:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 50.20
Split: 06, Run: 02
None time:  0.8931386270560324
None Run 17:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 50.90
Split: 06, Run: 03
None time:  0.8218476548790932
None Run 18:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 51.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0126580400392413
None Run 19:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 52.20
Split: 07, Run: 02
None time:  1.1142183120828122
None Run 20:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 50.70
Split: 07, Run: 03
None time:  0.9892007291782647
None Run 21:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 51.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9047744821291417
None Run 22:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.50
Split: 08, Run: 02
None time:  1.061974928015843
None Run 23:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.10
Split: 08, Run: 03
None time:  0.9090585368685424
None Run 24:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 57.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9133874410763383
None Run 25:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.00
Split: 09, Run: 02
None time:  0.9751742728985846
None Run 26:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.80
Split: 09, Run: 03
None time:  0.8763586608693004
None Run 27:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 58.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8629570519551635
None Run 28:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 53.70
Split: 10, Run: 02
None time:  1.0163837319705635
None Run 29:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.70
Split: 10, Run: 03, Epoch: 100, Loss: 0.0221, Train: 100.00%, Valid: 54.40% Test: 54.60%
Split: 10, Run: 03
None time:  2.140668089967221
None Run 30:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 54.20
run time now: 4.054600477218628
total time:  31.61337073193863
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.66 ± 6.59
  Final Train: 100.00 ± 0.00
   Final Test: 53.09 ± 4.61
best run test_acc: 54.090003967285156
[I 2023-06-11 23:26:28,360] Trial 11 finished with value: 53.65999984741211 and parameters: {'Fwd': 0.001212566623791516, 'K': 3, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 3.1381610360499743, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013558652201712193, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0801444137366439, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.001848751285082094
weight_decay:  0.018186707172946282
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7804699870757759
None Run 01:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 43.30
Split: 01, Run: 02
None time:  0.7639604969881475
None Run 02:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 43.90
Split: 01, Run: 03
None time:  0.9873669389635324
None Run 03:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 42.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0102486619725823
None Run 04:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.90
Split: 02, Run: 02
None time:  0.7118628530297428
None Run 05:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 55.50
Split: 02, Run: 03
None time:  0.7303164480254054
None Run 06:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 56.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8796223860699683
None Run 07:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 42.20
Split: 03, Run: 02
None time:  0.8271274440921843
None Run 08:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 44.10
Split: 03, Run: 03
None time:  0.9628139678388834
None Run 09:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 44.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7523406520485878
None Run 10:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 54.00
Split: 04, Run: 02
None time:  1.0528784710913897
None Run 11:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.30
Split: 04, Run: 03
None time:  0.7042345330119133
None Run 12:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 53.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.908710272051394
None Run 13:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 57.10
Split: 05, Run: 02
None time:  1.2380383929703385
None Run 14:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 57.70
Split: 05, Run: 03
None time:  0.702561347046867
None Run 15:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 57.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0335328259970993
None Run 16:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 51.30
Split: 06, Run: 02
None time:  0.8704263870604336
None Run 17:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 52.10
Split: 06, Run: 03
None time:  0.8098985629621893
None Run 18:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 52.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1130566890351474
None Run 19:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 51.70
Split: 07, Run: 02
None time:  0.8801618961151689
None Run 20:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 52.10
Split: 07, Run: 03
None time:  0.9902070800308138
None Run 21:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 50.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8172454189043492
None Run 22:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.00
Split: 08, Run: 02
None time:  1.1170540971215814
None Run 23:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 52.60
Split: 08, Run: 03
None time:  1.1358210858888924
None Run 24:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 54.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7982293390668929
None Run 25:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 54.10
Split: 09, Run: 02
None time:  1.384350687963888
None Run 26:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.70
Split: 09, Run: 03
None time:  1.1298541889991611
None Run 27:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 56.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8025536718778312
None Run 28:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 52.00
Split: 10, Run: 02
None time:  0.7632489281240851
None Run 29:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 53.10
Split: 10, Run: 03
None time:  0.8539182760287076
None Run 30:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 53.10
run time now: 2.4546802043914795
total time:  28.499792000046
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.98 ± 6.61
  Final Train: 100.00 ± 0.00
   Final Test: 52.07 ± 4.83
best run test_acc: 52.8900032043457
[I 2023-06-11 23:26:57,287] Trial 12 finished with value: 52.97999954223633 and parameters: {'Fwd': 0.0007682691429192879, 'K': 2, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 2.7649254334719275, 'loop': 1, 'loss': 'MSE', 'lr': 0.001848751285082094, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.018186707172946282, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9
lr:  0.0005737721821716722
weight_decay:  0.051419916099719465
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6629231700208038
None Run 01:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 46.50
Split: 01, Run: 02
None time:  0.8120061701629311
None Run 02:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 48.40
Split: 01, Run: 03
None time:  0.973489997908473
None Run 03:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 93.33
   Final Test: 43.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9721377561800182
None Run 04:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 63.70
Split: 02, Run: 02
None time:  0.6969434348866343
None Run 05:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.40
Split: 02, Run: 03
None time:  0.639792978996411
None Run 06:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 50.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8837869248818606
None Run 07:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 90.00
   Final Test: 52.00
Split: 03, Run: 02
None time:  0.7102669780142605
None Run 08:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 50.90
Split: 03, Run: 03
None time:  0.7033183251041919
None Run 09:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 52.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1233022881206125
None Run 10:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 83.33
   Final Test: 41.60
Split: 04, Run: 02
None time:  0.5823346010874957
None Run 11:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 43.40
Split: 04, Run: 03
None time:  0.6117333290167153
None Run 12:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 38.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9145242050290108
None Run 13:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 60.70
Split: 05, Run: 02
None time:  0.6819452301133424
None Run 14:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.00
Split: 05, Run: 03
None time:  0.7290656748227775
None Run 15:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 49.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7882027260493487
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.60
Split: 06, Run: 02
None time:  0.7755914782173932
None Run 17:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.80
Split: 06, Run: 03
None time:  0.6656405490357429
None Run 18:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 51.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0742970940191299
None Run 19:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 96.67
   Final Test: 54.10
Split: 07, Run: 02
None time:  0.7015441041439772
None Run 20:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 43.50
Split: 07, Run: 03
None time:  0.6764986179769039
None Run 21:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 41.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6447578370571136
None Run 22:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 57.10
Split: 08, Run: 02
None time:  0.7275254549458623
None Run 23:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 57.80
Split: 08, Run: 03
None time:  0.7116198388393968
None Run 24:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 53.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6731253708712757
None Run 25:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 46.60
Split: 09, Run: 02
None time:  0.5682509911712259
None Run 26:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 45.50
Split: 09, Run: 03
None time:  0.6908696079626679
None Run 27:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 43.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2929859480354935
None Run 28:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 90.00
   Final Test: 54.70
Split: 10, Run: 02
None time:  0.625319411046803
None Run 29:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 43.80
Split: 10, Run: 03
None time:  0.5980809791944921
None Run 30:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 44.10
run time now: 2.5524137020111084
total time:  23.9265662971884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.15 ± 7.48
  Final Train: 98.33 ± 3.99
   Final Test: 50.25 ± 6.70
best run test_acc: 54.21000289916992
[I 2023-06-11 23:27:21,647] Trial 13 finished with value: 51.15333557128906 and parameters: {'Fwd': 0.0003632277923542635, 'K': 3, 'alpha': 0.9, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 2.932073728673254, 'loop': 2, 'loss': 'CE', 'lr': 0.0005737721821716722, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.051419916099719465, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0007013406760371161
weight_decay:  0.0917988223419564
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9231813300866634
None Run 01:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 36.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.2672, Train: 100.00%, Valid: 38.40% Test: 40.20%
Split: 01, Run: 02
None time:  1.8773766609374434
None Run 02:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 40.00
Split: 01, Run: 03
None time:  0.657890262780711
None Run 03:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 41.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3677455820143223
None Run 04:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 44.80
Split: 02, Run: 02, Epoch: 100, Loss: 0.2656, Train: 100.00%, Valid: 41.00% Test: 38.80%
Split: 02, Run: 02
None time:  1.9041760289110243
None Run 05:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 38.40
Split: 02, Run: 03
None time:  0.421310766832903
None Run 06:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 32.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.4198787740897387
None Run 07:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 32.30
Split: 03, Run: 02
None time:  1.177340742899105
None Run 08:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 49.50
Split: 03, Run: 03
None time:  0.939915067050606
None Run 09:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 48.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7191877891309559
None Run 10:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 44.90
Split: 04, Run: 02
None time:  1.2199781709350646
None Run 11:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 36.00
Split: 04, Run: 03
None time:  0.4291236640419811
None Run 12:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 29.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.3911406430415809
None Run 13:
Highest Train: 100.00
Highest Valid: 33.00
  Final Train: 100.00
   Final Test: 31.80
Split: 05, Run: 02, Epoch: 100, Loss: 0.2681, Train: 100.00%, Valid: 54.40% Test: 51.50%
Split: 05, Run: 02
None time:  1.8165607040282339
None Run 14:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 51.40
Split: 05, Run: 03, Epoch: 100, Loss: 0.2971, Train: 100.00%, Valid: 47.60% Test: 47.30%
Split: 05, Run: 03
None time:  1.8115046140737832
None Run 15:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 47.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.2561, Train: 100.00%, Valid: 47.60% Test: 44.10%
Split: 06, Run: 01
None time:  1.8054764438420534
None Run 16:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 44.10
Split: 06, Run: 02
None time:  0.6299972049891949
None Run 17:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 54.50
Split: 06, Run: 03
None time:  0.8359864249359816
None Run 18:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 54.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2256659381091595
None Run 19:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 35.30
Split: 07, Run: 02
None time:  0.4408179339952767
None Run 20:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 35.30
Split: 07, Run: 03, Epoch: 100, Loss: 0.2943, Train: 100.00%, Valid: 39.60% Test: 42.20%
Split: 07, Run: 03
None time:  1.8153636557981372
None Run 21:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 42.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.2598, Train: 100.00%, Valid: 52.40% Test: 54.20%
Split: 08, Run: 01
None time:  1.7718652349431068
None Run 22:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 54.30
Split: 08, Run: 02
None time:  0.6845547470729798
None Run 23:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 53.00
Split: 08, Run: 03, Epoch: 100, Loss: 0.2824, Train: 100.00%, Valid: 49.00% Test: 45.40%
Split: 08, Run: 03
None time:  1.7653441671282053
None Run 24:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 45.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.2616, Train: 100.00%, Valid: 35.80% Test: 35.60%
Split: 09, Run: 01
None time:  1.8155023828148842
None Run 25:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 35.20
Split: 09, Run: 02
None time:  0.4559020069427788
None Run 26:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 58.80
Split: 09, Run: 03
None time:  0.50638586608693
None Run 27:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 48.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.43007721402682364
None Run 28:
Highest Train: 100.00
Highest Valid: 25.20
  Final Train: 100.00
   Final Test: 24.40
Split: 10, Run: 02, Epoch: 100, Loss: 0.2780, Train: 100.00%, Valid: 46.00% Test: 45.70%
Split: 10, Run: 02
None time:  1.861838033888489
None Run 29:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 45.70
Split: 10, Run: 03
None time:  0.377452946966514
None Run 30:
Highest Train: 100.00
Highest Valid: 25.20
  Final Train: 100.00
   Final Test: 24.40
run time now: 2.70656156539917
total time:  33.47037495393306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 42.30 ± 9.35
  Final Train: 100.00 ± 0.00
   Final Test: 42.00 ± 9.17
best run test_acc: 48.72999954223633
[I 2023-06-11 23:27:55,572] Trial 14 finished with value: 42.29999923706055 and parameters: {'Fwd': 0.003064790369472217, 'K': 4, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 30, 'lambda1': 0.6000000000000001, 'lambda2': 3.7276312310276616, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007013406760371161, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0917988223419564, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8
lr:  0.0018235142651833172
weight_decay:  1.2628403341122359e-06
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5646911708172411
None Run 01:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 44.20
Split: 01, Run: 02
None time:  0.6927241571247578
None Run 02:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 43.30
Split: 01, Run: 03
None time:  0.6003435370512307
None Run 03:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 38.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5286905688699335
None Run 04:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 54.70
Split: 02, Run: 02
None time:  0.6026789539027959
None Run 05:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 57.50
Split: 02, Run: 03
None time:  0.5911117889918387
None Run 06:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 53.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5916394200176001
None Run 07:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 50.60
Split: 03, Run: 02
None time:  0.4681391818448901
None Run 08:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 52.00
Split: 03, Run: 03
None time:  0.5583693119697273
None Run 09:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6651251199655235
None Run 10:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 49.00
Split: 04, Run: 02
None time:  0.5350196310319006
None Run 11:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 45.80
Split: 04, Run: 03
None time:  0.6881031999364495
None Run 12:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 93.33
   Final Test: 38.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5711278519593179
None Run 13:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.20
Split: 05, Run: 02
None time:  0.5511321160010993
None Run 14:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 53.80
Split: 05, Run: 03
None time:  0.6176872549112886
None Run 15:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 51.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6196022380609065
None Run 16:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 58.60
Split: 06, Run: 02
None time:  0.538197536021471
None Run 17:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 56.70
Split: 06, Run: 03
None time:  0.5420969761908054
None Run 18:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5822092089802027
None Run 19:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.30
Split: 07, Run: 02
None time:  0.6255680171307176
None Run 20:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 48.60
Split: 07, Run: 03
None time:  0.5428771039005369
None Run 21:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 40.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6122782379388809
None Run 22:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.90
Split: 08, Run: 02
None time:  0.5974102260079235
None Run 23:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 52.40
Split: 08, Run: 03
None time:  0.6216078528668731
None Run 24:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 51.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5809925540816039
None Run 25:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 38.30
Split: 09, Run: 02
None time:  0.5987193959299475
None Run 26:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 47.50
Split: 09, Run: 03
None time:  0.5888683770317584
None Run 27:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 46.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5446734779980034
None Run 28:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 51.80
Split: 10, Run: 02
None time:  0.7194160809740424
None Run 29:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 51.70
Split: 10, Run: 03
None time:  0.5673778369091451
None Run 30:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 42.10
run time now: 1.867570400238037
total time:  18.718719477998093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.61 ± 6.17
  Final Train: 99.78 ± 1.22
   Final Test: 49.67 ± 6.04
best run test_acc: 53.099998474121094
[I 2023-06-11 23:28:14,829] Trial 15 finished with value: 50.61333465576172 and parameters: {'Fwd': 5.5873828977387635e-05, 'K': 3, 'alpha': 0.8, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 1.882418472567572, 'loop': 1, 'loss': 'CE', 'lr': 0.0018235142651833172, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.2628403341122359e-06, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.00022377742417491035
weight_decay:  0.02376540270025193
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9737194029148668
None Run 01:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 47.50
Split: 01, Run: 02
None time:  0.9730053688399494
None Run 02:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 44.00
Split: 01, Run: 03
None time:  1.0107382838614285
None Run 03:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 47.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8208658171351999
None Run 04:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 54.50
Split: 02, Run: 02
None time:  0.8365342880133539
None Run 05:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 50.20
Split: 02, Run: 03
None time:  0.8258571790065616
None Run 06:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 53.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8705757369752973
None Run 07:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 46.80
Split: 03, Run: 02
None time:  0.7672432879917324
None Run 08:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 49.60
Split: 03, Run: 03
None time:  0.8784615360200405
None Run 09:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 46.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9738988960161805
None Run 10:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 52.60
Split: 04, Run: 02
None time:  0.9341965839266777
None Run 11:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 51.20
Split: 04, Run: 03
None time:  0.9109764411114156
None Run 12:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 47.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9343210051301867
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.40
Split: 05, Run: 02
None time:  0.8400247630197555
None Run 14:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 60.20
Split: 05, Run: 03
None time:  0.8178908340632915
None Run 15:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 51.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8444791629444808
None Run 16:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 44.90
Split: 06, Run: 02
None time:  0.9389025708660483
None Run 17:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 49.90
Split: 06, Run: 03
None time:  0.9287961469963193
None Run 18:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 57.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7924902220256627
None Run 19:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 46.00
Split: 07, Run: 02
None time:  0.8511850549839437
None Run 20:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 44.80
Split: 07, Run: 03
None time:  0.8402045560069382
None Run 21:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 48.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8717364389449358
None Run 22:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 57.90
Split: 08, Run: 02
None time:  0.8431996030267328
None Run 23:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 50.20
Split: 08, Run: 03
None time:  0.9389507649466395
None Run 24:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 62.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8327426281757653
None Run 25:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 48.80
Split: 09, Run: 02
None time:  0.7473072148859501
None Run 26:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 50.00
Split: 09, Run: 03
None time:  0.9348354979883879
None Run 27:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 55.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.812576622935012
None Run 28:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 45.10
Split: 10, Run: 02
None time:  0.9236697531305254
None Run 29:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 50.40
Split: 10, Run: 03
None time:  0.9536032069008797
None Run 30:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.80
run time now: 2.728579044342041
total time:  27.452011232962832
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.45 ± 6.52
  Final Train: 100.00 ± 0.00
   Final Test: 50.88 ± 4.91
best run test_acc: 54.040000915527344
[I 2023-06-11 23:28:42,806] Trial 16 finished with value: 51.45333480834961 and parameters: {'Fwd': 0.0006002957410000574, 'K': 6, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 1.5820028453192538, 'loop': 2, 'loss': 'CE', 'lr': 0.00022377742417491035, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02376540270025193, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.65
lr:  0.0001043415971743257
weight_decay:  9.987840329240411e-06
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8476449369918555
None Run 01:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 35.40
Split: 01, Run: 02
None time:  0.7898569479584694
None Run 02:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 35.40
Split: 01, Run: 03
None time:  0.917087386129424
None Run 03:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 35.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1185922278091311
None Run 04:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 42.00
Split: 02, Run: 02
None time:  1.1264720470644534
None Run 05:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 42.00
Split: 02, Run: 03
None time:  1.1027817011345178
None Run 06:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 42.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7235254519619048
None Run 07:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 41.50
Split: 03, Run: 02
None time:  0.7312362401280552
None Run 08:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 41.50
Split: 03, Run: 03
None time:  0.763018982950598
None Run 09:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 41.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6890814108774066
None Run 10:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 41.30
Split: 04, Run: 02
None time:  0.6642890931107104
None Run 11:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 41.30
Split: 04, Run: 03
None time:  0.7005409570410848
None Run 12:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 41.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1394336398225278
None Run 13:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 44.60
Split: 05, Run: 02
None time:  1.2065605900716037
None Run 14:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 44.60
Split: 05, Run: 03
None time:  1.2019544709473848
None Run 15:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 44.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1405803740490228
None Run 16:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 44.60
Split: 06, Run: 02
None time:  1.2033590199425817
None Run 17:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 44.60
Split: 06, Run: 03
None time:  1.245610237121582
None Run 18:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 44.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.2916, Train: 100.00%, Valid: 33.20% Test: 36.10%
Split: 07, Run: 01
None time:  1.266449652146548
None Run 19:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.10
Split: 07, Run: 02, Epoch: 100, Loss: 0.1910, Train: 100.00%, Valid: 33.20% Test: 36.10%
Split: 07, Run: 02
None time:  1.387661092914641
None Run 20:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.10
Split: 07, Run: 03, Epoch: 100, Loss: 0.1734, Train: 100.00%, Valid: 33.20% Test: 36.10%
Split: 07, Run: 03
None time:  1.2563304568175226
None Run 21:
Highest Train: 100.00
Highest Valid: 33.20
  Final Train: 100.00
   Final Test: 36.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8539425728376955
None Run 22:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 42.80
Split: 08, Run: 02
None time:  0.808595531154424
None Run 23:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 42.80
Split: 08, Run: 03
None time:  0.8244287350680679
None Run 24:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 42.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9471260057762265
None Run 25:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 40.30
Split: 09, Run: 02
None time:  0.8242367671336979
None Run 26:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 40.30
Split: 09, Run: 03
None time:  0.8893271440174431
None Run 27:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 40.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9232376459985971
None Run 28:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 37.30
Split: 10, Run: 02
None time:  0.8684818290639669
None Run 29:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 37.30
Split: 10, Run: 03
None time:  0.8910985440015793
None Run 30:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 37.30
run time now: 2.724750280380249
total time:  30.08182474412024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.04 ± 4.13
  Final Train: 100.00 ± 0.00
   Final Test: 40.59 ± 3.19
best run test_acc: 40.59000015258789
[I 2023-06-11 23:29:13,422] Trial 17 finished with value: 41.03999710083008 and parameters: {'Fwd': 0.06406088674558903, 'K': 1, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 4.400845289833247, 'loop': 1, 'loss': 'MSE', 'lr': 0.0001043415971743257, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.987840329240411e-06, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.0008003279894413092
weight_decay:  0.0029763449254838915
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.241043641930446
None Run 01:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 37.70
Split: 01, Run: 02
None time:  1.525541007053107
None Run 02:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 47.10
Split: 01, Run: 03
None time:  1.5636471640318632
None Run 03:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 36.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.2465, Train: 100.00%, Valid: 52.20% Test: 51.20%
Split: 02, Run: 01
None time:  1.7721463181078434
None Run 04:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 50.70
Split: 02, Run: 02, Epoch: 100, Loss: 0.2671, Train: 100.00%, Valid: 52.40% Test: 51.50%
Split: 02, Run: 02
None time:  1.7452257191762328
None Run 05:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 51.20
Split: 02, Run: 03, Epoch: 100, Loss: 0.2443, Train: 100.00%, Valid: 44.80% Test: 43.20%
Split: 02, Run: 03
None time:  1.7142033679410815
None Run 06:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 43.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3917796469759196
None Run 07:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 47.40
Split: 03, Run: 02
None time:  0.9316425749566406
None Run 08:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 48.90
Split: 03, Run: 03
None time:  0.568346232874319
None Run 09:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 42.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.2886, Train: 100.00%, Valid: 41.60% Test: 43.50%
Split: 04, Run: 01
None time:  1.6930249938741326
None Run 10:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 43.50
Split: 04, Run: 02
None time:  1.2989225790370256
None Run 11:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 45.60
Split: 04, Run: 03, Epoch: 100, Loss: 0.2928, Train: 100.00%, Valid: 33.60% Test: 35.20%
Split: 04, Run: 03
None time:  1.694969333941117
None Run 12:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 35.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.405800353968516
None Run 13:
Highest Train: 100.00
Highest Valid: 23.00
  Final Train: 100.00
   Final Test: 22.90
Split: 05, Run: 02, Epoch: 100, Loss: 0.2695, Train: 100.00%, Valid: 52.20% Test: 49.40%
Split: 05, Run: 02
None time:  1.7522653238847852
None Run 14:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 49.50
Split: 05, Run: 03
None time:  0.8690191239584237
None Run 15:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 50.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9217836889438331
None Run 16:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 49.20
Split: 06, Run: 02, Epoch: 100, Loss: 0.2548, Train: 100.00%, Valid: 36.60% Test: 32.90%
Split: 06, Run: 02
None time:  1.7265323379542679
None Run 17:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 32.90
Split: 06, Run: 03
None time:  1.3899239609017968
None Run 18:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 35.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.2797, Train: 100.00%, Valid: 39.60% Test: 42.20%
Split: 07, Run: 01
None time:  1.720620064996183
None Run 19:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 42.30
Split: 07, Run: 02
None time:  0.9951550890691578
None Run 20:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 41.00
Split: 07, Run: 03
None time:  0.8879401709418744
None Run 21:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 49.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.2778, Train: 100.00%, Valid: 48.00% Test: 51.80%
Split: 08, Run: 01
None time:  1.7796823349781334
None Run 22:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 51.80
Split: 08, Run: 02
None time:  1.4814200720284134
None Run 23:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 47.00
Split: 08, Run: 03
None time:  1.1721305469982326
None Run 24:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 48.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0599258879665285
None Run 25:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 50.10
Split: 09, Run: 02, Epoch: 100, Loss: 0.2574, Train: 100.00%, Valid: 44.40% Test: 44.60%
Split: 09, Run: 02
None time:  1.737115944037214
None Run 26:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 44.60
Split: 09, Run: 03, Epoch: 100, Loss: 0.2631, Train: 100.00%, Valid: 49.60% Test: 50.70%
Split: 09, Run: 03
None time:  1.6666965780314058
None Run 27:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 50.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6111377761699259
None Run 28:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 45.60
Split: 10, Run: 02, Epoch: 100, Loss: 0.2621, Train: 100.00%, Valid: 42.40% Test: 43.40%
Split: 10, Run: 02
None time:  1.6863745779264718
None Run 29:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 43.10
Split: 10, Run: 03, Epoch: 100, Loss: 0.2676, Train: 100.00%, Valid: 41.60% Test: 42.90%
Split: 10, Run: 03
None time:  1.7446461180225015
None Run 30:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 42.90
run time now: 4.076987266540527
total time:  41.744322557002306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 44.15 ± 7.02
  Final Train: 100.00 ± 0.00
   Final Test: 44.20 ± 6.65
best run test_acc: 48.959999084472656
[I 2023-06-11 23:29:55,611] Trial 18 finished with value: 44.15333557128906 and parameters: {'Fwd': 0.005078483460102185, 'K': 3, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 30, 'lambda1': 0.65, 'lambda2': 6.203180775287745, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008003279894413092, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0029763449254838915, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.8
lr:  0.00038236612526106306
weight_decay:  0.013300074381413266
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4937483898829669
None Run 01:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 37.20
Split: 01, Run: 02
None time:  0.5085913920775056
None Run 02:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 45.10
Split: 01, Run: 03
None time:  1.0382102418225259
None Run 03:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 44.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1177846319042146
None Run 04:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 93.33
   Final Test: 64.10
Split: 02, Run: 02
None time:  0.6195578139740974
None Run 05:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 58.10
Split: 02, Run: 03
None time:  0.7111465539783239
None Run 06:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 51.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.017212179955095
None Run 07:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 96.67
   Final Test: 52.50
Split: 03, Run: 02
None time:  0.5774989130441099
None Run 08:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 52.10
Split: 03, Run: 03
None time:  0.5059024449437857
None Run 09:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 52.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.4575642079580575
None Run 10:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 29.70
Split: 04, Run: 02
None time:  0.546167089836672
None Run 11:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.40
Split: 04, Run: 03
None time:  0.9086989851202816
None Run 12:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 93.33
   Final Test: 43.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8742434228770435
None Run 13:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.90
Split: 05, Run: 02
None time:  0.56651700893417
None Run 14:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 56.80
Split: 05, Run: 03
None time:  0.5309424609877169
None Run 15:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 52.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6951629309915006
None Run 16:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 58.40
Split: 06, Run: 02
None time:  0.5146556929685175
None Run 17:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 57.50
Split: 06, Run: 03
None time:  0.5701977119315416
None Run 18:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 56.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8192114639095962
None Run 19:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 52.90
Split: 07, Run: 02
None time:  0.6169055150821805
None Run 20:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 47.50
Split: 07, Run: 03
None time:  0.6558971758931875
None Run 21:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 45.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6560535300523043
None Run 22:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.80
Split: 08, Run: 02
None time:  0.5216022501699626
None Run 23:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.00
Split: 08, Run: 03
None time:  0.6379443139303476
None Run 24:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6796949561685324
None Run 25:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 43.90
Split: 09, Run: 02
None time:  0.5172476819716394
None Run 26:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 48.60
Split: 09, Run: 03
None time:  0.5983263140078634
None Run 27:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 44.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0614409300033003
None Run 28:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 93.33
   Final Test: 59.30
Split: 10, Run: 02
None time:  0.5646083601750433
None Run 29:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 52.20
Split: 10, Run: 03
None time:  0.5507605460006744
None Run 30:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 48.80
run time now: 2.2140491008758545
total time:  21.19343570782803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.83 ± 9.10
  Final Train: 99.22 ± 2.09
   Final Test: 51.61 ± 8.13
best run test_acc: 54.81999588012695
[I 2023-06-11 23:30:17,244] Trial 19 finished with value: 51.83333206176758 and parameters: {'Fwd': 0.0001751290956687509, 'K': 4, 'alpha': 0.8, 'dropout': 0.0, 'gnnepoch': 60, 'lambda1': 0.4, 'lambda2': 4.203355769046482, 'loop': 2, 'loss': 'CE', 'lr': 0.00038236612526106306, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.013300074381413266, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0006675928485852019
weight_decay:  0.0014826767212043753
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6892261018510908
None Run 01:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 35.10
Split: 01, Run: 02
None time:  0.7955759780015796
None Run 02:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 41.00
Split: 01, Run: 03
None time:  0.6206469079479575
None Run 03:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 44.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7944254269823432
None Run 04:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 46.10
Split: 02, Run: 02
None time:  0.6866866671480238
None Run 05:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 54.00
Split: 02, Run: 03
None time:  0.7733706010039896
None Run 06:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 56.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9338399979751557
None Run 07:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 43.80
Split: 03, Run: 02
None time:  0.866970150033012
None Run 08:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 51.20
Split: 03, Run: 03
None time:  1.0366663008462638
None Run 09:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6983964550308883
None Run 10:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 41.70
Split: 04, Run: 02
None time:  0.9289116209838539
None Run 11:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 55.10
Split: 04, Run: 03
None time:  1.0824551328551024
None Run 12:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 56.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7379688159562647
None Run 13:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 41.60
Split: 05, Run: 02
None time:  0.7358567831106484
None Run 14:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 52.90
Split: 05, Run: 03
None time:  0.9140669049229473
None Run 15:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 53.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8349453120026737
None Run 16:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 44.70
Split: 06, Run: 02
None time:  0.8796242431271821
None Run 17:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 52.60
Split: 06, Run: 03
None time:  0.9550129100680351
None Run 18:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 51.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.183567102998495
None Run 19:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 33.50
Split: 07, Run: 02
None time:  0.8869107570499182
None Run 20:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 40.10
Split: 07, Run: 03
None time:  0.7471163680311292
None Run 21:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 41.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7682192909996957
None Run 22:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 49.80
Split: 08, Run: 02
None time:  1.3252984420396388
None Run 23:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 51.30
Split: 08, Run: 03
None time:  0.6980575900524855
None Run 24:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8654522199649364
None Run 25:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 40.70
Split: 09, Run: 02
None time:  1.2594190831296146
None Run 26:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 49.30
Split: 09, Run: 03
None time:  1.086220543133095
None Run 27:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 53.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7648951879236847
None Run 28:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 40.00
Split: 10, Run: 02
None time:  0.7013137890025973
None Run 29:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 41.10
Split: 10, Run: 03
None time:  0.6777874219696969
None Run 30:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 48.60
run time now: 2.18821120262146
total time:  27.008478462928906
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.91 ± 7.35
  Final Train: 100.00 ± 0.00
   Final Test: 47.46 ± 6.73
best run test_acc: 51.8900032043457
[I 2023-06-11 23:30:44,698] Trial 20 finished with value: 48.90666580200195 and parameters: {'Fwd': 0.0008343756724247596, 'K': 10, 'alpha': 0.4, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 6.886497202890073, 'loop': 1, 'loss': 'MSE', 'lr': 0.0006675928485852019, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0014826767212043753, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.0018857814402343678
weight_decay:  0.03349285914812885
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8599968960043043
None Run 01:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 43.50
Split: 01, Run: 02
None time:  0.8020970900543034
None Run 02:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 42.80
Split: 01, Run: 03
None time:  0.8522029221057892
None Run 03:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 44.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8739545398857445
None Run 04:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.10
Split: 02, Run: 02
None time:  0.7931756540201604
None Run 05:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 53.50
Split: 02, Run: 03
None time:  0.7744430731981993
None Run 06:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 52.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8220872711390257
None Run 07:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 43.00
Split: 03, Run: 02
None time:  0.8729738020338118
None Run 08:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 43.70
Split: 03, Run: 03
None time:  0.7145546048413962
None Run 09:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 42.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7474201079457998
None Run 10:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 53.80
Split: 04, Run: 02
None time:  1.0085935001261532
None Run 11:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 54.70
Split: 04, Run: 03
None time:  0.7095943840686232
None Run 12:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 53.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7000129090156406
None Run 13:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 54.90
Split: 05, Run: 02
None time:  0.9915974151808769
None Run 14:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 56.10
Split: 05, Run: 03
None time:  0.6898414539173245
None Run 15:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 55.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8273833089042455
None Run 16:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 51.40
Split: 06, Run: 02
None time:  0.8242478298489004
None Run 17:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 51.90
Split: 06, Run: 03
None time:  0.7462139120325446
None Run 18:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 49.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7288509551435709
None Run 19:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 51.00
Split: 07, Run: 02
None time:  0.7539960369467735
None Run 20:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 50.80
Split: 07, Run: 03
None time:  0.9687360641546547
None Run 21:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 49.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9910475199576467
None Run 22:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 54.50
Split: 08, Run: 02
None time:  1.1366183848585933
None Run 23:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 53.70
Split: 08, Run: 03
None time:  0.8804130798671395
None Run 24:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 53.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8161053820513189
None Run 25:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 55.80
Split: 09, Run: 02
None time:  0.75183275481686
None Run 26:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 55.20
Split: 09, Run: 03
None time:  0.8868620870634913
None Run 27:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 55.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7826320759486407
None Run 28:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 54.90
Split: 10, Run: 02
None time:  0.9465208631008863
None Run 29:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 52.80
Split: 10, Run: 03, Epoch: 100, Loss: 0.0142, Train: 100.00%, Valid: 54.40% Test: 56.60%
Split: 10, Run: 03
None time:  2.017809629905969
None Run 30:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 56.70
run time now: 3.7796995639801025
total time:  27.245514531852677
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.02 ± 5.96
  Final Train: 100.00 ± 0.00
   Final Test: 51.59 ± 4.55
best run test_acc: 52.540000915527344
[I 2023-06-11 23:31:12,476] Trial 21 finished with value: 52.02000045776367 and parameters: {'Fwd': 0.0006698845967931345, 'K': 2, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 3.3800700057080975, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018857814402343678, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.03349285914812885, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.0024413111026144745
weight_decay:  0.012037409201010525
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9307611251715571
None Run 01:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 45.10
Split: 01, Run: 02
None time:  0.7373710591346025
None Run 02:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 42.40
Split: 01, Run: 03
None time:  0.8363654019776732
None Run 03:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 41.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.715198480989784
None Run 04:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 53.70
Split: 02, Run: 02
None time:  0.8829952469095588
None Run 05:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.00
Split: 02, Run: 03
None time:  0.7463718550279737
None Run 06:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 53.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7469181260094047
None Run 07:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 40.80
Split: 03, Run: 02
None time:  0.8975546068977565
None Run 08:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 43.40
Split: 03, Run: 03
None time:  0.8793839071877301
None Run 09:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 43.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7819284810684621
None Run 10:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 53.10
Split: 04, Run: 02
None time:  0.7257700448390096
None Run 11:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.60
Split: 04, Run: 03
None time:  0.8057941049337387
None Run 12:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 52.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7490400921087712
None Run 13:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 53.60
Split: 05, Run: 02
None time:  0.9656366538256407
None Run 14:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 54.20
Split: 05, Run: 03
None time:  1.1401626931037754
None Run 15:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 55.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.826424767030403
None Run 16:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 50.10
Split: 06, Run: 02
None time:  0.8341506209690124
None Run 17:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 51.80
Split: 06, Run: 03
None time:  0.8382518629077822
None Run 18:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 51.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7421591179445386
None Run 19:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 50.50
Split: 07, Run: 02
None time:  0.8683243610430509
None Run 20:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 50.90
Split: 07, Run: 03
None time:  0.755700427107513
None Run 21:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 50.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6883358061313629
None Run 22:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 50.70
Split: 08, Run: 02
None time:  0.7505503271240741
None Run 23:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 53.30
Split: 08, Run: 03
None time:  0.7822977951727808
None Run 24:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 51.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1886436480563134
None Run 25:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 55.40
Split: 09, Run: 02
None time:  0.7908232961781323
None Run 26:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 53.10
Split: 09, Run: 03
None time:  0.883135715033859
None Run 27:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7439395720139146
None Run 28:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 53.10
Split: 10, Run: 02
None time:  0.8531904770061374
None Run 29:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 51.90
Split: 10, Run: 03
None time:  0.7595019028522074
None Run 30:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 53.50
run time now: 2.390795946121216
total time:  25.820754929911345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.07 ± 6.09
  Final Train: 100.00 ± 0.00
   Final Test: 50.71 ± 4.35
best run test_acc: 51.67000198364258
[I 2023-06-11 23:31:38,779] Trial 22 finished with value: 51.07332992553711 and parameters: {'Fwd': 0.005855163980601889, 'K': 2, 'alpha': 0.55, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 2.5785297831044462, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024413111026144745, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.012037409201010525, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.7000000000000001
lr:  0.001331573337725316
weight_decay:  0.08244114658835365
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8280620891600847
None Run 01:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 48.80
Split: 01, Run: 02
None time:  0.7734042648226023
None Run 02:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 47.20
Split: 01, Run: 03
None time:  0.6533315798733383
None Run 03:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 41.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7422308709938079
None Run 04:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 52.90
Split: 02, Run: 02
None time:  0.8826359650120139
None Run 05:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.90
Split: 02, Run: 03
None time:  0.7108967879321426
None Run 06:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 55.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5779184971470386
None Run 07:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 52.00
Split: 03, Run: 02
None time:  0.6173184809740633
None Run 08:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 51.90
Split: 03, Run: 03
None time:  0.590872841887176
None Run 09:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 52.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8051701809745282
None Run 10:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 53.40
Split: 04, Run: 02
None time:  1.0407996368594468
None Run 11:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 52.80
Split: 04, Run: 03
None time:  0.6354247471317649
None Run 12:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 55.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6137241430114955
None Run 13:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 59.60
Split: 05, Run: 02
None time:  1.73761074594222
None Run 14:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 56.60
Split: 05, Run: 03
None time:  1.0576436610426754
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 60.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8733556759543717
None Run 16:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 51.90
Split: 06, Run: 02
None time:  1.3028473919257522
None Run 17:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 49.40
Split: 06, Run: 03
None time:  0.6896368060261011
None Run 18:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7630778080783784
None Run 19:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 52.00
Split: 07, Run: 02
None time:  0.635868611978367
None Run 20:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 51.60
Split: 07, Run: 03
None time:  1.3906875478569418
None Run 21:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 49.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4356793710030615
None Run 22:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 54.50
Split: 08, Run: 02
None time:  0.6266166670247912
None Run 23:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.20
Split: 08, Run: 03
None time:  0.6608759211376309
None Run 24:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 60.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7899773849640042
None Run 25:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.00
Split: 09, Run: 02
None time:  0.6937855558935553
None Run 26:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 55.40
Split: 09, Run: 03
None time:  0.6595358569175005
None Run 27:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 55.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5843769449274987
None Run 28:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 52.80
Split: 10, Run: 02
None time:  0.8221222208812833
None Run 29:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 55.80
Split: 10, Run: 03, Epoch: 100, Loss: 0.0499, Train: 100.00%, Valid: 50.20% Test: 51.40%
Split: 10, Run: 03
None time:  1.8415854710619897
None Run 30:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 51.30
run time now: 3.284440040588379
total time:  28.055055996170267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.71 ± 6.16
  Final Train: 100.00 ± 0.00
   Final Test: 53.69 ± 4.14
best run test_acc: 55.790000915527344
[I 2023-06-11 23:32:07,360] Trial 23 finished with value: 53.71333312988281 and parameters: {'Fwd': 0.0011399713321294707, 'K': 4, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 3.914784073103247, 'loop': 1, 'loss': 'MSE', 'lr': 0.001331573337725316, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08244114658835365, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.0011037381241897214
weight_decay:  0.048603256479408434
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8432346049230546
None Run 01:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 47.60
Split: 01, Run: 02
None time:  0.6123959550168365
None Run 02:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 55.20
Split: 01, Run: 03
None time:  0.6592585500329733
None Run 03:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 48.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6694157549645752
None Run 04:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.30
Split: 02, Run: 02
None time:  0.6067168300505728
None Run 05:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.00
Split: 02, Run: 03
None time:  1.1796945470850915
None Run 06:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 51.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5890903079416603
None Run 07:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.80
Split: 03, Run: 02
None time:  0.6945826560258865
None Run 08:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 56.90
Split: 03, Run: 03
None time:  0.750515079125762
None Run 09:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 55.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9716950028669089
None Run 10:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 52.10
Split: 04, Run: 02
None time:  1.1081793799530715
None Run 11:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 53.00
Split: 04, Run: 03
None time:  0.6752647359389812
None Run 12:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 58.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5033365171402693
None Run 13:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 56.40
Split: 05, Run: 02
None time:  0.8420183649286628
None Run 14:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 58.20
Split: 05, Run: 03
None time:  1.9490315068978816
None Run 15:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 53.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7224339439999312
None Run 16:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 47.40
Split: 06, Run: 02
None time:  0.6130486798938364
None Run 17:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 55.50
Split: 06, Run: 03
None time:  0.6632522770669311
None Run 18:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 54.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1598496939986944
None Run 19:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 55.50
Split: 07, Run: 02
None time:  0.6890125018544495
None Run 20:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 54.70
Split: 07, Run: 03
None time:  0.698789652902633
None Run 21:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 51.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6806012238375843
None Run 22:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 52.10
Split: 08, Run: 02
None time:  0.8586932581383735
None Run 23:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 52.30
Split: 08, Run: 03
None time:  0.7820708970539272
None Run 24:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9961943549569696
None Run 25:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.40
Split: 09, Run: 02
None time:  0.9986811329144984
None Run 26:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 54.90
Split: 09, Run: 03
None time:  1.0114967308472842
None Run 27:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 55.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6440543250646442
None Run 28:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 57.50
Split: 10, Run: 02
None time:  0.8277981397695839
None Run 29:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 51.10
Split: 10, Run: 03
None time:  0.6800496599171311
None Run 30:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 53.40
run time now: 2.190265655517578
total time:  26.670926840044558
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.73 ± 4.02
  Final Train: 100.00 ± 0.00
   Final Test: 54.16 ± 3.02
best run test_acc: 56.70000076293945
[I 2023-06-11 23:32:34,494] Trial 24 finished with value: 54.733333587646484 and parameters: {'Fwd': 0.0013882588654617791, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 4.210632857520169, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011037381241897214, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.048603256479408434, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9
lr:  0.0009446959279391653
weight_decay:  0.005963283558441351
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4207111168652773
None Run 01:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 44.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.60% Test: 43.60%
Split: 01, Run: 02
None time:  1.0178596889600158
None Run 02:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 43.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 47.00% Test: 47.80%
Split: 01, Run: 03
None time:  1.0205740758683532
None Run 03:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 47.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.80% Test: 48.10%
Split: 02, Run: 01
None time:  0.9897132578771561
None Run 04:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 47.90
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.00% Test: 52.50%
Split: 02, Run: 02
None time:  1.0079723689705133
None Run 05:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 52.60
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.60% Test: 53.40%
Split: 02, Run: 03
None time:  1.0415031958837062
None Run 06:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 53.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 54.30%
Split: 03, Run: 01
None time:  1.0614362489432096
None Run 07:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 54.30
Split: 03, Run: 02
None time:  0.5260330948513001
None Run 08:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 46.10
Split: 03, Run: 03
None time:  0.4264560148585588
None Run 09:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 35.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.48429052997380495
None Run 10:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 45.30
Split: 04, Run: 02
None time:  0.4501157980412245
None Run 11:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 49.30
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.80% Test: 44.90%
Split: 04, Run: 03
None time:  1.0353894459549338
None Run 12:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 44.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.4538855280261487
None Run 13:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 58.10
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.80% Test: 58.50%
Split: 05, Run: 02
None time:  1.0924189768265933
None Run 14:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 58.50
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.60% Test: 57.60%
Split: 05, Run: 03
None time:  1.0394979799166322
None Run 15:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 57.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.40% Test: 46.60%
Split: 06, Run: 01
None time:  1.061444210121408
None Run 16:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 46.60
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 63.60% Test: 59.90%
Split: 06, Run: 02
None time:  1.0473361548501998
None Run 17:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.80
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.80% Test: 59.00%
Split: 06, Run: 03
None time:  1.0405106679536402
None Run 18:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.49051318783313036
None Run 19:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 39.30
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.60% Test: 53.90%
Split: 07, Run: 02
None time:  1.0703677269630134
None Run 20:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.80
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 37.40% Test: 42.20%
Split: 07, Run: 03
None time:  0.9864529150072485
None Run 21:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 42.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.60% Test: 56.40%
Split: 08, Run: 01
None time:  1.0426062298938632
None Run 22:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.30
Split: 08, Run: 02
None time:  0.4818530341144651
None Run 23:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.90
Split: 08, Run: 03
None time:  0.4647990521043539
None Run 24:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 36.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.80% Test: 40.90%
Split: 09, Run: 01
None time:  1.0514195391442627
None Run 25:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 40.80
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 47.20% Test: 47.00%
Split: 09, Run: 02
None time:  1.1093280098866671
None Run 26:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 47.00
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.80% Test: 47.80%
Split: 09, Run: 03
None time:  1.001505444990471
None Run 27:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 47.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.43432256602682173
None Run 28:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.70
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.00% Test: 48.00%
Split: 10, Run: 02
None time:  1.0769886730704457
None Run 29:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 48.00
Split: 10, Run: 03
None time:  0.4728573758620769
None Run 30:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 2.0212724208831787
total time:  25.924537954153493
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.92 ± 8.15
  Final Train: 100.00 ± 0.00
   Final Test: 49.20 ± 6.91
best run test_acc: 53.599998474121094
[I 2023-06-11 23:33:00,901] Trial 25 finished with value: 48.92000198364258 and parameters: {'Fwd': 0.00028746823527626595, 'K': 5, 'alpha': 0.9, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 4.256053256774548, 'loop': 0, 'loss': 'MSE', 'lr': 0.0009446959279391653, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005963283558441351, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.0005155774078625432
weight_decay:  0.03810098511324677
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5553866131231189
None Run 01:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 49.90
Split: 01, Run: 02
None time:  0.5755817950703204
None Run 02:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 47.50
Split: 01, Run: 03
None time:  0.5608258531428874
None Run 03:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 53.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5465714510064572
None Run 04:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 42.10
Split: 02, Run: 02
None time:  0.5071252211928368
None Run 05:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 49.20
Split: 02, Run: 03
None time:  0.5214563980698586
None Run 06:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 62.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.45926511008292437
None Run 07:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 47.30
Split: 03, Run: 02
None time:  0.5630319360643625
None Run 08:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 48.10
Split: 03, Run: 03
None time:  0.4982584130484611
None Run 09:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 42.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5234381600748748
None Run 10:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 53.20
Split: 04, Run: 02
None time:  0.5766069779638201
None Run 11:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 51.40
Split: 04, Run: 03
None time:  0.47901287116110325
None Run 12:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 51.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.500960067147389
None Run 13:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 55.60
Split: 05, Run: 02
None time:  0.5030388811137527
None Run 14:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 57.40
Split: 05, Run: 03
None time:  0.49769952916540205
None Run 15:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5344337420538068
None Run 16:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 57.40
Split: 06, Run: 02
None time:  0.5544122660066932
None Run 17:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 54.20
Split: 06, Run: 03
None time:  0.44080225308425725
None Run 18:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 48.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6835706969723105
None Run 19:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 53.60
Split: 07, Run: 02
None time:  0.5178799862042069
None Run 20:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 48.10
Split: 07, Run: 03
None time:  0.5195047149900347
None Run 21:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5090166558511555
None Run 22:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 54.30
Split: 08, Run: 02
None time:  0.5431689629331231
None Run 23:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.70
Split: 08, Run: 03
None time:  0.5732853189110756
None Run 24:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5458476280327886
None Run 25:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 51.30
Split: 09, Run: 02
None time:  0.46923846984282136
None Run 26:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 44.40
Split: 09, Run: 03
None time:  0.5319954210426658
None Run 27:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 48.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6370464658830315
None Run 28:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 50.00
Split: 10, Run: 02
None time:  0.6037124099675566
None Run 29:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.60
Split: 10, Run: 03
None time:  0.5341680638957769
None Run 30:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 57.00
run time now: 1.8151941299438477
total time:  17.08122743596323
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.06 ± 6.27
  Final Train: 100.00 ± 0.00
   Final Test: 52.00 ± 5.22
best run test_acc: 55.590003967285156
[I 2023-06-11 23:33:18,397] Trial 26 finished with value: 52.060001373291016 and parameters: {'Fwd': 0.005309047705991324, 'K': 7, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 3.9921026900569325, 'loop': 2, 'loss': 'CE', 'lr': 0.0005155774078625432, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03810098511324677, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0009020000962209571
weight_decay:  0.08309147998506566
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.688340136082843
None Run 01:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 44.10
Split: 01, Run: 02
None time:  0.7250451180152595
None Run 02:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 52.90
Split: 01, Run: 03
None time:  0.9152194261550903
None Run 03:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 46.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9437467269599438
None Run 04:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 54.40
Split: 02, Run: 02
None time:  0.741414109012112
None Run 05:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 50.80
Split: 02, Run: 03
None time:  0.8422317430377007
None Run 06:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 60.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6075021200813353
None Run 07:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 57.70
Split: 03, Run: 02
None time:  0.858261720975861
None Run 08:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 49.20
Split: 03, Run: 03
None time:  0.6761798250954598
None Run 09:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 52.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.2019, Train: 100.00%, Valid: 46.60% Test: 51.30%
Split: 04, Run: 01
None time:  1.9828677880577743
None Run 10:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 49.90
Split: 04, Run: 02
None time:  1.2007398111745715
None Run 11:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 50.30
Split: 04, Run: 03
None time:  1.3280820730142295
None Run 12:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 53.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8449636350851506
None Run 13:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 56.00
Split: 05, Run: 02
None time:  1.7980430589523166
None Run 14:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 45.90
Split: 05, Run: 03
None time:  0.6976878319401294
None Run 15:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 51.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7416566230822355
None Run 16:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 02
None time:  1.8467045261058956
None Run 17:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 54.20
Split: 06, Run: 03
None time:  1.320825811009854
None Run 18:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 45.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8203162970021367
None Run 19:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 43.20
Split: 07, Run: 02
None time:  1.063788543920964
None Run 20:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 49.00
Split: 07, Run: 03
None time:  1.3825450500007719
None Run 21:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 47.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3017086391337216
None Run 22:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 50.30
Split: 08, Run: 02
None time:  0.7839916099328548
None Run 23:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 58.90
Split: 08, Run: 03
None time:  0.9412904670462012
None Run 24:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7055975159164518
None Run 25:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.80
Split: 09, Run: 02
None time:  0.6207985528744757
None Run 26:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 52.00
Split: 09, Run: 03
None time:  2.039163696812466
None Run 27:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 56.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6291497640777379
None Run 28:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 46.20
Split: 10, Run: 02
None time:  1.04067860590294
None Run 29:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 47.70
Split: 10, Run: 03
None time:  0.8517741342075169
None Run 30:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 45.70
run time now: 2.5594687461853027
total time:  33.990679214010015
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.33 ± 6.80
  Final Train: 100.00 ± 0.00
   Final Test: 51.65 ± 5.13
best run test_acc: 55.54999923706055
[I 2023-06-11 23:33:52,890] Trial 27 finished with value: 52.32666778564453 and parameters: {'Fwd': 0.0017999986865177356, 'K': 6, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 4.831909667524027, 'loop': 1, 'loss': 'MSE', 'lr': 0.0009020000962209571, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08309147998506566, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.0013383460370998451
weight_decay:  0.009578256819121243
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6026095119304955
None Run 01:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 44.90
Split: 01, Run: 02
None time:  0.6993715199641883
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 86.67
   Final Test: 61.20
Split: 01, Run: 03
None time:  0.3329650601372123
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.36982872313819826
None Run 04:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 32.80
Split: 02, Run: 02
None time:  0.9070998639799654
None Run 05:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 90.00
   Final Test: 66.60
Split: 02, Run: 03
None time:  0.3860436291433871
None Run 06:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.3605248660314828
None Run 07:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 32.30
Split: 03, Run: 02
None time:  0.5884639059659094
None Run 08:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 53.90
Split: 03, Run: 03
None time:  0.380492142168805
None Run 09:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 56.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.341812256956473
None Run 10:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 29.70
Split: 04, Run: 02
None time:  0.7846339319366962
None Run 11:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 93.33
   Final Test: 49.60
Split: 04, Run: 03
None time:  0.3363492682110518
None Run 12:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.3424375040922314
None Run 13:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 41.50
Split: 05, Run: 02
None time:  0.7482987518887967
None Run 14:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 62.70
Split: 05, Run: 03
None time:  0.4399631670676172
None Run 15:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 63.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.2848571790382266
None Run 16:
Highest Train: 100.00
Highest Valid: 30.20
  Final Train: 100.00
   Final Test: 31.80
Split: 06, Run: 02
None time:  0.8286415219772607
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 66.20
Split: 06, Run: 03
None time:  0.3442776838783175
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.3279596830252558
None Run 19:
Highest Train: 100.00
Highest Valid: 21.60
  Final Train: 100.00
   Final Test: 23.40
Split: 07, Run: 02
None time:  1.1330034770071507
None Run 20:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 83.33
   Final Test: 61.50
Split: 07, Run: 03
None time:  0.3969201650470495
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 61.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.290509345009923
None Run 22:
Highest Train: 100.00
Highest Valid: 31.60
  Final Train: 100.00
   Final Test: 30.10
Split: 08, Run: 02
None time:  0.8855953530874103
None Run 23:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 83.33
   Final Test: 62.10
Split: 08, Run: 03
None time:  0.349377061938867
None Run 24:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.3487567421980202
None Run 25:
Highest Train: 100.00
Highest Valid: 28.60
  Final Train: 100.00
   Final Test: 27.00
Split: 09, Run: 02
None time:  0.6549016931094229
None Run 26:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 96.67
   Final Test: 59.60
Split: 09, Run: 03
None time:  0.4339417591691017
None Run 27:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0039071179926395
None Run 28:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 76.67
   Final Test: 34.00
Split: 10, Run: 02
None time:  0.3330938790459186
None Run 29:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 39.80
Split: 10, Run: 03
None time:  0.3631995399482548
None Run 30:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 46.10
run time now: 1.7385756969451904
total time:  16.592603811062872
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.88 ± 14.54
  Final Train: 96.67 ± 6.31
   Final Test: 50.40 ± 14.51
best run test_acc: 60.159996032714844
[I 2023-06-11 23:34:09,999] Trial 28 finished with value: 50.8800048828125 and parameters: {'Fwd': 0.007926905112308404, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 40, 'lambda1': 0.9, 'lambda2': 3.668159099172735, 'loop': 1, 'loss': 'CE', 'lr': 0.0013383460370998451, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.009578256819121243, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0033060146108939248
weight_decay:  0.024739012192399042
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.00% Test: 45.20%
Split: 01, Run: 01
None time:  1.0667188130319118
None Run 01:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 45.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 39.00% Test: 42.50%
Split: 01, Run: 02
None time:  1.083203308051452
None Run 02:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 42.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.20% Test: 43.60%
Split: 01, Run: 03
None time:  1.0657761842012405
None Run 03:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 43.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.60% Test: 58.60%
Split: 02, Run: 01
None time:  1.035140534862876
None Run 04:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.30
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.40% Test: 55.20%
Split: 02, Run: 02
None time:  1.0352289779111743
None Run 05:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 55.20
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.20% Test: 59.90%
Split: 02, Run: 03
None time:  1.0708597460761666
None Run 06:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 59.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.80% Test: 43.80%
Split: 03, Run: 01
None time:  1.1078009901102632
None Run 07:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 43.80
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.40% Test: 46.60%
Split: 03, Run: 02
None time:  1.0862197030801326
None Run 08:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 46.50
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.80% Test: 41.90%
Split: 03, Run: 03
None time:  1.0463370562065393
None Run 09:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 41.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.40% Test: 51.10%
Split: 04, Run: 01
None time:  1.0648166970349848
None Run 10:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 51.10
Split: 04, Run: 02
None time:  0.42066770093515515
None Run 11:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.20
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 56.10%
Split: 04, Run: 03
None time:  1.066952388966456
None Run 12:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 56.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.20% Test: 57.00%
Split: 05, Run: 01
None time:  1.1081956550478935
None Run 13:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.80
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.80% Test: 59.30%
Split: 05, Run: 02
None time:  1.1111327928956598
None Run 14:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.40
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.80% Test: 58.50%
Split: 05, Run: 03
None time:  1.0805980530567467
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 58.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.60% Test: 56.00%
Split: 06, Run: 01
None time:  1.0746916099451482
None Run 16:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 55.90
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.40% Test: 49.10%
Split: 06, Run: 02
None time:  1.0322333271615207
None Run 17:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 49.10
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.60% Test: 51.80%
Split: 06, Run: 03
None time:  1.0574576270300895
None Run 18:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 51.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.20% Test: 52.90%
Split: 07, Run: 01
None time:  1.0604424090124667
None Run 19:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 52.90
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.80% Test: 45.20%
Split: 07, Run: 02
None time:  1.0596153719816357
None Run 20:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 45.30
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 47.40% Test: 52.10%
Split: 07, Run: 03
None time:  1.0468979738652706
None Run 21:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 52.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 58.20% Test: 57.50%
Split: 08, Run: 01
None time:  1.0514184380881488
None Run 22:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.50
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.20% Test: 54.80%
Split: 08, Run: 02
None time:  1.109173231991008
None Run 23:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 54.80
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.20% Test: 58.20%
Split: 08, Run: 03
None time:  1.0728455029893667
None Run 24:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.80% Test: 53.20%
Split: 09, Run: 01
None time:  1.1091697819065303
None Run 25:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 53.10
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.60% Test: 55.10%
Split: 09, Run: 02
None time:  1.0662186529953033
None Run 26:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 55.10
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.80% Test: 56.20%
Split: 09, Run: 03
None time:  1.0122305240947753
None Run 27:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 56.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.39903291780501604
None Run 28:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 53.90
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.80% Test: 59.30%
Split: 10, Run: 02
None time:  1.1199411100242287
None Run 29:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 59.30
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.00% Test: 54.60%
Split: 10, Run: 03
None time:  1.083110400941223
None Run 30:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 54.50
run time now: 2.642545223236084
total time:  31.81439835089259
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.74 ± 7.00
  Final Train: 100.00 ± 0.00
   Final Test: 52.71 ± 5.50
best run test_acc: 54.93999481201172
[I 2023-06-11 23:34:42,255] Trial 29 finished with value: 52.73999786376953 and parameters: {'Fwd': 7.937012460883057e-05, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.8500000000000001, 'lambda2': 5.5831097683848965, 'loop': 0, 'loss': 'MSE', 'lr': 0.0033060146108939248, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.024739012192399042, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.0008760362914402621
weight_decay:  0.0026536503938711883
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4117234500590712
None Run 01:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 32.60
Split: 01, Run: 02
None time:  0.33898516092449427
None Run 02:
Highest Train: 100.00
Highest Valid: 28.60
  Final Train: 100.00
   Final Test: 26.20
Split: 01, Run: 03
None time:  0.3390724000055343
None Run 03:
Highest Train: 100.00
Highest Valid: 28.60
  Final Train: 100.00
   Final Test: 26.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.3223216598853469
None Run 04:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 36.10
Split: 02, Run: 02, Epoch: 100, Loss: 0.2889, Train: 100.00%, Valid: 45.20% Test: 43.60%
Split: 02, Run: 02
None time:  1.7488618069328368
None Run 05:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 43.50
Split: 02, Run: 03
None time:  0.3207687179092318
None Run 06:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 36.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.32689418108202517
None Run 07:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 35.20
Split: 03, Run: 02
None time:  0.47161587816663086
None Run 08:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.80
Split: 03, Run: 03
None time:  0.3386341480072588
None Run 09:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 35.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.3003, Train: 100.00%, Valid: 51.20% Test: 54.40%
Split: 04, Run: 01
None time:  1.8178085130639374
None Run 10:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 54.20
Split: 04, Run: 02
None time:  0.9108240089844912
None Run 11:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 41.20
Split: 04, Run: 03
None time:  1.4419054510071874
None Run 12:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 51.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.3638340048491955
None Run 13:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 37.40
Split: 05, Run: 02, Epoch: 100, Loss: 0.3040, Train: 100.00%, Valid: 61.80% Test: 58.40%
Split: 05, Run: 02
None time:  1.7922407609876245
None Run 14:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 58.30
Split: 05, Run: 03
None time:  0.7790523958392441
None Run 15:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 51.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.35283469990827143
None Run 16:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 36.60
Split: 06, Run: 02
None time:  0.4012282728217542
None Run 17:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 36.60
Split: 06, Run: 03
None time:  0.36200272804126143
None Run 18:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 36.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.37584395008161664
None Run 19:
Highest Train: 100.00
Highest Valid: 24.00
  Final Train: 100.00
   Final Test: 27.00
Split: 07, Run: 02
None time:  0.4578939089551568
None Run 20:
Highest Train: 100.00
Highest Valid: 30.80
  Final Train: 100.00
   Final Test: 33.70
Split: 07, Run: 03
None time:  0.49120054789818823
None Run 21:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 33.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.35195396887138486
None Run 22:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 36.60
Split: 08, Run: 02
None time:  1.0470131509937346
None Run 23:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 45.80
Split: 08, Run: 03
None time:  0.3315993510186672
None Run 24:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 36.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.3203463749960065
None Run 25:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 30.90
Split: 09, Run: 02
None time:  0.3964654440060258
None Run 26:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 38.00
Split: 09, Run: 03
None time:  0.3052690071053803
None Run 27:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 30.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.710606190841645
None Run 28:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 47.00
Split: 10, Run: 02
None time:  0.9122719340957701
None Run 29:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 43.10
Split: 10, Run: 03
None time:  0.8518402050249279
None Run 30:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 45.70
run time now: 3.512500762939453
total time:  21.461045850999653
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 39.09 ± 8.21
  Final Train: 100.00 ± 0.00
   Final Test: 38.83 ± 8.09
best run test_acc: 43.150001525878906
[I 2023-06-11 23:35:04,244] Trial 30 finished with value: 39.09333419799805 and parameters: {'Fwd': 0.0013523715395605364, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 20, 'lambda1': 0.6000000000000001, 'lambda2': 4.610491900404899, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008760362914402621, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0026536503938711883, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.7000000000000001
lr:  0.0013695791534448522
weight_decay:  0.07924687346316817
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8975990291219205
None Run 01:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 45.20
Split: 01, Run: 02
None time:  1.372319912072271
None Run 02:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 44.60
Split: 01, Run: 03
None time:  0.872239621123299
None Run 03:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 44.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.984353075036779
None Run 04:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.60
Split: 02, Run: 02
None time:  1.1577742770314217
None Run 05:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 56.20
Split: 02, Run: 03
None time:  0.8668805200140923
None Run 06:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8904704751912504
None Run 07:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 48.40
Split: 03, Run: 02
None time:  1.158770082052797
None Run 08:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 47.00
Split: 03, Run: 03
None time:  0.8535917969420552
None Run 09:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 46.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7891381629742682
None Run 10:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 54.20
Split: 04, Run: 02
None time:  1.0084458340425044
None Run 11:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 53.80
Split: 04, Run: 03
None time:  1.6907057811040431
None Run 12:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 56.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2364769058767706
None Run 13:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 55.70
Split: 05, Run: 02
None time:  1.537296321010217
None Run 14:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 57.90
Split: 05, Run: 03
None time:  1.3597535379230976
None Run 15:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 56.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.931235034018755
None Run 16:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 52.00
Split: 06, Run: 02
None time:  1.3046184328850359
None Run 17:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 53.30
Split: 06, Run: 03
None time:  0.9122027610428631
None Run 18:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 54.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4808636161033064
None Run 19:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 51.70
Split: 07, Run: 02
None time:  0.7971602028701454
None Run 20:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 52.40
Split: 07, Run: 03
None time:  0.894464354030788
None Run 21:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 53.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9200882010627538
None Run 22:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 52.60
Split: 08, Run: 02
None time:  1.1117658140137792
None Run 23:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 54.00
Split: 08, Run: 03
None time:  0.9443932720459998
None Run 24:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 53.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.86090690898709
None Run 25:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.30
Split: 09, Run: 02
None time:  0.9444789281114936
None Run 26:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 55.10
Split: 09, Run: 03
None time:  0.9483848379459232
None Run 27:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 55.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8710766471922398
None Run 28:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 53.90
Split: 10, Run: 02
None time:  0.9891942860558629
None Run 29:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 52.90
Split: 10, Run: 03
None time:  1.0092777591198683
None Run 30:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 54.60
run time now: 2.9063186645507812
total time:  33.617470853962004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.25 ± 5.60
  Final Train: 100.00 ± 0.00
   Final Test: 52.70 ± 3.79
best run test_acc: 53.54999923706055
[I 2023-06-11 23:35:38,315] Trial 31 finished with value: 53.246665954589844 and parameters: {'Fwd': 0.0012936938127497178, 'K': 3, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 3.3490892283977973, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013695791534448522, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.07924687346316817, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.6000000000000001
lr:  0.0005766192334150185
weight_decay:  0.04259503116150798
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.105799226090312
None Run 01:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.30
Split: 01, Run: 02
None time:  1.1179943920578808
None Run 02:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 38.20
Split: 01, Run: 03
None time:  0.7654328760690987
None Run 03:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 43.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8491131190676242
None Run 04:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 55.00
Split: 02, Run: 02
None time:  2.082113539101556
None Run 05:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 52.60
Split: 02, Run: 03
None time:  1.618975818855688
None Run 06:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 57.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8494160629343241
None Run 07:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 52.10
Split: 03, Run: 02
None time:  1.863118854817003
None Run 08:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 52.90
Split: 03, Run: 03
None time:  2.0204843098763376
None Run 09:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 45.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7730624019168317
None Run 10:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 47.80
Split: 04, Run: 02
None time:  0.852628581225872
None Run 11:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 54.20
Split: 04, Run: 03
None time:  1.1890518369618803
None Run 12:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 55.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.1410, Train: 100.00%, Valid: 58.60% Test: 58.00%
Split: 05, Run: 01
None time:  2.093604633817449
None Run 13:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 58.20
Split: 05, Run: 02
None time:  1.5278167829383165
None Run 14:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 57.00
Split: 05, Run: 03
None time:  0.655951309017837
None Run 15:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 40.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3714163398835808
None Run 16:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 54.50
Split: 06, Run: 02
None time:  1.3039530857931823
None Run 17:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 53.20
Split: 06, Run: 03
None time:  0.9665147219784558
None Run 18:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 43.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2752931651193649
None Run 19:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 47.50
Split: 07, Run: 02
None time:  1.3766565760597587
None Run 20:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 50.60
Split: 07, Run: 03
None time:  1.1017290051095188
None Run 21:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 50.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.999077821848914
None Run 22:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 50.30
Split: 08, Run: 02, Epoch: 100, Loss: 0.1612, Train: 100.00%, Valid: 49.60% Test: 48.00%
Split: 08, Run: 02
None time:  2.1787225601729006
None Run 23:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 47.80
Split: 08, Run: 03
None time:  0.6272935860324651
None Run 24:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 37.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0585527729708701
None Run 25:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 44.20
Split: 09, Run: 02
None time:  1.7962182760238647
None Run 26:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 45.30
Split: 09, Run: 03, Epoch: 100, Loss: 0.1417, Train: 100.00%, Valid: 45.60% Test: 45.90%
Split: 09, Run: 03
None time:  2.2427468402311206
None Run 27:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 45.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0351919159293175
None Run 28:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 50.20
Split: 10, Run: 02
None time:  1.3956227120943367
None Run 29:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 33.20
Split: 10, Run: 03
None time:  0.8404975780285895
None Run 30:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 56.50
run time now: 3.3107895851135254
total time:  39.97360620391555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.81 ± 6.77
  Final Train: 100.00 ± 0.00
   Final Test: 48.74 ± 6.55
best run test_acc: 52.55999755859375
[I 2023-06-11 23:36:18,889] Trial 32 finished with value: 48.81333541870117 and parameters: {'Fwd': 0.00267324273861714, 'K': 6, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 2.204584465636826, 'loop': 1, 'loss': 'MSE', 'lr': 0.0005766192334150185, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.04259503116150798, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.75
lr:  0.0014362509037574782
weight_decay:  0.09101644674822755
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0955858388915658
None Run 01:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 43.60
Split: 01, Run: 02
None time:  1.1710133079905063
None Run 02:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 42.90
Split: 01, Run: 03
None time:  1.3607130760792643
None Run 03:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 41.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0379716427996755
None Run 04:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 55.70
Split: 02, Run: 02
None time:  0.9548960311803967
None Run 05:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.30
Split: 02, Run: 03
None time:  1.7976095150224864
None Run 06:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9916929970495403
None Run 07:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 42.60
Split: 03, Run: 02
None time:  1.1537227288354188
None Run 08:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 42.60
Split: 03, Run: 03
None time:  1.0991894397884607
None Run 09:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 45.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0411997518967837
None Run 10:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 54.10
Split: 04, Run: 02
None time:  1.0411133819725364
None Run 11:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.80
Split: 04, Run: 03
None time:  0.9993966440670192
None Run 12:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 54.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2776625440455973
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 55.80
Split: 05, Run: 02
None time:  1.7171398820355535
None Run 14:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 56.90
Split: 05, Run: 03
None time:  1.7163431739900261
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 57.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.016399934887886
None Run 16:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 50.90
Split: 06, Run: 02
None time:  0.9671643110923469
None Run 17:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 54.00
Split: 06, Run: 03
None time:  1.5713241540361196
None Run 18:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 51.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1147103998810053
None Run 19:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 51.80
Split: 07, Run: 02
None time:  0.9485646039247513
None Run 20:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 52.50
Split: 07, Run: 03
None time:  1.0657764428760856
None Run 21:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 51.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0728909359313548
None Run 22:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 52.50
Split: 08, Run: 02
None time:  1.0860275961458683
None Run 23:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 54.00
Split: 08, Run: 03
None time:  1.062936777016148
None Run 24:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 53.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9604005010332912
None Run 25:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 56.60
Split: 09, Run: 02
None time:  1.1475260260049254
None Run 26:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 57.70
Split: 09, Run: 03
None time:  1.0148571620229632
None Run 27:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0456535699777305
None Run 28:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.60
Split: 10, Run: 02
None time:  0.9652437120676041
None Run 29:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 55.60
Split: 10, Run: 03
None time:  0.9951264439150691
None Run 30:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 54.70
run time now: 3.0470361709594727
total time:  35.48081763298251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.43 ± 6.32
  Final Train: 100.00 ± 0.00
   Final Test: 52.16 ± 4.97
best run test_acc: 52.970001220703125
[I 2023-06-11 23:36:54,886] Trial 33 finished with value: 52.42667007446289 and parameters: {'Fwd': 0.00035150934864021664, 'K': 4, 'alpha': 0.75, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 3.518071702466584, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014362509037574782, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.09101644674822755, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.0009724776100401647
weight_decay:  0.0004187166217335537
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7011687571648508
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 47.70
Split: 01, Run: 02
None time:  0.6788589949719608
None Run 02:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 47.30
Split: 01, Run: 03
None time:  0.7104537959676236
None Run 03:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 46.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6753979520872235
None Run 04:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 57.70
Split: 02, Run: 02
None time:  1.0636919271200895
None Run 05:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.30
Split: 02, Run: 03
None time:  0.6672382280230522
None Run 06:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 53.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7170209449250251
None Run 07:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 52.10
Split: 03, Run: 02
None time:  0.8795001769904047
None Run 08:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 47.40
Split: 03, Run: 03
None time:  0.8617676622234285
None Run 09:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 54.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0574, Train: 100.00%, Valid: 49.20% Test: 53.50%
Split: 04, Run: 01
None time:  1.9670662358403206
None Run 10:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 53.40
Split: 04, Run: 02
None time:  0.6904542911797762
None Run 11:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.20
Split: 04, Run: 03
None time:  1.0640641739591956
None Run 12:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 52.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.735202417941764
None Run 13:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 56.00
Split: 05, Run: 02
None time:  1.203690447844565
None Run 14:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 61.90
Split: 05, Run: 03
None time:  0.8097570310346782
None Run 15:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9104374558664858
None Run 16:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 50.00
Split: 06, Run: 02
None time:  1.0027556768618524
None Run 17:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 55.40
Split: 06, Run: 03
None time:  0.9547651070170105
None Run 18:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 53.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7724234948400408
None Run 19:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 57.30
Split: 07, Run: 02
None time:  0.9247248661704361
None Run 20:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 53.80
Split: 07, Run: 03
None time:  0.8859137289691716
None Run 21:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 51.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6210403288714588
None Run 22:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 57.70
Split: 08, Run: 02
None time:  0.642847873037681
None Run 23:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.90
Split: 08, Run: 03
None time:  0.7003873949870467
None Run 24:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7931411049794406
None Run 25:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 54.80
Split: 09, Run: 02, Epoch: 100, Loss: 0.0532, Train: 100.00%, Valid: 54.20% Test: 54.00%
Split: 09, Run: 02
None time:  2.0676600218284875
None Run 26:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 54.40
Split: 09, Run: 03
None time:  1.484003531979397
None Run 27:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 53.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.704304686980322
None Run 28:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 47.70
Split: 10, Run: 02
None time:  0.7421217691153288
None Run 29:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 52.30
Split: 10, Run: 03
None time:  1.1049354090355337
None Run 30:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 55.00
run time now: 2.5886404514312744
total time:  29.76197070092894
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.14 ± 6.22
  Final Train: 100.00 ± 0.00
   Final Test: 53.99 ± 4.40
best run test_acc: 56.15000534057617
[I 2023-06-11 23:37:25,178] Trial 34 finished with value: 54.13999938964844 and parameters: {'Fwd': 0.00130034629823088, 'K': 5, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 1.639904026377601, 'loop': 1, 'loss': 'MSE', 'lr': 0.0009724776100401647, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004187166217335537, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.000942706913068351
weight_decay:  0.0005761851698991954
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.43598671606741846
None Run 01:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 44.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.60% Test: 43.70%
Split: 01, Run: 02
None time:  1.0495105849113315
None Run 02:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 43.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.80% Test: 47.80%
Split: 01, Run: 03
None time:  1.122463057981804
None Run 03:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 47.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.508098566904664
None Run 04:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 47.80
Split: 02, Run: 02
None time:  0.4871315860655159
None Run 05:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 52.50
Split: 02, Run: 03
None time:  0.4256564751267433
None Run 06:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 53.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 54.40%
Split: 03, Run: 01
None time:  1.0386875849217176
None Run 07:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 54.30
Split: 03, Run: 02
None time:  0.46104164491407573
None Run 08:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 46.00
Split: 03, Run: 03
None time:  0.4749802309088409
None Run 09:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 35.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5087934560142457
None Run 10:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 45.20
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 47.80% Test: 49.30%
Split: 04, Run: 02
None time:  1.0287756440229714
None Run 11:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 49.40
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.80% Test: 44.90%
Split: 04, Run: 03
None time:  1.0316593090537935
None Run 12:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 44.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.60% Test: 58.20%
Split: 05, Run: 01
None time:  1.0110926670022309
None Run 13:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.20
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.40% Test: 58.50%
Split: 05, Run: 02
None time:  1.010768017033115
None Run 14:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 58.40
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.60% Test: 57.60%
Split: 05, Run: 03
None time:  1.0752344850916415
None Run 15:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 57.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.40% Test: 46.60%
Split: 06, Run: 01
None time:  0.9961837979499251
None Run 16:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 46.70
Split: 06, Run: 02
None time:  0.48461484792642295
None Run 17:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 59.60
Split: 06, Run: 03
None time:  0.4579877690412104
None Run 18:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 59.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.49163954704999924
None Run 19:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 39.30
Split: 07, Run: 02
None time:  0.4963056070264429
None Run 20:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 53.80
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 37.40% Test: 42.20%
Split: 07, Run: 03
None time:  1.0454981389921159
None Run 21:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 42.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.60% Test: 56.20%
Split: 08, Run: 01
None time:  1.053832511883229
None Run 22:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.20
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.80% Test: 60.00%
Split: 08, Run: 02
None time:  1.0855573019944131
None Run 23:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.00
Split: 08, Run: 03
None time:  0.4919519529212266
None Run 24:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 36.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.80% Test: 41.00%
Split: 09, Run: 01
None time:  1.1051487009972334
None Run 25:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 41.00
Split: 09, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 47.20% Test: 47.00%
Split: 09, Run: 02
None time:  0.9992640248965472
None Run 26:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 47.00
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.00% Test: 47.70%
Split: 09, Run: 03
None time:  1.055057844845578
None Run 27:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 47.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.4406540999189019
None Run 28:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 48.50
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.80% Test: 48.10%
Split: 10, Run: 02
None time:  1.0703420208301395
None Run 29:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 48.10
Split: 10, Run: 03
None time:  0.507115843007341
None Run 30:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 51.60
run time now: 2.0622289180755615
total time:  24.48724800697528
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.92 ± 8.17
  Final Train: 100.00 ± 0.00
   Final Test: 49.21 ± 6.88
best run test_acc: 53.57999801635742
[I 2023-06-11 23:37:50,187] Trial 35 finished with value: 48.92000198364258 and parameters: {'Fwd': 0.0028053634527537667, 'K': 5, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 1.346758919389254, 'loop': 0, 'loss': 'MSE', 'lr': 0.000942706913068351, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005761851698991954, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.001105551567330672
weight_decay:  0.00016414215505336594
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9306983230635524
None Run 01:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 49.60
Split: 01, Run: 02
None time:  1.2005111388862133
None Run 02:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 45.70
Split: 01, Run: 03
None time:  1.3608965210150927
None Run 03:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 43.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.328757484909147
None Run 04:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.20
Split: 02, Run: 02
None time:  0.7086601171176881
None Run 05:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 54.30
Split: 02, Run: 03
None time:  0.7580832450184971
None Run 06:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0314555410295725
None Run 07:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 48.60
Split: 03, Run: 02
None time:  0.7079158399719745
None Run 08:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.40
Split: 03, Run: 03
None time:  0.6955265239812434
None Run 09:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 46.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8901653320062906
None Run 10:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 55.70
Split: 04, Run: 02
None time:  0.8376202050130814
None Run 11:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 53.90
Split: 04, Run: 03
None time:  1.5112084827851504
None Run 12:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 51.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8104343730956316
None Run 13:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 55.50
Split: 05, Run: 02
None time:  1.508276626933366
None Run 14:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 59.90
Split: 05, Run: 03
None time:  0.8000930941198021
None Run 15:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 56.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8617018631193787
None Run 16:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 50.40
Split: 06, Run: 02
None time:  0.8537154088262469
None Run 17:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 53.00
Split: 06, Run: 03
None time:  1.004313567886129
None Run 18:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 47.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6687004109844565
None Run 19:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 53.00
Split: 07, Run: 02
None time:  1.5426828160416335
None Run 20:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 53.90
Split: 07, Run: 03
None time:  1.224030063021928
None Run 21:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 51.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.315493375994265
None Run 22:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.00
Split: 08, Run: 02
None time:  0.755471965065226
None Run 23:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 54.30
Split: 08, Run: 03, Epoch: 100, Loss: 0.1009, Train: 100.00%, Valid: 57.60% Test: 54.90%
Split: 08, Run: 03
None time:  2.0179694411344826
None Run 24:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 55.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6978786238469183
None Run 25:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.60
Split: 09, Run: 02
None time:  1.7925800939556211
None Run 26:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 57.60
Split: 09, Run: 03
None time:  1.2156485109589994
None Run 27:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 52.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8640452360268682
None Run 28:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 54.70
Split: 10, Run: 02
None time:  1.0845785459969193
None Run 29:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 49.20
Split: 10, Run: 03
None time:  0.6973735939245671
None Run 30:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 52.90
run time now: 2.683551073074341
total time:  33.73661889717914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.49 ± 5.87
  Final Train: 100.00 ± 0.00
   Final Test: 52.95 ± 4.13
best run test_acc: 55.339996337890625
[I 2023-06-11 23:38:24,380] Trial 36 finished with value: 53.49333190917969 and parameters: {'Fwd': 0.0005100077905086102, 'K': 5, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 1.1081294349014392, 'loop': 1, 'loss': 'MSE', 'lr': 0.001105551567330672, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016414215505336594, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.0007364532778926235
weight_decay:  0.00044547227888724536
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 35.00% Test: 35.00%
Split: 01, Run: 01
None time:  1.0206375441048294
None Run 01:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 35.00
Split: 01, Run: 02
None time:  0.3940918839070946
None Run 02:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 29.60
Split: 01, Run: 03
None time:  0.37686929386109114
None Run 03:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 29.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.00% Test: 44.00%
Split: 02, Run: 01
None time:  1.0351386319380254
None Run 04:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 44.00
Split: 02, Run: 02
None time:  0.41035109106451273
None Run 05:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 38.00
Split: 02, Run: 03
None time:  0.4256666121073067
None Run 06:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 43.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 40.20% Test: 40.30%
Split: 03, Run: 01
None time:  1.0490330969914794
None Run 07:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 40.10
Split: 03, Run: 02
None time:  0.40376814012415707
None Run 08:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 37.40
Split: 03, Run: 03
None time:  0.40904640802182257
None Run 09:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 37.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.4100620618555695
None Run 10:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 37.90
Split: 04, Run: 02
None time:  0.3902941250707954
None Run 11:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 37.90
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.20% Test: 50.60%
Split: 04, Run: 03
None time:  1.0247293969150633
None Run 12:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 50.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.60% Test: 42.90%
Split: 05, Run: 01
None time:  1.0476682560984045
None Run 13:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 42.90
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.80% Test: 49.80%
Split: 05, Run: 02
None time:  1.0724994628690183
None Run 14:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 50.00
Split: 05, Run: 03
None time:  0.3581107039935887
None Run 15:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 40.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 43.20% Test: 40.70%
Split: 06, Run: 01
None time:  1.0130431649740785
None Run 16:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 41.00
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.60% Test: 44.10%
Split: 06, Run: 02
None time:  1.0432993539143354
None Run 17:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 44.20
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.20% Test: 46.70%
Split: 06, Run: 03
None time:  0.9702928639017045
None Run 18:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 46.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.46047592000104487
None Run 19:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 45.80
Split: 07, Run: 02
None time:  0.41417215019464493
None Run 20:
Highest Train: 100.00
Highest Valid: 26.00
  Final Train: 100.00
   Final Test: 30.10
Split: 07, Run: 03
None time:  0.41207399615086615
None Run 21:
Highest Train: 100.00
Highest Valid: 29.00
  Final Train: 100.00
   Final Test: 36.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.60% Test: 46.70%
Split: 08, Run: 01
None time:  1.0108821168541908
None Run 22:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 47.20
Split: 08, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 43.60% Test: 41.60%
Split: 08, Run: 02
None time:  0.9913306210655719
None Run 23:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 41.60
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.80% Test: 55.30%
Split: 08, Run: 03
None time:  1.043502900050953
None Run 24:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 55.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.4398668371140957
None Run 25:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 32.40
Split: 09, Run: 02
None time:  0.42213618918322027
None Run 26:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 39.80
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 36.80% Test: 35.40%
Split: 09, Run: 03
None time:  1.0162775788921863
None Run 27:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 35.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 46.00% Test: 45.40%
Split: 10, Run: 01
None time:  1.0473746000789106
None Run 28:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 45.40
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.00% Test: 48.30%
Split: 10, Run: 02
None time:  1.0553503539413214
None Run 29:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.30
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 43.40% Test: 43.00%
Split: 10, Run: 03
None time:  1.0331898890435696
None Run 30:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 43.10
run time now: 3.174574375152588
total time:  23.249459020793438
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.94 ± 6.81
  Final Train: 100.00 ± 0.00
   Final Test: 40.92 ± 6.37
best run test_acc: 45.56999969482422
[I 2023-06-11 23:38:48,184] Trial 37 finished with value: 40.939998626708984 and parameters: {'Fwd': 0.0013514091404070463, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.5, 'gnnepoch': 40, 'lambda1': 0.55, 'lambda2': 2.2837964603336953, 'loop': 0, 'loss': 'MSE', 'lr': 0.0007364532778926235, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00044547227888724536, 'weightedloss': False}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.25
lr:  0.0004869695651842311
weight_decay:  0.006043401184180345
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8345682080835104
None Run 01:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 90.00
   Final Test: 36.30
Split: 01, Run: 02
None time:  0.3722413219511509
None Run 02:
Highest Train: 100.00
Highest Valid: 32.60
  Final Train: 100.00
   Final Test: 36.20
Split: 01, Run: 03
None time:  0.41202681395225227
None Run 03:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 36.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.3961404000874609
None Run 04:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 32.70
Split: 02, Run: 02
None time:  0.5544294689316303
None Run 05:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 50.20
Split: 02, Run: 03
None time:  0.3630429361946881
None Run 06:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 50.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.3754718729760498
None Run 07:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 32.30
Split: 03, Run: 02
None time:  0.6119793250691146
None Run 08:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 52.60
Split: 03, Run: 03
None time:  0.4363471460528672
None Run 09:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 53.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.3439437039196491
None Run 10:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 29.80
Split: 04, Run: 02
None time:  0.5304598121438175
None Run 11:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 47.60
Split: 04, Run: 03
None time:  0.4378794119693339
None Run 12:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 48.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6079258969984949
None Run 13:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 96.67
   Final Test: 36.60
Split: 05, Run: 02
None time:  0.41229705000296235
None Run 14:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 37.80
Split: 05, Run: 03
None time:  0.3970583030022681
None Run 15:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 38.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.379458996001631
None Run 16:
Highest Train: 100.00
Highest Valid: 30.20
  Final Train: 100.00
   Final Test: 31.80
Split: 06, Run: 02
None time:  0.7045668659266084
None Run 17:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 60.00
Split: 06, Run: 03
None time:  0.6167220510542393
None Run 18:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 60.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.4114492458757013
None Run 19:
Highest Train: 100.00
Highest Valid: 21.60
  Final Train: 100.00
   Final Test: 23.40
Split: 07, Run: 02
None time:  0.5473499768413603
None Run 20:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 96.67
   Final Test: 35.30
Split: 07, Run: 03
None time:  0.4018644809257239
None Run 21:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 35.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.4006963849533349
None Run 22:
Highest Train: 100.00
Highest Valid: 31.60
  Final Train: 100.00
   Final Test: 30.20
Split: 08, Run: 02
None time:  0.7308819401077926
None Run 23:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 86.67
   Final Test: 57.30
Split: 08, Run: 03
None time:  0.3891902780160308
None Run 24:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.3341103009879589
None Run 25:
Highest Train: 100.00
Highest Valid: 28.60
  Final Train: 100.00
   Final Test: 27.00
Split: 09, Run: 02
None time:  0.4704710131045431
None Run 26:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 39.60
Split: 09, Run: 03
None time:  0.34606188000179827
None Run 27:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 40.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.767551596974954
None Run 28:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 31.50
Split: 10, Run: 02
None time:  0.38891550502739847
None Run 29:
Highest Train: 100.00
Highest Valid: 33.40
  Final Train: 100.00
   Final Test: 33.30
Split: 10, Run: 03
None time:  0.37712236982770264
None Run 30:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 32.60
run time now: 1.5697388648986816
total time:  15.363378413021564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.41 ± 11.70
  Final Train: 98.78 ± 3.09
   Final Test: 40.48 ± 10.52
best run test_acc: 45.409996032714844
[I 2023-06-11 23:39:03,959] Trial 38 finished with value: 40.40666580200195 and parameters: {'Fwd': 0.00020240382125855992, 'K': 4, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 2.3656990181487254, 'loop': 1, 'loss': 'CE', 'lr': 0.0004869695651842311, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006043401184180345, 'weightedloss': False}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.000405745044200712
weight_decay:  0.0017541412903573468
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.33544151298701763
None Run 01:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 31.90
Split: 01, Run: 02
None time:  0.3676548229996115
None Run 02:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 31.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.80% Test: 39.50%
Split: 01, Run: 03
None time:  0.9739197408780456
None Run 03:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 39.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.33116989699192345
None Run 04:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 39.90
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.00% Test: 43.00%
Split: 02, Run: 02
None time:  1.0086386080365628
None Run 05:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 43.00
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.20% Test: 46.90%
Split: 02, Run: 03
None time:  0.9925640008877963
None Run 06:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 46.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.3100711409933865
None Run 07:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 38.30
Split: 03, Run: 02
None time:  0.39712767489254475
None Run 08:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 38.30
Split: 03, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.40% Test: 51.90%
Split: 03, Run: 03
None time:  0.9720219159498811
None Run 09:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 51.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.32591988588683307
None Run 10:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 39.60
Split: 04, Run: 02
None time:  0.33200662583112717
None Run 11:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 39.60
Split: 04, Run: 03
None time:  0.2912964711431414
None Run 12:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 39.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.34786546509712934
None Run 13:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 41.60
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 43.60% Test: 42.90%
Split: 05, Run: 02
None time:  1.0098297798540443
None Run 14:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 42.90
Split: 05, Run: 03
None time:  0.30542459711432457
None Run 15:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 41.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 42.60% Test: 37.80%
Split: 06, Run: 01
None time:  1.002095429925248
None Run 16:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 37.90
Split: 06, Run: 02
None time:  0.31831159396097064
None Run 17:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.70
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.80% Test: 44.20%
Split: 06, Run: 03
None time:  1.00657006399706
None Run 18:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 44.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.3168093890417367
None Run 19:
Highest Train: 100.00
Highest Valid: 25.80
  Final Train: 100.00
   Final Test: 29.40
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 30.60% Test: 30.20%
Split: 07, Run: 02
None time:  0.992812915937975
None Run 20:
Highest Train: 100.00
Highest Valid: 30.60
  Final Train: 100.00
   Final Test: 30.20
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 32.40% Test: 32.00%
Split: 07, Run: 03
None time:  0.9808644040022045
None Run 21:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 32.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.3064608599524945
None Run 22:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 39.90
Split: 08, Run: 02
None time:  0.36663103103637695
None Run 23:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 44.10
Split: 08, Run: 03
None time:  0.3127437802031636
None Run 24:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 39.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.34166100691072643
None Run 25:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 33.80
Split: 09, Run: 02
None time:  0.3098130039870739
None Run 26:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 33.80
Split: 09, Run: 03
None time:  0.30001086788251996
None Run 27:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 33.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 41.60% Test: 43.10%
Split: 10, Run: 01
None time:  0.9888690349180251
None Run 28:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 43.10
Split: 10, Run: 02
None time:  0.3341209639329463
None Run 29:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 33.20
Split: 10, Run: 03
None time:  0.3070035041309893
None Run 30:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 33.20
run time now: 1.6704518795013428
total time:  17.51633796398528
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 39.39 ± 5.55
  Final Train: 100.00 ± 0.00
   Final Test: 38.49 ± 5.28
best run test_acc: 41.79999923706055
[I 2023-06-11 23:39:21,972] Trial 39 finished with value: 39.38666534423828 and parameters: {'Fwd': 0.012807367093244922, 'K': 7, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 3.9108683810413125, 'loop': 0, 'loss': 'MSE', 'lr': 0.000405745044200712, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0017541412903573468, 'weightedloss': True}. Best is trial 7 with value: 58.19333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.6000000000000001
lr:  0.001086533168746766
weight_decay:  5.828080160589031e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7628319191280752
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 83.33
   Final Test: 61.00
Split: 01, Run: 02
None time:  0.5036394430790097
None Run 02:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 93.33
   Final Test: 57.80
Split: 01, Run: 03
None time:  0.6090607189107686
None Run 03:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 83.33
   Final Test: 58.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7834433920215815
None Run 04:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 86.67
   Final Test: 66.40
Split: 02, Run: 02
None time:  0.48450274812057614
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 03
None time:  0.4610451329499483
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7986899970564991
None Run 07:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 93.33
   Final Test: 58.90
Split: 03, Run: 02
None time:  0.4444604020100087
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 03
None time:  0.42332067899405956
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8681895900517702
None Run 10:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 76.67
   Final Test: 52.60
Split: 04, Run: 02
None time:  0.46972778788767755
None Run 11:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 65.10
Split: 04, Run: 03
None time:  0.4043206819333136
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8279835409484804
None Run 13:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 62.30
Split: 05, Run: 02
None time:  0.45708914287388325
None Run 14:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 64.20
Split: 05, Run: 03
None time:  0.4756237049587071
None Run 15:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6912698070518672
None Run 16:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 86.67
   Final Test: 64.50
Split: 06, Run: 02
None time:  0.5341975400224328
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 86.67
   Final Test: 64.00
Split: 06, Run: 03
None time:  0.5806693139020354
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 86.67
   Final Test: 63.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8093025770504028
None Run 19:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 86.67
   Final Test: 56.90
Split: 07, Run: 02
None time:  0.46615722798742354
None Run 20:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 56.00
Split: 07, Run: 03
None time:  0.6077398909255862
None Run 21:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 93.33
   Final Test: 53.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.572703419951722
None Run 22:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 93.33
   Final Test: 59.80
Split: 08, Run: 02
None time:  0.4212535968981683
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.20
Split: 08, Run: 03
None time:  0.47642982099205256
None Run 24:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7848923590499908
None Run 25:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 76.67
   Final Test: 60.30
Split: 09, Run: 02
None time:  0.43577833706513047
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.50
Split: 09, Run: 03
None time:  0.47606472205370665
None Run 27:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7643295270390809
None Run 28:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 73.33
   Final Test: 68.40
Split: 10, Run: 02
None time:  0.48193341586738825
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 10, Run: 03
None time:  0.5287645200733095
None Run 30:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.60
run time now: 1.8114509582519531
total time:  18.437442854978144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.62 ± 5.60
  Final Train: 93.00 ± 8.32
   Final Test: 62.89 ± 4.60
best run test_acc: 64.72000122070312
[I 2023-06-11 23:39:40,941] Trial 40 finished with value: 63.62000274658203 and parameters: {'Fwd': 0.0034628412225955777, 'K': 5, 'alpha': 0.6000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 0.8444351103037709, 'loop': 1, 'loss': 'CE', 'lr': 0.001086533168746766, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.828080160589031e-05, 'weightedloss': False}. Best is trial 40 with value: 63.62000274658203.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.6000000000000001
lr:  0.0011059802021147422
weight_decay:  6.633941861752108e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7590482099913061
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 86.67
   Final Test: 60.40
Split: 01, Run: 02
None time:  0.7113105610478669
None Run 02:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 80.00
   Final Test: 58.20
Split: 01, Run: 03
None time:  0.6041390669997782
None Run 03:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 80.00
   Final Test: 56.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9226861849892884
None Run 04:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 70.00
   Final Test: 65.60
Split: 02, Run: 02
None time:  0.4960999768227339
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 70.10
Split: 02, Run: 03
None time:  0.4753851401619613
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9418285659048706
None Run 07:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 70.00
   Final Test: 57.50
Split: 03, Run: 02
None time:  0.46543022990226746
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 65.90
Split: 03, Run: 03
None time:  0.4198045169468969
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7634577809367329
None Run 10:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 83.33
   Final Test: 55.80
Split: 04, Run: 02
None time:  0.44114530202932656
None Run 11:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.90
Split: 04, Run: 03
None time:  0.4090859608259052
None Run 12:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8867201751563698
None Run 13:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 69.50
Split: 05, Run: 02
None time:  0.4736024411395192
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.60
Split: 05, Run: 03
None time:  0.40949833602644503
None Run 15:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 65.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7612870540469885
None Run 16:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 63.40
Split: 06, Run: 02
None time:  0.5498144889716059
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 64.40
Split: 06, Run: 03
None time:  0.44847989082336426
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 64.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7613834561780095
None Run 19:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 76.67
   Final Test: 53.70
Split: 07, Run: 02
None time:  0.4983453981112689
None Run 20:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 55.20
Split: 07, Run: 03
None time:  0.45996621693484485
None Run 21:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 56.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6090023729484528
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 86.67
   Final Test: 67.80
Split: 08, Run: 02
None time:  0.458800220862031
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 65.00
Split: 08, Run: 03
None time:  0.5388152950908989
None Run 24:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 90.00
   Final Test: 63.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7186819310300052
None Run 25:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 80.00
   Final Test: 56.40
Split: 09, Run: 02
None time:  0.5080273721832782
None Run 26:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.40
Split: 09, Run: 03
None time:  0.44750479189679027
None Run 27:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7480756938457489
None Run 28:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 86.67
   Final Test: 63.10
Split: 10, Run: 02
None time:  0.4787484861444682
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.80
Split: 10, Run: 03
None time:  0.44760029087774456
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.80
run time now: 1.723292350769043
total time:  18.66398980212398
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.60 ± 6.22
  Final Train: 91.22 ± 9.33
   Final Test: 63.13 ± 4.89
best run test_acc: 65.25999450683594
[I 2023-06-11 23:40:00,103] Trial 41 finished with value: 63.59999465942383 and parameters: {'Fwd': 0.0031136857648271276, 'K': 5, 'alpha': 0.6000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 0.8026506267292574, 'loop': 1, 'loss': 'CE', 'lr': 0.0011059802021147422, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.633941861752108e-05, 'weightedloss': False}. Best is trial 40 with value: 63.62000274658203.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.6000000000000001
lr:  0.0011092921569408436
weight_decay:  4.991609236644079e-05
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.944283934077248
None Run 01:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 63.33
   Final Test: 61.70
Split: 01, Run: 02
None time:  0.4949096869677305
None Run 02:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 80.00
   Final Test: 60.10
Split: 01, Run: 03
None time:  0.5183764949906617
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 83.33
   Final Test: 60.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8669590798672289
None Run 04:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 70.00
   Final Test: 68.30
Split: 02, Run: 02
None time:  0.5256753109861165
None Run 05:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 70.10
Split: 02, Run: 03
None time:  0.45142895192839205
None Run 06:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7735416300129145
None Run 07:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 93.33
   Final Test: 60.00
Split: 03, Run: 02
None time:  0.4391277199611068
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 03
None time:  0.49253838299773633
None Run 09:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 63.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.4707652998622507
None Run 10:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 34.20
Split: 04, Run: 02
None time:  0.45639896602369845
None Run 11:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 55.40
Split: 04, Run: 03
None time:  0.444951084908098
None Run 12:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 60.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8265007170848548
None Run 13:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 93.33
   Final Test: 60.20
Split: 05, Run: 02
None time:  0.45921194390393794
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 64.30
Split: 05, Run: 03
None time:  0.49514903919771314
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.75284868106246
None Run 16:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 65.40
Split: 06, Run: 02
None time:  0.3939405740238726
None Run 17:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 65.00
Split: 06, Run: 03
None time:  0.5192270099651068
None Run 18:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 65.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6823977117892355
None Run 19:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 90.00
   Final Test: 54.30
Split: 07, Run: 02
None time:  0.4449853580445051
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 59.30
Split: 07, Run: 03
None time:  0.4770429232157767
None Run 21:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 58.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5129621310625225
None Run 22:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 61.20
Split: 08, Run: 02
None time:  0.44153270381502807
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 65.80
Split: 08, Run: 03
None time:  0.4443114798050374
None Run 24:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9056627789977938
None Run 25:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 83.33
   Final Test: 57.80
Split: 09, Run: 02
None time:  0.489802555879578
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.50
Split: 09, Run: 03
None time:  0.46135549899190664
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7474924230482429
None Run 28:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 83.33
   Final Test: 67.50
Split: 10, Run: 02
None time:  0.3991886558942497
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.40
Split: 10, Run: 03
None time:  0.5226166881620884
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.10
run time now: 1.707667350769043
total time:  17.868981295032427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.93 ± 7.88
  Final Train: 94.00 ± 9.61
   Final Test: 62.29 ± 6.72
best run test_acc: 64.50999450683594
[I 2023-06-11 23:40:18,374] Trial 42 finished with value: 62.926673889160156 and parameters: {'Fwd': 0.003438377237806246, 'K': 5, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 0.952759584110723, 'loop': 1, 'loss': 'CE', 'lr': 0.0011092921569408436, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.991609236644079e-05, 'weightedloss': False}. Best is trial 40 with value: 63.62000274658203.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.6000000000000001
lr:  0.0006860236233428541
weight_decay:  5.147620367701436e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.066268497146666
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 56.67
   Final Test: 58.80
Split: 01, Run: 02
None time:  0.6499885611701757
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 76.67
   Final Test: 62.70
Split: 01, Run: 03
None time:  0.5795683150645345
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 76.67
   Final Test: 62.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9474887209944427
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 68.60
Split: 02, Run: 02
None time:  0.481814841972664
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 71.10
Split: 02, Run: 03
None time:  0.5382475941441953
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 71.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8641726970672607
None Run 07:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 93.33
   Final Test: 58.70
Split: 03, Run: 02
None time:  0.4964700317941606
None Run 08:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.20
Split: 03, Run: 03
None time:  0.5201963800936937
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1676136869937181
None Run 10:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 80.00
   Final Test: 61.00
Split: 04, Run: 02
None time:  0.4934794681612402
None Run 11:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 66.50
Split: 04, Run: 03
None time:  0.5023791000712663
None Run 12:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 66.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9385996300261468
None Run 13:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.30
Split: 05, Run: 02
None time:  0.49598481715656817
None Run 14:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.60
Split: 05, Run: 03
None time:  0.5250625018961728
None Run 15:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7647902171593159
None Run 16:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 90.00
   Final Test: 64.40
Split: 06, Run: 02
None time:  0.5767151420004666
None Run 17:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 66.50
Split: 06, Run: 03
None time:  0.5982077450025827
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 66.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1095241899602115
None Run 19:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 70.00
   Final Test: 56.30
Split: 07, Run: 02
None time:  0.5304155149497092
None Run 20:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 90.00
   Final Test: 57.40
Split: 07, Run: 03
None time:  0.6946912899147719
None Run 21:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 86.67
   Final Test: 57.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7704386911354959
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 83.33
   Final Test: 66.60
Split: 08, Run: 02
None time:  0.5899254309479147
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 90.00
   Final Test: 66.20
Split: 08, Run: 03
None time:  0.5504966550506651
None Run 24:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 67.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0398777010850608
None Run 25:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 73.33
   Final Test: 58.50
Split: 09, Run: 02
None time:  0.5241269008256495
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 65.60
Split: 09, Run: 03
None time:  0.4970752920489758
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9956498220562935
None Run 28:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 86.67
   Final Test: 64.10
Split: 10, Run: 02
None time:  0.5391865430865437
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 10, Run: 03
None time:  0.5180794950574636
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.0908379554748535
total time:  21.625285166781396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.06 ± 5.26
  Final Train: 90.56 ± 11.01
   Final Test: 64.67 ± 4.15
best run test_acc: 66.15999603271484
[I 2023-06-11 23:40:40,439] Trial 43 finished with value: 65.05998992919922 and parameters: {'Fwd': 0.003922626483869824, 'K': 6, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 0.7500293214432453, 'loop': 1, 'loss': 'CE', 'lr': 0.0006860236233428541, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.147620367701436e-05, 'weightedloss': False}. Best is trial 43 with value: 65.05998992919922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0006818742191392942
weight_decay:  6.281925834742193e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0949980719015002
None Run 01:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 70.00
   Final Test: 61.90
Split: 01, Run: 02
None time:  0.649657147936523
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 86.67
   Final Test: 62.80
Split: 01, Run: 03
None time:  0.5871026329696178
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 93.33
   Final Test: 62.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0354760121554136
None Run 04:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 83.33
   Final Test: 67.40
Split: 02, Run: 02
None time:  0.5644636421930045
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.10
Split: 02, Run: 03
None time:  0.5349583528004587
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1113497400656343
None Run 07:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 93.33
   Final Test: 62.70
Split: 03, Run: 02
None time:  0.5622311958577484
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 03
None time:  0.5439939210191369
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2238953500054777
None Run 10:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 80.00
   Final Test: 53.90
Split: 04, Run: 02
None time:  0.545716764871031
None Run 11:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 65.30
Split: 04, Run: 03
None time:  0.5405303749721497
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1274643489159644
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.60
Split: 05, Run: 02
None time:  0.5216727878432721
None Run 14:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.60
Split: 05, Run: 03
None time:  0.6193818808533251
None Run 15:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5385777670890093
None Run 16:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 59.90
Split: 06, Run: 02
None time:  0.699272049125284
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 64.30
Split: 06, Run: 03
None time:  0.5425824979320168
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 65.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7985991819296032
None Run 19:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 90.00
   Final Test: 55.60
Split: 07, Run: 02
None time:  0.7812189550604671
None Run 20:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 90.00
   Final Test: 55.70
Split: 07, Run: 03
None time:  0.9695069331210107
None Run 21:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 83.33
   Final Test: 56.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8218325348570943
None Run 22:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 83.33
   Final Test: 67.30
Split: 08, Run: 02
None time:  0.5925718380603939
None Run 23:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 68.40
Split: 08, Run: 03
None time:  0.5338225669693202
None Run 24:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 67.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9894112669862807
None Run 25:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 80.00
   Final Test: 56.70
Split: 09, Run: 02
None time:  0.5332002001814544
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 67.20
Split: 09, Run: 03
None time:  0.5272075070533901
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8539930540136993
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 90.00
   Final Test: 65.60
Split: 10, Run: 02
None time:  0.6018116159830242
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.30
Split: 10, Run: 03
None time:  0.511377772083506
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.20
run time now: 2.0087239742279053
total time:  22.62661805585958
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.85 ± 5.68
  Final Train: 93.22 ± 7.95
   Final Test: 64.11 ± 4.65
best run test_acc: 65.93000793457031
[I 2023-06-11 23:41:03,486] Trial 44 finished with value: 64.85334014892578 and parameters: {'Fwd': 0.010012028623140311, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 0.8186727539708482, 'loop': 1, 'loss': 'CE', 'lr': 0.0006818742191392942, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.281925834742193e-05, 'weightedloss': False}. Best is trial 43 with value: 65.05998992919922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0006631553940861701
weight_decay:  6.0574526265360046e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1933070961385965
None Run 01:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 66.67
   Final Test: 57.20
Split: 01, Run: 02
None time:  0.9738983670249581
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 63.33
   Final Test: 60.90
Split: 01, Run: 03
None time:  0.7372734029777348
None Run 03:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 70.00
   Final Test: 60.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1254086920525879
None Run 04:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 73.33
   Final Test: 68.90
Split: 02, Run: 02
None time:  0.4851064670365304
None Run 05:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 70.60
Split: 02, Run: 03
None time:  0.5234967391006649
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 70.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1897605168633163
None Run 07:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 86.67
   Final Test: 59.10
Split: 03, Run: 02
None time:  0.4748519000131637
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  0.5599679439328611
None Run 09:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5010051499120891
None Run 10:
Highest Train: 100.00
Highest Valid: 37.20
  Final Train: 100.00
   Final Test: 41.50
Split: 04, Run: 02
None time:  0.5972688731271774
None Run 11:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 93.33
   Final Test: 58.60
Split: 04, Run: 03
None time:  0.48163161892443895
None Run 12:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 93.33
   Final Test: 63.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3459745701402426
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 66.50
Split: 05, Run: 02
None time:  0.5552403449546546
None Run 14:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 65.90
Split: 05, Run: 03
None time:  0.7106504738330841
None Run 15:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8879036568105221
None Run 16:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 65.00
Split: 06, Run: 02
None time:  0.5521428908687085
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.00
Split: 06, Run: 03
None time:  0.5519450060091913
None Run 18:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 67.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6078439150005579
None Run 19:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 93.33
   Final Test: 54.50
Split: 07, Run: 02
None time:  0.6718896131496876
None Run 20:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 93.33
   Final Test: 55.60
Split: 07, Run: 03
None time:  0.5471743550151587
None Run 21:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 93.33
   Final Test: 55.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0063306111842394
None Run 22:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 80.00
   Final Test: 60.10
Split: 08, Run: 02
None time:  0.5640649339184165
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.40
Split: 08, Run: 03
None time:  0.5946335271000862
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 68.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.407509634969756
None Run 25:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 76.67
   Final Test: 58.00
Split: 09, Run: 02
None time:  0.5345257949084044
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.30
Split: 09, Run: 03
None time:  0.607420943910256
None Run 27:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 67.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9798067910596728
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 80.00
   Final Test: 64.10
Split: 10, Run: 02
None time:  0.5231501371599734
None Run 29:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.10
Split: 10, Run: 03
None time:  0.5875049300957471
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.136669397354126
total time:  23.176629496971145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.24 ± 7.89
  Final Train: 90.22 ± 10.61
   Final Test: 63.41 ± 6.44
best run test_acc: 65.81999969482422
[I 2023-06-11 23:41:27,230] Trial 45 finished with value: 64.23999786376953 and parameters: {'Fwd': 0.0115165753389958, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 0.03782816668593192, 'loop': 1, 'loss': 'CE', 'lr': 0.0006631553940861701, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.0574526265360046e-05, 'weightedloss': False}. Best is trial 43 with value: 65.05998992919922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0007195758359698294
weight_decay:  7.18301384741991e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.314318309072405
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 76.67
   Final Test: 62.80
Split: 01, Run: 02
None time:  0.70694071194157
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 76.67
   Final Test: 60.50
Split: 01, Run: 03
None time:  0.8622533259913325
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 73.33
   Final Test: 61.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0028918508905917
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 80.00
   Final Test: 68.40
Split: 02, Run: 02
None time:  0.5327781999949366
None Run 05:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 70.00
Split: 02, Run: 03
None time:  0.5194054858293384
None Run 06:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 70.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2050292629282922
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 86.67
   Final Test: 63.40
Split: 03, Run: 02
None time:  0.5815527699887753
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  0.5715044341050088
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9435800120700151
None Run 10:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 90.00
   Final Test: 54.60
Split: 04, Run: 02
None time:  0.5302317959722131
None Run 11:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 65.70
Split: 04, Run: 03
None time:  0.5874860240146518
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 65.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.210787477903068
None Run 13:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 93.33
   Final Test: 68.30
Split: 05, Run: 02
None time:  0.8128954761195928
None Run 14:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 96.67
   Final Test: 69.20
Split: 05, Run: 03
None time:  0.7771932280156761
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 68.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6488852568436414
None Run 16:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 63.20
Split: 06, Run: 02
None time:  0.5559607848990709
None Run 17:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 67.10
Split: 06, Run: 03
None time:  0.5508826908189803
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0598443548660725
None Run 19:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 90.00
   Final Test: 57.00
Split: 07, Run: 02
None time:  0.547170412959531
None Run 20:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 96.67
   Final Test: 56.60
Split: 07, Run: 03
None time:  0.5537341530434787
None Run 21:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 96.67
   Final Test: 56.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.593589851167053
None Run 22:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.50
Split: 08, Run: 02
None time:  0.5620701038278639
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.70
Split: 08, Run: 03
None time:  0.50528490007855
None Run 24:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 66.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2153495240490884
None Run 25:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 76.67
   Final Test: 64.90
Split: 09, Run: 02
None time:  0.5963064490351826
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.20
Split: 09, Run: 03
None time:  0.5184205519035459
None Run 27:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1511618439108133
None Run 28:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 83.33
   Final Test: 67.80
Split: 10, Run: 02
None time:  0.49133251304738224
None Run 29:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 10, Run: 03
None time:  0.43463815189898014
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.1189680099487305
total time:  23.240627912804484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.07 ± 5.58
  Final Train: 92.56 ± 8.24
   Final Test: 64.93 ± 4.46
best run test_acc: 66.23999786376953
[I 2023-06-11 23:41:50,986] Trial 46 finished with value: 66.06666564941406 and parameters: {'Fwd': 0.026509709812701857, 'K': 9, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 0.3671550935657433, 'loop': 1, 'loss': 'CE', 'lr': 0.0007195758359698294, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.18301384741991e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.0006353035165827965
weight_decay:  2.1064512890813218e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8009922460187227
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 93.33
   Final Test: 60.70
Split: 01, Run: 02
None time:  1.0550147390458733
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 83.33
   Final Test: 66.00
Split: 01, Run: 03
None time:  0.7481065909378231
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 86.67
   Final Test: 65.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0311818059999496
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 86.67
   Final Test: 68.70
Split: 02, Run: 02
None time:  0.463228696025908
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.30
Split: 02, Run: 03
None time:  0.5750727569684386
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.8937056851573288
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 90.00
   Final Test: 62.40
Split: 03, Run: 02
None time:  0.5318702349904925
None Run 08:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  0.578050514915958
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5170194290112704
None Run 10:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 41.50
Split: 04, Run: 02
None time:  0.5615555411204696
None Run 11:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 96.67
   Final Test: 61.10
Split: 04, Run: 03
None time:  0.5241225589998066
None Run 12:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 64.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6368004321120679
None Run 13:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 93.33
   Final Test: 50.20
Split: 05, Run: 02
None time:  0.4954636699985713
None Run 14:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 61.90
Split: 05, Run: 03
None time:  0.49705558409914374
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5886210829485208
None Run 16:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 55.20
Split: 06, Run: 02
None time:  0.6348513457924128
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 65.00
Split: 06, Run: 03
None time:  0.5810428007971495
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0172429019585252
None Run 19:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 86.67
   Final Test: 56.80
Split: 07, Run: 02
None time:  0.4739819539245218
None Run 20:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 96.67
   Final Test: 59.50
Split: 07, Run: 03
None time:  0.4828158230520785
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 96.67
   Final Test: 59.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6560331559740007
None Run 22:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 86.67
   Final Test: 58.60
Split: 08, Run: 02
None time:  0.6416479300241917
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 67.20
Split: 08, Run: 03
None time:  0.5604716169182211
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 93.33
   Final Test: 68.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3558937842026353
None Run 25:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 76.67
   Final Test: 62.10
Split: 09, Run: 02
None time:  0.5314781530760229
None Run 26:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 68.00
Split: 09, Run: 03
None time:  0.5541594631504267
None Run 27:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 67.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1469733531121165
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 80.00
   Final Test: 66.00
Split: 10, Run: 02
None time:  0.5011816369369626
None Run 29:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 69.20
Split: 10, Run: 03
None time:  0.5629189659375697
None Run 30:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 69.60
run time now: 2.252350091934204
total time:  21.264024722855538
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.81 ± 7.50
  Final Train: 93.44 ± 6.34
   Final Test: 63.20 ± 6.28
best run test_acc: 66.15000915527344
[I 2023-06-11 23:42:12,695] Trial 47 finished with value: 63.80666732788086 and parameters: {'Fwd': 0.03068894750373876, 'K': 9, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 0.23523621993497879, 'loop': 1, 'loss': 'CE', 'lr': 0.0006353035165827965, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.1064512890813218e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0006773436469266546
weight_decay:  1.9532405348847558e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1691278009675443
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 80.00
   Final Test: 61.90
Split: 01, Run: 02
None time:  0.8630183020140976
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 76.67
   Final Test: 61.10
Split: 01, Run: 03
None time:  0.8158152480609715
None Run 03:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 70.00
   Final Test: 59.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0237165680155158
None Run 04:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 76.67
   Final Test: 68.70
Split: 02, Run: 02
None time:  0.5800967370159924
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.00
Split: 02, Run: 03
None time:  0.6174147089477628
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7699711199384183
None Run 07:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 90.00
   Final Test: 61.60
Split: 03, Run: 02
None time:  0.5824758769012988
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.00
Split: 03, Run: 03
None time:  0.5258195840287954
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0289753009565175
None Run 10:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 93.33
   Final Test: 60.70
Split: 04, Run: 02
None time:  0.6832895069383085
None Run 11:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 66.30
Split: 04, Run: 03
None time:  0.5927104509901255
None Run 12:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.7287080299574882
None Run 13:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 65.40
Split: 05, Run: 02
None time:  0.9614801809657365
None Run 14:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 65.80
Split: 05, Run: 03
None time:  0.7236720719374716
None Run 15:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 65.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0317593978252262
None Run 16:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 73.33
   Final Test: 62.80
Split: 06, Run: 02
None time:  0.6184515729546547
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.90
Split: 06, Run: 03
None time:  0.6410302731674165
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 67.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0376967331394553
None Run 19:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 63.33
   Final Test: 59.30
Split: 07, Run: 02
None time:  0.6429268019273877
None Run 20:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 70.00
   Final Test: 59.40
Split: 07, Run: 03
None time:  0.5594457911793143
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 70.00
   Final Test: 60.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6841053450480103
None Run 22:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 60.30
Split: 08, Run: 02
None time:  0.6326879179105163
None Run 23:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 96.67
   Final Test: 68.00
Split: 08, Run: 03
None time:  0.6996740738395602
None Run 24:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 96.67
   Final Test: 68.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1651720572263002
None Run 25:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 80.00
   Final Test: 58.20
Split: 09, Run: 02
None time:  0.5456843699794263
None Run 26:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 67.80
Split: 09, Run: 03
None time:  0.5490339889656752
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.132748271105811
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 80.00
   Final Test: 67.50
Split: 10, Run: 02
None time:  0.6575047648511827
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 70.10
Split: 10, Run: 03
None time:  0.564613243099302
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 70.00
run time now: 2.401686191558838
total time:  24.89616375300102
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.70 ± 4.30
  Final Train: 88.67 ± 11.16
   Final Test: 64.97 ± 3.82
best run test_acc: 66.45000457763672
[I 2023-06-11 23:42:38,119] Trial 48 finished with value: 65.69999694824219 and parameters: {'Fwd': 0.03594849076807968, 'K': 9, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 0.19133177729723597, 'loop': 2, 'loss': 'CE', 'lr': 0.0006773436469266546, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.9532405348847558e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0007654794077594463
weight_decay:  2.829317351129164e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9395302080083638
None Run 01:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 93.33
   Final Test: 58.90
Split: 01, Run: 02
None time:  0.7806812978815287
None Run 02:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 96.67
   Final Test: 59.50
Split: 01, Run: 03
None time:  0.8400030210614204
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 96.67
   Final Test: 60.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9727924370672554
None Run 04:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 93.33
   Final Test: 66.00
Split: 02, Run: 02
None time:  0.7633731849491596
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.60
Split: 02, Run: 03
None time:  0.6892849588766694
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 68.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9959415621124208
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 65.80
Split: 03, Run: 02
None time:  0.7630216309335083
None Run 08:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.00
Split: 03, Run: 03
None time:  0.7070552969817072
None Run 09:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 65.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9801386541221291
None Run 10:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 96.67
   Final Test: 61.50
Split: 04, Run: 02
None time:  0.7355650381650776
None Run 11:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 65.10
Split: 04, Run: 03
None time:  0.7671567359939218
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 65.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.054767329012975
None Run 13:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 64.80
Split: 05, Run: 02
None time:  0.6986506499815732
None Run 14:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 63.40
Split: 05, Run: 03
None time:  0.7101551950909197
None Run 15:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9453387588728219
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 64.00
Split: 06, Run: 02
None time:  0.7418711648788303
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.10
Split: 06, Run: 03
None time:  0.6906432528048754
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 66.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.734278904972598
None Run 19:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 56.67
   Final Test: 56.60
Split: 07, Run: 02
None time:  0.7459105639718473
None Run 20:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 76.67
   Final Test: 58.60
Split: 07, Run: 03
None time:  0.6935922210104764
None Run 21:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 76.67
   Final Test: 58.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.132497062208131
None Run 22:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 73.33
   Final Test: 52.60
Split: 08, Run: 02
None time:  0.727615806972608
None Run 23:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 64.00
Split: 08, Run: 03
None time:  0.6783769191242754
None Run 24:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 90.00
   Final Test: 63.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0620811441913247
None Run 25:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 90.00
   Final Test: 59.70
Split: 09, Run: 02
None time:  0.704059740062803
None Run 26:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.70
Split: 09, Run: 03
None time:  0.6438099639490247
None Run 27:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 61.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.916148834163323
None Run 28:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 68.00
Split: 10, Run: 02
None time:  0.684492798987776
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.90
Split: 10, Run: 03
None time:  0.7271502460353076
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.90
run time now: 2.3703908920288086
total time:  26.330109753180295
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.35 ± 4.08
  Final Train: 93.00 ± 9.84
   Final Test: 63.38 ± 3.95
best run test_acc: 64.59999084472656
[I 2023-06-11 23:43:04,880] Trial 49 finished with value: 63.34666442871094 and parameters: {'Fwd': 0.07263012874136196, 'K': 9, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 0.17645283450177374, 'loop': 2, 'loss': 'CE', 'lr': 0.0007654794077594463, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.829317351129164e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.000297698230892315
weight_decay:  0.00010420065030096741
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1953888349235058
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 80.00
   Final Test: 61.40
Split: 01, Run: 02
None time:  0.7735164661426097
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.50
Split: 01, Run: 03
None time:  0.7701823678798974
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.240238412981853
None Run 04:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 69.20
Split: 02, Run: 02
None time:  0.7188157509081066
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.40
Split: 02, Run: 03
None time:  0.7966878560837358
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3000129559077322
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 62.60
Split: 03, Run: 02
None time:  0.7830208661034703
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.20
Split: 03, Run: 03
None time:  0.7185780990403146
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2931628779042512
None Run 10:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 90.00
   Final Test: 54.30
Split: 04, Run: 02
None time:  0.8146342060063034
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 65.20
Split: 04, Run: 03
None time:  0.7319394152145833
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 65.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5212746981997043
None Run 13:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 63.30
Split: 05, Run: 02
None time:  0.9641424650326371
None Run 14:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 62.00
Split: 05, Run: 03
None time:  0.9444721348118037
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 61.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0802031909115613
None Run 16:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 64.70
Split: 06, Run: 02
None time:  0.7239458260592073
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 03
None time:  0.7392382379621267
None Run 18:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3279242140706629
None Run 19:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 86.67
   Final Test: 58.00
Split: 07, Run: 02
None time:  0.7540586481336504
None Run 20:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 96.67
   Final Test: 58.70
Split: 07, Run: 03
None time:  0.7926810279022902
None Run 21:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 96.67
   Final Test: 58.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1782166538760066
None Run 22:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 83.33
   Final Test: 65.30
Split: 08, Run: 02
None time:  0.8075526829343289
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 90.00
   Final Test: 68.80
Split: 08, Run: 03
None time:  0.738739478867501
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 67.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8851299490779638
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 83.33
   Final Test: 63.00
Split: 09, Run: 02
None time:  0.7359066780190915
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 67.60
Split: 09, Run: 03
None time:  0.8506269748322666
None Run 27:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 67.20
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0700498400256038
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 66.20
Split: 10, Run: 02
None time:  0.7866465910337865
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  0.7372431578114629
None Run 30:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.6375045776367188
total time:  29.847934407182038
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.06 ± 4.31
  Final Train: 94.44 ± 5.70
   Final Test: 64.50 ± 3.86
best run test_acc: 65.66999816894531
[I 2023-06-11 23:43:35,294] Trial 50 finished with value: 65.06000518798828 and parameters: {'Fwd': 0.027360186947021012, 'K': 9, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 0.5761491959870806, 'loop': 2, 'loss': 'CE', 'lr': 0.000297698230892315, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00010420065030096741, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.0002959274788325238
weight_decay:  9.853082706775816e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9018227730412036
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 73.33
   Final Test: 62.90
Split: 01, Run: 02
None time:  1.209668091032654
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 76.67
   Final Test: 61.60
Split: 01, Run: 03
None time:  0.8266500229947269
None Run 03:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 62.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2849581809714437
None Run 04:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.60
Split: 02, Run: 02
None time:  0.8098719739355147
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.10
Split: 02, Run: 03
None time:  0.8450541449710727
None Run 06:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0670683030039072
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.10
Split: 03, Run: 02
None time:  0.8411034720484167
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.70
Split: 03, Run: 03
None time:  0.8167462879791856
None Run 09:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4683919828385115
None Run 10:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 63.10
Split: 04, Run: 02
None time:  0.8949842231813818
None Run 11:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 66.00
Split: 04, Run: 03
None time:  0.8576720799319446
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 66.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1702414320316166
None Run 13:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 63.30
Split: 05, Run: 02
None time:  0.9896230900194496
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.10
Split: 05, Run: 03
None time:  0.9263513190671802
None Run 15:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2378762180451304
None Run 16:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 86.67
   Final Test: 65.40
Split: 06, Run: 02
None time:  0.911433950997889
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.40
Split: 06, Run: 03
None time:  0.8545916879083961
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.1956784350331873
None Run 19:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 70.00
   Final Test: 58.70
Split: 07, Run: 02
None time:  0.8802818390540779
None Run 20:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 83.33
   Final Test: 59.30
Split: 07, Run: 03
None time:  0.9024424920789897
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 83.33
   Final Test: 59.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3328524630051106
None Run 22:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 83.33
   Final Test: 66.30
Split: 08, Run: 02
None time:  0.9362548771314323
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 90.00
   Final Test: 69.00
Split: 08, Run: 03
None time:  0.9707578720990568
None Run 24:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 68.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7580335289239883
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 86.67
   Final Test: 65.70
Split: 09, Run: 02
None time:  0.8944784631021321
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.30
Split: 09, Run: 03
None time:  0.9240394188091159
None Run 27:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1590535619761795
None Run 28:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 66.30
Split: 10, Run: 02
None time:  0.8469273899681866
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  0.819523355923593
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.8700921535491943
total time:  33.6325037679635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.51 ± 3.36
  Final Train: 92.89 ± 8.56
   Final Test: 65.00 ± 3.05
best run test_acc: 65.80999755859375
[I 2023-06-11 23:44:09,445] Trial 51 finished with value: 65.51333618164062 and parameters: {'Fwd': 0.02997652532485934, 'K': 9, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 0.5647342806780926, 'loop': 2, 'loss': 'CE', 'lr': 0.0002959274788325238, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.853082706775816e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.00028965156542525033
weight_decay:  0.00011894461479019863
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7501032680738717
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 76.67
   Final Test: 61.80
Split: 01, Run: 02
None time:  1.0609703022055328
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 76.67
   Final Test: 61.90
Split: 01, Run: 03
None time:  0.99102648999542
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 76.67
   Final Test: 61.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1430585561320186
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 86.67
   Final Test: 68.20
Split: 02, Run: 02
None time:  0.8243950658943504
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 02, Run: 03
None time:  0.7931572620291263
None Run 06:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2873354339972138
None Run 07:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 90.00
   Final Test: 61.70
Split: 03, Run: 02
None time:  0.795496417907998
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.00
Split: 03, Run: 03
None time:  0.7296219209674746
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3428373869974166
None Run 10:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 93.33
   Final Test: 63.00
Split: 04, Run: 02
None time:  0.7664602871518582
None Run 11:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 66.50
Split: 04, Run: 03
None time:  0.7970464217942208
None Run 12:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9945288028102368
None Run 13:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.70
Split: 05, Run: 02
None time:  1.057694060029462
None Run 14:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 63.10
Split: 05, Run: 03
None time:  0.7208282200153917
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9591403030790389
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 63.50
Split: 06, Run: 02
None time:  0.728637726046145
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.10
Split: 06, Run: 03
None time:  0.7795145700220019
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.85492396610789
None Run 19:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 70.00
   Final Test: 58.00
Split: 07, Run: 02
None time:  0.8516925079748034
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 83.33
   Final Test: 58.60
Split: 07, Run: 03
None time:  0.8292184569872916
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 86.67
   Final Test: 59.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2078583110123873
None Run 22:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 86.67
   Final Test: 61.90
Split: 08, Run: 02
None time:  0.809982379199937
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 67.00
Split: 08, Run: 03
None time:  0.7698254850693047
None Run 24:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 67.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4659821540117264
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 90.00
   Final Test: 64.10
Split: 09, Run: 02
None time:  0.7681969969999045
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 67.00
Split: 09, Run: 03
None time:  0.848520286846906
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.405007743043825
None Run 28:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 86.67
   Final Test: 64.70
Split: 10, Run: 02
None time:  0.7424542140215635
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.60
Split: 10, Run: 03
None time:  0.709844569908455
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.40
run time now: 2.8979103565216064
total time:  30.837895658100024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.29 ± 3.29
  Final Train: 92.00 ± 8.47
   Final Test: 64.47 ± 3.11
best run test_acc: 65.62000274658203
[I 2023-06-11 23:44:40,738] Trial 52 finished with value: 65.2933349609375 and parameters: {'Fwd': 0.028208253800231665, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 0.5477869096627019, 'loop': 2, 'loss': 'CE', 'lr': 0.00028965156542525033, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00011894461479019863, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0002715382499311353
weight_decay:  0.0001106035071351385
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8152293290477246
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 73.33
   Final Test: 62.60
Split: 01, Run: 02
None time:  1.1015404108911753
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 76.67
   Final Test: 63.30
Split: 01, Run: 03
None time:  1.0808533111121505
None Run 03:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 73.33
   Final Test: 62.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0420146039687097
None Run 04:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 02, Run: 02
None time:  0.8078319109044969
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 03
None time:  0.8836257960647345
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1879686589818448
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 61.60
Split: 03, Run: 02
None time:  0.8158881608396769
None Run 08:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.70
Split: 03, Run: 03
None time:  0.9870005319826305
None Run 09:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5815499438904226
None Run 10:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 90.00
   Final Test: 61.20
Split: 04, Run: 02
None time:  0.8955226538237184
None Run 11:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 65.80
Split: 04, Run: 03
None time:  0.9304763930849731
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4231624589301646
None Run 13:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 63.80
Split: 05, Run: 02
None time:  0.8405375489965081
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.70
Split: 05, Run: 03
None time:  0.885697873076424
None Run 15:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.255587129155174
None Run 16:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 65.70
Split: 06, Run: 02
None time:  0.8622375871054828
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.90
Split: 06, Run: 03
None time:  0.9229646569583565
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4691849830560386
None Run 19:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 86.67
   Final Test: 58.10
Split: 07, Run: 02
None time:  0.8977829487994313
None Run 20:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 58.90
Split: 07, Run: 03
None time:  0.8972530867904425
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 96.67
   Final Test: 59.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.095144314924255
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 83.33
   Final Test: 64.70
Split: 08, Run: 02
None time:  0.8618886598851532
None Run 23:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 93.33
   Final Test: 68.70
Split: 08, Run: 03
None time:  0.862685423810035
None Run 24:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 68.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.844996744999662
None Run 25:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 76.67
   Final Test: 63.30
Split: 09, Run: 02
None time:  0.8872413521166891
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.10
Split: 09, Run: 03
None time:  0.8799067749641836
None Run 27:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 66.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.584330830955878
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 83.33
   Final Test: 67.60
Split: 10, Run: 02
None time:  0.8911673289258033
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 68.30
Split: 10, Run: 03
None time:  0.8943885751068592
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 68.50
run time now: 3.414030075073242
total time:  33.485510224010795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.31 ± 4.12
  Final Train: 92.44 ± 8.35
   Final Test: 64.84 ± 3.39
best run test_acc: 65.71000671386719
[I 2023-06-11 23:45:14,699] Trial 53 finished with value: 65.3066635131836 and parameters: {'Fwd': 0.022585689568965586, 'K': 10, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 0.5193285994856913, 'loop': 2, 'loss': 'CE', 'lr': 0.0002715382499311353, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0001106035071351385, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00026163836089321285
weight_decay:  0.00010582796079239706
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.928828134201467
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 73.33
   Final Test: 62.60
Split: 01, Run: 02
None time:  1.0699401749297976
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 76.67
   Final Test: 62.30
Split: 01, Run: 03
None time:  1.0034246589057148
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 80.00
   Final Test: 61.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3437754220794886
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.10
Split: 02, Run: 02
None time:  0.90270318207331
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 03
None time:  0.9410749769303948
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1982101020403206
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 62.60
Split: 03, Run: 02
None time:  1.0413725981488824
None Run 08:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 03
None time:  0.8740403291303664
None Run 09:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3084600649308413
None Run 10:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 90.00
   Final Test: 55.70
Split: 04, Run: 02
None time:  0.8740537080448121
None Run 11:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 96.67
   Final Test: 64.10
Split: 04, Run: 03
None time:  0.8829677088651806
None Run 12:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 63.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.664333577034995
None Run 13:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 61.30
Split: 05, Run: 02
None time:  0.8536762951407582
None Run 14:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.60
Split: 05, Run: 03
None time:  1.1190987250301987
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 60.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1522456009406596
None Run 16:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 66.20
Split: 06, Run: 02
None time:  0.9327499580103904
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.00
Split: 06, Run: 03
None time:  0.8409727530088276
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: -4993.9482, Train: 63.33%, Valid: 55.80% Test: 59.10%
Split: 07, Run: 01
None time:  2.3772408000659198
None Run 19:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 73.33
   Final Test: 58.80
Split: 07, Run: 02
None time:  0.8833440078888088
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 83.33
   Final Test: 59.70
Split: 07, Run: 03
None time:  0.8347745551727712
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 83.33
   Final Test: 59.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3253990220837295
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 83.33
   Final Test: 64.60
Split: 08, Run: 02
None time:  0.8951762679498643
None Run 23:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 90.00
   Final Test: 67.90
Split: 08, Run: 03
None time:  0.9223609599284828
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8239910330157727
None Run 25:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 63.50
Split: 09, Run: 02
None time:  0.9170698008965701
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.20
Split: 09, Run: 03
None time:  0.9212515770923346
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4663194678723812
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 90.00
   Final Test: 66.90
Split: 10, Run: 02
None time:  0.8286684460472316
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.80
Split: 10, Run: 03
None time:  0.7871022040490061
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.124981641769409
total time:  34.994877805002034
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.97 ± 4.25
  Final Train: 92.00 ± 8.24
   Final Test: 64.34 ± 3.66
best run test_acc: 65.33000183105469
[I 2023-06-11 23:45:50,147] Trial 54 finished with value: 64.97333526611328 and parameters: {'Fwd': 0.02565740430334452, 'K': 10, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 0.45067070966792244, 'loop': 2, 'loss': 'CE', 'lr': 0.00026163836089321285, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00010582796079239706, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.0002223817189724903
weight_decay:  0.00017489127111932866
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7962966039776802
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 70.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  0.9450201860163361
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 76.67
   Final Test: 59.10
Split: 01, Run: 03
None time:  0.9353458730038255
None Run 03:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 76.67
   Final Test: 59.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.406639622990042
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 67.10
Split: 02, Run: 02
None time:  0.7763040049467236
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 03
None time:  0.7266234899871051
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.33499377197586
None Run 07:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 60.20
Split: 03, Run: 02
None time:  0.8088314330670983
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.30
Split: 03, Run: 03
None time:  0.7771518209483474
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.462371040135622
None Run 10:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 96.67
   Final Test: 60.90
Split: 04, Run: 02
None time:  0.8407076229341328
None Run 11:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 62.20
Split: 04, Run: 03
None time:  0.8039235000032932
None Run 12:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 96.67
   Final Test: 61.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3270845210645348
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.20
Split: 05, Run: 02
None time:  0.8446034688968211
None Run 14:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.30
Split: 05, Run: 03
None time:  0.9250711610075086
None Run 15:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 59.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4202474160119891
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 86.67
   Final Test: 64.80
Split: 06, Run: 02
None time:  0.8407057011500001
None Run 17:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 65.10
Split: 06, Run: 03
None time:  0.8061689641326666
None Run 18:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1359244438353926
None Run 19:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 93.33
   Final Test: 51.00
Split: 07, Run: 02
None time:  1.0133673041127622
None Run 20:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 86.67
   Final Test: 53.50
Split: 07, Run: 03
None time:  1.0107902239542454
None Run 21:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 86.67
   Final Test: 55.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.414124981034547
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 86.67
   Final Test: 63.30
Split: 08, Run: 02
None time:  0.8215477399062365
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 66.40
Split: 08, Run: 03
None time:  0.8379448759369552
None Run 24:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8485267970245332
None Run 25:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 86.67
   Final Test: 62.60
Split: 09, Run: 02
None time:  0.7906120719853789
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 63.80
Split: 09, Run: 03
None time:  0.8175368260126561
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 64.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.5244748359546065
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 67.30
Split: 10, Run: 02
None time:  0.7991625550203025
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 68.30
Split: 10, Run: 03
None time:  0.8791643162257969
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 68.30
run time now: 3.244138717651367
total time:  32.73282267409377
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.77 ± 5.29
  Final Train: 92.44 ± 7.63
   Final Test: 62.85 ± 4.59
best run test_acc: 63.970008850097656
[I 2023-06-11 23:46:23,319] Trial 55 finished with value: 63.773338317871094 and parameters: {'Fwd': 0.04335565887965782, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 0.5786995277153564, 'loop': 2, 'loss': 'CE', 'lr': 0.0002223817189724903, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00017489127111932866, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0003086949949879739
weight_decay:  0.00023450687672471496
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.784580604871735
None Run 01:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 60.00
Split: 01, Run: 02
None time:  0.7396547999233007
None Run 02:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  0.8358928798697889
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 59.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2180389510467649
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 02, Run: 02
None time:  0.7442634920589626
None Run 05:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 03
None time:  0.8543803070206195
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.410930034937337
None Run 07:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.70
Split: 03, Run: 02
None time:  0.7914468320086598
None Run 08:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.10
Split: 03, Run: 03
None time:  0.8003651138860732
None Run 09:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.400735504925251
None Run 10:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 96.67
   Final Test: 56.20
Split: 04, Run: 02
None time:  0.7796336661558598
None Run 11:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 63.40
Split: 04, Run: 03
None time:  0.7492846539244056
None Run 12:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 62.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1796648169402033
None Run 13:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.50
Split: 05, Run: 02
None time:  0.9815820450894535
None Run 14:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.40
Split: 05, Run: 03
None time:  0.7337293778546154
None Run 15:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0894181730691344
None Run 16:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 64.00
Split: 06, Run: 02
None time:  0.6577636380679905
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.20
Split: 06, Run: 03
None time:  0.7652431079186499
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7791606849059463
None Run 19:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 93.33
   Final Test: 58.60
Split: 07, Run: 02
None time:  0.9317629630677402
None Run 20:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 96.67
   Final Test: 59.10
Split: 07, Run: 03
None time:  0.9706509381067008
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 93.33
   Final Test: 59.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.441842650063336
None Run 22:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.00
Split: 08, Run: 02
None time:  0.7351555330678821
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.10
Split: 08, Run: 03
None time:  0.8228809530846775
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2389443591237068
None Run 25:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.40
Split: 09, Run: 02
None time:  0.9006743840873241
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 65.30
Split: 09, Run: 03
None time:  0.8335287601221353
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2216697398107499
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 10, Run: 02
None time:  0.9886343108955771
None Run 29:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.20
Split: 10, Run: 03
None time:  0.8478196321520954
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.50
run time now: 3.1000583171844482
total time:  31.291351216845214
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.40 ± 4.11
  Final Train: 98.78 ± 2.05
   Final Test: 64.31 ± 3.71
best run test_acc: 65.29000091552734
[I 2023-06-11 23:46:55,153] Trial 56 finished with value: 65.4000015258789 and parameters: {'Fwd': 0.09788039528952504, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 1.2729478825171823, 'loop': 2, 'loss': 'CE', 'lr': 0.0003086949949879739, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00023450687672471496, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.00041460655125142583
weight_decay:  0.00019131027957358323
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6298948649782687
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 96.67
   Final Test: 60.60
Split: 01, Run: 02
None time:  0.887590877013281
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 66.50
Split: 01, Run: 03
None time:  0.7875311558600515
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5170298751909286
None Run 04:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
Split: 02, Run: 02
None time:  0.8396620380226523
None Run 05:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 02, Run: 03
None time:  0.9943476230837405
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.39777547493577
None Run 07:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.10
Split: 03, Run: 02
None time:  0.8949230280704796
None Run 08:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.10
Split: 03, Run: 03
None time:  0.8803562810644507
None Run 09:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4343075470533222
None Run 10:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 96.67
   Final Test: 57.90
Split: 04, Run: 02
None time:  0.8523393301293254
None Run 11:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 64.10
Split: 04, Run: 03
None time:  0.8361526918597519
None Run 12:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 62.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8025045639369637
None Run 13:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.80
Split: 05, Run: 02
None time:  1.0125137909781188
None Run 14:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.60
Split: 05, Run: 03
None time:  0.8970954930409789
None Run 15:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8939134711399674
None Run 16:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 02
None time:  0.997524922946468
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.20
Split: 06, Run: 03
None time:  0.8905778550542891
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0481738690286875
None Run 19:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 83.33
   Final Test: 59.00
Split: 07, Run: 02
None time:  0.887046042829752
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 96.67
   Final Test: 58.50
Split: 07, Run: 03
None time:  0.9533934639766812
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 90.00
   Final Test: 58.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4451049477793276
None Run 22:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.10
Split: 08, Run: 02
None time:  0.8258974270429462
None Run 23:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.00
Split: 08, Run: 03
None time:  0.7486958110239357
None Run 24:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.28846721095033
None Run 25:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.70
Split: 09, Run: 02
None time:  1.0465033969376236
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.70
Split: 09, Run: 03
None time:  1.0170511030592024
None Run 27:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 65.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.5893735259305686
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.90
Split: 10, Run: 02
None time:  0.7558838140685111
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.50
Split: 10, Run: 03
None time:  0.7963233438786119
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.50
run time now: 3.1850874423980713
total time:  32.943833503872156
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.09 ± 5.72
  Final Train: 98.56 ± 3.58
   Final Test: 64.21 ± 5.58
best run test_acc: 66.61000061035156
[I 2023-06-11 23:47:28,658] Trial 57 finished with value: 65.08666229248047 and parameters: {'Fwd': 0.09344804071850682, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.15000000000000002, 'lambda2': 1.2196521241405625, 'loop': 2, 'loss': 'CE', 'lr': 0.00041460655125142583, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00019131027957358323, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0003356880514122889
weight_decay:  0.0002333908979468593
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9546146199572831
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 93.33
   Final Test: 59.90
Split: 01, Run: 02
None time:  0.8389639060478657
None Run 02:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 58.90
Split: 01, Run: 03
None time:  0.8179708339739591
None Run 03:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3052268619649112
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.30
Split: 02, Run: 02
None time:  0.7784312691073865
None Run 05:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.80
Split: 02, Run: 03
None time:  0.7841175210196525
None Run 06:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2195446740370244
None Run 07:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 93.33
   Final Test: 61.40
Split: 03, Run: 02
None time:  0.7652386480476707
None Run 08:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 03
None time:  0.8023795140907168
None Run 09:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 63.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9208163160365075
None Run 10:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 96.67
   Final Test: 57.30
Split: 04, Run: 02
None time:  0.7857181380968541
None Run 11:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 62.70
Split: 04, Run: 03
None time:  0.8491862439550459
None Run 12:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 96.67
   Final Test: 63.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0541086599696428
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 02
None time:  0.9148886499460787
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.90
Split: 05, Run: 03
None time:  0.9995949808508158
None Run 15:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 62.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2878443649969995
None Run 16:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 65.90
Split: 06, Run: 02
None time:  0.8247373080812395
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 64.80
Split: 06, Run: 03
None time:  0.794099162099883
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 64.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7699643829837441
None Run 19:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 80.00
   Final Test: 59.30
Split: 07, Run: 02
None time:  0.7897829979192466
None Run 20:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 90.00
   Final Test: 59.40
Split: 07, Run: 03
None time:  0.772610830841586
None Run 21:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 96.67
   Final Test: 59.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9800986351910979
None Run 22:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 65.80
Split: 08, Run: 02
None time:  0.8702948531135917
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 65.40
Split: 08, Run: 03
None time:  0.8351373979821801
None Run 24:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 64.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3742996009532362
None Run 25:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 90.00
   Final Test: 60.80
Split: 09, Run: 02
None time:  0.740072889951989
None Run 26:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.40
Split: 09, Run: 03
None time:  0.7975038189906627
None Run 27:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2837311350740492
None Run 28:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 90.00
   Final Test: 65.60
Split: 10, Run: 02
None time:  0.8509904928505421
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.30
Split: 10, Run: 03
None time:  0.9152991129085422
None Run 30:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.80
run time now: 3.093402862548828
total time:  29.76719822594896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.61 ± 4.23
  Final Train: 96.33 ± 4.58
   Final Test: 63.08 ± 3.17
best run test_acc: 64.19000244140625
[I 2023-06-11 23:47:58,916] Trial 58 finished with value: 63.61333465576172 and parameters: {'Fwd': 0.045278565611076904, 'K': 10, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 0.029354044033193638, 'loop': 2, 'loss': 'CE', 'lr': 0.0003356880514122889, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0002333908979468593, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.0001991893162412833
weight_decay:  0.0003252443528230966
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3483186739031225
None Run 01:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 38.40
Split: 01, Run: 02
None time:  1.4172070329077542
None Run 02:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 38.40
Split: 01, Run: 03
None time:  1.3595260579604656
None Run 03:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 38.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8731910160277039
None Run 04:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 42.30
Split: 02, Run: 02
None time:  0.8692912540864199
None Run 05:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 42.30
Split: 02, Run: 03
None time:  0.8960079289972782
None Run 06:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 42.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7007213758770376
None Run 07:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 41.60
Split: 03, Run: 02
None time:  0.7374413029756397
None Run 08:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 41.60
Split: 03, Run: 03
None time:  0.7744033639319241
None Run 09:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 41.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.7753022690303624
None Run 10:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 40.50
Split: 04, Run: 02
None time:  0.7959734729956836
None Run 11:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 40.50
Split: 04, Run: 03
None time:  0.7617818801663816
None Run 12:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 40.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0957, Train: 100.00%, Valid: 44.80% Test: 44.10%
Split: 05, Run: 01
None time:  2.250385765917599
None Run 13:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 44.00
Split: 05, Run: 02, Epoch: 100, Loss: 0.0840, Train: 100.00%, Valid: 44.80% Test: 44.10%
Split: 05, Run: 02
None time:  2.1207068210933357
None Run 14:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 44.00
Split: 05, Run: 03, Epoch: 100, Loss: 0.0755, Train: 100.00%, Valid: 44.80% Test: 44.10%
Split: 05, Run: 03
None time:  2.2404072990175337
None Run 15:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 44.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7901466730982065
None Run 16:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 44.10
Split: 06, Run: 02
None time:  1.7233052880037576
None Run 17:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 44.10
Split: 06, Run: 03
None time:  1.833207206102088
None Run 18:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 44.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.1009, Train: 100.00%, Valid: 33.60% Test: 37.00%
Split: 07, Run: 01
None time:  2.105615426087752
None Run 19:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 37.00
Split: 07, Run: 02, Epoch: 100, Loss: 0.0903, Train: 100.00%, Valid: 33.60% Test: 37.00%
Split: 07, Run: 02
None time:  2.2908360899891704
None Run 20:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 37.00
Split: 07, Run: 03, Epoch: 100, Loss: 0.0892, Train: 100.00%, Valid: 33.60% Test: 37.00%
Split: 07, Run: 03
None time:  2.225804638117552
None Run 21:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 37.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8544374529737979
None Run 22:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 43.30
Split: 08, Run: 02
None time:  0.8299600821919739
None Run 23:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 43.30
Split: 08, Run: 03
None time:  0.8380753758829087
None Run 24:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 43.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8144623129628599
None Run 25:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 40.50
Split: 09, Run: 02
None time:  0.848797288024798
None Run 26:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 40.50
Split: 09, Run: 03
None time:  0.7889606938697398
None Run 27:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 40.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8666306671220809
None Run 28:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 37.20
Split: 10, Run: 02
None time:  0.822906413115561
None Run 29:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 37.20
Split: 10, Run: 03
None time:  0.7571122259832919
None Run 30:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 37.20
run time now: 2.4883220195770264
total time:  38.38279838999733
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.16 ± 4.06
  Final Train: 100.00 ± 0.00
   Final Test: 40.89 ± 2.56
best run test_acc: 40.88999938964844
[I 2023-06-11 23:48:37,809] Trial 59 finished with value: 41.15999984741211 and parameters: {'Fwd': 0.016660772752936853, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 1.5760290682190885, 'loop': 2, 'loss': 'CE', 'lr': 0.0001991893162412833, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0003252443528230966, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.00017874806635270556
weight_decay:  0.00011417592382748234
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8219064918812364
None Run 01:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 35.40
Split: 01, Run: 02
None time:  1.342621502932161
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 83.33
   Final Test: 60.80
Split: 01, Run: 03
None time:  1.0528313610702753
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 80.00
   Final Test: 59.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7191251469776034
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 86.67
   Final Test: 66.50
Split: 02, Run: 02
None time:  0.8391077728010714
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.20
Split: 02, Run: 03
None time:  0.8303536258172244
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5750335280317813
None Run 07:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 61.80
Split: 03, Run: 02
None time:  0.8666490910109133
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 03
None time:  0.8796756209339947
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8544649530667812
None Run 10:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 41.10
Split: 04, Run: 02
None time:  0.7973115409258753
None Run 11:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 54.60
Split: 04, Run: 03
None time:  0.8684567511081696
None Run 12:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 60.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4290060079656541
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 96.67
   Final Test: 60.80
Split: 05, Run: 02
None time:  0.8845638281200081
None Run 14:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 60.70
Split: 05, Run: 03
None time:  1.087149117141962
None Run 15:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 60.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3227189590688795
None Run 16:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 83.33
   Final Test: 59.00
Split: 06, Run: 02
None time:  0.9311639601364732
None Run 17:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 64.60
Split: 06, Run: 03
None time:  0.7937906999140978
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8880576379597187
None Run 19:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 76.67
   Final Test: 46.20
Split: 07, Run: 02
None time:  0.87527617206797
None Run 20:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 90.00
   Final Test: 48.60
Split: 07, Run: 03
None time:  0.8561437330208719
None Run 21:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 96.67
   Final Test: 49.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.95987748214975
None Run 22:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 50.30
Split: 08, Run: 02
None time:  0.9595258238259703
None Run 23:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 60.50
Split: 08, Run: 03
None time:  0.9252649710979313
None Run 24:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 63.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.89554298017174
None Run 25:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 80.00
   Final Test: 62.20
Split: 09, Run: 02
None time:  0.8759802570566535
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 64.30
Split: 09, Run: 03
None time:  0.8083542790263891
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 64.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.7247885579708964
None Run 28:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 86.67
   Final Test: 65.10
Split: 10, Run: 02
None time:  0.8618404411245137
None Run 29:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 67.20
Split: 10, Run: 03
None time:  0.8535155560821295
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.488456964492798
total time:  33.47459201095626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.49 ± 8.96
  Final Train: 94.00 ± 7.24
   Final Test: 59.60 ± 8.34
best run test_acc: 62.709999084472656
[I 2023-06-11 23:49:11,722] Trial 60 finished with value: 60.48666763305664 and parameters: {'Fwd': 0.02033704429921616, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 0.4156095112931027, 'loop': 2, 'loss': 'CE', 'lr': 0.00017874806635270556, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00011417592382748234, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0004141334708019073
weight_decay:  0.0002356166927005117
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6562762181274593
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 02
None time:  0.9174708439968526
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 03
None time:  0.9354637959040701
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4449035620782524
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 02
None time:  0.8515413720160723
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.40
Split: 02, Run: 03
None time:  0.8284656768664718
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.387415668927133
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.50
Split: 03, Run: 02
None time:  0.8735085679218173
None Run 08:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.50
Split: 03, Run: 03
None time:  0.8784141091164201
None Run 09:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7195713289547712
None Run 10:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 55.30
Split: 04, Run: 02
None time:  0.8552369438111782
None Run 11:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 60.40
Split: 04, Run: 03
None time:  0.861815933836624
None Run 12:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 59.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7370022388640791
None Run 13:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.80
Split: 05, Run: 02
None time:  0.8393902459647506
None Run 14:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.20
Split: 05, Run: 03
None time:  1.0375664681196213
None Run 15:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9040819020010531
None Run 16:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.60
Split: 06, Run: 02
None time:  0.9650722912047058
None Run 17:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.80
Split: 06, Run: 03
None time:  0.8551997679751366
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.1048026620410383
None Run 19:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 96.67
   Final Test: 59.10
Split: 07, Run: 02
None time:  0.8729888501111418
None Run 20:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 58.60
Split: 07, Run: 03
None time:  0.9506734788883477
None Run 21:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 58.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.370607728837058
None Run 22:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 58.40
Split: 08, Run: 02
None time:  0.8066727749537677
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.00
Split: 08, Run: 03
None time:  0.9201464729849249
None Run 24:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3097409470938146
None Run 25:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.90
Split: 09, Run: 02
None time:  0.8290565719362348
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.50
Split: 09, Run: 03
None time:  0.8020926250610501
None Run 27:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1984271958936006
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.00
Split: 10, Run: 02
None time:  0.9241529870778322
None Run 29:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  0.8412359249778092
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 3.005394220352173
total time:  33.54228898789734
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.92 ± 5.06
  Final Train: 99.89 ± 0.61
   Final Test: 64.20 ± 3.99
best run test_acc: 65.65998840332031
[I 2023-06-11 23:49:45,771] Trial 61 finished with value: 64.91999816894531 and parameters: {'Fwd': 0.08190654195939272, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.05, 'lambda2': 1.1524664181826214, 'loop': 2, 'loss': 'CE', 'lr': 0.0004141334708019073, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0002356166927005117, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0002782886775757429
weight_decay:  9.663773489284657e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9858410831075162
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 86.67
   Final Test: 60.60
Split: 01, Run: 02
None time:  0.8856632851529866
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 90.00
   Final Test: 60.60
Split: 01, Run: 03
None time:  0.9423368300776929
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 86.67
   Final Test: 59.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3848760451655835
None Run 04:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.90
Split: 02, Run: 02
None time:  1.011490711942315
None Run 05:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.20
Split: 02, Run: 03
None time:  0.7705495408736169
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.334169055102393
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.30
Split: 03, Run: 02
None time:  0.8236703348811716
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 03
None time:  0.840596733847633
None Run 09:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2408685819245875
None Run 10:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 96.67
   Final Test: 55.10
Split: 04, Run: 02
None time:  0.7441536439582705
None Run 11:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 63.60
Split: 04, Run: 03
None time:  0.8710585318040103
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 64.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.182816229062155
None Run 13:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.20
Split: 05, Run: 02
None time:  0.8265767260454595
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.60
Split: 05, Run: 03
None time:  0.896959078963846
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2165592468809336
None Run 16:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 66.60
Split: 06, Run: 02
None time:  0.8036224851384759
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.30
Split: 06, Run: 03
None time:  0.8550257601309568
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8462262710090727
None Run 19:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 90.00
   Final Test: 59.10
Split: 07, Run: 02
None time:  0.7693543750792742
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.60
Split: 07, Run: 03
None time:  0.7881376501172781
None Run 21:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0850152939092368
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.40
Split: 08, Run: 02
None time:  0.7202782409731299
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.80
Split: 08, Run: 03
None time:  0.8213522369042039
None Run 24:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.946398430969566
None Run 25:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 63.40
Split: 09, Run: 02
None time:  0.9241087441332638
None Run 26:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 64.50
Split: 09, Run: 03
None time:  0.824748395010829
None Run 27:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2288645601365715
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.40
Split: 10, Run: 02
None time:  0.8093044350389391
None Run 29:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.60
Split: 10, Run: 03
None time:  0.7840893289539963
None Run 30:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.8625950813293457
total time:  32.234521315898746
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.29 ± 4.28
  Final Train: 97.89 ± 4.15
   Final Test: 64.31 ± 3.75
best run test_acc: 65.4000015258789
[I 2023-06-11 23:50:18,485] Trial 62 finished with value: 65.28666687011719 and parameters: {'Fwd': 0.05119953215844448, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 1.3106092212491034, 'loop': 2, 'loss': 'CE', 'lr': 0.0002782886775757429, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.663773489284657e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.00027469111494875085
weight_decay:  3.145968640879415e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2280380360316485
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 86.67
   Final Test: 62.00
Split: 01, Run: 02
None time:  1.1685534080024809
None Run 02:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 86.67
   Final Test: 61.60
Split: 01, Run: 03
None time:  1.1481426099780947
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 86.67
   Final Test: 61.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.448507962981239
None Run 04:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.20
Split: 02, Run: 02
None time:  0.8322418711613864
None Run 05:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.70
Split: 02, Run: 03
None time:  0.8040060589555651
None Run 06:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2016633979510516
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.10
Split: 03, Run: 02
None time:  0.8567381070461124
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 03
None time:  0.864960314007476
None Run 09:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5242527849040926
None Run 10:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 96.67
   Final Test: 63.00
Split: 04, Run: 02
None time:  0.7985247960314155
None Run 11:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.70
Split: 04, Run: 03
None time:  0.8476146701723337
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 64.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.6406224449165165
None Run 13:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.70
Split: 05, Run: 02
None time:  0.8406739130150527
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.30
Split: 05, Run: 03
None time:  0.8584706080146134
None Run 15:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2179296580143273
None Run 16:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 02
None time:  0.9081263688858598
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.80
Split: 06, Run: 03
None time:  0.8088264102116227
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.191678280942142
None Run 19:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 86.67
   Final Test: 59.60
Split: 07, Run: 02
None time:  1.0279832070227712
None Run 20:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 96.67
   Final Test: 59.80
Split: 07, Run: 03
None time:  0.8372549039777368
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 93.33
   Final Test: 58.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3299193379934877
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 63.90
Split: 08, Run: 02
None time:  0.8840567860752344
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.60
Split: 08, Run: 03
None time:  0.818071834044531
None Run 24:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6058892069850117
None Run 25:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 65.00
Split: 09, Run: 02
None time:  0.782459604088217
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.00
Split: 09, Run: 03
None time:  0.7540019447915256
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6108076409436762
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.20
Split: 10, Run: 02
None time:  0.7650920620653778
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 10, Run: 03
None time:  0.8793037389405072
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.2977423667907715
total time:  34.554516572039574
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.30 ± 3.70
  Final Train: 97.33 ± 4.58
   Final Test: 64.48 ± 3.10
best run test_acc: 65.33999633789062
[I 2023-06-11 23:50:53,504] Trial 63 finished with value: 65.30000305175781 and parameters: {'Fwd': 0.04626646959203071, 'K': 9, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 1.376942892351559, 'loop': 2, 'loss': 'CE', 'lr': 0.00027469111494875085, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.145968640879415e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0003369774457652551
weight_decay:  3.328540687270944e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0516630299389362
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 83.33
   Final Test: 62.70
Split: 01, Run: 02
None time:  0.7740419649053365
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 90.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  0.7933477610349655
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 90.00
   Final Test: 62.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0830372490454465
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.50
Split: 02, Run: 02
None time:  0.6921840240247548
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 03
None time:  0.738905780017376
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.096388990059495
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.20
Split: 03, Run: 02
None time:  0.7104898900724947
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.80
Split: 03, Run: 03
None time:  0.7438491340726614
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.045020428020507
None Run 10:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 96.67
   Final Test: 55.30
Split: 04, Run: 02
None time:  0.7458067801780999
None Run 11:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 61.30
Split: 04, Run: 03
None time:  0.6825854030903429
None Run 12:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 60.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.345922642154619
None Run 13:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.10
Split: 05, Run: 02
None time:  0.7032946909312159
None Run 14:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.50
Split: 05, Run: 03
None time:  0.7190797049552202
None Run 15:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0671434921678156
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 65.20
Split: 06, Run: 02
None time:  0.7575135380029678
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.50
Split: 06, Run: 03
None time:  0.7511291150003672
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.9332245828118175
None Run 19:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 57.00
Split: 07, Run: 02
None time:  0.8789839579258114
None Run 20:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 93.33
   Final Test: 58.70
Split: 07, Run: 03
None time:  1.6241362770088017
None Run 21:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 86.67
   Final Test: 59.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9195167149882764
None Run 22:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.70
Split: 08, Run: 02
None time:  0.7623154979664832
None Run 23:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.90
Split: 08, Run: 03
None time:  0.7010752491187304
None Run 24:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5077595110051334
None Run 25:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 65.10
Split: 09, Run: 02
None time:  0.7357914359308779
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.40
Split: 09, Run: 03
None time:  0.7648076391778886
None Run 27:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1490942768286914
None Run 28:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 93.33
   Final Test: 65.70
Split: 10, Run: 02
None time:  0.7043808458838612
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.20
Split: 10, Run: 03
None time:  0.6997256828472018
None Run 30:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.00
run time now: 2.5948026180267334
total time:  28.93812109110877
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.79 ± 4.81
  Final Train: 97.33 ± 4.58
   Final Test: 64.49 ± 3.73
best run test_acc: 65.33999633789062
[I 2023-06-11 23:51:23,017] Trial 64 finished with value: 64.7933349609375 and parameters: {'Fwd': 0.039108496541076496, 'K': 9, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 1.8503259022446024, 'loop': 2, 'loss': 'CE', 'lr': 0.0003369774457652551, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.328540687270944e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.00023701784852264476
weight_decay:  1.7191402977258837e-05
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4654016941785812
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 90.00
   Final Test: 61.50
Split: 01, Run: 02
None time:  1.2490301351062953
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 93.33
   Final Test: 62.20
Split: 01, Run: 03
None time:  1.2970564390998334
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 86.67
   Final Test: 62.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4036081780213863
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.70
Split: 02, Run: 02
None time:  0.8627491530496627
None Run 05:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.30
Split: 02, Run: 03
None time:  0.7376803657971323
None Run 06:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9529767469502985
None Run 07:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.60
Split: 03, Run: 02
None time:  0.8692572750151157
None Run 08:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.60
Split: 03, Run: 03
None time:  1.3922551779542118
None Run 09:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 63.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2612281509209424
None Run 10:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 96.67
   Final Test: 55.00
Split: 04, Run: 02
None time:  0.8109204559586942
None Run 11:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 96.67
   Final Test: 62.80
Split: 04, Run: 03
None time:  0.8954572658985853
None Run 12:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1736697789747268
None Run 13:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.90
Split: 05, Run: 02
None time:  1.0459330591838807
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 62.30
Split: 05, Run: 03
None time:  0.8733777299057692
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 60.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3271997729316354
None Run 16:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 66.80
Split: 06, Run: 02
None time:  0.8141298000700772
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 03
None time:  0.8373010749928653
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: -2494.4316, Train: 73.33%, Valid: 58.80% Test: 58.80%
Split: 07, Run: 01
None time:  2.3844394891057163
None Run 19:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 80.00
   Final Test: 60.20
Split: 07, Run: 02
None time:  0.8334261470008641
None Run 20:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 83.33
   Final Test: 59.20
Split: 07, Run: 03
None time:  1.0812286850996315
None Run 21:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 83.33
   Final Test: 58.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0439896918833256
None Run 22:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 66.30
Split: 08, Run: 02
None time:  0.9338751011528075
None Run 23:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 65.80
Split: 08, Run: 03
None time:  0.8429404150228947
None Run 24:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 66.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.547206143848598
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 90.00
   Final Test: 63.30
Split: 09, Run: 02
None time:  0.9124186921399087
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 63.20
Split: 09, Run: 03
None time:  0.8508745201397687
None Run 27:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 63.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6041581900790334
None Run 28:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 66.30
Split: 10, Run: 02
None time:  0.820238723186776
None Run 29:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.20
Split: 10, Run: 03
None time:  0.8529257508926094
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.70
run time now: 3.320417642593384
total time:  34.080572658916935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.51 ± 4.06
  Final Train: 94.67 ± 5.58
   Final Test: 63.75 ± 3.15
best run test_acc: 64.6500015258789
[I 2023-06-11 23:51:57,634] Trial 65 finished with value: 64.5133285522461 and parameters: {'Fwd': 0.05580776070320012, 'K': 10, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 0.45566940088134433, 'loop': 2, 'loss': 'CE', 'lr': 0.00023701784852264476, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.7191402977258837e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.00034713414928155947
weight_decay:  1.0808200792252168e-05
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3486564778722823
None Run 01:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 80.00
   Final Test: 62.40
Split: 01, Run: 02
None time:  1.3188137388788164
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 76.67
   Final Test: 62.50
Split: 01, Run: 03
None time:  0.7951428638771176
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 93.33
   Final Test: 61.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.194919880013913
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 90.00
   Final Test: 68.20
Split: 02, Run: 02
None time:  0.8702579140663147
None Run 05:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 67.20
Split: 02, Run: 03
None time:  0.7387870450038463
None Run 06:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1945041590370238
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 64.60
Split: 03, Run: 02
None time:  0.7106884398963302
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.90
Split: 03, Run: 03
None time:  0.7632362570147961
None Run 09:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 65.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2889809051994234
None Run 10:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 56.60
Split: 04, Run: 02
None time:  0.7701531241182238
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 64.60
Split: 04, Run: 03
None time:  0.7389447968453169
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.14576828898862
None Run 13:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.30
Split: 05, Run: 02
None time:  0.8740047428291291
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.30
Split: 05, Run: 03
None time:  0.8576119551435113
None Run 15:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 62.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0113761681132019
None Run 16:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 65.10
Split: 06, Run: 02
None time:  0.808576000155881
None Run 17:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 65.50
Split: 06, Run: 03
None time:  0.7459400540683419
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.321172066964209
None Run 19:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 83.33
   Final Test: 59.60
Split: 07, Run: 02
None time:  0.7399655950721353
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.30
Split: 07, Run: 03
None time:  0.7341709989123046
None Run 21:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0972274108789861
None Run 22:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 90.00
   Final Test: 61.10
Split: 08, Run: 02
None time:  0.7753713510464877
None Run 23:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 68.00
Split: 08, Run: 03
None time:  0.8388133679982275
None Run 24:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4861329989507794
None Run 25:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 86.67
   Final Test: 60.20
Split: 09, Run: 02
None time:  0.7817732358817011
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.70
Split: 09, Run: 03
None time:  0.7329922879580408
None Run 27:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2597013469785452
None Run 28:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 90.00
   Final Test: 63.90
Split: 10, Run: 02
None time:  0.8106174301356077
None Run 29:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.50
Split: 10, Run: 03
None time:  0.795300813857466
None Run 30:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.90
run time now: 2.90942120552063
total time:  29.624977027997375
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.33 ± 3.35
  Final Train: 95.22 ± 6.47
   Final Test: 63.73 ± 2.85
best run test_acc: 64.93000793457031
[I 2023-06-11 23:52:27,820] Trial 66 finished with value: 64.32666015625 and parameters: {'Fwd': 0.03358662854408894, 'K': 9, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 0.9696497151253733, 'loop': 2, 'loss': 'CE', 'lr': 0.00034713414928155947, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.0808200792252168e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0002780795115973034
weight_decay:  3.62965479672679e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3149091429077089
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 86.67
   Final Test: 60.30
Split: 01, Run: 02
None time:  0.8712399092037231
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 62.00
Split: 01, Run: 03
None time:  0.8828196949325502
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 61.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.291626247111708
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 68.10
Split: 02, Run: 02
None time:  0.7689053968060762
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.70
Split: 02, Run: 03
None time:  0.7917166010010988
None Run 06:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.20434060995467
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.00
Split: 03, Run: 02
None time:  0.8858399300370365
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.50
Split: 03, Run: 03
None time:  0.924211431061849
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5880981250666082
None Run 10:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 90.00
   Final Test: 54.20
Split: 04, Run: 02
None time:  0.8678630630020052
None Run 11:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 63.90
Split: 04, Run: 03
None time:  0.8682503099553287
None Run 12:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 64.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.407955938950181
None Run 13:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 62.20
Split: 05, Run: 02
None time:  1.280862154904753
None Run 14:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.10
Split: 05, Run: 03
None time:  1.0862188569735736
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 60.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2875501259695739
None Run 16:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 86.67
   Final Test: 63.50
Split: 06, Run: 02
None time:  0.9229691519867629
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.90
Split: 06, Run: 03
None time:  0.8638415869791061
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.2171956070233136
None Run 19:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 76.67
   Final Test: 58.40
Split: 07, Run: 02
None time:  0.8884747971314937
None Run 20:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 86.67
   Final Test: 58.80
Split: 07, Run: 03
None time:  0.9194121719338
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 86.67
   Final Test: 58.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3949355280492455
None Run 22:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 80.00
   Final Test: 62.30
Split: 08, Run: 02
None time:  0.8609350100159645
None Run 23:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 69.50
Split: 08, Run: 03
None time:  0.8414114890620112
None Run 24:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.066497680032626
None Run 25:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 73.33
   Final Test: 66.10
Split: 09, Run: 02
None time:  0.9804597669281065
None Run 26:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.90
Split: 09, Run: 03
None time:  0.9644003049470484
None Run 27:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 67.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4106222440022975
None Run 28:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 86.67
   Final Test: 65.90
Split: 10, Run: 02
None time:  0.8646038840524852
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  0.8555818779859692
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.172761917114258
total time:  34.44519060989842
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.11 ± 4.10
  Final Train: 93.67 ± 7.50
   Final Test: 64.44 ± 3.96
best run test_acc: 65.74000549316406
[I 2023-06-11 23:53:02,711] Trial 67 finished with value: 65.11333465576172 and parameters: {'Fwd': 0.020928012463591363, 'K': 9, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.1, 'lambda2': 0.26296448467391825, 'loop': 2, 'loss': 'CE', 'lr': 0.0002780795115973034, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.62965479672679e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00014568142879226284
weight_decay:  0.00014779605971464068
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7698136989492923
None Run 01:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 35.50
Split: 01, Run: 02
None time:  1.8326551439240575
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 76.67
   Final Test: 60.70
Split: 01, Run: 03
None time:  1.269309886964038
None Run 03:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 80.00
   Final Test: 61.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6539627930615097
None Run 04:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 80.00
   Final Test: 68.40
Split: 02, Run: 02
None time:  0.8346333540976048
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 70.20
Split: 02, Run: 03
None time:  0.805036538047716
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5801998120732605
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 90.00
   Final Test: 63.70
Split: 03, Run: 02
None time:  0.7537514108698815
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.30
Split: 03, Run: 03
None time:  0.7299402570351958
None Run 09:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2972573679871857
None Run 10:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 90.00
   Final Test: 55.40
Split: 04, Run: 02
None time:  0.7950437108520418
None Run 11:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 96.67
   Final Test: 60.50
Split: 04, Run: 03
None time:  0.7622117828577757
None Run 12:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 96.67
   Final Test: 61.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5832521598786116
None Run 13:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.50
Split: 05, Run: 02
None time:  1.3045415428932756
None Run 14:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 59.50
Split: 05, Run: 03
None time:  0.7275230400264263
None Run 15:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.620632119011134
None Run 16:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 70.00
   Final Test: 64.00
Split: 06, Run: 02
None time:  0.8909523750189692
None Run 17:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 86.67
   Final Test: 65.60
Split: 06, Run: 03
None time:  0.6358809929806739
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4543728060089052
None Run 19:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 83.33
   Final Test: 50.50
Split: 07, Run: 02
None time:  1.2589174129534513
None Run 20:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 90.00
   Final Test: 54.10
Split: 07, Run: 03
None time:  1.0760265560820699
None Run 21:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 90.00
   Final Test: 54.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6820575681049377
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 86.67
   Final Test: 62.70
Split: 08, Run: 02
None time:  0.7318501910194755
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 66.20
Split: 08, Run: 03
None time:  0.7825742061249912
None Run 24:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 90.00
   Final Test: 67.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7756727051455528
None Run 25:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 73.33
   Final Test: 65.30
Split: 09, Run: 02
None time:  0.8679283910896629
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 66.40
Split: 09, Run: 03
None time:  1.0940809771418571
None Run 27:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 66.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3891927080694586
None Run 28:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 83.33
   Final Test: 64.10
Split: 10, Run: 02
None time:  0.7207113278564066
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.10
Split: 10, Run: 03
None time:  0.7593494208995253
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.00
run time now: 2.9127163887023926
total time:  34.528730168007314
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.33 ± 7.17
  Final Train: 90.67 ± 8.51
   Final Test: 62.15 ± 6.94
best run test_acc: 64.08000183105469
[I 2023-06-11 23:53:37,650] Trial 68 finished with value: 63.326663970947266 and parameters: {'Fwd': 0.09523987978109934, 'K': 10, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 0.01861192790882993, 'loop': 2, 'loss': 'CE', 'lr': 0.00014568142879226284, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00014779605971464068, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.00046134755391860724
weight_decay:  8.197170113226011e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4214332499541342
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 63.30
Split: 01, Run: 02
None time:  0.9707076461054385
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 96.67
   Final Test: 63.00
Split: 01, Run: 03
None time:  0.8665399400051683
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 93.33
   Final Test: 62.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.27109440905042
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 68.10
Split: 02, Run: 02
None time:  0.7887473509181291
None Run 05:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.10
Split: 02, Run: 03
None time:  0.8039782079868019
None Run 06:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.204599912976846
None Run 07:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.90
Split: 03, Run: 02
None time:  0.7957228450104594
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.60
Split: 03, Run: 03
None time:  0.8224792021792382
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.351610187906772
None Run 10:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 96.67
   Final Test: 56.60
Split: 04, Run: 02
None time:  0.8549785290379077
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
Split: 04, Run: 03
None time:  0.8139953210484236
None Run 12:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 63.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0552813459653407
None Run 13:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.70
Split: 05, Run: 02
None time:  0.8441977670881897
None Run 14:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.20
Split: 05, Run: 03
None time:  0.7867730390280485
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0056824521161616
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 62.80
Split: 06, Run: 02
None time:  0.7487600280437618
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.30
Split: 06, Run: 03
None time:  0.7981014638207853
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.643870118074119
None Run 19:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 83.33
   Final Test: 58.00
Split: 07, Run: 02
None time:  0.8367913600523025
None Run 20:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 93.33
   Final Test: 59.60
Split: 07, Run: 03
None time:  0.8411652399227023
None Run 21:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 93.33
   Final Test: 60.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8572163288481534
None Run 22:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.20
Split: 08, Run: 02
None time:  0.8502662191167474
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.30
Split: 08, Run: 03
None time:  0.8142501611728221
None Run 24:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3293966420460492
None Run 25:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 93.33
   Final Test: 57.10
Split: 09, Run: 02
None time:  0.80806057411246
None Run 26:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 62.40
Split: 09, Run: 03
None time:  0.8396366941742599
None Run 27:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 61.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.273404227104038
None Run 28:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.70
Split: 10, Run: 02
None time:  0.7984316830988973
None Run 29:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.00
Split: 10, Run: 03
None time:  0.8470985919702798
None Run 30:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 64.00
run time now: 2.973247766494751
total time:  29.995777636067942
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.93 ± 4.41
  Final Train: 97.78 ± 3.64
   Final Test: 63.72 ± 3.32
best run test_acc: 65.37999725341797
[I 2023-06-11 23:54:08,092] Trial 69 finished with value: 63.93333435058594 and parameters: {'Fwd': 0.06374621733701057, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 1.9638167275089151, 'loop': 2, 'loss': 'CE', 'lr': 0.00046134755391860724, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.197170113226011e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.30000000000000004
lr:  0.0003165537195349699
weight_decay:  4.114710730373692e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2630296989809722
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 80.00
   Final Test: 59.00
Split: 01, Run: 02
None time:  0.898075464181602
None Run 02:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 83.33
   Final Test: 61.30
Split: 01, Run: 03
None time:  0.8498910961207002
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 86.67
   Final Test: 61.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5146982269361615
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.60
Split: 02, Run: 02
None time:  0.8152584549970925
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 03
None time:  0.7491820040158927
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0759831359609962
None Run 07:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 65.10
Split: 03, Run: 02
None time:  0.801325896056369
None Run 08:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.40
Split: 03, Run: 03
None time:  0.7803606600500643
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3444507161621004
None Run 10:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 93.33
   Final Test: 52.80
Split: 04, Run: 02
None time:  0.8453825868200511
None Run 11:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 64.30
Split: 04, Run: 03
None time:  0.8208468439988792
None Run 12:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 96.67
   Final Test: 64.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0204622161109
None Run 13:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 57.40
Split: 05, Run: 02
None time:  1.003087324090302
None Run 14:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.30
Split: 05, Run: 03
None time:  0.8908671808894724
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 62.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.152245006058365
None Run 16:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 61.90
Split: 06, Run: 02
None time:  0.7711786399595439
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 65.90
Split: 06, Run: 03
None time:  0.7141431299969554
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5252073288429528
None Run 19:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 83.33
   Final Test: 58.40
Split: 07, Run: 02
None time:  0.8098916350863874
None Run 20:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 90.00
   Final Test: 58.00
Split: 07, Run: 03
None time:  0.7504997930955142
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 90.00
   Final Test: 58.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4868731631431729
None Run 22:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 80.00
   Final Test: 62.20
Split: 08, Run: 02
None time:  0.8484763309825212
None Run 23:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 90.00
   Final Test: 66.10
Split: 08, Run: 03
None time:  0.8830484361387789
None Run 24:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 90.00
   Final Test: 67.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.366332327015698
None Run 25:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 83.33
   Final Test: 62.80
Split: 09, Run: 02
None time:  0.8510901001282036
None Run 26:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.00
Split: 09, Run: 03
None time:  0.8228838241193444
None Run 27:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.834732349961996
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 83.33
   Final Test: 65.70
Split: 10, Run: 02
None time:  0.7805979510303587
None Run 29:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.60
Split: 10, Run: 03
None time:  0.79358019400388
None Run 30:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.60
run time now: 3.447078227996826
total time:  31.09532246296294
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.87 ± 4.71
  Final Train: 93.22 ± 6.64
   Final Test: 63.66 ± 4.13
best run test_acc: 65.11000061035156
[I 2023-06-11 23:54:39,716] Trial 70 finished with value: 64.87332916259766 and parameters: {'Fwd': 0.015506129019397404, 'K': 7, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 1.5545042805057598, 'loop': 2, 'loss': 'CE', 'lr': 0.0003165537195349699, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.114710730373692e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0002710173674630871
weight_decay:  8.371143303226529e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7033917799126357
None Run 01:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 96.67
   Final Test: 61.60
Split: 01, Run: 02
None time:  1.070380802033469
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 61.50
Split: 01, Run: 03
None time:  1.952699220040813
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 86.67
   Final Test: 61.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6160690998658538
None Run 04:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 02
None time:  0.7961996130179614
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
Split: 02, Run: 03
None time:  0.8788507832214236
None Run 06:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9587199010420591
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.00
Split: 03, Run: 02
None time:  0.7713503481354564
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.00
Split: 03, Run: 03
None time:  0.789692355087027
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2383144651539624
None Run 10:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 54.60
Split: 04, Run: 02
None time:  0.7524726781994104
None Run 11:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 60.00
Split: 04, Run: 03
None time:  0.869333409005776
None Run 12:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.110840868903324
None Run 13:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.00
Split: 05, Run: 02
None time:  0.9445701700169593
None Run 14:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.40
Split: 05, Run: 03
None time:  0.8049895700532943
None Run 15:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.307729545980692
None Run 16:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.90
Split: 06, Run: 02
None time:  0.8274525438901037
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.40
Split: 06, Run: 03
None time:  0.869762527057901
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3952635298483074
None Run 19:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 57.20
Split: 07, Run: 02
None time:  2.0706322169862688
None Run 20:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 90.00
   Final Test: 59.90
Split: 07, Run: 03
None time:  0.8550729819107801
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 59.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.307359276106581
None Run 22:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.50
Split: 08, Run: 02
None time:  0.8051903028972447
None Run 23:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 08, Run: 03
None time:  0.8076668588910252
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8657425388228148
None Run 25:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 62.70
Split: 09, Run: 02
None time:  0.7883640988729894
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 65.70
Split: 09, Run: 03
None time:  0.8801542730070651
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 64.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3861115591134876
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.80
Split: 10, Run: 02
None time:  0.8359523711260408
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.60
Split: 10, Run: 03
None time:  0.8120119362138212
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.0750839710235596
total time:  34.14832231798209
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.85 ± 4.78
  Final Train: 98.67 ± 3.11
   Final Test: 64.16 ± 4.02
best run test_acc: 65.12000274658203
[I 2023-06-11 23:55:14,349] Trial 71 finished with value: 64.85334014892578 and parameters: {'Fwd': 0.048964199713400616, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.1, 'lambda2': 1.28420001211538, 'loop': 2, 'loss': 'CE', 'lr': 0.0002710173674630871, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.371143303226529e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0002536912985573596
weight_decay:  0.000128182269342673
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6872741798870265
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 83.33
   Final Test: 61.30
Split: 01, Run: 02
None time:  1.1192527459934354
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 86.67
   Final Test: 61.70
Split: 01, Run: 03
None time:  0.8909511719830334
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 61.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4620873860549182
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.40
Split: 02, Run: 02
None time:  0.8158270658459514
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.50
Split: 02, Run: 03
None time:  0.8786781849339604
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2258735611103475
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.00
Split: 03, Run: 02
None time:  1.0126467440277338
None Run 08:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 64.20
Split: 03, Run: 03
None time:  0.9226301810704172
None Run 09:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3685443759895861
None Run 10:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 96.67
   Final Test: 55.10
Split: 04, Run: 02
None time:  0.9250827028881758
None Run 11:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 96.67
   Final Test: 62.70
Split: 04, Run: 03
None time:  0.929362801136449
None Run 12:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 62.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2525458261370659
None Run 13:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.60
Split: 05, Run: 02
None time:  0.9791175960563123
None Run 14:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.00
Split: 05, Run: 03
None time:  0.8831804450601339
None Run 15:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9790656447876245
None Run 16:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 62.60
Split: 06, Run: 02
None time:  0.9356227528769523
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 03
None time:  0.9627969509456307
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: -1282.9536, Train: 80.00%, Valid: 56.60% Test: 59.10%
Split: 07, Run: 01
None time:  2.3607786290813237
None Run 19:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 80.00
   Final Test: 59.40
Split: 07, Run: 02
None time:  0.837170816026628
None Run 20:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 96.67
   Final Test: 60.20
Split: 07, Run: 03
None time:  0.9049190687946975
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 96.67
   Final Test: 59.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2499375857878476
None Run 22:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 64.30
Split: 08, Run: 02
None time:  0.8753651571460068
None Run 23:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 08, Run: 03
None time:  0.9381730179302394
None Run 24:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 68.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7531555411405861
None Run 25:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 65.20
Split: 09, Run: 02
None time:  1.0399764578323811
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.60
Split: 09, Run: 03
None time:  0.8912070279475302
None Run 27:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4249149810057133
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 66.80
Split: 10, Run: 02
None time:  0.8572228460106999
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.50
Split: 10, Run: 03
None time:  0.9394106830004603
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.10
run time now: 3.262296199798584
total time:  34.407711181091145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.20 ± 4.48
  Final Train: 96.22 ± 5.08
   Final Test: 64.44 ± 3.64
best run test_acc: 65.47999572753906
[I 2023-06-11 23:55:49,229] Trial 72 finished with value: 65.19999694824219 and parameters: {'Fwd': 0.03380371393209507, 'K': 9, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.15000000000000002, 'lambda2': 0.5670046937376056, 'loop': 2, 'loss': 'CE', 'lr': 0.0002536912985573596, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.000128182269342673, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00036905790528343307
weight_decay:  8.914641202516577e-05
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6570978700183332
None Run 01:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 62.10
Split: 01, Run: 02
None time:  0.7656262570526451
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 62.30
Split: 01, Run: 03
None time:  0.806843149010092
None Run 03:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 62.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3459231229498982
None Run 04:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.60
Split: 02, Run: 02
None time:  0.7926861529704183
None Run 05:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.20
Split: 02, Run: 03
None time:  0.7074169488623738
None Run 06:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4613590359222144
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.80
Split: 03, Run: 02
None time:  0.7939805050846189
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.90
Split: 03, Run: 03
None time:  0.8511098399758339
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3992348611354828
None Run 10:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 96.67
   Final Test: 61.90
Split: 04, Run: 02
None time:  1.1427042519208044
None Run 11:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 96.67
   Final Test: 61.70
Split: 04, Run: 03
None time:  0.805688135093078
None Run 12:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 96.67
   Final Test: 64.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0791193030308932
None Run 13:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 51.90
Split: 05, Run: 02
None time:  0.8141258989926428
None Run 14:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 53.70
Split: 05, Run: 03
None time:  0.7560222169850022
None Run 15:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 53.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.099201651988551
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.00
Split: 06, Run: 02
None time:  0.7581047632265836
None Run 17:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.30
Split: 06, Run: 03
None time:  0.7662552271503955
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.379429766209796
None Run 19:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 93.33
   Final Test: 55.10
Split: 07, Run: 02
None time:  0.766317883040756
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 96.67
   Final Test: 56.40
Split: 07, Run: 03
None time:  0.8459995579905808
None Run 21:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 96.67
   Final Test: 57.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.087323894025758
None Run 22:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.00
Split: 08, Run: 02
None time:  0.7840979809407145
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.80
Split: 08, Run: 03
None time:  0.7317405298817903
None Run 24:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 67.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6601813531015068
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 59.90
Split: 09, Run: 02
None time:  0.7976442161016166
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 63.30
Split: 09, Run: 03
None time:  0.8222640100866556
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 64.20
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2072112339083105
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.80
Split: 10, Run: 02
None time:  0.7989143710583448
None Run 29:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.90
Split: 10, Run: 03
None time:  0.7839805039111525
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.30
run time now: 2.833685874938965
total time:  30.525836431887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.17 ± 4.36
  Final Train: 98.44 ± 1.90
   Final Test: 62.55 ± 4.46
best run test_acc: 63.22999954223633
[I 2023-06-11 23:56:20,193] Trial 73 finished with value: 63.17333221435547 and parameters: {'Fwd': 0.06429671553166644, 'K': 9, 'alpha': 0.1, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 1.4530960167423232, 'loop': 2, 'loss': 'CE', 'lr': 0.00036905790528343307, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.914641202516577e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0003064048270861119
weight_decay:  0.0001273513112828135
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5665670551825315
None Run 01:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 66.67
   Final Test: 59.50
Split: 01, Run: 02
None time:  0.8225316680036485
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 96.67
   Final Test: 59.50
Split: 01, Run: 03
None time:  0.6660779449157417
None Run 03:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 90.00
   Final Test: 60.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0583841879852116
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.00
Split: 02, Run: 02
None time:  0.6637307370547205
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.40
Split: 02, Run: 03
None time:  0.6372721730731428
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2440126540604979
None Run 07:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 93.33
   Final Test: 62.60
Split: 03, Run: 02
None time:  0.6842158460058272
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.30
Split: 03, Run: 03
None time:  0.6408629280049354
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6729350718669593
None Run 10:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 86.67
   Final Test: 56.90
Split: 04, Run: 02
None time:  0.7383660690393299
None Run 11:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 96.67
   Final Test: 62.50
Split: 04, Run: 03
None time:  0.7631285358220339
None Run 12:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 96.67
   Final Test: 63.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.152195326052606
None Run 13:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.40
Split: 05, Run: 02
None time:  0.7168288959655911
None Run 14:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 61.20
Split: 05, Run: 03
None time:  0.7142178369686007
None Run 15:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 61.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0272610618267208
None Run 16:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 63.30
Split: 06, Run: 02
None time:  0.6737597109749913
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 65.80
Split: 06, Run: 03
None time:  0.8076405159663409
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: -4192.7070, Train: 80.00%, Valid: 55.20% Test: 57.40%
Split: 07, Run: 01
None time:  2.299707735190168
None Run 19:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 80.00
   Final Test: 57.40
Split: 07, Run: 02
None time:  0.7280601398088038
None Run 20:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 90.00
   Final Test: 59.10
Split: 07, Run: 03
None time:  0.6645139520987868
None Run 21:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 90.00
   Final Test: 59.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7182692899368703
None Run 22:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 54.60
Split: 08, Run: 02
None time:  0.7553238410037011
None Run 23:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 61.20
Split: 08, Run: 03
None time:  0.7057215280365199
None Run 24:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9572866330854595
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 80.00
   Final Test: 64.30
Split: 09, Run: 02
None time:  0.711801148019731
None Run 26:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 68.50
Split: 09, Run: 03
None time:  0.6698875511065125
None Run 27:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.5284118989948183
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 66.00
Split: 10, Run: 02
None time:  0.7058918059337884
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.40
Split: 10, Run: 03
None time:  0.6901368079707026
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 69.30
run time now: 2.9637880325317383
total time:  29.441644981037825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.09 ± 5.06
  Final Train: 93.89 ± 7.59
   Final Test: 63.61 ± 4.14
best run test_acc: 65.43000030517578
[I 2023-06-11 23:56:50,134] Trial 74 finished with value: 64.09333801269531 and parameters: {'Fwd': 0.022767862262556667, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.1049995344749317, 'loop': 2, 'loss': 'CE', 'lr': 0.0003064048270861119, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0001273513112828135, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00046882896021567473
weight_decay:  0.0003247185863512424
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3939942801371217
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 80.00
   Final Test: 61.00
Split: 01, Run: 02
None time:  1.1967716589570045
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 80.00
   Final Test: 61.60
Split: 01, Run: 03
None time:  0.7847605331335217
None Run 03:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 96.67
   Final Test: 59.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1772808460518718
None Run 04:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.10
Split: 02, Run: 02
None time:  0.8400620250031352
None Run 05:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.60
Split: 02, Run: 03
None time:  0.8378639849834144
None Run 06:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3676680279895663
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 65.10
Split: 03, Run: 02
None time:  0.8491619769483805
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.40
Split: 03, Run: 03
None time:  0.7875927530694753
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3189671928994358
None Run 10:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 57.50
Split: 04, Run: 02
None time:  0.867743403185159
None Run 11:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 64.90
Split: 04, Run: 03
None time:  0.826249951031059
None Run 12:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 64.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.107817375799641
None Run 13:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.50
Split: 05, Run: 02
None time:  0.9725311640650034
None Run 14:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 65.40
Split: 05, Run: 03
None time:  0.8196174439508468
None Run 15:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.126171626150608
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 64.90
Split: 06, Run: 02
None time:  0.7768325279466808
None Run 17:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 67.20
Split: 06, Run: 03
None time:  0.8840149079915136
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.675091460114345
None Run 19:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 83.33
   Final Test: 59.20
Split: 07, Run: 02
None time:  0.8663122251164168
None Run 20:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 90.00
   Final Test: 60.10
Split: 07, Run: 03
None time:  0.9009904689155519
None Run 21:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 93.33
   Final Test: 60.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0978834100533277
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 86.67
   Final Test: 64.50
Split: 08, Run: 02
None time:  0.8112959931604564
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 69.20
Split: 08, Run: 03
None time:  0.8811715738847852
None Run 24:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 69.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.33914828998968
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 90.00
   Final Test: 60.50
Split: 09, Run: 02
None time:  0.873654117109254
None Run 26:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 64.80
Split: 09, Run: 03
None time:  0.8279830261599272
None Run 27:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 64.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1319960851687938
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 67.50
Split: 10, Run: 02
None time:  0.8273422750644386
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.80
Split: 10, Run: 03
None time:  0.9033832920249552
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.10
run time now: 2.9063196182250977
total time:  31.177016790024936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.62 ± 4.38
  Final Train: 94.67 ± 5.78
   Final Test: 64.52 ± 3.22
best run test_acc: 65.71000671386719
[I 2023-06-11 23:57:21,811] Trial 75 finished with value: 64.62000274658203 and parameters: {'Fwd': 0.04654857095994274, 'K': 10, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 0.6886408923492053, 'loop': 2, 'loss': 'CE', 'lr': 0.00046882896021567473, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0003247185863512424, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0005394413504192907
weight_decay:  0.0002436803552178342
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.1864370289258659
None Run 01:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 34.10
Split: 01, Run: 02
None time:  0.2207821139600128
None Run 02:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 34.10
Split: 01, Run: 03
None time:  0.21650077402591705
None Run 03:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 34.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.20774232293479145
None Run 04:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 40.30
Split: 02, Run: 02
None time:  0.9454873527865857
None Run 05:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.10
Split: 02, Run: 03
None time:  0.2573223460931331
None Run 06:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.22178228409029543
None Run 07:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.40
Split: 03, Run: 02
None time:  0.20445308601483703
None Run 08:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 39.40
Split: 03, Run: 03
None time:  0.8233133777976036
None Run 09:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 58.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.20485588791780174
None Run 10:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 40.50
Split: 04, Run: 02
None time:  0.18120482680387795
None Run 11:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 40.50
Split: 04, Run: 03
None time:  0.6991472879890352
None Run 12:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 46.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.19055898184888065
None Run 13:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 42.00
Split: 05, Run: 02
None time:  0.24623572290875018
None Run 14:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 42.00
Split: 05, Run: 03
None time:  0.5670296931639314
None Run 15:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 53.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.35853215493261814
None Run 16:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 36.20
Split: 06, Run: 02
None time:  0.7039924811106175
None Run 17:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 49.00
Split: 06, Run: 03
None time:  0.22576183010824025
None Run 18:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.18786209099926054
None Run 19:
Highest Train: 100.00
Highest Valid: 26.60
  Final Train: 100.00
   Final Test: 31.20
Split: 07, Run: 02
None time:  0.20051093702204525
None Run 20:
Highest Train: 100.00
Highest Valid: 26.60
  Final Train: 100.00
   Final Test: 31.20
Split: 07, Run: 03
None time:  0.4395538680255413
None Run 21:
Highest Train: 100.00
Highest Valid: 30.60
  Final Train: 100.00
   Final Test: 31.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.19940371601842344
None Run 22:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 41.30
Split: 08, Run: 02
None time:  0.5159397949464619
None Run 23:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 55.30
Split: 08, Run: 03
None time:  0.17814498697407544
None Run 24:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 56.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.20694440696388483
None Run 25:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 35.70
Split: 09, Run: 02
None time:  1.0199224140960723
None Run 26:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 96.67
   Final Test: 51.50
Split: 09, Run: 03
None time:  0.2837287778966129
None Run 27:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 96.67
   Final Test: 50.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.26834990200586617
None Run 28:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 34.10
Split: 10, Run: 02
None time:  1.0441753179766238
None Run 29:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 60.00
Split: 10, Run: 03
None time:  0.34563982696272433
None Run 30:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 60.60
run time now: 1.7093584537506104
total time:  12.619095744099468
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.26 ± 11.95
  Final Train: 99.56 ± 1.15
   Final Test: 45.15 ± 10.86
best run test_acc: 51.08000183105469
[I 2023-06-11 23:57:34,926] Trial 76 finished with value: 46.26000213623047 and parameters: {'Fwd': 0.027814899495949574, 'K': 8, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 0, 'lambda1': 0.05, 'lambda2': 1.0070726354873978, 'loop': 2, 'loss': 'CE', 'lr': 0.0005394413504192907, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0002436803552178342, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.00038218892542113625
weight_decay:  8.111414175226093e-05
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.043284956132993
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 90.00
   Final Test: 61.60
Split: 01, Run: 02
None time:  1.070434955181554
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 76.67
   Final Test: 62.50
Split: 01, Run: 03
None time:  0.8793447150383145
None Run 03:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 76.67
   Final Test: 60.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0774255960714072
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 68.20
Split: 02, Run: 02
None time:  0.720251593971625
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.30
Split: 02, Run: 03
None time:  0.6594524849206209
None Run 06:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9712006119079888
None Run 07:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 60.80
Split: 03, Run: 02
None time:  0.6515002008527517
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 03
None time:  0.6661542830988765
None Run 09:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2118946970440447
None Run 10:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 93.33
   Final Test: 55.00
Split: 04, Run: 02
None time:  0.657348474022001
None Run 11:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 65.70
Split: 04, Run: 03
None time:  0.6199178311508149
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0578279190231115
None Run 13:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.90
Split: 05, Run: 02
None time:  0.6511232589837164
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.50
Split: 05, Run: 03
None time:  0.662193780997768
None Run 15:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8205942739732563
None Run 16:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 65.70
Split: 06, Run: 02
None time:  0.6912202190142125
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.50
Split: 06, Run: 03
None time:  0.7290964860003442
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 65.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9581415478605777
None Run 19:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 80.00
   Final Test: 59.50
Split: 07, Run: 02
None time:  0.6497815388720483
None Run 20:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 86.67
   Final Test: 59.40
Split: 07, Run: 03
None time:  0.659576804144308
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7918492639437318
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.30
Split: 08, Run: 02
None time:  0.7159079229459167
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.60
Split: 08, Run: 03
None time:  0.6530207011383027
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.096580102108419
None Run 25:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 86.67
   Final Test: 62.00
Split: 09, Run: 02
None time:  0.6314817450474948
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.60
Split: 09, Run: 03
None time:  0.6493211949709803
None Run 27:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9796175949741155
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 65.50
Split: 10, Run: 02
None time:  0.6606244100257754
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.20
Split: 10, Run: 03
None time:  0.6097222708631307
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.30
run time now: 2.2889840602874756
total time:  25.895148226059973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.67 ± 4.21
  Final Train: 95.67 ± 7.38
   Final Test: 63.98 ± 3.44
best run test_acc: 65.12998962402344
[I 2023-06-11 23:58:01,268] Trial 77 finished with value: 64.66666412353516 and parameters: {'Fwd': 0.009095964018806956, 'K': 7, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 1.9293063859985393, 'loop': 2, 'loss': 'CE', 'lr': 0.00038218892542113625, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.111414175226093e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.0002841134832385598
weight_decay:  4.170261770844486e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4648899980820715
None Run 01:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 73.33
   Final Test: 61.60
Split: 01, Run: 02
None time:  1.1529392348602414
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 76.67
   Final Test: 61.10
Split: 01, Run: 03
None time:  1.026107412064448
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 76.67
   Final Test: 61.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1833133769687265
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 68.80
Split: 02, Run: 02
None time:  0.9176775678060949
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.80
Split: 02, Run: 03
None time:  0.9446629930753261
None Run 06:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7649973498191684
None Run 07:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 90.00
   Final Test: 61.90
Split: 03, Run: 02
None time:  1.0122225519735366
None Run 08:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 63.10
Split: 03, Run: 03
None time:  0.8289562920108438
None Run 09:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 62.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3789809050504118
None Run 10:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 83.33
   Final Test: 50.20
Split: 04, Run: 02
None time:  0.8262420820537955
None Run 11:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 96.67
   Final Test: 56.00
Split: 04, Run: 03
None time:  0.8152535578701645
None Run 12:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 96.67
   Final Test: 56.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4534665779210627
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 64.30
Split: 05, Run: 02
None time:  0.8991610070224851
None Run 14:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.00
Split: 05, Run: 03
None time:  0.9222722959239036
None Run 15:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 61.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1637492550071329
None Run 16:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 86.67
   Final Test: 64.90
Split: 06, Run: 02
None time:  0.8600388609338552
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.90
Split: 06, Run: 03
None time:  0.8625573171302676
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1531326579861343
None Run 19:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 86.67
   Final Test: 57.20
Split: 07, Run: 02
None time:  0.8618992641568184
None Run 20:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 96.67
   Final Test: 58.00
Split: 07, Run: 03
None time:  0.8989543619100004
None Run 21:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 96.67
   Final Test: 58.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1475869249552488
None Run 22:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 86.67
   Final Test: 62.20
Split: 08, Run: 02
None time:  0.9218192871194333
None Run 23:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.90
Split: 08, Run: 03
None time:  0.8305211539845914
None Run 24:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7598180568311363
None Run 25:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 83.33
   Final Test: 61.70
Split: 09, Run: 02
None time:  0.8359783149790019
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.00
Split: 09, Run: 03
None time:  0.8997597862035036
None Run 27:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 66.20
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2656643050722778
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 86.67
   Final Test: 65.50
Split: 10, Run: 02
None time:  0.8401964141521603
None Run 29:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.50
Split: 10, Run: 03
None time:  0.9337679608725011
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.0801689624786377
total time:  32.877224679803476
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.87 ± 5.76
  Final Train: 92.44 ± 7.78
   Final Test: 63.36 ± 4.79
best run test_acc: 64.56000518798828
[I 2023-06-11 23:58:34,680] Trial 78 finished with value: 63.87333297729492 and parameters: {'Fwd': 0.015370950311573471, 'K': 9, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 0.3193794296909076, 'loop': 2, 'loss': 'CE', 'lr': 0.0002841134832385598, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.170261770844486e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.00022894700637368022
weight_decay:  2.6307710783644308e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.552382511086762
None Run 01:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.40
Split: 01, Run: 02
None time:  1.0295094090979546
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.70
Split: 01, Run: 03
None time:  1.1005289431195706
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 62.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3165398628916591
None Run 04:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.90
Split: 02, Run: 02
None time:  0.7850860620383173
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 02, Run: 03
None time:  0.8514084510970861
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5150709189474583
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.50
Split: 03, Run: 02
None time:  0.8260146130342036
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 03
None time:  0.7592205430846661
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4848136459477246
None Run 10:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 53.50
Split: 04, Run: 02
None time:  0.7905041461344808
None Run 11:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 58.70
Split: 04, Run: 03
None time:  0.7594289889093488
None Run 12:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 57.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8559129070490599
None Run 13:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.40
Split: 05, Run: 02
None time:  0.804691530065611
None Run 14:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 64.90
Split: 05, Run: 03
None time:  0.8434015510138124
None Run 15:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 63.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3761767779942602
None Run 16:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.00
Split: 06, Run: 02
None time:  0.852036408148706
None Run 17:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.40
Split: 06, Run: 03
None time:  1.0943201112095267
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8555422348435968
None Run 19:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 96.67
   Final Test: 55.60
Split: 07, Run: 02
None time:  0.9372704199049622
None Run 20:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 56.50
Split: 07, Run: 03
None time:  0.886307239998132
None Run 21:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 57.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4268899988383055
None Run 22:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.00
Split: 08, Run: 02
None time:  0.7769223218783736
None Run 23:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 66.80
Split: 08, Run: 03
None time:  0.7942269649356604
None Run 24:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.162843120051548
None Run 25:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 65.60
Split: 09, Run: 02
None time:  0.8303943888749927
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.70
Split: 09, Run: 03
None time:  0.8316389820538461
None Run 27:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.5452159219421446
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.20
Split: 10, Run: 02
None time:  0.8755272070411593
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.90
Split: 10, Run: 03
None time:  0.9631276158615947
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.42471981048584
total time:  34.578247484983876
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.76 ± 5.78
  Final Train: 99.33 ± 1.36
   Final Test: 63.84 ± 4.49
best run test_acc: 64.80999755859375
[I 2023-06-11 23:59:09,673] Trial 79 finished with value: 64.75999450683594 and parameters: {'Fwd': 0.05868203405767496, 'K': 8, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.1, 'lambda2': 1.356352548306715, 'loop': 2, 'loss': 'CE', 'lr': 0.00022894700637368022, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.6307710783644308e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.000315863699197026
weight_decay:  0.00017904674743599223
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1954560838639736
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 90.00
   Final Test: 62.80
Split: 01, Run: 02
None time:  1.3022686690092087
None Run 02:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 76.67
   Final Test: 62.90
Split: 01, Run: 03
None time:  0.9341011939104646
None Run 03:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 83.33
   Final Test: 62.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.257062240038067
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.10
Split: 02, Run: 02
None time:  0.7604047618806362
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.70
Split: 02, Run: 03
None time:  0.7094022680539638
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4744981389958411
None Run 07:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 65.20
Split: 03, Run: 02
None time:  0.7063873698934913
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.40
Split: 03, Run: 03
None time:  0.7737746199127287
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2560282710473984
None Run 10:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 96.67
   Final Test: 59.10
Split: 04, Run: 02
None time:  0.7643003240227699
None Run 11:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 65.80
Split: 04, Run: 03
None time:  0.7297118850983679
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 64.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1290016470011324
None Run 13:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.20
Split: 05, Run: 02
None time:  0.9046910859178752
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 61.80
Split: 05, Run: 03
None time:  0.8281634701415896
None Run 15:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 61.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.285991673124954
None Run 16:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 90.00
   Final Test: 65.70
Split: 06, Run: 02
None time:  0.759237761143595
None Run 17:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 03
None time:  0.7628076709806919
None Run 18:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6859148419462144
None Run 19:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 80.00
   Final Test: 58.00
Split: 07, Run: 02
None time:  0.8072806908749044
None Run 20:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 86.67
   Final Test: 59.40
Split: 07, Run: 03
None time:  0.7891725630033761
None Run 21:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 90.00
   Final Test: 59.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2549301870167255
None Run 22:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 80.00
   Final Test: 67.10
Split: 08, Run: 02
None time:  0.8464894918724895
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.40
Split: 08, Run: 03
None time:  0.7660088008269668
None Run 24:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 90.00
   Final Test: 68.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.8150058931205422
None Run 25:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 86.67
   Final Test: 63.10
Split: 09, Run: 02
None time:  0.7595857058186084
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.60
Split: 09, Run: 03
None time:  0.7847887759562582
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.20
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.554637469118461
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 86.67
   Final Test: 68.00
Split: 10, Run: 02
None time:  0.790906507987529
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 67.80
Split: 10, Run: 03
None time:  0.7194022058974952
None Run 30:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 66.80
run time now: 3.106731653213501
total time:  31.18462008005008
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.40 ± 3.82
  Final Train: 93.22 ± 6.81
   Final Test: 64.90 ± 3.26
best run test_acc: 65.7800064086914
[I 2023-06-11 23:59:41,265] Trial 80 finished with value: 65.4000015258789 and parameters: {'Fwd': 0.03946901489201109, 'K': 10, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 0.7431182696721458, 'loop': 2, 'loss': 'CE', 'lr': 0.000315863699197026, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00017904674743599223, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00030535678636858663
weight_decay:  0.00020123405064433994
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8792010999750346
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 80.00
   Final Test: 61.90
Split: 01, Run: 02
None time:  0.939340190961957
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 86.67
   Final Test: 62.10
Split: 01, Run: 03
None time:  0.8775880471803248
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 86.67
   Final Test: 61.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.187111031031236
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.10
Split: 02, Run: 02
None time:  0.7792090480215847
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.70
Split: 02, Run: 03
None time:  0.7167114820331335
None Run 06:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5857206259388477
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 63.00
Split: 03, Run: 02
None time:  0.8214512141421437
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 62.70
Split: 03, Run: 03
None time:  0.8952369370963424
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 62.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2474029089789838
None Run 10:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 55.90
Split: 04, Run: 02
None time:  0.8083476731553674
None Run 11:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 65.40
Split: 04, Run: 03
None time:  0.7744555298704654
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 65.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9879628629423678
None Run 13:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.60
Split: 05, Run: 02
None time:  0.9529018590692431
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.20
Split: 05, Run: 03
None time:  0.7686089798808098
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.138086035149172
None Run 16:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 65.40
Split: 06, Run: 02
None time:  0.7505799368955195
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.90
Split: 06, Run: 03
None time:  0.7385298279114068
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: -1700.0828, Train: 80.00%, Valid: 57.60% Test: 58.80%
Split: 07, Run: 01
None time:  2.5009237499907613
None Run 19:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 80.00
   Final Test: 59.10
Split: 07, Run: 02
None time:  0.7834808009210974
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 86.67
   Final Test: 60.00
Split: 07, Run: 03
None time:  0.8196178211364895
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 93.33
   Final Test: 60.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1489418870769441
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 67.30
Split: 08, Run: 02
None time:  0.7540727369487286
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 68.10
Split: 08, Run: 03
None time:  0.7774651399813592
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7849854910746217
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 64.70
Split: 09, Run: 02
None time:  0.7884994221385568
None Run 26:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.80
Split: 09, Run: 03
None time:  0.8256906268652529
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2442909290548414
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 67.00
Split: 10, Run: 02
None time:  0.8105551139451563
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  0.718873776961118
None Run 30:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.60
run time now: 2.820380687713623
total time:  31.899826952954754
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.13 ± 3.75
  Final Train: 95.22 ± 5.85
   Final Test: 64.53 ± 3.25
best run test_acc: 65.29000091552734
[I 2023-06-12 00:00:13,610] Trial 81 finished with value: 65.13333129882812 and parameters: {'Fwd': 0.03626964495388537, 'K': 10, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 0.6627629563492057, 'loop': 2, 'loss': 'CE', 'lr': 0.00030535678636858663, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00020123405064433994, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.00035995246033357917
weight_decay:  0.00015966002352747725
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1791692359838635
None Run 01:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 93.33
   Final Test: 62.90
Split: 01, Run: 02
None time:  1.0682564100716263
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 63.10
Split: 01, Run: 03
None time:  0.655276333913207
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 96.67
   Final Test: 63.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.227160558803007
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.50
Split: 02, Run: 02
None time:  0.7358072330243886
None Run 05:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 03
None time:  0.687968502053991
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1064599710516632
None Run 07:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.00
Split: 03, Run: 02
None time:  0.7115181048866361
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 03
None time:  0.6612246390432119
None Run 09:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3783500629942864
None Run 10:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 57.20
Split: 04, Run: 02
None time:  0.6822338588535786
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 64.60
Split: 04, Run: 03
None time:  0.7962238830514252
None Run 12:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 64.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.0398205360397696
None Run 13:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.00
Split: 05, Run: 02
None time:  0.7693384829908609
None Run 14:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.70
Split: 05, Run: 03
None time:  0.7273385871667415
None Run 15:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1203227450605482
None Run 16:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 66.50
Split: 06, Run: 02
None time:  0.796139758778736
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.60
Split: 06, Run: 03
None time:  0.7762541559059173
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.393153219949454
None Run 19:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 83.33
   Final Test: 59.50
Split: 07, Run: 02
None time:  1.0330676650628448
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 83.33
   Final Test: 59.00
Split: 07, Run: 03
None time:  0.8620327899698168
None Run 21:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 86.67
   Final Test: 58.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2402085361536592
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 65.30
Split: 08, Run: 02
None time:  0.7464184169657528
None Run 23:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 68.70
Split: 08, Run: 03
None time:  0.7320056711323559
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 66.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5876359038520604
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 65.00
Split: 09, Run: 02
None time:  0.7571939760819077
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.10
Split: 09, Run: 03
None time:  0.6947279318701476
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1307717449963093
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 67.30
Split: 10, Run: 02
None time:  0.7257370101287961
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.40
Split: 10, Run: 03
None time:  0.7174060731194913
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 2.6167056560516357
total time:  28.811679663835093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.11 ± 3.85
  Final Train: 95.89 ± 4.85
   Final Test: 64.79 ± 3.26
best run test_acc: 65.72999572753906
[I 2023-06-12 00:00:42,970] Trial 82 finished with value: 65.1066665649414 and parameters: {'Fwd': 0.09403205185069756, 'K': 10, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 0.9129404006375539, 'loop': 2, 'loss': 'CE', 'lr': 0.00035995246033357917, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00015966002352747725, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.00025117793079931664
weight_decay:  6.984807485339822e-05
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2088213039096445
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 93.33
   Final Test: 61.00
Split: 01, Run: 02
None time:  1.6146649229340255
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 90.00
   Final Test: 61.40
Split: 01, Run: 03
None time:  1.0817801859229803
None Run 03:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 93.33
   Final Test: 59.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4252471479121596
None Run 04:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.80
Split: 02, Run: 02
None time:  0.8721896579954773
None Run 05:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.30
Split: 02, Run: 03
None time:  0.9843494750093669
None Run 06:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.188128471840173
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 63.20
Split: 03, Run: 02
None time:  0.8154557680245489
None Run 08:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 03
None time:  0.7938312829937786
None Run 09:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.45214623096399
None Run 10:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 96.67
   Final Test: 56.40
Split: 04, Run: 02
None time:  0.8129127160646021
None Run 11:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 96.67
   Final Test: 61.70
Split: 04, Run: 03
None time:  0.8021152010187507
None Run 12:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 62.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2098434451036155
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.00
Split: 05, Run: 02
None time:  0.8904757269192487
None Run 14:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.70
Split: 05, Run: 03
None time:  0.8866873511578888
None Run 15:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2876890010666102
None Run 16:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 65.30
Split: 06, Run: 02
None time:  0.7617952309083194
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 65.80
Split: 06, Run: 03
None time:  0.8365207971073687
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0163177580107003
None Run 19:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 80.00
   Final Test: 60.30
Split: 07, Run: 02
None time:  0.7928649771492928
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 90.00
   Final Test: 58.90
Split: 07, Run: 03
None time:  0.8653349559754133
None Run 21:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 90.00
   Final Test: 59.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1841412521898746
None Run 22:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 67.30
Split: 08, Run: 02
None time:  0.8446870890911669
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 67.90
Split: 08, Run: 03
None time:  0.757659297902137
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 65.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.732652063947171
None Run 25:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 90.00
   Final Test: 63.10
Split: 09, Run: 02
None time:  0.8559778360649943
None Run 26:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 61.90
Split: 09, Run: 03
None time:  0.8260348341427743
None Run 27:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 61.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3525228509679437
None Run 28:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 65.80
Split: 10, Run: 02
None time:  0.842260398901999
None Run 29:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.00
Split: 10, Run: 03
None time:  0.7759738708846271
None Run 30:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 66.10
run time now: 3.013124942779541
total time:  32.80703112320043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.36 ± 4.00
  Final Train: 95.44 ± 4.50
   Final Test: 63.62 ± 3.17
best run test_acc: 64.72999572753906
[I 2023-06-12 00:01:16,233] Trial 83 finished with value: 64.36000061035156 and parameters: {'Fwd': 0.06486162238094832, 'K': 9, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 0.3743509065329764, 'loop': 2, 'loss': 'CE', 'lr': 0.00025117793079931664, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.984807485339822e-05, 'weightedloss': False}. Best is trial 46 with value: 66.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00043146609808163725
weight_decay:  0.00011138728675715785
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8071241800207645
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 63.33
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.0892153100576252
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 70.00
   Final Test: 65.90
Split: 01, Run: 03
None time:  0.9410824929364026
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 70.00
   Final Test: 64.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.220901328139007
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.70
Split: 02, Run: 02
None time:  0.8326995619572699
None Run 05:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.20
Split: 02, Run: 03
None time:  1.1425001029856503
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 86.67
   Final Test: 69.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0939737809821963
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.80
Split: 03, Run: 02
None time:  0.8832020880654454
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  0.9015331938862801
None Run 09:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5133558481466025
None Run 10:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 90.00
   Final Test: 55.20
Split: 04, Run: 02
None time:  0.7906145160086453
None Run 11:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 64.90
Split: 04, Run: 03
None time:  0.9046601448208094
None Run 12:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 65.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5655340610537678
None Run 13:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.80
Split: 05, Run: 02
None time:  0.9789081821218133
None Run 14:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.20
Split: 05, Run: 03
None time:  0.8191924782004207
None Run 15:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0746504680719227
None Run 16:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 60.30
Split: 06, Run: 02
None time:  0.8901811828836799
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.10
Split: 06, Run: 03
None time:  0.8716726501006633
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3522852358873934
None Run 19:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 86.67
   Final Test: 58.50
Split: 07, Run: 02
None time:  0.8294145790860057
None Run 20:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 59.90
Split: 07, Run: 03
None time:  0.899561433121562
None Run 21:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 96.67
   Final Test: 59.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.218124947976321
None Run 22:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 83.33
   Final Test: 67.10
Split: 08, Run: 02
None time:  0.9370935680344701
None Run 23:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 70.10
Split: 08, Run: 03
None time:  0.8644955630879849
None Run 24:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 69.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3703040319960564
None Run 25:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 86.67
   Final Test: 59.10
Split: 09, Run: 02
None time:  0.8848715878557414
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 67.20
Split: 09, Run: 03
None time:  0.9792385851033032
None Run 27:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 66.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3404326350428164
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 66.40
Split: 10, Run: 02
None time:  0.8963896851055324
None Run 29:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
Split: 10, Run: 03
None time:  0.8384900619275868
None Run 30:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.1183154582977295
total time:  32.80844767601229
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.19 ± 4.59
  Final Train: 92.78 ± 9.71
   Final Test: 65.46 ± 3.91
best run test_acc: 66.99000549316406
[I 2023-06-12 00:01:49,432] Trial 84 finished with value: 66.1866683959961 and parameters: {'Fwd': 0.024236196743914293, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 1.261025365479354, 'loop': 2, 'loss': 'CE', 'lr': 0.00043146609808163725, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00011138728675715785, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00043901917124259033
weight_decay:  0.00013349869919861544
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6098183719441295
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 70.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  1.0975496480241418
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 60.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.001774256117642
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 63.33
   Final Test: 66.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.176747770048678
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.00
Split: 02, Run: 02
None time:  0.8503691209480166
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 03
None time:  0.9256970051210374
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.290764685953036
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 64.90
Split: 03, Run: 02
None time:  0.9386608088389039
None Run 08:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.10
Split: 03, Run: 03
None time:  0.9107250769156963
None Run 09:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.095101977000013
None Run 10:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 90.00
   Final Test: 54.00
Split: 04, Run: 02
None time:  0.8431227500550449
None Run 11:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 63.10
Split: 04, Run: 03
None time:  0.8950411160476506
None Run 12:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 63.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.761637075105682
None Run 13:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 63.80
Split: 05, Run: 02
None time:  0.9630451421253383
None Run 14:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.20
Split: 05, Run: 03
None time:  0.9544658169616014
None Run 15:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5169733560178429
None Run 16:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 80.00
   Final Test: 63.20
Split: 06, Run: 02
None time:  0.9352700118906796
None Run 17:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.70
Split: 06, Run: 03
None time:  0.8832879739347845
None Run 18:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 67.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.588183576008305
None Run 19:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 76.67
   Final Test: 58.10
Split: 07, Run: 02
None time:  0.8975044549442828
None Run 20:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 86.67
   Final Test: 60.30
Split: 07, Run: 03
None time:  0.8286002960521728
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 86.67
   Final Test: 60.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0530504861380905
None Run 22:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 83.33
   Final Test: 59.10
Split: 08, Run: 02
None time:  0.8756470591761172
None Run 23:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.30
Split: 08, Run: 03
None time:  0.9199452551547438
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 68.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2863364908844233
None Run 25:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 65.10
Split: 09, Run: 02
None time:  1.0749235360417515
None Run 26:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 66.80
Split: 09, Run: 03
None time:  0.9023227610159665
None Run 27:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 67.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2829674920067191
None Run 28:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 86.67
   Final Test: 64.10
Split: 10, Run: 02
None time:  0.8739232949446887
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 69.70
Split: 10, Run: 03
None time:  0.8156714839860797
None Run 30:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 70.10
run time now: 3.015557289123535
total time:  33.11699756607413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.92 ± 4.56
  Final Train: 90.44 ± 10.89
   Final Test: 65.24 ± 3.81
best run test_acc: 66.87999725341797
[I 2023-06-12 00:02:23,093] Trial 85 finished with value: 65.91999816894531 and parameters: {'Fwd': 0.020703791098368382, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 0.6723594679264466, 'loop': 2, 'loss': 'CE', 'lr': 0.00043901917124259033, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00013349869919861544, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0005866183990534428
weight_decay:  5.762585888940083e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6863008639775217
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 60.00
   Final Test: 63.80
Split: 01, Run: 02
None time:  0.9049945529550314
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 73.33
   Final Test: 66.30
Split: 01, Run: 03
None time:  0.9761466679628938
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 73.33
   Final Test: 65.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2987868869677186
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 86.67
   Final Test: 66.30
Split: 02, Run: 02
None time:  0.8602041460108012
None Run 05:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 68.70
Split: 02, Run: 03
None time:  0.8740952860098332
None Run 06:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9958811870310456
None Run 07:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.20
Split: 03, Run: 02
None time:  0.9133152470458299
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.20
Split: 03, Run: 03
None time:  0.8694958658888936
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7071885201148689
None Run 10:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 73.33
   Final Test: 55.50
Split: 04, Run: 02
None time:  0.8447148869745433
None Run 11:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 66.80
Split: 04, Run: 03
None time:  0.9017925981897861
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 65.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7175875841639936
None Run 13:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 96.67
   Final Test: 61.30
Split: 05, Run: 02
None time:  0.8595084040425718
None Run 14:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.40
Split: 05, Run: 03
None time:  0.8847106620669365
None Run 15:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2864474148955196
None Run 16:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 80.00
   Final Test: 59.60
Split: 06, Run: 02
None time:  0.897059076000005
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.10
Split: 06, Run: 03
None time:  0.9029259148519486
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5432985650841147
None Run 19:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 76.67
   Final Test: 56.60
Split: 07, Run: 02
None time:  0.8849065990652889
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 83.33
   Final Test: 58.60
Split: 07, Run: 03
None time:  0.8749609480146319
None Run 21:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 83.33
   Final Test: 58.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.396215320797637
None Run 22:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 70.00
   Final Test: 58.90
Split: 08, Run: 02
None time:  0.9022009570617229
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 68.50
Split: 08, Run: 03
None time:  0.9119059960357845
None Run 24:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 67.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4231604470405728
None Run 25:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 70.00
   Final Test: 50.40
Split: 09, Run: 02
None time:  0.8586805940140039
None Run 26:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 67.00
Split: 09, Run: 03
None time:  0.8618847317993641
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 66.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.004085071850568
None Run 28:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 63.60
Split: 10, Run: 02
None time:  0.9682358149439096
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 10, Run: 03
None time:  0.8504559979774058
None Run 30:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.8690316677093506
total time:  32.91884229006246
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.19 ± 5.55
  Final Train: 89.11 ± 11.68
   Final Test: 63.78 ± 4.84
best run test_acc: 66.3699951171875
[I 2023-06-12 00:02:56,448] Trial 86 finished with value: 64.19332885742188 and parameters: {'Fwd': 0.007540259670681576, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 1.7378328964863565, 'loop': 2, 'loss': 'CE', 'lr': 0.0005866183990534428, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.762585888940083e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0004995270880484737
weight_decay:  0.0002926954961991808
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1064366928767413
None Run 01:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 46.00
Split: 01, Run: 02
None time:  0.9376875120215118
None Run 02:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 47.00
Split: 01, Run: 03
None time:  0.9406302471179515
None Run 03:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 46.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4369648359715939
None Run 04:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 61.30
Split: 02, Run: 02
None time:  0.8847563061863184
None Run 05:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.00
Split: 02, Run: 03
None time:  1.235555921914056
None Run 06:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3904184619896114
None Run 07:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 55.10
Split: 03, Run: 02
None time:  0.9263837828766555
None Run 08:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 55.60
Split: 03, Run: 03
None time:  0.9874248791020364
None Run 09:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 55.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9537971350364387
None Run 10:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 49.70
Split: 04, Run: 02
None time:  1.2834768239408731
None Run 11:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 90.00
   Final Test: 49.60
Split: 04, Run: 03
None time:  0.8449068241752684
None Run 12:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 50.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2659520017914474
None Run 13:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 96.67
   Final Test: 51.40
Split: 05, Run: 02
None time:  0.8584438438992947
None Run 14:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 51.40
Split: 05, Run: 03
None time:  0.9613973980303854
None Run 15:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 51.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0072779431939125
None Run 16:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 62.60
Split: 06, Run: 02
None time:  0.9914297859650105
None Run 17:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 62.90
Split: 06, Run: 03
None time:  1.1051306510344148
None Run 18:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.118942832108587
None Run 19:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 96.67
   Final Test: 49.80
Split: 07, Run: 02
None time:  0.9239636578131467
None Run 20:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 50.30
Split: 07, Run: 03
None time:  0.9897638040129095
None Run 21:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 50.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.067790247965604
None Run 22:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.80
Split: 08, Run: 02
None time:  0.8710175198502839
None Run 23:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.30
Split: 08, Run: 03
None time:  0.9888895459007472
None Run 24:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.560776332160458
None Run 25:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 61.10
Split: 09, Run: 02
None time:  1.1995882499031723
None Run 26:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 60.70
Split: 09, Run: 03
None time:  1.0022617850918323
None Run 27:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 60.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4950974399689585
None Run 28:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 90.00
   Final Test: 61.60
Split: 10, Run: 02
None time:  0.9523494858294725
None Run 29:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.20
Split: 10, Run: 03
None time:  1.0207739300094545
None Run 30:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 61.70
run time now: 3.5115208625793457
total time:  33.40815762593411
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.25 ± 7.90
  Final Train: 98.22 ± 2.87
   Final Test: 56.17 ± 6.02
best run test_acc: 56.43999481201172
[I 2023-06-12 00:03:30,412] Trial 87 finished with value: 57.25333786010742 and parameters: {'Fwd': 0.019468071296363423, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 0.8310285288943808, 'loop': 2, 'loss': 'CE', 'lr': 0.0004995270880484737, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002926954961991808, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00045599477926518763
weight_decay:  0.0004153843660626381
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5701250340789557
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 70.00
   Final Test: 63.50
Split: 01, Run: 02
None time:  1.0014394458848983
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 70.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  1.0982722600456327
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 70.00
   Final Test: 60.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.519876141101122
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 86.67
   Final Test: 70.10
Split: 02, Run: 02
None time:  0.9212030528578907
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.40
Split: 02, Run: 03
None time:  0.8417204939760268
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9704177370294929
None Run 07:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 60.10
Split: 03, Run: 02
None time:  0.9123772580642253
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.70
Split: 03, Run: 03
None time:  0.934481258969754
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5264802239835262
None Run 10:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 83.33
   Final Test: 54.50
Split: 04, Run: 02
None time:  0.8854216099716723
None Run 11:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 96.67
   Final Test: 56.80
Split: 04, Run: 03
None time:  0.957992099924013
None Run 12:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 96.67
   Final Test: 58.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5241066701710224
None Run 13:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 67.50
Split: 05, Run: 02
None time:  1.1605073160026222
None Run 14:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 68.00
Split: 05, Run: 03
None time:  1.3927003340795636
None Run 15:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 66.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.095814618980512
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 83.33
   Final Test: 64.50
Split: 06, Run: 02
None time:  0.8809641320258379
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.90
Split: 06, Run: 03
None time:  0.8360319640487432
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 67.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.27236801199615
None Run 19:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 83.33
   Final Test: 57.00
Split: 07, Run: 02
None time:  0.8559548780322075
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 96.67
   Final Test: 59.50
Split: 07, Run: 03
None time:  0.8803859290201217
None Run 21:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 93.33
   Final Test: 60.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.3540359078906476
None Run 22:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 70.00
   Final Test: 56.30
Split: 08, Run: 02
None time:  0.8115369030274451
None Run 23:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 68.50
Split: 08, Run: 03
None time:  0.9402326389681548
None Run 24:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 90.00
   Final Test: 68.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8860247069969773
None Run 25:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 56.80
Split: 09, Run: 02
None time:  0.8879704100545496
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.00
Split: 09, Run: 03
None time:  0.762403923086822
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2116958510596305
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 86.67
   Final Test: 65.60
Split: 10, Run: 02
None time:  0.8221450890414417
None Run 29:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 10, Run: 03
None time:  0.914083719952032
None Run 30:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 70.30
run time now: 2.9911224842071533
total time:  32.71505613299087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.85 ± 6.00
  Final Train: 91.11 ± 9.88
   Final Test: 64.22 ± 4.93
best run test_acc: 66.12999725341797
[I 2023-06-12 00:04:03,674] Trial 88 finished with value: 64.85333251953125 and parameters: {'Fwd': 0.013005726207829645, 'K': 10, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 1.0815832713497968, 'loop': 2, 'loss': 'CE', 'lr': 0.00045599477926518763, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0004153843660626381, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0004222016822729848
weight_decay:  4.8818241287292744e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7222729588393122
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 60.00
   Final Test: 65.30
Split: 01, Run: 02
None time:  0.975016315933317
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 80.00
   Final Test: 65.10
Split: 01, Run: 03
None time:  0.981371118221432
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 80.00
   Final Test: 64.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4958869721740484
None Run 04:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 80.00
   Final Test: 66.90
Split: 02, Run: 02
None time:  0.9047926221974194
None Run 05:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 67.50
Split: 02, Run: 03
None time:  0.845019614091143
None Run 06:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.4077777089551091
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 86.67
   Final Test: 64.60
Split: 03, Run: 02
None time:  0.8819784128572792
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.40
Split: 03, Run: 03
None time:  0.8418410299345851
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.430218025809154
None Run 10:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 66.00
Split: 04, Run: 02
None time:  0.8613915028981864
None Run 11:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 93.33
   Final Test: 67.70
Split: 04, Run: 03
None time:  1.0371610599104315
None Run 12:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 90.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.861287659034133
None Run 13:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 90.00
   Final Test: 61.50
Split: 05, Run: 02
None time:  1.0071644010022283
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 62.10
Split: 05, Run: 03
None time:  0.9198705451563001
None Run 15:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 62.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9781580970156938
None Run 16:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 60.30
Split: 06, Run: 02
None time:  1.0010651268530637
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.00
Split: 06, Run: 03
None time:  0.864298335975036
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: -13734.0840, Train: 60.00%, Valid: 56.80% Test: 60.60%
Split: 07, Run: 01
None time:  2.421390817966312
None Run 19:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 60.00
   Final Test: 60.60
Split: 07, Run: 02
None time:  0.9114399601239711
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 76.67
   Final Test: 59.80
Split: 07, Run: 03
None time:  0.9007579791359603
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 76.67
   Final Test: 60.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1038158191367984
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 80.00
   Final Test: 61.90
Split: 08, Run: 02
None time:  0.8987539790105075
None Run 23:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 90.00
   Final Test: 68.10
Split: 08, Run: 03
None time:  0.8689366350881755
None Run 24:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 90.00
   Final Test: 68.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7455970591399819
None Run 25:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 73.33
   Final Test: 63.70
Split: 09, Run: 02
None time:  0.8631628479342908
None Run 26:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 86.67
   Final Test: 67.50
Split: 09, Run: 03
None time:  0.9017578810453415
None Run 27:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 90.00
   Final Test: 67.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.423545298865065
None Run 28:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 80.00
   Final Test: 64.90
Split: 10, Run: 02
None time:  0.8905042759142816
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 69.00
Split: 10, Run: 03
None time:  0.841958133969456
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 68.60
run time now: 3.2006096839904785
total time:  34.833864639978856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.77 ± 3.65
  Final Train: 87.33 ± 10.66
   Final Test: 65.24 ± 2.86
best run test_acc: 66.41999816894531
[I 2023-06-12 00:04:38,998] Trial 89 finished with value: 65.76666259765625 and parameters: {'Fwd': 0.023534075448014714, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 0.11079786000587544, 'loop': 2, 'loss': 'CE', 'lr': 0.0004222016822729848, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.8818241287292744e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0007728940737301953
weight_decay:  0.00013669644385339288
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3337083170190454
None Run 01:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 66.67
   Final Test: 58.70
Split: 01, Run: 02
None time:  0.9393042079173028
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 80.00
   Final Test: 66.00
Split: 01, Run: 03
None time:  0.9147638271097094
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 80.00
   Final Test: 65.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1468605110421777
None Run 04:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 86.67
   Final Test: 64.90
Split: 02, Run: 02
None time:  0.9398040778469294
None Run 05:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.20
Split: 02, Run: 03
None time:  0.8096259080339223
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0115406149998307
None Run 07:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 96.67
   Final Test: 61.50
Split: 03, Run: 02
None time:  0.821088198106736
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.00
Split: 03, Run: 03
None time:  0.8289720518514514
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.85305119282566
None Run 10:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 73.33
   Final Test: 63.90
Split: 04, Run: 02
None time:  0.797763611888513
None Run 11:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 68.00
Split: 04, Run: 03
None time:  0.8567083568777889
None Run 12:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 66.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.9681322008837014
None Run 13:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 48.70
Split: 05, Run: 02
None time:  0.9220735940616578
None Run 14:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.20
Split: 05, Run: 03
None time:  0.9765952050220221
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1536917928606272
None Run 16:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 90.00
   Final Test: 57.70
Split: 06, Run: 02
None time:  0.8459237350616604
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.70
Split: 06, Run: 03
None time:  0.9619604030158371
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0477223619818687
None Run 19:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 90.00
   Final Test: 56.10
Split: 07, Run: 02
None time:  0.8224041999783367
None Run 20:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 96.67
   Final Test: 58.10
Split: 07, Run: 03
None time:  0.9114601570181549
None Run 21:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 96.67
   Final Test: 58.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4761107941158116
None Run 22:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 73.33
   Final Test: 62.70
Split: 08, Run: 02
None time:  0.8439241959713399
None Run 23:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 83.33
   Final Test: 67.80
Split: 08, Run: 03
None time:  0.8511380760464817
None Run 24:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 80.00
   Final Test: 65.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7823955600615591
None Run 25:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 48.50
Split: 09, Run: 02
None time:  0.91004080302082
None Run 26:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 64.40
Split: 09, Run: 03
None time:  0.8863597630988806
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0949879221152514
None Run 28:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 63.20
Split: 10, Run: 02
None time:  0.8489715529140085
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.20
Split: 10, Run: 03
None time:  0.9027499060612172
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.889951229095459
total time:  30.52083415305242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.69 ± 5.51
  Final Train: 91.78 ± 9.46
   Final Test: 63.59 ± 5.56
best run test_acc: 66.5
[I 2023-06-12 00:05:10,052] Trial 90 finished with value: 63.686668395996094 and parameters: {'Fwd': 0.022158382973142935, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 0.2159143092192362, 'loop': 2, 'loss': 'CE', 'lr': 0.0007728940737301953, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00013669644385339288, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0004021114286856907
weight_decay:  4.166523266394701e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7750715289730579
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 76.67
   Final Test: 64.20
Split: 01, Run: 02
None time:  1.1105886900331825
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 66.67
   Final Test: 62.30
Split: 01, Run: 03
None time:  0.9712879960425198
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 80.00
   Final Test: 63.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9694848181679845
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.80
Split: 02, Run: 02
None time:  0.8976304680109024
None Run 05:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.70
Split: 02, Run: 03
None time:  0.8476129220798612
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3810555229429156
None Run 07:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 63.40
Split: 03, Run: 02
None time:  0.8249692970421165
None Run 08:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.30
Split: 03, Run: 03
None time:  0.8856025729328394
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4018015810288489
None Run 10:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 93.33
   Final Test: 57.90
Split: 04, Run: 02
None time:  0.9376701470464468
None Run 11:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 62.80
Split: 04, Run: 03
None time:  0.9145255461335182
None Run 12:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 64.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5835716659203172
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.00
Split: 05, Run: 02
None time:  1.3514847459737211
None Run 14:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 64.30
Split: 05, Run: 03
None time:  0.9429307878017426
None Run 15:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2121569430455565
None Run 16:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 86.67
   Final Test: 61.90
Split: 06, Run: 02
None time:  0.7907052040100098
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.10
Split: 06, Run: 03
None time:  0.9336845129728317
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9567983909510076
None Run 19:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 70.00
   Final Test: 58.30
Split: 07, Run: 02
None time:  1.1871811079327017
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 76.67
   Final Test: 58.30
Split: 07, Run: 03
None time:  1.0957415699958801
None Run 21:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 76.67
   Final Test: 57.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.066099711926654
None Run 22:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 93.33
   Final Test: 58.60
Split: 08, Run: 02
None time:  0.8861531659495085
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 67.50
Split: 08, Run: 03
None time:  0.910998617997393
None Run 24:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 90.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6690325699746609
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 76.67
   Final Test: 61.50
Split: 09, Run: 02
None time:  0.8606706710997969
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 67.00
Split: 09, Run: 03
None time:  0.8745069799479097
None Run 27:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 67.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.765898167854175
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 86.67
   Final Test: 66.90
Split: 10, Run: 02
None time:  0.8536793298553675
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 69.10
Split: 10, Run: 03
None time:  0.8369004030246288
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 68.80
run time now: 3.4987359046936035
total time:  34.786880569998175
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.64 ± 4.40
  Final Train: 90.33 ± 9.64
   Final Test: 64.79 ± 3.99
best run test_acc: 66.44999694824219
[I 2023-06-12 00:05:45,345] Trial 91 finished with value: 65.63999938964844 and parameters: {'Fwd': 0.03824074552516335, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 0.66916710630146, 'loop': 2, 'loss': 'CE', 'lr': 0.0004021114286856907, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.166523266394701e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0004046153573667708
weight_decay:  7.294512852283208e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.777680492028594
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 70.00
   Final Test: 65.30
Split: 01, Run: 02
None time:  0.9280662320088595
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 83.33
   Final Test: 65.40
Split: 01, Run: 03
None time:  1.0261082218494266
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 73.33
   Final Test: 63.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.32091514300555
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 83.33
   Final Test: 68.80
Split: 02, Run: 02
None time:  0.9517768360674381
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 69.30
Split: 02, Run: 03
None time:  0.8443279899656773
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6870271798688918
None Run 07:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 86.67
   Final Test: 62.70
Split: 03, Run: 02
None time:  0.9212818581145257
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 64.70
Split: 03, Run: 03
None time:  0.8881015339866281
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 64.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8919169860891998
None Run 10:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 96.67
   Final Test: 52.10
Split: 04, Run: 02
None time:  0.8532083812169731
None Run 11:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 93.33
   Final Test: 64.00
Split: 04, Run: 03
None time:  0.9337759278714657
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 93.33
   Final Test: 65.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3015725021250546
None Run 13:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 93.33
   Final Test: 61.20
Split: 05, Run: 02
None time:  0.9138058240059763
None Run 14:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.20
Split: 05, Run: 03
None time:  0.9348314618691802
None Run 15:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.2479110120330006
None Run 16:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 86.67
   Final Test: 63.10
Split: 06, Run: 02
None time:  0.8800623058341444
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.00
Split: 06, Run: 03
None time:  0.8895879609044641
None Run 18:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9642630629241467
None Run 19:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 73.33
   Final Test: 60.00
Split: 07, Run: 02
None time:  0.7665759059600532
None Run 20:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 83.33
   Final Test: 59.70
Split: 07, Run: 03
None time:  0.904128243913874
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 83.33
   Final Test: 60.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0641328729689121
None Run 22:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 80.00
   Final Test: 65.40
Split: 08, Run: 02
None time:  0.9949461279902607
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 90.00
   Final Test: 68.60
Split: 08, Run: 03
None time:  0.8802461461164057
None Run 24:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 90.00
   Final Test: 69.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9638300079386681
None Run 25:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 57.20
Split: 09, Run: 02
None time:  0.7846150600817055
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.30
Split: 09, Run: 03
None time:  0.8353597579989582
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9764055251143873
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 90.00
   Final Test: 65.80
Split: 10, Run: 02
None time:  0.8441410211380571
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.10
Split: 10, Run: 03
None time:  0.9167758559342474
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.10
run time now: 2.783297061920166
total time:  32.17606438300572
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.00 ± 4.93
  Final Train: 90.56 ± 8.54
   Final Test: 64.59 ± 3.92
best run test_acc: 66.18000030517578
[I 2023-06-12 00:06:17,949] Trial 92 finished with value: 64.99999237060547 and parameters: {'Fwd': 0.03668167370750417, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 0.03250340074990679, 'loop': 2, 'loss': 'CE', 'lr': 0.0004046153573667708, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.294512852283208e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0005648894447870596
weight_decay:  4.4789115039103475e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4819517750293016
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 66.67
   Final Test: 64.60
Split: 01, Run: 02
None time:  0.9088384308852255
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 70.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  0.9903737499844283
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 73.33
   Final Test: 66.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.012604058953002
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.60
Split: 02, Run: 02
None time:  0.9000287870876491
None Run 05:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 02, Run: 03
None time:  0.9579393779858947
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3923467451240867
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 63.10
Split: 03, Run: 02
None time:  0.916730587137863
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.80
Split: 03, Run: 03
None time:  0.796880068955943
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.3570988241117448
None Run 10:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 76.67
   Final Test: 54.80
Split: 04, Run: 02
None time:  0.8049365929327905
None Run 11:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 67.30
Split: 04, Run: 03
None time:  0.8717230029869825
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1473585648927838
None Run 13:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 67.40
Split: 05, Run: 02
None time:  0.9193544539157301
None Run 14:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 66.10
Split: 05, Run: 03
None time:  0.8931660440284759
None Run 15:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1594158539082855
None Run 16:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 86.67
   Final Test: 56.00
Split: 06, Run: 02
None time:  0.8798333979211748
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 68.90
Split: 06, Run: 03
None time:  0.9107309661339968
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5240206508897245
None Run 19:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 73.33
   Final Test: 56.50
Split: 07, Run: 02
None time:  0.9692917258944362
None Run 20:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 83.33
   Final Test: 57.80
Split: 07, Run: 03
None time:  0.8962137140333652
None Run 21:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 83.33
   Final Test: 59.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6791032541077584
None Run 22:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 63.33
   Final Test: 58.60
Split: 08, Run: 02
None time:  0.8506778231821954
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 67.00
Split: 08, Run: 03
None time:  0.9123116810806096
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 83.33
   Final Test: 66.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5902923739049584
None Run 25:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 70.00
   Final Test: 57.20
Split: 09, Run: 02
None time:  0.8660011168103665
None Run 26:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 68.70
Split: 09, Run: 03
None time:  0.9112132659647614
None Run 27:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 68.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2063345210626721
None Run 28:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 83.33
   Final Test: 65.00
Split: 10, Run: 02
None time:  0.8596197511069477
None Run 29:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 93.33
   Final Test: 70.70
Split: 10, Run: 03
None time:  0.8283276199363172
None Run 30:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 69.90
run time now: 2.9393115043640137
total time:  32.51290819607675
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.65 ± 5.08
  Final Train: 88.22 ± 11.44
   Final Test: 65.03 ± 4.77
best run test_acc: 67.4000015258789
[I 2023-06-12 00:06:50,857] Trial 93 finished with value: 65.64665985107422 and parameters: {'Fwd': 0.011791834773092957, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 0.7370011050815658, 'loop': 2, 'loss': 'CE', 'lr': 0.0005648894447870596, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.4789115039103475e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0006011474506095521
weight_decay:  4.973987905120082e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3389763380400836
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 66.67
   Final Test: 60.70
Split: 01, Run: 02
None time:  0.750628957990557
None Run 02:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 70.00
   Final Test: 62.50
Split: 01, Run: 03
None time:  0.6811164189130068
None Run 03:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 83.33
   Final Test: 62.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.9896584500093013
None Run 04:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 86.67
   Final Test: 69.30
Split: 02, Run: 02
None time:  0.6172961730044335
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.80
Split: 02, Run: 03
None time:  0.7409411671105772
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 70.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0468194340355694
None Run 07:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 90.00
   Final Test: 54.90
Split: 03, Run: 02
None time:  0.6381351521704346
None Run 08:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 03
None time:  0.7104155039414763
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5937002629507333
None Run 10:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 66.67
   Final Test: 61.40
Split: 04, Run: 02
None time:  0.7296665511094034
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 86.67
   Final Test: 65.50
Split: 04, Run: 03
None time:  0.6921120861079544
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8966406651306897
None Run 13:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.50
Split: 05, Run: 02
None time:  1.1513346971478313
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 64.70
Split: 05, Run: 03
None time:  0.6613394271116704
None Run 15:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.047151025151834
None Run 16:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 86.67
   Final Test: 59.20
Split: 06, Run: 02
None time:  0.7773164249956608
None Run 17:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.00
Split: 06, Run: 03
None time:  0.7030638291034847
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3885047449730337
None Run 19:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 76.67
   Final Test: 57.10
Split: 07, Run: 02
None time:  0.6901437127962708
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 86.67
   Final Test: 59.90
Split: 07, Run: 03
None time:  0.6300429080147296
None Run 21:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 83.33
   Final Test: 59.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0055946039501578
None Run 22:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 70.00
   Final Test: 53.40
Split: 08, Run: 02
None time:  0.6670246270950884
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 68.70
Split: 08, Run: 03
None time:  0.735961503116414
None Run 24:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 86.67
   Final Test: 68.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3301942930556834
None Run 25:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 70.00
   Final Test: 58.50
Split: 09, Run: 02
None time:  0.6590117970481515
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.20
Split: 09, Run: 03
None time:  0.6316537370439619
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 90.00
   Final Test: 67.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3900012602098286
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 86.67
   Final Test: 66.00
Split: 10, Run: 02
None time:  0.6772885541431606
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 68.50
Split: 10, Run: 03
None time:  0.6227960961405188
None Run 30:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 68.50
run time now: 2.733283042907715
total time:  27.292797836940736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.01 ± 4.51
  Final Train: 88.00 ± 10.53
   Final Test: 64.16 ± 4.62
best run test_acc: 66.18000793457031
[I 2023-06-12 00:07:18,602] Trial 94 finished with value: 65.01333618164062 and parameters: {'Fwd': 0.011493057419374711, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 0.7505530645537489, 'loop': 2, 'loss': 'CE', 'lr': 0.0006011474506095521, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.973987905120082e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.25
lr:  0.0005493807492930361
weight_decay:  4.4000742552646133e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5210255989804864
None Run 01:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 66.67
   Final Test: 59.30
Split: 01, Run: 02
None time:  0.9022735010366887
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.902800110867247
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 67.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.293160568922758
None Run 04:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 80.00
   Final Test: 69.00
Split: 02, Run: 02
None time:  0.8215667139738798
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.00
Split: 02, Run: 03
None time:  1.0517435960937291
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 83.33
   Final Test: 68.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.374950683908537
None Run 07:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 83.33
   Final Test: 62.60
Split: 03, Run: 02
None time:  0.8298242120072246
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 03
None time:  0.8532191158737987
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4582168809138238
None Run 10:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 86.67
   Final Test: 62.40
Split: 04, Run: 02
None time:  0.8702948899008334
None Run 11:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 67.50
Split: 04, Run: 03
None time:  0.8624929888173938
None Run 12:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 67.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.3962731221690774
None Run 13:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 83.33
   Final Test: 51.20
Split: 05, Run: 02
None time:  0.9203613370191306
None Run 14:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 64.00
Split: 05, Run: 03
None time:  0.916870032902807
None Run 15:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 64.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0774271059781313
None Run 16:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 83.33
   Final Test: 56.00
Split: 06, Run: 02
None time:  0.97136774007231
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.30
Split: 06, Run: 03
None time:  0.8739576600492001
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 67.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.887733347946778
None Run 19:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 73.33
   Final Test: 57.70
Split: 07, Run: 02
None time:  0.9155615421477705
None Run 20:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 80.00
   Final Test: 57.40
Split: 07, Run: 03
None time:  0.9216046328656375
None Run 21:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 70.00
   Final Test: 58.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4428502700757235
None Run 22:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 70.00
   Final Test: 56.40
Split: 08, Run: 02
None time:  0.8973133771214634
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 80.00
   Final Test: 67.60
Split: 08, Run: 03
None time:  0.8891655330080539
None Run 24:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 80.00
   Final Test: 66.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.677018990041688
None Run 25:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 73.33
   Final Test: 58.20
Split: 09, Run: 02
None time:  0.8461149940267205
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 64.50
Split: 09, Run: 03
None time:  0.8923928048461676
None Run 27:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 86.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.476644508074969
None Run 28:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 70.00
   Final Test: 64.40
Split: 10, Run: 02
None time:  0.8763280499260873
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 68.80
Split: 10, Run: 03
None time:  0.8455360119696707
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 68.50
run time now: 3.2408368587493896
total time:  33.542378172045574
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.14 ± 5.09
  Final Train: 86.44 ± 10.43
   Final Test: 63.77 ± 4.84
best run test_acc: 66.20999908447266
[I 2023-06-12 00:07:52,584] Trial 95 finished with value: 64.13999938964844 and parameters: {'Fwd': 0.016901742149117903, 'K': 10, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 0.15568298916595963, 'loop': 2, 'loss': 'CE', 'lr': 0.0005493807492930361, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.4000742552646133e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.00043346984766592846
weight_decay:  2.4334054171409167e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6725884031038731
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 76.67
   Final Test: 61.40
Split: 01, Run: 02
None time:  0.9116632319055498
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 61.70
Split: 01, Run: 03
None time:  0.8929254340473562
None Run 03:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 90.00
   Final Test: 60.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2922363949473947
None Run 04:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.30
Split: 02, Run: 02
None time:  0.8867372598033398
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.40
Split: 02, Run: 03
None time:  0.8669553569052368
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1704035471193492
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.70
Split: 03, Run: 02
None time:  0.880842121085152
None Run 08:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.00
Split: 03, Run: 03
None time:  0.9063281379640102
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6123931449837983
None Run 10:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 96.67
   Final Test: 60.50
Split: 04, Run: 02
None time:  0.8447559529449791
None Run 11:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 64.10
Split: 04, Run: 03
None time:  0.8404437708668411
None Run 12:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 63.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1778380039613694
None Run 13:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 66.50
Split: 05, Run: 02
None time:  1.16320172813721
None Run 14:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.30
Split: 05, Run: 03
None time:  1.1314293360337615
None Run 15:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 65.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3280654451809824
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 63.60
Split: 06, Run: 02
None time:  0.8891154229640961
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.60
Split: 06, Run: 03
None time:  0.8365903028752655
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.593248012010008
None Run 19:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 80.00
   Final Test: 57.40
Split: 07, Run: 02
None time:  1.029489940032363
None Run 20:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 86.67
   Final Test: 59.20
Split: 07, Run: 03
None time:  1.2384185090195388
None Run 21:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 83.33
   Final Test: 59.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.220199553994462
None Run 22:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 63.20
Split: 08, Run: 02
None time:  0.8313957909122109
None Run 23:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.80
Split: 08, Run: 03
None time:  0.7951576339546591
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.556730997050181
None Run 25:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 64.10
Split: 09, Run: 02
None time:  0.9770393788348883
None Run 26:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 66.40
Split: 09, Run: 03
None time:  1.0092869859654456
None Run 27:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2965143399778754
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 67.60
Split: 10, Run: 02
None time:  0.8846485069952905
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 10, Run: 03
None time:  0.8616334279067814
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 69.10
run time now: 3.0918209552764893
total time:  33.652187714818865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.18 ± 4.14
  Final Train: 94.22 ± 6.19
   Final Test: 64.96 ± 3.39
best run test_acc: 66.04000091552734
[I 2023-06-12 00:08:26,679] Trial 96 finished with value: 66.18000030517578 and parameters: {'Fwd': 0.07808833649762909, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 1.067936942130702, 'loop': 2, 'loss': 'CE', 'lr': 0.00043346984766592846, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.4334054171409167e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.000429816510269719
weight_decay:  2.179320919483512e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6637118260841817
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 76.67
   Final Test: 64.50
Split: 01, Run: 02
None time:  1.059315225109458
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 76.67
   Final Test: 64.50
Split: 01, Run: 03
None time:  0.8368006569799036
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 65.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1269979199860245
None Run 04:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 66.20
Split: 02, Run: 02
None time:  0.9252549828961492
None Run 05:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.60
Split: 02, Run: 03
None time:  0.7973884099628776
None Run 06:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.232903400901705
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 62.20
Split: 03, Run: 02
None time:  0.9123963399324566
None Run 08:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 03
None time:  0.8873371931258589
None Run 09:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6325332061387599
None Run 10:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 93.33
   Final Test: 65.30
Split: 04, Run: 02
None time:  0.8931107479147613
None Run 11:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 65.10
Split: 04, Run: 03
None time:  0.8938231109641492
None Run 12:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 65.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4228535511065274
None Run 13:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 93.33
   Final Test: 63.30
Split: 05, Run: 02
None time:  0.8455649840179831
None Run 14:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 63.10
Split: 05, Run: 03
None time:  0.9733195391017944
None Run 15:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 62.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4641442550346255
None Run 16:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 83.33
   Final Test: 62.40
Split: 06, Run: 02
None time:  0.8491643501911312
None Run 17:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.00
Split: 06, Run: 03
None time:  0.8710493089165539
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.00098087079823
None Run 19:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 73.33
   Final Test: 60.30
Split: 07, Run: 02
None time:  0.947031055111438
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 86.67
   Final Test: 60.20
Split: 07, Run: 03
None time:  0.8790554942097515
None Run 21:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 86.67
   Final Test: 59.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1755487869959325
None Run 22:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 83.33
   Final Test: 59.90
Split: 08, Run: 02
None time:  0.8437313451431692
None Run 23:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 93.33
   Final Test: 67.70
Split: 08, Run: 03
None time:  0.8386277598328888
None Run 24:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 90.00
   Final Test: 69.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3909446159377694
None Run 25:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 86.67
   Final Test: 60.60
Split: 09, Run: 02
None time:  0.830606876173988
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.60
Split: 09, Run: 03
None time:  0.8027312958147377
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.0721171190962195
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.10
Split: 10, Run: 02
None time:  0.8192623108625412
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.60
Split: 10, Run: 03
None time:  1.0385147770866752
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 69.50
run time now: 2.9707093238830566
total time:  33.02126940805465
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.83 ± 3.68
  Final Train: 92.56 ± 7.62
   Final Test: 64.79 ± 2.88
best run test_acc: 65.87999725341797
[I 2023-06-12 00:09:00,143] Trial 97 finished with value: 65.82667541503906 and parameters: {'Fwd': 0.07631714557574493, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 0.3513060468395649, 'loop': 2, 'loss': 'CE', 'lr': 0.000429816510269719, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.179320919483512e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0005003504703251155
weight_decay:  2.0319190742673612e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2759208630304784
None Run 01:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 96.67
   Final Test: 46.40
Split: 01, Run: 02
None time:  0.9298195759765804
None Run 02:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 46.80
Split: 01, Run: 03
None time:  0.8792281849309802
None Run 03:
Highest Train: 100.00
Highest Valid: 44.40
  Final Train: 100.00
   Final Test: 47.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1895967009477317
None Run 04:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.60
Split: 02, Run: 02
None time:  0.8016466989647597
None Run 05:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.70
Split: 02, Run: 03
None time:  0.9084253408946097
None Run 06:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.150110863847658
None Run 07:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 57.40
Split: 03, Run: 02, Epoch: 100, Loss: 0.5539, Train: 93.33%, Valid: 58.60% Test: 56.90%
Split: 03, Run: 02
None time:  2.4372873050160706
None Run 08:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 96.67
   Final Test: 56.90
Split: 03, Run: 03, Epoch: 100, Loss: 0.4590, Train: 93.33%, Valid: 58.80% Test: 57.10%
Split: 03, Run: 03
None time:  2.2777048340067267
None Run 09:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 96.67
   Final Test: 57.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2665964728221297
None Run 10:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 96.67
   Final Test: 60.10
Split: 04, Run: 02
None time:  0.9288675950374454
None Run 11:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 60.00
Split: 04, Run: 03
None time:  0.9912386101204902
None Run 12:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 93.33
   Final Test: 61.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.847388498019427
None Run 13:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.60
Split: 05, Run: 02
None time:  0.9324454120360315
None Run 14:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.70
Split: 05, Run: 03
None time:  0.8551502779591829
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0885103170294315
None Run 16:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 96.67
   Final Test: 54.90
Split: 06, Run: 02
None time:  1.2047939070034772
None Run 17:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 55.80
Split: 06, Run: 03
None time:  1.3873726278543472
None Run 18:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 96.67
   Final Test: 55.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1753432739060372
None Run 19:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 96.67
   Final Test: 51.70
Split: 07, Run: 02
None time:  0.8627450801432133
None Run 20:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 51.30
Split: 07, Run: 03, Epoch: 100, Loss: 0.5037, Train: 86.67%, Valid: 52.80% Test: 56.60%
Split: 07, Run: 03
None time:  2.432960217818618
None Run 21:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 90.00
   Final Test: 56.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0293284801300615
None Run 22:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.90
Split: 08, Run: 02
None time:  0.8455294719897211
None Run 23:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.00
Split: 08, Run: 03
None time:  0.8915605552028865
None Run 24:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0863338788039982
None Run 25:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 57.70
Split: 09, Run: 02
None time:  0.9044877090491354
None Run 26:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 58.70
Split: 09, Run: 03
None time:  0.8399871969595551
None Run 27:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2546484218910336
None Run 28:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 60.50
Split: 10, Run: 02
None time:  0.8795111509971321
None Run 29:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.20
Split: 10, Run: 03
None time:  0.8628651020117104
None Run 30:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.20
run time now: 3.0410232543945312
total time:  36.48576978617348
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.38 ± 6.58
  Final Train: 98.67 ± 2.41
   Final Test: 58.00 ± 5.00
best run test_acc: 58.66999435424805
[I 2023-06-12 00:09:37,049] Trial 98 finished with value: 58.3800048828125 and parameters: {'Fwd': 0.07452409977957568, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 0.35948406099473423, 'loop': 2, 'loss': 'CE', 'lr': 0.0005003504703251155, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.0319190742673612e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.0006082021818970657
weight_decay:  1.399308777815946e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7382699090521783
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 63.33
   Final Test: 66.40
Split: 01, Run: 02
None time:  0.9673515218310058
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 76.67
   Final Test: 67.50
Split: 01, Run: 03
None time:  0.8998159989714622
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 66.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2384775560349226
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 68.90
Split: 02, Run: 02
None time:  0.9329059140291065
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.50
Split: 02, Run: 03
None time:  0.8492300109937787
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9434436620213091
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.00
Split: 03, Run: 02
None time:  0.8377493750303984
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
Split: 03, Run: 03
None time:  0.8606884609907866
None Run 09:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.1311630699783564
None Run 10:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 90.00
   Final Test: 55.70
Split: 04, Run: 02
None time:  0.8920269468799233
None Run 11:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 67.10
Split: 04, Run: 03
None time:  0.8319149608723819
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2112140178214759
None Run 13:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 96.67
   Final Test: 59.60
Split: 05, Run: 02
None time:  0.9482686189003289
None Run 14:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.80
Split: 05, Run: 03
None time:  0.9399658208712935
None Run 15:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0434776400215924
None Run 16:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 86.67
   Final Test: 54.60
Split: 06, Run: 02
None time:  0.9448107380885631
None Run 17:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.30
Split: 06, Run: 03
None time:  0.9183410569094121
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.306900210911408
None Run 19:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 76.67
   Final Test: 55.70
Split: 07, Run: 02
None time:  1.3192315241321921
None Run 20:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 76.67
   Final Test: 58.00
Split: 07, Run: 03
None time:  0.996121629839763
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 76.67
   Final Test: 58.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4280426101759076
None Run 22:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 70.00
   Final Test: 60.00
Split: 08, Run: 02
None time:  0.866958841914311
None Run 23:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 90.00
   Final Test: 68.40
Split: 08, Run: 03
None time:  0.9196577151305974
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 90.00
   Final Test: 68.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1493691019713879
None Run 25:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 93.33
   Final Test: 55.50
Split: 09, Run: 02
None time:  0.8551109291147441
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 66.60
Split: 09, Run: 03
None time:  0.8402693399693817
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9981177758891135
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.40
Split: 10, Run: 02
None time:  0.9034321329090744
None Run 29:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  0.7990866529289633
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.742820978164673
total time:  31.540350459050387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.06 ± 4.94
  Final Train: 91.22 ± 10.00
   Final Test: 64.69 ± 4.83
best run test_acc: 66.80000305175781
[I 2023-06-12 00:10:09,027] Trial 99 finished with value: 65.06000518798828 and parameters: {'Fwd': 0.029383002413640762, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 0.9730885676996883, 'loop': 2, 'loss': 'CE', 'lr': 0.0006082021818970657, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.399308777815946e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0005289668953643425
weight_decay:  2.750817413338922e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.560374815016985
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 66.67
   Final Test: 62.10
Split: 01, Run: 02
None time:  0.8222186751663685
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 63.80
Split: 01, Run: 03
None time:  0.840580799151212
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 64.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.300002846866846
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 80.00
   Final Test: 67.00
Split: 02, Run: 02
None time:  0.8446742189116776
None Run 05:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 68.60
Split: 02, Run: 03
None time:  0.7611877471208572
None Run 06:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3383372370153666
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 86.67
   Final Test: 62.90
Split: 03, Run: 02
None time:  0.8451401488855481
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.90
Split: 03, Run: 03
None time:  0.8228705080691725
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5343002509325743
None Run 10:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 86.67
   Final Test: 61.90
Split: 04, Run: 02
None time:  0.8615095799323171
None Run 11:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 66.90
Split: 04, Run: 03
None time:  0.7866091520991176
None Run 12:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 66.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.174799680011347
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 93.33
   Final Test: 60.40
Split: 05, Run: 02
None time:  0.8072169648949057
None Run 14:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.40
Split: 05, Run: 03
None time:  0.8276187558658421
None Run 15:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7654924329835922
None Run 16:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 55.70
Split: 06, Run: 02
None time:  0.7810136592015624
None Run 17:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 64.20
Split: 06, Run: 03
None time:  0.8717462429776788
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.168147973017767
None Run 19:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 83.33
   Final Test: 50.80
Split: 07, Run: 02
None time:  0.8018135500606149
None Run 20:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 86.67
   Final Test: 55.20
Split: 07, Run: 03
None time:  0.8224688079208136
None Run 21:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 93.33
   Final Test: 55.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9701956820208579
None Run 22:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 80.00
   Final Test: 64.10
Split: 08, Run: 02
None time:  0.8329523119609803
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 67.70
Split: 08, Run: 03
None time:  0.854061660123989
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 83.33
   Final Test: 68.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.8848622429650277
None Run 25:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 42.80
Split: 09, Run: 02
None time:  0.8881352918688208
None Run 26:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 62.80
Split: 09, Run: 03
None time:  0.9309411391150206
None Run 27:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.162013100925833
None Run 28:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 67.40
Split: 10, Run: 02
None time:  0.7530958410352468
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 68.40
Split: 10, Run: 03
None time:  0.8112173960544169
None Run 30:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 68.90
run time now: 2.7684152126312256
total time:  29.500316007994115
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.87 ± 6.14
  Final Train: 92.33 ± 7.79
   Final Test: 63.26 ± 5.88
best run test_acc: 65.63999938964844
[I 2023-06-12 00:10:38,996] Trial 100 finished with value: 63.86666488647461 and parameters: {'Fwd': 0.025981441917656698, 'K': 9, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 0.27580402144929284, 'loop': 2, 'loss': 'CE', 'lr': 0.0005289668953643425, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.750817413338922e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.00045534409914217174
weight_decay:  2.294763656109681e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6553330679889768
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 80.00
   Final Test: 62.40
Split: 01, Run: 02
None time:  0.8329340240452439
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 66.50
Split: 01, Run: 03
None time:  0.8550920290872455
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 67.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0129238250665367
None Run 04:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 67.90
Split: 02, Run: 02
None time:  0.8408631500788033
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.10
Split: 02, Run: 03
None time:  0.848594848997891
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.0636797479819506
None Run 07:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 02
None time:  1.1114418008364737
None Run 08:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.20
Split: 03, Run: 03
None time:  0.8522363752126694
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4672140639740974
None Run 10:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 96.67
   Final Test: 63.80
Split: 04, Run: 02
None time:  0.8830831430386752
None Run 11:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 65.00
Split: 04, Run: 03
None time:  0.9079031841829419
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.21251654997468
None Run 13:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.00
Split: 05, Run: 02
None time:  0.9120118159335107
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.70
Split: 05, Run: 03
None time:  0.8871479600202292
None Run 15:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.389968791976571
None Run 16:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 90.00
   Final Test: 61.30
Split: 06, Run: 02
None time:  0.9047709628939629
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.30
Split: 06, Run: 03
None time:  0.7926148611586541
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4548135560471565
None Run 19:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 76.67
   Final Test: 54.40
Split: 07, Run: 02
None time:  1.4145462068263441
None Run 20:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 86.67
   Final Test: 55.30
Split: 07, Run: 03
None time:  0.8714370299130678
None Run 21:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 83.33
   Final Test: 56.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4620513408444822
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 80.00
   Final Test: 65.70
Split: 08, Run: 02
None time:  0.7987198769114912
None Run 23:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 69.60
Split: 08, Run: 03
None time:  0.9222566147800535
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 83.33
   Final Test: 69.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4892124261241406
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 76.67
   Final Test: 61.70
Split: 09, Run: 02
None time:  0.8666675069835037
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.00
Split: 09, Run: 03
None time:  0.9927939958870411
None Run 27:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 67.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4571372629143298
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 66.60
Split: 10, Run: 02
None time:  0.858150654938072
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.50
Split: 10, Run: 03
None time:  0.8136734098661691
None Run 30:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.80
run time now: 3.1716275215148926
total time:  32.92489002086222
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.89 ± 4.43
  Final Train: 93.11 ± 7.53
   Final Test: 65.19 ± 4.02
best run test_acc: 66.37999725341797
[I 2023-06-12 00:11:12,445] Trial 101 finished with value: 65.8933334350586 and parameters: {'Fwd': 0.08025501177966805, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 0.6341429217980501, 'loop': 2, 'loss': 'CE', 'lr': 0.00045534409914217174, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.294763656109681e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.0004377064056221251
weight_decay:  2.18483128721578e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6840317558962852
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 83.33
   Final Test: 64.80
Split: 01, Run: 02
None time:  1.1895488100126386
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 90.00
   Final Test: 65.40
Split: 01, Run: 03
None time:  0.9271035739220679
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 86.67
   Final Test: 65.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3252092199400067
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 68.50
Split: 02, Run: 02
None time:  0.9232153960037977
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.00
Split: 02, Run: 03
None time:  0.8967428631149232
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3679587710648775
None Run 07:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 64.80
Split: 03, Run: 02
None time:  0.8599598128348589
None Run 08:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.20
Split: 03, Run: 03
None time:  0.9376645481679589
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2465399110224098
None Run 10:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 96.67
   Final Test: 62.60
Split: 04, Run: 02
None time:  0.9130764359142631
None Run 11:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 66.90
Split: 04, Run: 03
None time:  0.8920416419859976
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.4068921839352697
None Run 13:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 60.90
Split: 05, Run: 02
None time:  1.0344133430626243
None Run 14:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 62.20
Split: 05, Run: 03
None time:  0.9060762419831008
None Run 15:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1913490688893944
None Run 16:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 64.00
Split: 06, Run: 02
None time:  0.8826902559958398
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.10
Split: 06, Run: 03
None time:  0.8863080700393766
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0853226471226662
None Run 19:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 93.33
   Final Test: 57.10
Split: 07, Run: 02
None time:  0.9513354860246181
None Run 20:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 93.33
   Final Test: 54.70
Split: 07, Run: 03
None time:  1.1553902809973806
None Run 21:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 86.67
   Final Test: 55.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.514861656818539
None Run 22:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 83.33
   Final Test: 60.90
Split: 08, Run: 02
None time:  0.8765553270932287
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 80.00
   Final Test: 66.30
Split: 08, Run: 03
None time:  0.8909316689241678
None Run 24:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 68.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1825429808814079
None Run 25:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 64.30
Split: 09, Run: 02
None time:  0.9592447490431368
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 67.30
Split: 09, Run: 03
None time:  0.9473286038264632
None Run 27:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6258391828741878
None Run 28:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 68.50
Split: 10, Run: 02
None time:  0.75647510192357
None Run 29:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 68.60
Split: 10, Run: 03
None time:  0.8805248900316656
None Run 30:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 69.00
run time now: 3.3063790798187256
total time:  33.39040721789934
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.40 ± 4.70
  Final Train: 93.44 ± 5.14
   Final Test: 64.90 ± 3.96
best run test_acc: 66.02999114990234
[I 2023-06-12 00:11:46,345] Trial 102 finished with value: 65.4000015258789 and parameters: {'Fwd': 0.07518672903744045, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 0.6966614141918044, 'loop': 2, 'loss': 'CE', 'lr': 0.0004377064056221251, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.18483128721578e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.0004227219163585406
weight_decay:  4.050118964385307e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7470054829027504
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 76.67
   Final Test: 66.70
Split: 01, Run: 02
None time:  1.164966301061213
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 86.67
   Final Test: 65.10
Split: 01, Run: 03
None time:  0.9369016760028899
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 76.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3978281849995255
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 69.00
Split: 02, Run: 02
None time:  0.7856475058943033
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 70.00
Split: 02, Run: 03
None time:  0.8678692169487476
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1992459539324045
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 63.40
Split: 03, Run: 02
None time:  0.8944146579597145
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 03
None time:  0.8452007269952446
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5255323089659214
None Run 10:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 93.33
   Final Test: 62.30
Split: 04, Run: 02
None time:  0.8659513359889388
None Run 11:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 66.30
Split: 04, Run: 03
None time:  0.9184377049095929
None Run 12:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 65.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2801121920347214
None Run 13:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 60.70
Split: 05, Run: 02
None time:  0.9545508930459619
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.20
Split: 05, Run: 03
None time:  0.8840157648082823
None Run 15:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.404595049098134
None Run 16:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 62.70
Split: 06, Run: 02
None time:  0.845330995041877
None Run 17:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.80
Split: 06, Run: 03
None time:  0.8922677859663963
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.664982233894989
None Run 19:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 76.67
   Final Test: 55.00
Split: 07, Run: 02
None time:  0.9125207420438528
None Run 20:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 86.67
   Final Test: 58.20
Split: 07, Run: 03
None time:  1.1194133190438151
None Run 21:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 83.33
   Final Test: 59.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.574905531015247
None Run 22:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 70.00
   Final Test: 60.50
Split: 08, Run: 02
None time:  0.7986408961005509
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 90.00
   Final Test: 67.90
Split: 08, Run: 03
None time:  0.8285610349848866
None Run 24:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 90.00
   Final Test: 68.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6417430259753019
None Run 25:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 80.00
   Final Test: 59.20
Split: 09, Run: 02
None time:  0.9694811140652746
None Run 26:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 63.90
Split: 09, Run: 03
None time:  0.9851824908982962
None Run 27:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 64.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2737252591177821
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 90.00
   Final Test: 66.60
Split: 10, Run: 02
None time:  0.8995133400894701
None Run 29:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  0.8152260740753263
None Run 30:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.033785581588745
total time:  33.95226266304962
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.17 ± 4.25
  Final Train: 91.22 ± 8.28
   Final Test: 64.62 ± 3.66
best run test_acc: 65.98999786376953
[I 2023-06-12 00:12:20,859] Trial 103 finished with value: 65.16666412353516 and parameters: {'Fwd': 0.05338192290064827, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 0.440496220918404, 'loop': 2, 'loss': 'CE', 'lr': 0.0004227219163585406, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.050118964385307e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0003770228557834379
weight_decay:  1.5960914019780537e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.758164288010448
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 76.67
   Final Test: 65.80
Split: 01, Run: 02
None time:  2.002276388928294
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 76.67
   Final Test: 64.90
Split: 01, Run: 03
None time:  1.9127710368484259
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 76.67
   Final Test: 64.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1533698679413646
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 69.60
Split: 02, Run: 02
None time:  1.480099219828844
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.40
Split: 02, Run: 03
None time:  1.5444761549588293
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.311457837931812
None Run 07:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 65.30
Split: 03, Run: 02
None time:  1.4317713340278715
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.70
Split: 03, Run: 03
None time:  1.4256622169632465
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  4.0091691659763455
None Run 10:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 83.33
   Final Test: 55.60
Split: 04, Run: 02
None time:  1.4674779139459133
None Run 11:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 96.67
   Final Test: 61.10
Split: 04, Run: 03
None time:  1.4882976568769664
None Run 12:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 96.67
   Final Test: 61.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.3436274349223822
None Run 13:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 65.50
Split: 05, Run: 02
None time:  2.860847085947171
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 64.40
Split: 05, Run: 03
None time:  1.462516909930855
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 63.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.6241200829390436
None Run 16:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 93.33
   Final Test: 64.50
Split: 06, Run: 02
None time:  1.4678575948346406
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.00
Split: 06, Run: 03
None time:  1.5268487930297852
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 67.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.8649950090330094
None Run 19:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 83.33
   Final Test: 55.30
Split: 07, Run: 02
None time:  2.8754750171210617
None Run 20:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 80.00
   Final Test: 58.10
Split: 07, Run: 03
None time:  1.8474292408209294
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 80.00
   Final Test: 56.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.3267737780697644
None Run 22:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 80.00
   Final Test: 64.90
Split: 08, Run: 02
None time:  1.406126172048971
None Run 23:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 96.67
   Final Test: 69.60
Split: 08, Run: 03
None time:  1.523718792013824
None Run 24:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 69.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.6760577850509435
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 64.70
Split: 09, Run: 02
None time:  1.5704163638874888
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 67.60
Split: 09, Run: 03
None time:  1.5349988520611078
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 90.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.3715424111578614
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 65.80
Split: 10, Run: 02
None time:  1.5661153169348836
None Run 29:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.30
Split: 10, Run: 03
None time:  1.5483298520557582
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 5.541931867599487
total time:  64.63731943606399
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.51 ± 4.92
  Final Train: 91.67 ± 8.01
   Final Test: 64.97 ± 4.21
best run test_acc: 66.05999755859375
[I 2023-06-12 00:13:26,097] Trial 104 finished with value: 65.50666809082031 and parameters: {'Fwd': 0.03420679307963971, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 1.1252539638978596, 'loop': 2, 'loss': 'CE', 'lr': 0.0003770228557834379, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.5960914019780537e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.0004543784626936632
weight_decay:  6.964128945354869e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6749747949652374
None Run 01:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 83.33
   Final Test: 61.50
Split: 01, Run: 02
None time:  1.9451878969557583
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 90.00
   Final Test: 65.00
Split: 01, Run: 03
None time:  1.834937863983214
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 66.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.5130244430620223
None Run 04:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 64.80
Split: 02, Run: 02
None time:  1.5689803920686245
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 69.10
Split: 02, Run: 03
None time:  1.5787002560682595
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.533108585048467
None Run 07:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.80
Split: 03, Run: 02
None time:  1.6514306399039924
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.90
Split: 03, Run: 03
None time:  1.6727981748990715
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.424636899959296
None Run 10:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 96.67
   Final Test: 61.70
Split: 04, Run: 02
None time:  1.5782383719924837
None Run 11:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 64.50
Split: 04, Run: 03
None time:  1.8277533589862287
None Run 12:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 63.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.789610961917788
None Run 13:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 96.67
   Final Test: 58.60
Split: 05, Run: 02
None time:  1.6323776838835329
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.80
Split: 05, Run: 03
None time:  1.608585098059848
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.038593673845753
None Run 16:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 63.10
Split: 06, Run: 02
None time:  1.7765936029609293
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 66.80
Split: 06, Run: 03
None time:  1.5697404381353408
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.3343568979762495
None Run 19:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 76.67
   Final Test: 49.80
Split: 07, Run: 02
None time:  1.725106311030686
None Run 20:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 86.67
   Final Test: 52.20
Split: 07, Run: 03
None time:  1.8390811490826309
None Run 21:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 86.67
   Final Test: 52.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.0851267180405557
None Run 22:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 73.33
   Final Test: 58.20
Split: 08, Run: 02
None time:  1.572563742985949
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 90.00
   Final Test: 67.30
Split: 08, Run: 03
None time:  1.6288114618510008
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 67.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.18740855390206
None Run 25:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 83.33
   Final Test: 59.20
Split: 09, Run: 02
None time:  1.617851114133373
None Run 26:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 66.10
Split: 09, Run: 03
None time:  1.544811476022005
None Run 27:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.3383459269534796
None Run 28:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 83.33
   Final Test: 67.70
Split: 10, Run: 02
None time:  1.6017742010299116
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 68.00
Split: 10, Run: 03
None time:  1.4879429570864886
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 68.00
run time now: 6.479268550872803
total time:  63.434474488021806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.68 ± 5.07
  Final Train: 92.56 ± 6.93
   Final Test: 63.64 ± 5.07
best run test_acc: 65.27000427246094
[I 2023-06-12 00:14:30,014] Trial 105 finished with value: 64.68000030517578 and parameters: {'Fwd': 0.07759690423256209, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 0.5720846819459546, 'loop': 2, 'loss': 'CE', 'lr': 0.0004543784626936632, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.964128945354869e-06, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0006405539958886031
weight_decay:  3.4021815979597216e-05
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9285493709612638
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 96.67
   Final Test: 57.40
Split: 01, Run: 02
None time:  1.6826742889825255
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 96.67
   Final Test: 56.60
Split: 01, Run: 03
None time:  1.6160377450287342
None Run 03:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 96.67
   Final Test: 54.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0965698959771544
None Run 04:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.20
Split: 02, Run: 02
None time:  1.6446495831478387
None Run 05:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.80
Split: 02, Run: 03
None time:  1.6636977039743215
None Run 06:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.7218606651294976
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 80.00
   Final Test: 65.10
Split: 03, Run: 02
None time:  1.7651291049551219
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 63.10
Split: 03, Run: 03
None time:  1.637709730071947
None Run 09:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 93.33
   Final Test: 62.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1618201539386064
None Run 10:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 86.67
   Final Test: 54.20
Split: 04, Run: 02
None time:  1.5761664560995996
None Run 11:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 96.67
   Final Test: 59.30
Split: 04, Run: 03
None time:  1.5318525088950992
None Run 12:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 96.67
   Final Test: 59.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.757439024047926
None Run 13:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.60
Split: 05, Run: 02
None time:  1.6130719580687582
None Run 14:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 59.80
Split: 05, Run: 03
None time:  1.3147147169802338
None Run 15:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 54.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.1731717069633305
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 64.30
Split: 06, Run: 02
None time:  1.5424337720032781
None Run 17:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 64.30
Split: 06, Run: 03
None time:  1.5893968672025949
None Run 18:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 62.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9451914930250496
None Run 19:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 93.33
   Final Test: 51.20
Split: 07, Run: 02
None time:  1.4282640418969095
None Run 20:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 96.67
   Final Test: 50.10
Split: 07, Run: 03
None time:  2.518421795917675
None Run 21:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 83.33
   Final Test: 48.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5916898208670318
None Run 22:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 58.50
Split: 08, Run: 02
None time:  1.545919205993414
None Run 23:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 63.30
Split: 08, Run: 03
None time:  1.500270718941465
None Run 24:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 93.33
   Final Test: 62.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9199902308173478
None Run 25:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 60.00
Split: 09, Run: 02
None time:  1.5505447371397167
None Run 26:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 96.67
   Final Test: 59.00
Split: 09, Run: 03
None time:  1.4492280709091574
None Run 27:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 96.67
   Final Test: 54.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9232671319041401
None Run 28:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 90.00
   Final Test: 61.40
Split: 10, Run: 02
None time:  1.4407566979061812
None Run 29:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.60
Split: 10, Run: 03
None time:  1.546802839031443
None Run 30:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 90.00
   Final Test: 60.10
run time now: 4.962985515594482
total time:  53.60958890803158
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.69 ± 6.39
  Final Train: 95.33 ± 5.00
   Final Test: 59.20 ± 4.66
best run test_acc: 60.8599967956543
[I 2023-06-12 00:15:24,163] Trial 106 finished with value: 59.69334030151367 and parameters: {'Fwd': 0.04429834306493083, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 0.1952217245073002, 'loop': 2, 'loss': 'CE', 'lr': 0.0006405539958886031, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.4021815979597216e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0005345580743103643
weight_decay:  5.055966183195603e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8824121051002294
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 60.00
   Final Test: 63.90
Split: 01, Run: 02
None time:  1.4865310969762504
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 70.00
   Final Test: 65.40
Split: 01, Run: 03
None time:  1.5898031319957227
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 76.67
   Final Test: 65.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.5489710869733244
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 83.33
   Final Test: 69.10
Split: 02, Run: 02
None time:  1.4301902821753174
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.50
Split: 02, Run: 03
None time:  1.2443781420588493
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.542629317846149
None Run 07:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 90.00
   Final Test: 63.00
Split: 03, Run: 02
None time:  1.3686259880196303
None Run 08:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.70
Split: 03, Run: 03
None time:  1.3851836260873824
None Run 09:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.462963928002864
None Run 10:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 83.33
   Final Test: 60.00
Split: 04, Run: 02
None time:  1.3523219041526318
None Run 11:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 67.40
Split: 04, Run: 03
None time:  1.3218450089916587
None Run 12:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 65.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.471874340903014
None Run 13:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 66.40
Split: 05, Run: 02
None time:  1.94458122481592
None Run 14:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.50
Split: 05, Run: 03
None time:  1.3265106780454516
None Run 15:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.245390967000276
None Run 16:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 73.33
   Final Test: 59.90
Split: 06, Run: 02
None time:  1.3442213349044323
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.50
Split: 06, Run: 03
None time:  1.354611492017284
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 66.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.229367819149047
None Run 19:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 83.33
   Final Test: 57.20
Split: 07, Run: 02
None time:  1.3582656220532954
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 93.33
   Final Test: 59.70
Split: 07, Run: 03
None time:  1.366174868075177
None Run 21:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 86.67
   Final Test: 59.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8603253320325166
None Run 22:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 80.00
   Final Test: 65.60
Split: 08, Run: 02
None time:  1.4660257971845567
None Run 23:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 93.33
   Final Test: 69.80
Split: 08, Run: 03
None time:  1.3924443840514868
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 70.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.280736673856154
None Run 25:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 90.00
   Final Test: 59.60
Split: 09, Run: 02
None time:  1.547251163981855
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 66.70
Split: 09, Run: 03
None time:  1.4401497629005462
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 66.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.409356700023636
None Run 28:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 86.67
   Final Test: 64.50
Split: 10, Run: 02
None time:  1.5386769589968026
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.30
Split: 10, Run: 03
None time:  1.4652443861123174
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 5.466155767440796
total time:  53.85776925110258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.62 ± 3.95
  Final Train: 90.11 ± 10.04
   Final Test: 65.23 ± 3.69
best run test_acc: 66.6300048828125
[I 2023-06-12 00:16:18,571] Trial 107 finished with value: 65.62000274658203 and parameters: {'Fwd': 0.013848293645671767, 'K': 9, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 0.8800027790858412, 'loop': 2, 'loss': 'CE', 'lr': 0.0005345580743103643, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.055966183195603e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0005482588813649206
weight_decay:  2.542320629221468e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.119871773989871
None Run 01:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 66.67
   Final Test: 60.90
Split: 01, Run: 02
None time:  1.6480109470430762
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 80.00
   Final Test: 65.50
Split: 01, Run: 03
None time:  1.5867361649870872
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 65.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.8065999569371343
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 83.33
   Final Test: 69.70
Split: 02, Run: 02
None time:  1.4925745700020343
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.80
Split: 02, Run: 03
None time:  1.5409725259523839
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.339910037117079
None Run 07:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 90.00
   Final Test: 64.80
Split: 03, Run: 02
None time:  1.5351494171191007
None Run 08:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.90
Split: 03, Run: 03
None time:  1.5655172769911587
None Run 09:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.092325969133526
None Run 10:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 80.00
   Final Test: 57.90
Split: 04, Run: 02
None time:  1.503607602789998
None Run 11:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 67.10
Split: 04, Run: 03
None time:  1.556916267843917
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 66.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.6136662769131362
None Run 13:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 83.33
   Final Test: 64.80
Split: 05, Run: 02
None time:  1.5272045850288123
None Run 14:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 66.60
Split: 05, Run: 03
None time:  1.4872356769628823
None Run 15:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.3874684940092266
None Run 16:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 86.67
   Final Test: 63.20
Split: 06, Run: 02
None time:  1.5483155390247703
None Run 17:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 68.60
Split: 06, Run: 03
None time:  1.46477499906905
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.332289458019659
None Run 19:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 83.33
   Final Test: 55.90
Split: 07, Run: 02
None time:  1.5345110129565
None Run 20:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 93.33
   Final Test: 59.00
Split: 07, Run: 03
None time:  1.4894138958770782
None Run 21:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 93.33
   Final Test: 59.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.416536342119798
None Run 22:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 73.33
   Final Test: 60.70
Split: 08, Run: 02
None time:  1.5339032171759754
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 68.60
Split: 08, Run: 03
None time:  1.3956841179169714
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 90.00
   Final Test: 68.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.0224711790215224
None Run 25:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 73.33
   Final Test: 55.70
Split: 09, Run: 02
None time:  1.5038484241813421
None Run 26:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 66.60
Split: 09, Run: 03
None time:  1.4008425439242274
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 66.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9598030289635062
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 90.00
   Final Test: 65.40
Split: 10, Run: 02
None time:  1.3892615579534322
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.20
Split: 10, Run: 03
None time:  1.420949000865221
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.50
run time now: 4.825824975967407
total time:  58.671280732844025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.46 ± 5.35
  Final Train: 90.22 ± 8.88
   Final Test: 65.03 ± 4.08
best run test_acc: 66.80000305175781
[I 2023-06-12 00:17:17,646] Trial 108 finished with value: 65.45999908447266 and parameters: {'Fwd': 0.013290542069753305, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 0.8944762473894421, 'loop': 2, 'loss': 'CE', 'lr': 0.0005482588813649206, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.542320629221468e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.0008273173707510699
weight_decay:  5.1410536806964627e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2502061761915684
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 63.33
   Final Test: 65.10
Split: 01, Run: 02
None time:  1.3395290339831263
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 66.70
Split: 01, Run: 03
None time:  1.329522144049406
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.191400591051206
None Run 04:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 86.67
   Final Test: 62.30
Split: 02, Run: 02
None time:  1.3297256929799914
None Run 05:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 69.30
Split: 02, Run: 03
None time:  1.3673246400430799
None Run 06:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 68.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.9206076501868665
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.50
Split: 03, Run: 02
None time:  1.3721393658779562
None Run 08:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.20
Split: 03, Run: 03
None time:  1.3589420157950372
None Run 09:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.01520217792131
None Run 10:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 70.00
   Final Test: 54.70
Split: 04, Run: 02
None time:  1.290136304916814
None Run 11:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 67.30
Split: 04, Run: 03
None time:  1.3727674968540668
None Run 12:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.415324894944206
None Run 13:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 83.33
   Final Test: 48.90
Split: 05, Run: 02
None time:  1.4818170140497386
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 62.60
Split: 05, Run: 03
None time:  1.5071370180230588
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7626101861242205
None Run 16:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 96.67
   Final Test: 50.50
Split: 06, Run: 02
None time:  1.3518009760882705
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.50
Split: 06, Run: 03
None time:  1.4069103309884667
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.297244844958186
None Run 19:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 70.00
   Final Test: 58.50
Split: 07, Run: 02
None time:  1.4325628860387951
None Run 20:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 80.00
   Final Test: 60.50
Split: 07, Run: 03
None time:  1.4553528840187937
None Run 21:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 76.67
   Final Test: 60.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.081238071201369
None Run 22:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 76.67
   Final Test: 56.60
Split: 08, Run: 02
None time:  1.4432618068531156
None Run 23:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 80.00
   Final Test: 66.90
Split: 08, Run: 03
None time:  1.4486985388211906
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 67.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.4836277270223945
None Run 25:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 70.00
   Final Test: 55.70
Split: 09, Run: 02
None time:  1.4719160068780184
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.50
Split: 09, Run: 03
None time:  1.500937038101256
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 67.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.243734620977193
None Run 28:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 80.00
   Final Test: 58.90
Split: 10, Run: 02
None time:  1.4623866940382868
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.80
Split: 10, Run: 03
None time:  1.4252410200424492
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.90
run time now: 5.192384481430054
total time:  53.11705943290144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.53 ± 5.70
  Final Train: 89.22 ± 11.13
   Final Test: 63.58 ± 5.69
best run test_acc: 66.73999786376953
[I 2023-06-12 00:18:11,203] Trial 109 finished with value: 63.52666473388672 and parameters: {'Fwd': 0.01922192087957937, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 1.607302279399324, 'loop': 2, 'loss': 'CE', 'lr': 0.0008273173707510699, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.1410536806964627e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0007252863649286686
weight_decay:  3.1594043483761537e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6678145120386034
None Run 01:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 60.00
   Final Test: 62.40
Split: 01, Run: 02
None time:  1.9340439960360527
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 73.33
   Final Test: 65.70
Split: 01, Run: 03
None time:  1.8172065177932382
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 70.00
   Final Test: 65.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.8678741729818285
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 80.00
   Final Test: 69.20
Split: 02, Run: 02
None time:  1.4897205310408026
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 69.90
Split: 02, Run: 03
None time:  1.53484669001773
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 69.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.399422800168395
None Run 07:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 86.67
   Final Test: 60.90
Split: 03, Run: 02
None time:  1.741900924127549
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 65.00
Split: 03, Run: 03
None time:  1.533414914039895
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.2460056450217962
None Run 10:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 66.67
   Final Test: 43.80
Split: 04, Run: 02
None time:  1.614483943209052
None Run 11:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 93.33
   Final Test: 59.20
Split: 04, Run: 03
None time:  1.5202751690521836
None Run 12:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 93.33
   Final Test: 58.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.8043648418970406
None Run 13:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 90.00
   Final Test: 63.70
Split: 05, Run: 02
None time:  2.0286095140036196
None Run 14:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 66.40
Split: 05, Run: 03
None time:  1.4537876879330724
None Run 15:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7176463839132339
None Run 16:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 86.67
   Final Test: 55.90
Split: 06, Run: 02
None time:  1.4462765348143876
None Run 17:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.10
Split: 06, Run: 03
None time:  1.455131938913837
None Run 18:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: -194602.9375, Train: 63.33%, Valid: 56.40% Test: 59.00%
Split: 07, Run: 01
None time:  4.814182297093794
None Run 19:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 63.33
   Final Test: 59.10
Split: 07, Run: 02
None time:  1.3284764578565955
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 66.67
   Final Test: 61.20
Split: 07, Run: 03
None time:  1.449380830861628
None Run 21:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 66.67
   Final Test: 61.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.9555260189808905
None Run 22:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 63.33
   Final Test: 56.00
Split: 08, Run: 02
None time:  1.533380252076313
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 83.33
   Final Test: 68.40
Split: 08, Run: 03
None time:  1.5051158170681447
None Run 24:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 83.33
   Final Test: 67.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.1653762471396476
None Run 25:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 80.00
   Final Test: 52.00
Split: 09, Run: 02
None time:  1.5614229459315538
None Run 26:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 64.50
Split: 09, Run: 03
None time:  1.4871349721215665
None Run 27:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 64.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.000861414009705
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 66.90
Split: 10, Run: 02
None time:  1.4867693781852722
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 10, Run: 03
None time:  1.4489763351157308
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 69.40
run time now: 4.990902900695801
total time:  60.20879916800186
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.92 ± 5.87
  Final Train: 85.00 ± 12.80
   Final Test: 63.50 ± 5.98
best run test_acc: 66.11000061035156
[I 2023-06-12 00:19:11,905] Trial 110 finished with value: 63.91999816894531 and parameters: {'Fwd': 0.006804189298228235, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 0.04536419447128559, 'loop': 2, 'loss': 'CE', 'lr': 0.0007252863649286686, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.1594043483761537e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0004953262857389618
weight_decay:  6.879637767853383e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.2430135370232165
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 56.67
   Final Test: 66.90
Split: 01, Run: 02
None time:  1.3488597739487886
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.709852130850777
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9489332139492035
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 67.60
Split: 02, Run: 02
None time:  1.4250218991655856
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.20
Split: 02, Run: 03
None time:  1.546778735006228
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.2526411949656904
None Run 07:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 64.50
Split: 03, Run: 02
None time:  1.495294626103714
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  1.5167547520250082
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.016716474900022
None Run 10:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 96.67
   Final Test: 60.90
Split: 04, Run: 02
None time:  1.632113398052752
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 63.50
Split: 04, Run: 03
None time:  1.5015801850240678
None Run 12:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 96.67
   Final Test: 64.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.6573546989820898
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 65.70
Split: 05, Run: 02
None time:  2.164058752125129
None Run 14:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 65.60
Split: 05, Run: 03
None time:  1.7941158979665488
None Run 15:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3455193568952382
None Run 16:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 52.50
Split: 06, Run: 02
None time:  1.4522864348255098
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 65.60
Split: 06, Run: 03
None time:  1.553883695974946
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.159130841959268
None Run 19:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 73.33
   Final Test: 57.30
Split: 07, Run: 02
None time:  2.160734822973609
None Run 20:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 76.67
   Final Test: 58.80
Split: 07, Run: 03
None time:  1.5824884560424834
None Run 21:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 86.67
   Final Test: 58.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9754814798943698
None Run 22:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 83.33
   Final Test: 64.60
Split: 08, Run: 02
None time:  1.487724773818627
None Run 23:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 69.20
Split: 08, Run: 03
None time:  1.5559822511859238
None Run 24:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 90.00
   Final Test: 69.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.89547743787989
None Run 25:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 83.33
   Final Test: 61.10
Split: 09, Run: 02
None time:  1.5778169431723654
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 67.20
Split: 09, Run: 03
None time:  1.558691002894193
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 93.33
   Final Test: 67.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.6035338800866157
None Run 28:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 83.33
   Final Test: 64.30
Split: 10, Run: 02
None time:  1.4969624229706824
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.90
Split: 10, Run: 03
None time:  1.52837163512595
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.50
run time now: 5.690908670425415
total time:  58.494467535056174
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.58 ± 4.72
  Final Train: 91.78 ± 9.70
   Final Test: 65.02 ± 4.09
best run test_acc: 66.56001281738281
[I 2023-06-12 00:20:10,894] Trial 111 finished with value: 65.57999420166016 and parameters: {'Fwd': 0.02524078608565808, 'K': 9, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 0.5037651889274447, 'loop': 2, 'loss': 'CE', 'lr': 0.0004953262857389618, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.879637767853383e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0005036430567407382
weight_decay:  6.710715088323117e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.77445657690987
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 56.67
   Final Test: 66.50
Split: 01, Run: 02
None time:  1.9996234981808811
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 56.67
   Final Test: 66.60
Split: 01, Run: 03
None time:  1.8921869061887264
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 56.67
   Final Test: 66.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9347396241500974
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 68.50
Split: 02, Run: 02
None time:  1.4520115789491683
None Run 05:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 02, Run: 03
None time:  1.515599156031385
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.261084774043411
None Run 07:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 90.00
   Final Test: 61.90
Split: 03, Run: 02
None time:  1.4787171920761466
None Run 08:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.70
Split: 03, Run: 03
None time:  1.569168890826404
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.1375086640473455
None Run 10:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 73.33
   Final Test: 54.10
Split: 04, Run: 02
None time:  1.5173806571401656
None Run 11:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 65.80
Split: 04, Run: 03
None time:  1.5070257680490613
None Run 12:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 64.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.6781236650422215
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 65.50
Split: 05, Run: 02
None time:  1.5293787880800664
None Run 14:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.30
Split: 05, Run: 03
None time:  1.503439994994551
None Run 15:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.6267457851208746
None Run 16:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 80.00
   Final Test: 61.50
Split: 06, Run: 02
None time:  1.5399685529991984
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.10
Split: 06, Run: 03
None time:  1.4989446019753814
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.0166680549737066
None Run 19:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 73.33
   Final Test: 57.00
Split: 07, Run: 02
None time:  1.5732881291769445
None Run 20:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 90.00
   Final Test: 59.40
Split: 07, Run: 03
None time:  1.5487493718974292
None Run 21:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 90.00
   Final Test: 59.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.649060752009973
None Run 22:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.90
Split: 08, Run: 02
None time:  1.5358914949465543
None Run 23:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.30
Split: 08, Run: 03
None time:  1.5689042448066175
None Run 24:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 66.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.814455717103556
None Run 25:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 73.33
   Final Test: 60.60
Split: 09, Run: 02
None time:  1.5796996280550957
None Run 26:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 69.10
Split: 09, Run: 03
None time:  1.5969845501240343
None Run 27:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 86.67
   Final Test: 69.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.333307415014133
None Run 28:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 76.67
   Final Test: 62.50
Split: 10, Run: 02
None time:  1.573871144093573
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 68.90
Split: 10, Run: 03
None time:  1.5451650980394334
None Run 30:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 69.20
run time now: 6.502691268920898
total time:  62.00128802610561
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.40 ± 5.74
  Final Train: 88.00 ± 13.52
   Final Test: 64.50 ± 5.14
best run test_acc: 66.7199935913086
[I 2023-06-12 00:21:13,439] Trial 112 finished with value: 65.4000015258789 and parameters: {'Fwd': 0.00962548730318285, 'K': 9, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 0.3789608409398027, 'loop': 2, 'loss': 'CE', 'lr': 0.0005036430567407382, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.710715088323117e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0004779906971527654
weight_decay:  5.013454173843302e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4535477040335536
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 80.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.9792550201527774
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 83.33
   Final Test: 65.30
Split: 01, Run: 03
None time:  2.0239889689255506
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 86.67
   Final Test: 64.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.37415226502344
None Run 04:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 69.70
Split: 02, Run: 02
None time:  1.4904772110749036
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.50
Split: 02, Run: 03
None time:  1.60832458618097
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.9508107430301607
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 86.67
   Final Test: 63.10
Split: 03, Run: 02
None time:  1.561252768151462
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 65.20
Split: 03, Run: 03
None time:  1.5451635960489511
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.2423998219892383
None Run 10:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 93.33
   Final Test: 64.90
Split: 04, Run: 02
None time:  1.5336791689042002
None Run 11:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 67.30
Split: 04, Run: 03
None time:  1.594336437061429
None Run 12:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.436855464009568
None Run 13:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 65.40
Split: 05, Run: 02
None time:  2.0641306531615555
None Run 14:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 65.90
Split: 05, Run: 03
None time:  1.7017877439502627
None Run 15:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9931216929107904
None Run 16:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 93.33
   Final Test: 58.40
Split: 06, Run: 02
None time:  1.5567836628761142
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.10
Split: 06, Run: 03
None time:  1.677620654925704
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.7617286960594356
None Run 19:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 76.67
   Final Test: 57.90
Split: 07, Run: 02
None time:  1.8471572829876095
None Run 20:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 83.33
   Final Test: 58.30
Split: 07, Run: 03
None time:  1.6613930540625006
None Run 21:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 83.33
   Final Test: 58.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.8494968549348414
None Run 22:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 80.00
   Final Test: 60.90
Split: 08, Run: 02
None time:  1.6475188289768994
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 90.00
   Final Test: 68.20
Split: 08, Run: 03
None time:  1.6046994810458273
None Run 24:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 90.00
   Final Test: 68.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.4867415588814765
None Run 25:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 93.33
   Final Test: 60.80
Split: 09, Run: 02
None time:  1.5135596019681543
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.90
Split: 09, Run: 03
None time:  1.5557289279531687
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 67.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.417516832938418
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 86.67
   Final Test: 67.00
Split: 10, Run: 02
None time:  1.6083504278212786
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 10, Run: 03
None time:  1.5198442919645458
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 5.5994274616241455
total time:  62.609030151041225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.65 ± 3.89
  Final Train: 92.33 ± 7.01
   Final Test: 65.33 ± 3.66
best run test_acc: 66.5999984741211
[I 2023-06-12 00:22:16,480] Trial 113 finished with value: 65.65333557128906 and parameters: {'Fwd': 0.05825989197318856, 'K': 9, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 1.1469579306556885, 'loop': 2, 'loss': 'CE', 'lr': 0.0004779906971527654, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.013454173843302e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.00043610579320650276
weight_decay:  4.91476655160068e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.25325373490341
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 80.00
   Final Test: 65.30
Split: 01, Run: 02
None time:  1.8426575150806457
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 83.33
   Final Test: 64.60
Split: 01, Run: 03
None time:  1.900074047036469
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 83.33
   Final Test: 66.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.192919929046184
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 93.33
   Final Test: 65.80
Split: 02, Run: 02
None time:  1.5777591599617153
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.90
Split: 02, Run: 03
None time:  1.6223833260592073
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.5417170519940555
None Run 07:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 66.50
Split: 03, Run: 02
None time:  1.6011024268809706
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.60
Split: 03, Run: 03
None time:  1.563357514794916
None Run 09:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.978540920186788
None Run 10:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 90.00
   Final Test: 55.70
Split: 04, Run: 02
None time:  1.5548091370146722
None Run 11:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 96.67
   Final Test: 62.90
Split: 04, Run: 03
None time:  1.5660875691100955
None Run 12:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 96.67
   Final Test: 63.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.060497483005747
None Run 13:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.20
Split: 05, Run: 02
None time:  1.506975743919611
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.70
Split: 05, Run: 03
None time:  1.9253659201785922
None Run 15:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.3321393670048565
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 90.00
   Final Test: 63.30
Split: 06, Run: 02
None time:  1.5062909200787544
None Run 17:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.30
Split: 06, Run: 03
None time:  1.6143414850812405
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.5695955511182547
None Run 19:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 80.00
   Final Test: 57.60
Split: 07, Run: 02
None time:  1.8927553980611265
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 83.33
   Final Test: 57.60
Split: 07, Run: 03
None time:  1.75964087783359
None Run 21:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 86.67
   Final Test: 57.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.6237560741137713
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 76.67
   Final Test: 64.10
Split: 08, Run: 02
None time:  1.5674357828684151
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 67.90
Split: 08, Run: 03
None time:  1.6999828019179404
None Run 24:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 68.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.089366293977946
None Run 25:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 80.00
   Final Test: 58.30
Split: 09, Run: 02
None time:  1.6364735960960388
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 65.60
Split: 09, Run: 03
None time:  1.638473236002028
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.74295980297029
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 86.67
   Final Test: 66.90
Split: 10, Run: 02
None time:  1.6204834079835564
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 68.40
Split: 10, Run: 03
None time:  1.3827997490298003
None Run 30:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.90
run time now: 5.800828695297241
total time:  61.594527408946306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.05 ± 4.26
  Final Train: 92.00 ± 7.30
   Final Test: 64.51 ± 3.72
best run test_acc: 65.80000305175781
[I 2023-06-12 00:23:18,530] Trial 114 finished with value: 65.05333709716797 and parameters: {'Fwd': 0.05120898427940433, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 1.005691880286919, 'loop': 2, 'loss': 'CE', 'lr': 0.00043610579320650276, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.91476655160068e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.25
lr:  0.0005850340471780071
weight_decay:  2.2345250708603682e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4860775240231305
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 83.33
   Final Test: 58.60
Split: 01, Run: 02
None time:  1.4749036070425063
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.20
Split: 01, Run: 03
None time:  1.4751100719440728
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 64.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7814655271358788
None Run 04:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.80
Split: 02, Run: 02
None time:  1.4553618638310581
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 02, Run: 03
None time:  1.4118058599997312
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.2065869881771505
None Run 07:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 96.67
   Final Test: 59.10
Split: 03, Run: 02
None time:  1.4364175479859114
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.40
Split: 03, Run: 03
None time:  1.467539707897231
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.9226360300090164
None Run 10:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 66.90
Split: 04, Run: 02
None time:  1.6416978598572314
None Run 11:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 67.80
Split: 04, Run: 03
None time:  1.5454026530496776
None Run 12:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 67.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.250372973969206
None Run 13:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 93.33
   Final Test: 58.80
Split: 05, Run: 02
None time:  1.5501423198729753
None Run 14:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 64.30
Split: 05, Run: 03
None time:  1.4470594970043749
None Run 15:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.310736699961126
None Run 16:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 90.00
   Final Test: 55.60
Split: 06, Run: 02
None time:  1.4676869329996407
None Run 17:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.70
Split: 06, Run: 03
None time:  1.4343984019942582
None Run 18:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.323962864931673
None Run 19:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 90.00
   Final Test: 55.90
Split: 07, Run: 02
None time:  2.266229454893619
None Run 20:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 83.33
   Final Test: 56.30
Split: 07, Run: 03
None time:  1.5213881731033325
None Run 21:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 86.67
   Final Test: 57.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9382220599800348
None Run 22:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 86.67
   Final Test: 58.80
Split: 08, Run: 02
None time:  1.5949817849323153
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 66.70
Split: 08, Run: 03
None time:  1.5909758240450174
None Run 24:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 67.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4835693188942969
None Run 25:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 49.00
Split: 09, Run: 02
None time:  1.3297470898833126
None Run 26:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.90
Split: 09, Run: 03
None time:  1.572108588181436
None Run 27:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.112267949152738
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 90.00
   Final Test: 66.00
Split: 10, Run: 02
None time:  1.5319120320491493
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 67.70
Split: 10, Run: 03
None time:  1.4305479060858488
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 67.00
run time now: 6.130531072616577
total time:  54.784162105992436
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.85 ± 4.90
  Final Train: 94.89 ± 5.31
   Final Test: 63.22 ± 4.99
best run test_acc: 65.47999572753906
[I 2023-06-12 00:24:13,924] Trial 115 finished with value: 63.853336334228516 and parameters: {'Fwd': 0.059793080771149, 'K': 10, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 1.482898995189635, 'loop': 2, 'loss': 'CE', 'lr': 0.0005850340471780071, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.2345250708603682e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.00039052963575257236
weight_decay:  3.663400909664853e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.077985980082303
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 83.33
   Final Test: 63.70
Split: 01, Run: 02
None time:  1.6531993700191379
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 90.00
   Final Test: 64.60
Split: 01, Run: 03
None time:  1.71164406882599
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 80.00
   Final Test: 66.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.9224645770154893
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 66.70
Split: 02, Run: 02
None time:  1.6525876980740577
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.10
Split: 02, Run: 03
None time:  1.4959873280022293
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.2454513739794493
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.80
Split: 03, Run: 02
None time:  1.6509988969191909
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.00
Split: 03, Run: 03
None time:  1.4777185500133783
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.5589290759526193
None Run 10:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 83.33
   Final Test: 55.80
Split: 04, Run: 02
None time:  1.5341463070362806
None Run 11:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 96.67
   Final Test: 63.60
Split: 04, Run: 03
None time:  1.4904765710234642
None Run 12:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 96.67
   Final Test: 63.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.188733964925632
None Run 13:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 64.00
Split: 05, Run: 02
None time:  1.9116381069179624
None Run 14:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.80
Split: 05, Run: 03
None time:  1.7282032670918852
None Run 15:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 63.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.885814093053341
None Run 16:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 80.00
   Final Test: 62.40
Split: 06, Run: 02
None time:  1.5396170909516513
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.70
Split: 06, Run: 03
None time:  1.5780077788513154
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8683175898622721
None Run 19:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 49.70
Split: 07, Run: 02
None time:  1.7688754759728909
None Run 20:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 56.30
Split: 07, Run: 03
None time:  1.568638991797343
None Run 21:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 57.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.6547492840327322
None Run 22:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 80.00
   Final Test: 68.00
Split: 08, Run: 02
None time:  1.4820847839582711
None Run 23:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 68.60
Split: 08, Run: 03
None time:  1.4678435779642314
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 68.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.1301448789890856
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 90.00
   Final Test: 61.60
Split: 09, Run: 02
None time:  1.5500566579867154
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 65.30
Split: 09, Run: 03
None time:  1.4572718450799584
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.494981992058456
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 67.50
Split: 10, Run: 02
None time:  1.5431987249758095
None Run 29:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
Split: 10, Run: 03
None time:  1.3748656569514424
None Run 30:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.4677040576934814
total time:  60.96206549112685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.92 ± 5.18
  Final Train: 94.11 ± 6.47
   Final Test: 64.20 ± 4.45
best run test_acc: 65.5300064086914
[I 2023-06-12 00:25:15,442] Trial 116 finished with value: 64.92000579833984 and parameters: {'Fwd': 0.03943262103012718, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 1.2287271577115109, 'loop': 2, 'loss': 'CE', 'lr': 0.00039052963575257236, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.663400909664853e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.0006691025608901064
weight_decay:  5.694686459592304e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.064023793907836
None Run 01:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 50.20
Split: 01, Run: 02
None time:  1.456105331191793
None Run 02:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 50.30
Split: 01, Run: 03
None time:  1.5590832370799035
None Run 03:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 50.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.758424149826169
None Run 04:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 60.20
Split: 02, Run: 02
None time:  1.5868235731031746
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 59.90
Split: 02, Run: 03
None time:  1.6572297411039472
None Run 06:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 59.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8320963571313769
None Run 07:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 60.30
Split: 03, Run: 02
None time:  1.6944553737994283
None Run 08:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 60.10
Split: 03, Run: 03
None time:  1.6885101459920406
None Run 09:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 60.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.5346248589921743
None Run 10:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 96.67
   Final Test: 59.80
Split: 04, Run: 02
None time:  1.524834088049829
None Run 11:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 59.70
Split: 04, Run: 03
None time:  1.4795029030647129
None Run 12:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 59.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.5332864890806377
None Run 13:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.30
Split: 05, Run: 02
None time:  1.8205522210337222
None Run 14:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.10
Split: 05, Run: 03
None time:  1.6682925820350647
None Run 15:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6618375610560179
None Run 16:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 57.80
Split: 06, Run: 02
None time:  1.6947783268988132
None Run 17:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 60.10
Split: 06, Run: 03
None time:  1.4948256639763713
None Run 18:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 60.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8101201571989805
None Run 19:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 51.90
Split: 07, Run: 02
None time:  2.5417326509486884
None Run 20:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 52.80
Split: 07, Run: 03
None time:  2.3068638511467725
None Run 21:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 52.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.252120591001585
None Run 22:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 56.80
Split: 08, Run: 02
None time:  1.9816193520091474
None Run 23:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 56.40
Split: 08, Run: 03
None time:  2.4740380018483847
None Run 24:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 56.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6996156729292125
None Run 25:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 57.50
Split: 09, Run: 02
None time:  1.8126435258891433
None Run 26:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.80
Split: 09, Run: 03
None time:  1.8510708201210946
None Run 27:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0401845339220017
None Run 28:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.10
Split: 10, Run: 02
None time:  1.5960134351626039
None Run 29:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 60.10
Split: 10, Run: 03
None time:  1.937554873060435
None Run 30:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.20
run time now: 5.626110076904297
total time:  59.221286148997024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.99 ± 5.25
  Final Train: 99.78 ± 0.85
   Final Test: 57.59 ± 3.36
best run test_acc: 57.93999481201172
[I 2023-06-12 00:26:15,253] Trial 117 finished with value: 57.99333190917969 and parameters: {'Fwd': 0.09961427228060624, 'K': 9, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.7410701479790814, 'loop': 2, 'loss': 'CE', 'lr': 0.0006691025608901064, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.694686459592304e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.0003445723787112132
weight_decay:  2.7247109698190756e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8806137789506465
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 73.33
   Final Test: 65.10
Split: 01, Run: 02
None time:  1.3545459520537406
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 65.00
Split: 01, Run: 03
None time:  1.3121689648833126
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 64.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4744850168935955
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.20
Split: 02, Run: 02
None time:  1.3872915338724852
None Run 05:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.10
Split: 02, Run: 03
None time:  1.3572837931569666
None Run 06:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 66.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0717578979674727
None Run 07:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 65.70
Split: 03, Run: 02
None time:  1.6043847119435668
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.20
Split: 03, Run: 03
None time:  1.4652505270205438
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.403381235897541
None Run 10:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 96.67
   Final Test: 61.00
Split: 04, Run: 02
None time:  1.236415941035375
None Run 11:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 66.60
Split: 04, Run: 03
None time:  1.2242908680345863
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.4883265858516097
None Run 13:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 65.10
Split: 05, Run: 02
None time:  1.237413367955014
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.70
Split: 05, Run: 03
None time:  1.8030785250011832
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.337661910103634
None Run 16:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 83.33
   Final Test: 64.60
Split: 06, Run: 02
None time:  1.3280992179643363
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.40
Split: 06, Run: 03
None time:  1.3845403529703617
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 65.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.923392310971394
None Run 19:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 80.00
   Final Test: 58.70
Split: 07, Run: 02
None time:  1.4599704628344625
None Run 20:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 86.67
   Final Test: 59.70
Split: 07, Run: 03
None time:  1.5071181990206242
None Run 21:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 86.67
   Final Test: 60.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.1735754320397973
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 76.67
   Final Test: 65.50
Split: 08, Run: 02
None time:  1.3176712850108743
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.00
Split: 08, Run: 03
None time:  1.2630555550567806
None Run 24:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.60
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.893839303869754
None Run 25:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 73.33
   Final Test: 62.40
Split: 09, Run: 02
None time:  1.3964088649954647
None Run 26:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.70
Split: 09, Run: 03
None time:  1.286761752795428
None Run 27:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0297656538896263
None Run 28:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 86.67
   Final Test: 66.80
Split: 10, Run: 02
None time:  1.3379350719042122
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.40
Split: 10, Run: 03
None time:  1.3717036941088736
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
run time now: 4.783727645874023
total time:  53.468700079014525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.56 ± 3.32
  Final Train: 93.89 ± 8.67
   Final Test: 65.13 ± 2.53
best run test_acc: 66.11000061035156
[I 2023-06-12 00:27:09,313] Trial 118 finished with value: 65.55999755859375 and parameters: {'Fwd': 0.0171527065440157, 'K': 1, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 0.9336592680798251, 'loop': 2, 'loss': 'CE', 'lr': 0.0003445723787112132, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.7247109698190756e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.0005482851679055174
weight_decay:  1.7516372652280158e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7595366269815713
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 76.67
   Final Test: 63.80
Split: 01, Run: 02
None time:  1.4631448641885072
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 65.00
Split: 01, Run: 03
None time:  1.5702879501041025
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 64.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0780941611155868
None Run 04:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 67.00
Split: 02, Run: 02
None time:  1.3953188499435782
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 70.90
Split: 02, Run: 03
None time:  1.4766464640852064
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.6147314079571515
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 86.67
   Final Test: 66.60
Split: 03, Run: 02
None time:  1.5653476670850068
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.50
Split: 03, Run: 03
None time:  1.8838525488972664
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.0773920549545437
None Run 10:
Highest Train: 96.67
Highest Valid: 59.20
  Final Train: 83.33
   Final Test: 59.30
Split: 04, Run: 02
None time:  1.4935281809885055
None Run 11:
Highest Train: 96.67
Highest Valid: 64.00
  Final Train: 93.33
   Final Test: 65.30
Split: 04, Run: 03
None time:  1.4799867540132254
None Run 12:
Highest Train: 96.67
Highest Valid: 62.80
  Final Train: 93.33
   Final Test: 64.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.57802632288076
None Run 13:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 53.30
Split: 05, Run: 02
None time:  1.48725899704732
None Run 14:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 96.67
   Final Test: 59.10
Split: 05, Run: 03
None time:  1.4333137781359255
None Run 15:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 58.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.0181616058107466
None Run 16:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 59.70
Split: 06, Run: 02
None time:  1.515524139860645
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 03
None time:  1.5364772388711572
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 66.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7483856179751456
None Run 19:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 80.00
   Final Test: 57.80
Split: 07, Run: 02
None time:  1.675936423940584
None Run 20:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 86.67
   Final Test: 56.90
Split: 07, Run: 03
None time:  1.3289781247731298
None Run 21:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 83.33
   Final Test: 56.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.14468102180399
None Run 22:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 80.00
   Final Test: 56.00
Split: 08, Run: 02
None time:  1.4240668211132288
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 64.50
Split: 08, Run: 03
None time:  1.5686203490477055
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 66.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.699525701114908
None Run 25:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 73.33
   Final Test: 62.80
Split: 09, Run: 02
None time:  1.6257440440822393
None Run 26:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 86.67
   Final Test: 67.50
Split: 09, Run: 03
None time:  1.505405408097431
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 83.33
   Final Test: 66.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.81501083006151
None Run 28:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 90.00
   Final Test: 63.50
Split: 10, Run: 02
None time:  1.3128716519568115
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 68.80
Split: 10, Run: 03
None time:  1.4644221998751163
None Run 30:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.60
run time now: 5.671840667724609
total time:  58.05249989009462
None All runs:
Highest Train: 99.67 ± 1.02
Highest Valid: 64.34 ± 5.07
  Final Train: 91.11 ± 7.34
   Final Test: 63.74 ± 4.68
best run test_acc: 65.58999633789062
[I 2023-06-12 00:28:07,796] Trial 119 finished with value: 64.33999633789062 and parameters: {'Fwd': 0.06662766744964575, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.0009341084238758124, 'loop': 2, 'loss': 'CE', 'lr': 0.0005482851679055174, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.7516372652280158e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0004684256256720958
weight_decay:  4.1108712076495926e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1331404980737716
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 73.33
   Final Test: 63.60
Split: 01, Run: 02
None time:  1.4770302991382778
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.4636611267924309
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 66.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.22957267309539
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.40
Split: 02, Run: 02
None time:  1.4259294180665165
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 69.70
Split: 02, Run: 03
None time:  1.4611825118772686
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 70.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.1753829352092
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 90.00
   Final Test: 62.60
Split: 03, Run: 02
None time:  1.3975600500125438
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.30
Split: 03, Run: 03
None time:  1.4920503799803555
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.6762748730834574
None Run 10:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 83.33
   Final Test: 64.20
Split: 04, Run: 02
None time:  1.4835748930927366
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 65.70
Split: 04, Run: 03
None time:  1.3648058630060405
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 65.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.672787679824978
None Run 13:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 65.10
Split: 05, Run: 02
None time:  1.7962709160055965
None Run 14:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 63.00
Split: 05, Run: 03
None time:  1.6033844789490104
None Run 15:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 62.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.616044397931546
None Run 16:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 80.00
   Final Test: 61.60
Split: 06, Run: 02
None time:  1.4542639160063118
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 90.00
   Final Test: 67.20
Split: 06, Run: 03
None time:  1.2487725222017616
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.914384910138324
None Run 19:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 80.00
   Final Test: 59.10
Split: 07, Run: 02
None time:  1.224746200023219
None Run 20:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 96.67
   Final Test: 56.80
Split: 07, Run: 03
None time:  2.15087963687256
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 80.00
   Final Test: 57.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.0052351439371705
None Run 22:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 64.40
Split: 08, Run: 02
None time:  1.5008268270175904
None Run 23:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 69.10
Split: 08, Run: 03
None time:  1.594919481081888
None Run 24:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 90.00
   Final Test: 68.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.933827514993027
None Run 25:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 86.67
   Final Test: 63.00
Split: 09, Run: 02
None time:  1.4833757290616632
None Run 26:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 68.30
Split: 09, Run: 03
None time:  1.6289977771230042
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 67.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0153255939949304
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 67.60
Split: 10, Run: 02
None time:  1.484998726984486
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.20
Split: 10, Run: 03
None time:  1.4323682989925146
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 5.110800504684448
total time:  59.021919511957094
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.79 ± 4.09
  Final Train: 92.44 ± 6.83
   Final Test: 65.50 ± 3.55
best run test_acc: 66.83000183105469
[I 2023-06-12 00:29:07,462] Trial 120 finished with value: 65.7933349609375 and parameters: {'Fwd': 0.030583556720142572, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 1.1496352093455608, 'loop': 2, 'loss': 'CE', 'lr': 0.0004684256256720958, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.1108712076495926e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.00048152222902493044
weight_decay:  4.170520150474086e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0566357760690153
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 83.33
   Final Test: 62.90
Split: 01, Run: 02
None time:  1.5408243259880692
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 86.67
   Final Test: 64.40
Split: 01, Run: 03
None time:  1.6112517300061882
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 64.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.215858791023493
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 68.30
Split: 02, Run: 02
None time:  1.4387155619915575
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 69.40
Split: 02, Run: 03
None time:  1.4043310810811818
None Run 06:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.5887790739070624
None Run 07:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 90.00
   Final Test: 65.20
Split: 03, Run: 02
None time:  1.4307581731118262
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.30
Split: 03, Run: 03
None time:  1.4991926739457995
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.209067848045379
None Run 10:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 96.67
   Final Test: 59.20
Split: 04, Run: 02
None time:  1.455032333964482
None Run 11:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 66.10
Split: 04, Run: 03
None time:  1.4905755850486457
None Run 12:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 66.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1166570901405066
None Run 13:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.40
Split: 05, Run: 02
None time:  1.9346087810117751
None Run 14:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 65.20
Split: 05, Run: 03
None time:  2.068419062998146
None Run 15:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.838461329927668
None Run 16:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 83.33
   Final Test: 60.40
Split: 06, Run: 02
None time:  1.4193295298609883
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.80
Split: 06, Run: 03
None time:  1.4895131890662014
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 66.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.235121793113649
None Run 19:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 76.67
   Final Test: 59.50
Split: 07, Run: 02
None time:  2.6997059241402894
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 80.00
   Final Test: 59.70
Split: 07, Run: 03
None time:  1.3791849450208247
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 83.33
   Final Test: 58.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.319785156985745
None Run 22:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 80.00
   Final Test: 64.80
Split: 08, Run: 02
None time:  1.627696885028854
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 86.67
   Final Test: 68.00
Split: 08, Run: 03
None time:  1.5424945908598602
None Run 24:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 80.00
   Final Test: 67.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  4.055958860786632
None Run 25:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 73.33
   Final Test: 60.70
Split: 09, Run: 02
None time:  1.5066402140073478
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 67.80
Split: 09, Run: 03
None time:  1.5072974311187863
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 67.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.0473065089900047
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 86.67
   Final Test: 66.70
Split: 10, Run: 02
None time:  1.6693770980928093
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.00
   Final Test: 68.70
Split: 10, Run: 03
None time:  1.5567031840328127
None Run 30:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.50
run time now: 6.334510564804077
total time:  61.20961402403191
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.91 ± 3.62
  Final Train: 90.56 ± 7.59
   Final Test: 65.21 ± 3.19
best run test_acc: 66.41999816894531
[I 2023-06-12 00:30:09,220] Trial 121 finished with value: 65.90666198730469 and parameters: {'Fwd': 0.03118901401644905, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 1.1629386256299552, 'loop': 2, 'loss': 'CE', 'lr': 0.00048152222902493044, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.170520150474086e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0004690423575205137
weight_decay:  3.892959832103071e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.141964207869023
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 76.67
   Final Test: 65.40
Split: 01, Run: 02
None time:  2.024354918859899
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 76.67
   Final Test: 65.00
Split: 01, Run: 03
None time:  1.9100586159620434
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 76.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1416307319886982
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.20
Split: 02, Run: 02
None time:  1.6174874079879373
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.90
Split: 02, Run: 03
None time:  1.5591271489392966
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.0594667170662433
None Run 07:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 63.00
Split: 03, Run: 02
None time:  1.6541922008618712
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.70
Split: 03, Run: 03
None time:  1.816273408010602
None Run 09:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.6465166709385812
None Run 10:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 57.50
Split: 04, Run: 02
None time:  1.5494758950080723
None Run 11:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 64.10
Split: 04, Run: 03
None time:  1.5437435249332339
None Run 12:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 64.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.8241639300249517
None Run 13:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.60
Split: 05, Run: 02
None time:  1.6986079320777208
None Run 14:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.40
Split: 05, Run: 03
None time:  1.7517845930997282
None Run 15:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6146862560417503
None Run 16:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 59.50
Split: 06, Run: 02
None time:  1.6393084458541125
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 66.50
Split: 06, Run: 03
None time:  1.5317226559855044
None Run 18:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.0494127650745213
None Run 19:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 80.00
   Final Test: 58.10
Split: 07, Run: 02
None time:  1.8834645189344883
None Run 20:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 86.67
   Final Test: 58.80
Split: 07, Run: 03
None time:  2.1422238321974874
None Run 21:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 83.33
   Final Test: 59.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.3394105101469904
None Run 22:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 76.67
   Final Test: 61.10
Split: 08, Run: 02
None time:  1.6267840331420302
None Run 23:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 67.70
Split: 08, Run: 03
None time:  1.5517778971698135
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.882183005101979
None Run 25:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 80.00
   Final Test: 60.30
Split: 09, Run: 02
None time:  1.7039016589988023
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.10
Split: 09, Run: 03
None time:  1.760218651033938
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 66.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.503014317015186
None Run 28:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 68.40
Split: 10, Run: 02
None time:  1.6190249710343778
None Run 29:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
Split: 10, Run: 03
None time:  1.425105809001252
None Run 30:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 5.601572751998901
total time:  62.660303671844304
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.92 ± 4.20
  Final Train: 92.33 ± 8.58
   Final Test: 65.04 ± 3.82
best run test_acc: 66.51000213623047
[I 2023-06-12 00:31:12,435] Trial 122 finished with value: 65.92000579833984 and parameters: {'Fwd': 0.03259929544522139, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 1.451234245160796, 'loop': 2, 'loss': 'CE', 'lr': 0.0004690423575205137, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.892959832103071e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0004856995613337886
weight_decay:  9.444911962831709e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.288864466128871
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 66.67
   Final Test: 64.80
Split: 01, Run: 02
None time:  1.6765647681895643
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 73.33
   Final Test: 66.60
Split: 01, Run: 03
None time:  1.6703846307937056
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 76.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4802513069007546
None Run 04:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 70.30
Split: 02, Run: 02
None time:  1.4423649560194463
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 70.00
Split: 02, Run: 03
None time:  1.43400201597251
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.555956409079954
None Run 07:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 83.33
   Final Test: 60.60
Split: 03, Run: 02
None time:  1.6217277268879116
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 86.67
   Final Test: 65.20
Split: 03, Run: 03
None time:  1.6645185200031847
None Run 09:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 86.67
   Final Test: 65.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4969866208266467
None Run 10:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 96.67
   Final Test: 61.30
Split: 04, Run: 02
None time:  1.5254208440892398
None Run 11:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 66.60
Split: 04, Run: 03
None time:  1.47114438097924
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.590003789868206
None Run 13:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 63.30
Split: 05, Run: 02
None time:  1.7286510199774057
None Run 14:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 63.20
Split: 05, Run: 03
None time:  1.75050562992692
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.263885220978409
None Run 16:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 86.67
   Final Test: 59.60
Split: 06, Run: 02
None time:  1.429037209134549
None Run 17:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 67.40
Split: 06, Run: 03
None time:  1.4910287191160023
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.980604951037094
None Run 19:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 90.00
   Final Test: 56.80
Split: 07, Run: 02
None time:  2.7020400259643793
None Run 20:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 83.33
   Final Test: 59.10
Split: 07, Run: 03
None time:  1.4373587570153177
None Run 21:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 90.00
   Final Test: 59.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.9764217999763787
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 76.67
   Final Test: 66.20
Split: 08, Run: 02
None time:  1.5555655770003796
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 67.60
Split: 08, Run: 03
None time:  1.611954360967502
None Run 24:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 86.67
   Final Test: 66.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.711023678071797
None Run 25:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 80.00
   Final Test: 62.50
Split: 09, Run: 02
None time:  1.659344257088378
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 67.20
Split: 09, Run: 03
None time:  1.4768967090640217
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.286156057147309
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.70
Split: 10, Run: 02
None time:  1.5331274520140141
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.00
Split: 10, Run: 03
None time:  1.5605882939416915
None Run 30:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 5.434032678604126
total time:  61.36281742202118
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.86 ± 4.11
  Final Train: 90.44 ± 8.87
   Final Test: 65.17 ± 3.61
best run test_acc: 66.40000915527344
[I 2023-06-12 00:32:14,395] Trial 123 finished with value: 65.86000061035156 and parameters: {'Fwd': 0.03209436458348231, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 1.7760452255266828, 'loop': 2, 'loss': 'CE', 'lr': 0.0004856995613337886, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.444911962831709e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.00046471668608285134
weight_decay:  8.33095969024566e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.508698129095137
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 63.33
   Final Test: 66.80
Split: 01, Run: 02
None time:  1.474936646176502
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.4742489529307932
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 67.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.555937911849469
None Run 04:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.00
Split: 02, Run: 02
None time:  1.4984347650315613
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.40
Split: 02, Run: 03
None time:  1.5486821040976793
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.816449300153181
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 65.00
Split: 03, Run: 02
None time:  1.5033208751119673
None Run 08:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.70
Split: 03, Run: 03
None time:  1.5270430978853256
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.637012042105198
None Run 10:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 96.67
   Final Test: 53.70
Split: 04, Run: 02
None time:  1.5452199869323522
None Run 11:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 65.90
Split: 04, Run: 03
None time:  1.497821574099362
None Run 12:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 96.67
   Final Test: 64.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.553574674995616
None Run 13:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 63.00
Split: 05, Run: 02
None time:  1.586633794941008
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.30
Split: 05, Run: 03
None time:  2.280762145994231
None Run 15:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.372941011097282
None Run 16:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 64.60
Split: 06, Run: 02
None time:  1.5533199550118297
None Run 17:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.60
Split: 06, Run: 03
None time:  1.5283381610643119
None Run 18:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 68.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.5467209219932556
None Run 19:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 83.33
   Final Test: 56.70
Split: 07, Run: 02
None time:  1.5588420941494405
None Run 20:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 59.70
Split: 07, Run: 03
None time:  1.5825330768711865
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 96.67
   Final Test: 59.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5245446918997914
None Run 22:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.00
Split: 08, Run: 02
None time:  1.577683862997219
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 63.70
Split: 08, Run: 03
None time:  1.5211381840053946
None Run 24:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.743466124171391
None Run 25:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 86.67
   Final Test: 60.90
Split: 09, Run: 02
None time:  1.545510253868997
None Run 26:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 64.20
Split: 09, Run: 03
None time:  1.5852760109119117
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 63.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.1764380079694092
None Run 28:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 86.67
   Final Test: 65.10
Split: 10, Run: 02
None time:  1.6160414731130004
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 68.90
Split: 10, Run: 03
None time:  1.6061723318416625
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 68.50
run time now: 6.452462196350098
total time:  59.36234420607798
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.72 ± 4.49
  Final Train: 95.00 ± 7.52
   Final Test: 64.56 ± 4.10
best run test_acc: 66.16000366210938
[I 2023-06-12 00:33:14,292] Trial 124 finished with value: 64.72000122070312 and parameters: {'Fwd': 0.029927938523412644, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 2.0493998983099195, 'loop': 2, 'loss': 'CE', 'lr': 0.00046471668608285134, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.33095969024566e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.00042923832168658576
weight_decay:  9.94862910342293e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.5286509541328996
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 83.33
   Final Test: 65.30
Split: 01, Run: 02
None time:  1.5441877411212772
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 64.60
Split: 01, Run: 03
None time:  1.5221810080111027
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 66.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.604309835936874
None Run 04:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.30
Split: 02, Run: 02
None time:  1.5270457230508327
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.10
Split: 02, Run: 03
None time:  1.5400141549762338
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.5776202199049294
None Run 07:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.40
Split: 03, Run: 02
None time:  3.024003152968362
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 90.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  1.7066645838785917
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.057862706016749
None Run 10:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 96.67
   Final Test: 61.60
Split: 04, Run: 02
None time:  1.3833755070809275
None Run 11:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 65.00
Split: 04, Run: 03
None time:  1.5017581111751497
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 65.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.5099463597871363
None Run 13:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 67.90
Split: 05, Run: 02
None time:  1.9944411939941347
None Run 14:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.20
Split: 05, Run: 03
None time:  2.5907822060398757
None Run 15:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.608673440059647
None Run 16:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 60.30
Split: 06, Run: 02
None time:  1.546529153129086
None Run 17:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.50
Split: 06, Run: 03
None time:  1.578750445973128
None Run 18:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 65.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.3546019471250474
None Run 19:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 93.33
   Final Test: 48.80
Split: 07, Run: 02
None time:  1.4440024171490222
None Run 20:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 52.50
Split: 07, Run: 03
None time:  1.9847700169775635
None Run 21:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 93.33
   Final Test: 53.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.339158949209377
None Run 22:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 62.40
Split: 08, Run: 02
None time:  1.5725433127954602
None Run 23:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 66.40
Split: 08, Run: 03
None time:  1.50365298287943
None Run 24:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 67.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.264168652938679
None Run 25:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 86.67
   Final Test: 60.20
Split: 09, Run: 02
None time:  1.6068019040394574
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 65.70
Split: 09, Run: 03
None time:  1.6206035770010203
None Run 27:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.557052040938288
None Run 28:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 66.40
Split: 10, Run: 02
None time:  1.548177903983742
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.90
Split: 10, Run: 03
None time:  1.5034469799138606
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 5.66292667388916
total time:  63.94186237012036
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.59 ± 5.21
  Final Train: 95.67 ± 4.21
   Final Test: 64.56 ± 5.11
best run test_acc: 65.91000366210938
[I 2023-06-12 00:34:18,794] Trial 125 finished with value: 65.586669921875 and parameters: {'Fwd': 0.0552011780374717, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 1.711857618620993, 'loop': 2, 'loss': 'CE', 'lr': 0.00042923832168658576, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.94862910342293e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.00036404560554860536
weight_decay:  3.173678514241926e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.420060246018693
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 63.33
   Final Test: 60.40
Split: 01, Run: 02
None time:  1.373538397019729
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 83.33
   Final Test: 62.30
Split: 01, Run: 03
None time:  1.3751113060861826
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 76.67
   Final Test: 61.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9817835469730198
None Run 04:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.70
Split: 02, Run: 02
None time:  1.2443068430293351
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.70
Split: 02, Run: 03
None time:  1.2841208421159536
None Run 06:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.045005289139226
None Run 07:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 90.00
   Final Test: 62.90
Split: 03, Run: 02
None time:  1.19498392008245
None Run 08:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.80
Split: 03, Run: 03
None time:  1.204957780893892
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.1985344919376075
None Run 10:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 63.60
Split: 04, Run: 02
None time:  1.2135265942197293
None Run 11:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 66.10
Split: 04, Run: 03
None time:  1.2205191371031106
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 65.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.26798340305686
None Run 13:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 60.60
Split: 05, Run: 02
None time:  1.0981800199951977
None Run 14:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.60
Split: 05, Run: 03
None time:  1.2117727710865438
None Run 15:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9993397679645568
None Run 16:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 64.70
Split: 06, Run: 02
None time:  1.2182179640512913
None Run 17:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 03
None time:  1.1386634029913694
None Run 18:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 65.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.6504772840999067
None Run 19:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 80.00
   Final Test: 57.20
Split: 07, Run: 02
None time:  1.2501827857922763
None Run 20:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 83.33
   Final Test: 56.80
Split: 07, Run: 03
None time:  1.2406415638979524
None Run 21:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 83.33
   Final Test: 55.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.0633264160715044
None Run 22:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 83.33
   Final Test: 64.30
Split: 08, Run: 02
None time:  1.1950910680461675
None Run 23:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 90.00
   Final Test: 69.10
Split: 08, Run: 03
None time:  1.2132401510607451
None Run 24:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 90.00
   Final Test: 67.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.916917232098058
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 76.67
   Final Test: 59.50
Split: 09, Run: 02
None time:  1.351863575866446
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 64.50
Split: 09, Run: 03
None time:  1.2604542910121381
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 65.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.494811153039336
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 86.67
   Final Test: 66.70
Split: 10, Run: 02
None time:  1.145559904165566
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.10
Split: 10, Run: 03
None time:  1.180826392956078
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 4.875782251358032
total time:  55.962277807993814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.05 ± 3.98
  Final Train: 91.33 ± 9.16
   Final Test: 63.99 ± 3.91
best run test_acc: 64.99000549316406
[I 2023-06-12 00:35:15,298] Trial 126 finished with value: 65.05332946777344 and parameters: {'Fwd': 0.022539393047927167, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 1.4753612469047832, 'loop': 2, 'loss': 'CE', 'lr': 0.00036404560554860536, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.173678514241926e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.0004899156335321544
weight_decay:  6.218367107280759e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.2475894559174776
None Run 01:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 83.33
   Final Test: 63.00
Split: 01, Run: 02
None time:  1.8672331999987364
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 93.33
   Final Test: 63.30
Split: 01, Run: 03
None time:  1.7161146171856672
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 86.67
   Final Test: 64.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.425358752021566
None Run 04:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.70
Split: 02, Run: 02
None time:  1.5651125661097467
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.40
Split: 02, Run: 03
None time:  1.5732415069360286
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.800745409913361
None Run 07:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.30
Split: 03, Run: 02
None time:  2.063166603911668
None Run 08:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 66.90
Split: 03, Run: 03
None time:  1.561893945094198
None Run 09:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.7955075760837644
None Run 10:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 96.67
   Final Test: 54.80
Split: 04, Run: 02
None time:  1.5188206410966814
None Run 11:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 96.67
   Final Test: 63.90
Split: 04, Run: 03
None time:  1.552610034123063
None Run 12:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 96.67
   Final Test: 64.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.804845063947141
None Run 13:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 55.10
Split: 05, Run: 02
None time:  1.6420970971230417
None Run 14:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.30
Split: 05, Run: 03
None time:  1.5435037058778107
None Run 15:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.6623619119636714
None Run 16:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 64.40
Split: 06, Run: 02
None time:  1.5373662610072643
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.30
Split: 06, Run: 03
None time:  1.514223655918613
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.1553262220695615
None Run 19:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 83.33
   Final Test: 58.60
Split: 07, Run: 02
None time:  2.0177870159968734
None Run 20:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 86.67
   Final Test: 58.80
Split: 07, Run: 03
None time:  1.3781711820047349
None Run 21:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 86.67
   Final Test: 58.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.853126806905493
None Run 22:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 80.00
   Final Test: 58.30
Split: 08, Run: 02
None time:  1.5522831450216472
None Run 23:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.00
   Final Test: 65.50
Split: 08, Run: 03
None time:  1.5671447739005089
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 66.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.25941949384287
None Run 25:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 93.33
   Final Test: 60.50
Split: 09, Run: 02
None time:  1.5860774598550051
None Run 26:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 63.60
Split: 09, Run: 03
None time:  1.5797303849831223
None Run 27:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 63.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.6951847181189805
None Run 28:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 90.00
   Final Test: 66.90
Split: 10, Run: 02
None time:  1.5681364838965237
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 68.30
Split: 10, Run: 03
None time:  1.423397023929283
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 5.747539043426514
total time:  61.32499572704546
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.69 ± 4.58
  Final Train: 94.11 ± 5.92
   Final Test: 64.12 ± 4.33
best run test_acc: 65.4699935913086
[I 2023-06-12 00:36:17,187] Trial 127 finished with value: 64.6933364868164 and parameters: {'Fwd': 0.07770907049363097, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 1.2018971280843291, 'loop': 2, 'loss': 'CE', 'lr': 0.0004899156335321544, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.218367107280759e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0006328562118344311
weight_decay:  2.046541018730699e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.694355885963887
None Run 01:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 35.20
Split: 01, Run: 02
None time:  1.8473958210088313
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 93.33
   Final Test: 60.10
Split: 01, Run: 03
None time:  0.8954229899682105
None Run 03:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 90.00
   Final Test: 59.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6979433370288461
None Run 04:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 40.60
Split: 02, Run: 02
None time:  1.609351857099682
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 67.50
Split: 02, Run: 03
None time:  0.8701211800798774
None Run 06:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 65.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6912147491239011
None Run 07:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 40.50
Split: 03, Run: 02
None time:  1.7674839838873595
None Run 08:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 62.70
Split: 03, Run: 03
None time:  0.7702323100529611
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6999365279916674
None Run 10:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 41.20
Split: 04, Run: 02
None time:  1.1781730570364743
None Run 11:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 54.50
Split: 04, Run: 03
None time:  0.8021549622062594
None Run 12:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 62.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6733381559606642
None Run 13:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 43.00
Split: 05, Run: 02
None time:  1.328525837045163
None Run 14:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.30
Split: 05, Run: 03
None time:  0.9253217878285795
None Run 15:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 57.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9395425759721547
None Run 16:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 90.00
   Final Test: 61.50
Split: 06, Run: 02
None time:  0.7936103451065719
None Run 17:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 83.33
   Final Test: 61.80
Split: 06, Run: 03
None time:  0.8159779391717166
None Run 18:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 64.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6804846178274602
None Run 19:
Highest Train: 100.00
Highest Valid: 27.40
  Final Train: 100.00
   Final Test: 32.10
Split: 07, Run: 02
None time:  2.277522458927706
None Run 20:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 83.33
   Final Test: 54.80
Split: 07, Run: 03
None time:  0.7557959300465882
None Run 21:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 93.33
   Final Test: 53.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4975805589929223
None Run 22:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 59.90
Split: 08, Run: 02
None time:  0.7731478200294077
None Run 23:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 65.70
Split: 08, Run: 03
None time:  0.8399041008669883
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 66.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7022644598037004
None Run 25:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 36.70
Split: 09, Run: 02
None time:  1.9129533651284873
None Run 26:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 93.33
   Final Test: 62.80
Split: 09, Run: 03
None time:  0.9022449261974543
None Run 27:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 93.33
   Final Test: 64.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.1787638089153916
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 67.60
Split: 10, Run: 02
None time:  0.7744404580444098
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 69.40
Split: 10, Run: 03
None time:  0.7866374780423939
None Run 30:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 69.40
run time now: 3.79365611076355
total time:  34.368134116055444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.64 ± 11.92
  Final Train: 95.33 ± 4.84
   Final Test: 56.80 ± 11.13
best run test_acc: 63.30999755859375
[I 2023-06-12 00:36:52,126] Trial 128 finished with value: 57.6400032043457 and parameters: {'Fwd': 0.045337890568211886, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.5, 'lambda2': 1.6893795223530605, 'loop': 2, 'loss': 'CE', 'lr': 0.0006328562118344311, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.046541018730699e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.00045620522931936694
weight_decay:  1.3646276353231377e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1459227949380875
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 80.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  2.006388298003003
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 83.33
   Final Test: 66.60
Split: 01, Run: 03
None time:  1.8923238669522107
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 76.67
   Final Test: 66.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.904628388117999
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 69.10
Split: 02, Run: 02
None time:  1.5770673230290413
None Run 05:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.80
Split: 02, Run: 03
None time:  1.5251884758472443
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.2355603280011564
None Run 07:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 65.80
Split: 03, Run: 02
None time:  1.8683399430010468
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 64.70
Split: 03, Run: 03
None time:  1.4580874959938228
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.2448770869523287
None Run 10:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 93.33
   Final Test: 56.40
Split: 04, Run: 02
None time:  1.5122840309049934
None Run 11:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 65.70
Split: 04, Run: 03
None time:  1.6213603580836207
None Run 12:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.8060177529696375
None Run 13:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 62.50
Split: 05, Run: 02
None time:  1.5679699969477952
None Run 14:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.80
Split: 05, Run: 03
None time:  1.5594939948059618
None Run 15:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.132001067046076
None Run 16:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 60.50
Split: 06, Run: 02
None time:  1.544495427981019
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.50
Split: 06, Run: 03
None time:  1.5115628901403397
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.696030735038221
None Run 19:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 83.33
   Final Test: 58.00
Split: 07, Run: 02
None time:  1.5155134899541736
None Run 20:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 96.67
   Final Test: 59.80
Split: 07, Run: 03
None time:  1.5231417240574956
None Run 21:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 90.00
   Final Test: 60.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.872414373094216
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 86.67
   Final Test: 64.20
Split: 08, Run: 02
None time:  1.6476969420909882
None Run 23:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 68.00
Split: 08, Run: 03
None time:  1.6491164341568947
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 90.00
   Final Test: 68.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.796327277086675
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 93.33
   Final Test: 61.90
Split: 09, Run: 02
None time:  1.6535042370669544
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 64.80
Split: 09, Run: 03
None time:  1.6002661299426109
None Run 27:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 65.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0343232590239495
None Run 28:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.50
Split: 10, Run: 02
None time:  1.5164155270904303
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
Split: 10, Run: 03
None time:  1.5842983149923384
None Run 30:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 5.19081974029541
total time:  60.54207198298536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.71 ± 4.35
  Final Train: 93.89 ± 6.20
   Final Test: 65.25 ± 3.52
best run test_acc: 66.54000091552734
[I 2023-06-12 00:37:53,175] Trial 129 finished with value: 65.70667266845703 and parameters: {'Fwd': 0.031893477804316527, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 2.076069216783469, 'loop': 2, 'loss': 'CE', 'lr': 0.00045620522931936694, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.3646276353231377e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.25
lr:  0.0003900641760018051
weight_decay:  1.1672402293577785e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6331222830340266
None Run 01:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 35.20
Split: 01, Run: 02
None time:  0.6301401660311967
None Run 02:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 35.20
Split: 01, Run: 03
None time:  0.5944570961873978
None Run 03:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 35.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.61546111991629
None Run 04:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 40.60
Split: 02, Run: 02
None time:  1.9525968958623707
None Run 05:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 61.90
Split: 02, Run: 03
None time:  0.6511551630683243
None Run 06:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.6166827990673482
None Run 07:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 40.50
Split: 03, Run: 02
None time:  0.6179329240694642
None Run 08:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 40.50
Split: 03, Run: 03
None time:  3.0988334661815315
None Run 09:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 83.33
   Final Test: 47.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6434276930522174
None Run 10:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 41.20
Split: 04, Run: 02
None time:  0.6241221278905869
None Run 11:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 41.20
Split: 04, Run: 03
None time:  0.6273340159095824
None Run 12:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 41.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.6220284779556096
None Run 13:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 43.00
Split: 05, Run: 02
None time:  0.6183339529670775
None Run 14:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 43.00
Split: 05, Run: 03
None time:  0.6080380941275507
None Run 15:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 43.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6088198299985379
None Run 16:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.40
Split: 06, Run: 02
None time:  0.6294831121340394
None Run 17:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.40
Split: 06, Run: 03
None time:  1.0087526550050825
None Run 18:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 93.33
   Final Test: 47.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6146311298944056
None Run 19:
Highest Train: 100.00
Highest Valid: 27.40
  Final Train: 100.00
   Final Test: 32.10
Split: 07, Run: 02
None time:  0.6122544980607927
None Run 20:
Highest Train: 100.00
Highest Valid: 27.40
  Final Train: 100.00
   Final Test: 32.10
Split: 07, Run: 03
None time:  4.023325131973252
None Run 21:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 73.33
   Final Test: 40.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5893455990590155
None Run 22:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.20
Split: 08, Run: 02
None time:  0.566060284152627
None Run 23:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.20
Split: 08, Run: 03
None time:  0.5999024950433522
None Run 24:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.6314877669792622
None Run 25:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 36.60
Split: 09, Run: 02
None time:  0.605408723000437
None Run 26:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 36.60
Split: 09, Run: 03
None time:  1.9521899279206991
None Run 27:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 80.00
   Final Test: 49.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.3101963279768825
None Run 28:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 86.67
   Final Test: 49.80
Split: 10, Run: 02
None time:  0.630490856943652
None Run 29:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 90.00
   Final Test: 54.90
Split: 10, Run: 03
None time:  0.6609745630994439
None Run 30:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 90.00
   Final Test: 56.10
run time now: 4.656276226043701
total time:  31.49408335913904
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 43.77 ± 8.85
  Final Train: 96.44 ± 7.05
   Final Test: 43.30 ± 7.98
best run test_acc: 46.75
[I 2023-06-12 00:38:25,144] Trial 130 finished with value: 43.773338317871094 and parameters: {'Fwd': 0.029418630646102256, 'K': 10, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 10, 'lambda1': 0.6000000000000001, 'lambda2': 2.016230661052925, 'loop': 2, 'loss': 'CE', 'lr': 0.0003900641760018051, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.1672402293577785e-05, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0004271292347915962
weight_decay:  8.383476565224782e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.242719439091161
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 80.00
   Final Test: 64.10
Split: 01, Run: 02
None time:  1.8522194800898433
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 80.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.5949523139279336
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 90.00
   Final Test: 66.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.211634522071108
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 90.00
   Final Test: 67.30
Split: 02, Run: 02
None time:  1.5503442459739745
None Run 05:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.00
Split: 02, Run: 03
None time:  1.4922757418826222
None Run 06:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.258529835147783
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 62.90
Split: 03, Run: 02
None time:  1.555111285066232
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.90
Split: 03, Run: 03
None time:  1.5620461360085756
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.246943651000038
None Run 10:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 62.60
Split: 04, Run: 02
None time:  1.5595251498743892
None Run 11:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 66.60
Split: 04, Run: 03
None time:  1.4574004239402711
None Run 12:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.367540647974238
None Run 13:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 62.10
Split: 05, Run: 02
None time:  1.5928682589437813
None Run 14:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 63.00
Split: 05, Run: 03
None time:  1.6907098658848554
None Run 15:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4904117381665856
None Run 16:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 51.40
Split: 06, Run: 02
None time:  1.4865490610245615
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.40
Split: 06, Run: 03
None time:  1.5831473690923303
None Run 18:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.10495367879048
None Run 19:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 83.33
   Final Test: 57.40
Split: 07, Run: 02
None time:  1.5696110730059445
None Run 20:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 86.67
   Final Test: 57.80
Split: 07, Run: 03
None time:  1.5664782328531146
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 93.33
   Final Test: 57.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9380654150154442
None Run 22:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 90.00
   Final Test: 63.50
Split: 08, Run: 02
None time:  1.6028834450989962
None Run 23:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 67.90
Split: 08, Run: 03
None time:  1.6257582809776068
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 68.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.5957234071101993
None Run 25:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 83.33
   Final Test: 60.90
Split: 09, Run: 02
None time:  1.5455070629250258
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 66.30
Split: 09, Run: 03
None time:  1.6932422230020165
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 90.00
   Final Test: 66.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.9100035591982305
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 90.00
   Final Test: 66.80
Split: 10, Run: 02
None time:  1.5754455090500414
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 69.10
Split: 10, Run: 03
None time:  1.5340587261598557
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.20
run time now: 6.076930522918701
total time:  61.44694445817731
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.11 ± 4.34
  Final Train: 93.33 ± 5.81
   Final Test: 64.32 ± 4.15
best run test_acc: 65.77000427246094
[I 2023-06-12 00:39:27,134] Trial 131 finished with value: 65.11332702636719 and parameters: {'Fwd': 0.03397024320764539, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 1.3858558926801412, 'loop': 2, 'loss': 'CE', 'lr': 0.0004271292347915962, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.383476565224782e-06, 'weightedloss': False}. Best is trial 84 with value: 66.1866683959961.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0004497501722230735
weight_decay:  1.5069151856803971e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.0210531749762595
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 76.67
   Final Test: 67.20
Split: 01, Run: 02
None time:  2.1779388268478215
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 70.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  1.784230092074722
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 70.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8793103271164
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.70
Split: 02, Run: 02
None time:  1.5214416161179543
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.40
Split: 02, Run: 03
None time:  1.359732586890459
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.629289806820452
None Run 07:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.40
Split: 03, Run: 02
None time:  1.5740878081414849
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.60
Split: 03, Run: 03
None time:  1.5429083090275526
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.260512651875615
None Run 10:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 62.60
Split: 04, Run: 02
None time:  1.5597565611824393
None Run 11:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 64.90
Split: 04, Run: 03
None time:  1.630270244088024
None Run 12:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 96.67
   Final Test: 64.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.66750305891037
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.90
Split: 05, Run: 02
None time:  2.999634950887412
None Run 14:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 67.60
Split: 05, Run: 03
None time:  2.017794447951019
None Run 15:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 67.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6566339959390461
None Run 16:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.50
Split: 06, Run: 02
None time:  1.585810475051403
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.50
Split: 06, Run: 03
None time:  1.4783941258210689
None Run 18:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.0281100829597563
None Run 19:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 86.67
   Final Test: 59.60
Split: 07, Run: 02
None time:  1.662558012176305
None Run 20:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 86.67
   Final Test: 58.70
Split: 07, Run: 03
None time:  2.395152529934421
None Run 21:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 80.00
   Final Test: 58.10
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.6367227430455387
None Run 22:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 86.67
   Final Test: 67.00
Split: 08, Run: 02
None time:  1.5029380230698735
None Run 23:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 08, Run: 03
None time:  1.4990072499495
None Run 24:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 96.67
   Final Test: 70.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.7862728929612786
None Run 25:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 90.00
   Final Test: 62.50
Split: 09, Run: 02
None time:  1.5259199698921293
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.70
Split: 09, Run: 03
None time:  1.6224604500457644
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.384709537960589
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 93.33
   Final Test: 66.60
Split: 10, Run: 02
None time:  1.5116754539776593
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
Split: 10, Run: 03
None time:  1.5033130911178887
None Run 30:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 5.453178644180298
total time:  62.76402893685736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.56 ± 4.43
  Final Train: 93.44 ± 8.86
   Final Test: 65.70 ± 3.80
best run test_acc: 66.97999572753906
[I 2023-06-12 00:40:30,416] Trial 132 finished with value: 66.56000518798828 and parameters: {'Fwd': 0.022932135782817328, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 2.46139794672861, 'loop': 2, 'loss': 'CE', 'lr': 0.0004497501722230735, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.5069151856803971e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0004572576505024362
weight_decay:  1.4534084862010777e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4653401388786733
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 76.67
   Final Test: 63.70
Split: 01, Run: 02
None time:  1.8456454039551318
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 76.67
   Final Test: 64.50
Split: 01, Run: 03
None time:  2.0197755829431117
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 70.00
   Final Test: 64.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.2587176649831235
None Run 04:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 69.90
Split: 02, Run: 02
None time:  1.5108514728490263
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.10
Split: 02, Run: 03
None time:  1.6270207609049976
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.5747800040990114
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 93.33
   Final Test: 64.00
Split: 03, Run: 02
None time:  1.5154657219536602
None Run 08:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.90
Split: 03, Run: 03
None time:  1.5399078750051558
None Run 09:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.7507498140912503
None Run 10:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 90.00
   Final Test: 54.80
Split: 04, Run: 02
None time:  1.5855097761377692
None Run 11:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 96.67
   Final Test: 64.10
Split: 04, Run: 03
None time:  1.5284249489195645
None Run 12:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 96.67
   Final Test: 64.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.9614025140181184
None Run 13:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 60.30
Split: 05, Run: 02
None time:  1.604628206929192
None Run 14:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.80
Split: 05, Run: 03
None time:  2.207377262879163
None Run 15:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 63.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.6160419390071183
None Run 16:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 80.00
   Final Test: 62.40
Split: 06, Run: 02
None time:  1.4995487609412521
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.20
Split: 06, Run: 03
None time:  1.5494942020159215
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7528396260458976
None Run 19:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 86.67
   Final Test: 52.90
Split: 07, Run: 02
None time:  1.5921791750006378
None Run 20:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 90.00
   Final Test: 58.20
Split: 07, Run: 03
None time:  1.774263228988275
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 86.67
   Final Test: 58.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.382529621012509
None Run 22:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 83.33
   Final Test: 63.40
Split: 08, Run: 02
None time:  1.4934507110156119
None Run 23:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 08, Run: 03
None time:  1.5726009861100465
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 68.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.3371589470189065
None Run 25:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 80.00
   Final Test: 58.90
Split: 09, Run: 02
None time:  1.4901010859757662
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 64.90
Split: 09, Run: 03
None time:  1.3439192920923233
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 93.33
   Final Test: 66.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.6101037659682333
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 66.70
Split: 10, Run: 02
None time:  1.5016701868735254
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 10, Run: 03
None time:  1.4453495929483324
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 5.620190858840942
total time:  61.38732000486925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.25 ± 4.90
  Final Train: 92.00 ± 8.42
   Final Test: 64.30 ± 4.40
best run test_acc: 65.88999938964844
[I 2023-06-12 00:41:32,406] Trial 133 finished with value: 65.24666595458984 and parameters: {'Fwd': 0.019259385556696346, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 2.4845492629079318, 'loop': 2, 'loss': 'CE', 'lr': 0.0004572576505024362, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.4534084862010777e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.00035402094163738
weight_decay:  1.3224229791195453e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.008614581078291
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 80.00
   Final Test: 61.60
Split: 01, Run: 02
None time:  1.602411723928526
None Run 02:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 93.33
   Final Test: 60.70
Split: 01, Run: 03
None time:  1.6432028349954635
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 76.67
   Final Test: 60.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3521809910889715
None Run 04:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.50
Split: 02, Run: 02
None time:  1.3825514989439398
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.10
Split: 02, Run: 03
None time:  1.559729202883318
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.1278115960303694
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.90
Split: 03, Run: 02
None time:  1.4096690590959042
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.20
Split: 03, Run: 03
None time:  1.4178264448419213
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4132296410389245
None Run 10:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 61.80
Split: 04, Run: 02
None time:  1.5255802220199257
None Run 11:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 65.00
Split: 04, Run: 03
None time:  1.3943652480375022
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 65.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.423742272891104
None Run 13:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 96.67
   Final Test: 57.50
Split: 05, Run: 02
None time:  1.494402569020167
None Run 14:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 96.67
   Final Test: 57.20
Split: 05, Run: 03
None time:  1.4095654878765345
None Run 15:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5257441231515259
None Run 16:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 58.20
Split: 06, Run: 02
None time:  1.8566937278956175
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 64.40
Split: 06, Run: 03
None time:  1.5207141030114144
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.941510635893792
None Run 19:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 73.33
   Final Test: 47.00
Split: 07, Run: 02
None time:  1.3958729500882328
None Run 20:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 90.00
   Final Test: 50.70
Split: 07, Run: 03
None time:  1.4293336211703718
None Run 21:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 90.00
   Final Test: 51.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.1271854219958186
None Run 22:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 80.00
   Final Test: 58.20
Split: 08, Run: 02
None time:  1.3859636429697275
None Run 23:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 66.10
Split: 08, Run: 03
None time:  1.472365713212639
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 66.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.070391976973042
None Run 25:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 90.00
   Final Test: 61.80
Split: 09, Run: 02
None time:  1.6587661248631775
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 90.00
   Final Test: 64.00
Split: 09, Run: 03
None time:  1.5620211199857295
None Run 27:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 90.00
   Final Test: 64.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.6498462718445808
None Run 28:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 64.30
Split: 10, Run: 02
None time:  1.3441723780706525
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.50
Split: 10, Run: 03
None time:  1.4331362380180508
None Run 30:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 5.479296684265137
total time:  58.81066754902713
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.22 ± 6.02
  Final Train: 93.44 ± 7.40
   Final Test: 62.10 ± 5.61
best run test_acc: 63.55999755859375
[I 2023-06-12 00:42:31,812] Trial 134 finished with value: 63.219993591308594 and parameters: {'Fwd': 0.024288629075928547, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 2.1030800948440693, 'loop': 2, 'loss': 'CE', 'lr': 0.00035402094163738, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.3224229791195453e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0005109759210687957
weight_decay:  1.745972594073991e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9790244731120765
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 80.00
   Final Test: 63.50
Split: 01, Run: 02
None time:  1.750529841054231
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 86.67
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.9648805409669876
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 76.67
   Final Test: 64.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.7759932060725987
None Run 04:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 70.70
Split: 02, Run: 02
None time:  1.522610142827034
None Run 05:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
Split: 02, Run: 03
None time:  1.523959619924426
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 70.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.108004118083045
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 65.90
Split: 03, Run: 02
None time:  1.5466386389452964
None Run 08:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.20
Split: 03, Run: 03
None time:  1.4731160840019584
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.30
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.4827196560800076
None Run 10:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 90.00
   Final Test: 56.00
Split: 04, Run: 02
None time:  1.5764644329901785
None Run 11:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 96.67
   Final Test: 62.00
Split: 04, Run: 03
None time:  1.5075773920398206
None Run 12:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 96.67
   Final Test: 60.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.2899312579538673
None Run 13:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 65.70
Split: 05, Run: 02
None time:  1.5834988600108773
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 64.60
Split: 05, Run: 03
None time:  1.537657316075638
None Run 15:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5967912310734391
None Run 16:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 51.40
Split: 06, Run: 02
None time:  1.4415642418898642
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.60
Split: 06, Run: 03
None time:  1.4668296698946506
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.516773214098066
None Run 19:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 86.67
   Final Test: 58.60
Split: 07, Run: 02
None time:  1.5609744538087398
None Run 20:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 93.33
   Final Test: 60.90
Split: 07, Run: 03
None time:  1.5890637210104614
None Run 21:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 93.33
   Final Test: 60.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.482063847826794
None Run 22:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 90.00
   Final Test: 59.30
Split: 08, Run: 02
None time:  1.6214268221519887
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 66.40
Split: 08, Run: 03
None time:  1.5280186689924449
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.50
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.002653857227415
None Run 25:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 90.00
   Final Test: 62.60
Split: 09, Run: 02
None time:  1.5889667398296297
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.30
Split: 09, Run: 03
None time:  1.5970427959691733
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 93.33
   Final Test: 68.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.6011862528976053
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 90.00
   Final Test: 66.90
Split: 10, Run: 02
None time:  1.5066147791221738
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
Split: 10, Run: 03
None time:  1.492189799901098
None Run 30:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.654341459274292
total time:  60.45955728995614
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.68 ± 4.75
  Final Train: 94.56 ± 6.16
   Final Test: 64.70 ± 4.50
best run test_acc: 66.47000122070312
[I 2023-06-12 00:43:32,802] Trial 135 finished with value: 65.67999267578125 and parameters: {'Fwd': 0.04205447623926994, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 2.207631365265111, 'loop': 2, 'loss': 'CE', 'lr': 0.0005109759210687957, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.745972594073991e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0003985176954069868
weight_decay:  2.7450147280619327e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: -21435.7578, Train: 56.67%, Valid: 61.80% Test: 62.80%
Split: 01, Run: 01
None time:  5.372339455876499
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 56.67
   Final Test: 62.40
Split: 01, Run: 02
None time:  1.4454285639803857
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 63.90
Split: 01, Run: 03
None time:  1.4583393570501357
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 96.67
   Final Test: 63.30
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.1685940278694034
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 90.00
   Final Test: 66.60
Split: 02, Run: 02
None time:  1.4454941540025175
None Run 05:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.90
Split: 02, Run: 03
None time:  1.4334051869809628
None Run 06:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 65.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.6035369290038943
None Run 07:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 93.33
   Final Test: 63.70
Split: 03, Run: 02
None time:  1.4474197989329696
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.70
Split: 03, Run: 03
None time:  1.398565948009491
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.9598756909836084
None Run 10:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 62.70
Split: 04, Run: 02
None time:  1.4588907819706947
None Run 11:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 65.90
Split: 04, Run: 03
None time:  1.5343632290605456
None Run 12:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 65.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.3699866889510304
None Run 13:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 63.50
Split: 05, Run: 02
None time:  1.444584830896929
None Run 14:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.10
Split: 05, Run: 03
None time:  1.5707582070026547
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 62.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.3114997879602015
None Run 16:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 83.33
   Final Test: 61.10
Split: 06, Run: 02
None time:  1.448808095883578
None Run 17:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 66.20
Split: 06, Run: 03
None time:  1.4104365969542414
None Run 18:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 65.70
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.7568164148833603
None Run 19:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 80.00
   Final Test: 59.50
Split: 07, Run: 02
None time:  1.4267190140672028
None Run 20:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 86.67
   Final Test: 60.30
Split: 07, Run: 03
None time:  1.276367116952315
None Run 21:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 86.67
   Final Test: 59.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.8671935880556703
None Run 22:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 80.00
   Final Test: 59.90
Split: 08, Run: 02
None time:  1.5392844069283456
None Run 23:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.30
Split: 08, Run: 03
None time:  1.5464893691241741
None Run 24:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 90.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.1807935908436775
None Run 25:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 86.67
   Final Test: 61.30
Split: 09, Run: 02
None time:  1.4057300339918584
None Run 26:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.40
Split: 09, Run: 03
None time:  1.5111517370678484
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.4676943530794233
None Run 28:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 90.00
   Final Test: 64.00
Split: 10, Run: 02
None time:  1.4606033971067518
None Run 29:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.80
Split: 10, Run: 03
None time:  1.377545217052102
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.80
run time now: 5.358150005340576
total time:  63.34828353789635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.73 ± 3.38
  Final Train: 92.67 ± 9.03
   Final Test: 64.61 ± 2.89
best run test_acc: 66.05999755859375
[I 2023-06-12 00:44:36,626] Trial 136 finished with value: 64.7266616821289 and parameters: {'Fwd': 0.015202783063406571, 'K': 10, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 2.7746366413138577, 'loop': 2, 'loss': 'CE', 'lr': 0.0003985176954069868, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.7450147280619327e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0006037968692128745
weight_decay:  2.4230704868294693e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1448800819925964
None Run 01:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 86.67
   Final Test: 58.80
Split: 01, Run: 02
None time:  2.0268985689617693
None Run 02:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 76.67
   Final Test: 62.70
Split: 01, Run: 03
None time:  1.5900753901805729
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 73.33
   Final Test: 63.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.558269181055948
None Run 04:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 86.67
   Final Test: 70.10
Split: 02, Run: 02
None time:  1.2482877860311419
None Run 05:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 71.60
Split: 02, Run: 03
None time:  1.3242534510791302
None Run 06:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 70.20
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.833557102130726
None Run 07:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 60.50
Split: 03, Run: 02
None time:  1.2695347850676626
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.90
Split: 03, Run: 03
None time:  1.2631028310861439
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.530711787054315
None Run 10:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 93.33
   Final Test: 59.40
Split: 04, Run: 02
None time:  1.4143066951073706
None Run 11:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 64.80
Split: 04, Run: 03
None time:  1.2926158881746233
None Run 12:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 66.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.372274085180834
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 66.00
Split: 05, Run: 02
None time:  1.8153104218654335
None Run 14:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 65.50
Split: 05, Run: 03
None time:  2.4916225110646337
None Run 15:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8928782648872584
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 93.33
   Final Test: 59.00
Split: 06, Run: 02
None time:  1.2682539750821888
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.30
Split: 06, Run: 03
None time:  1.1396691638510674
None Run 18:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 68.40
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  4.9141488841269165
None Run 19:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 66.67
   Final Test: 58.40
Split: 07, Run: 02
None time:  1.2785762241110206
None Run 20:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 80.00
   Final Test: 60.00
Split: 07, Run: 03
None time:  1.2834585141390562
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 83.33
   Final Test: 60.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4841782478615642
None Run 22:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.40
Split: 08, Run: 02
None time:  1.3222114481031895
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 67.10
Split: 08, Run: 03
None time:  1.2899743909947574
None Run 24:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 93.33
   Final Test: 69.20
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.601374202873558
None Run 25:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 83.33
   Final Test: 62.40
Split: 09, Run: 02
None time:  1.295398618793115
None Run 26:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 68.30
Split: 09, Run: 03
None time:  1.414314170833677
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.019400160992518
None Run 28:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 90.00
   Final Test: 67.80
Split: 10, Run: 02
None time:  1.3000121768563986
None Run 29:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 10, Run: 03
None time:  1.2770346109755337
None Run 30:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 4.6510326862335205
total time:  54.20720902411267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.87 ± 4.72
  Final Train: 92.11 ± 8.73
   Final Test: 65.07 ± 3.98
best run test_acc: 66.74000549316406
[I 2023-06-12 00:45:31,460] Trial 137 finished with value: 65.86666107177734 and parameters: {'Fwd': 0.02063379259282844, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 1.7083936794558707, 'loop': 2, 'loss': 'CE', 'lr': 0.0006037968692128745, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.4230704868294693e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0005983097836338228
weight_decay:  2.423696929767439e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.739718978991732
None Run 01:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 80.00
   Final Test: 63.80
Split: 01, Run: 02
None time:  1.8901430200785398
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 80.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.706347948871553
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 90.00
   Final Test: 66.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.7763455000240356
None Run 04:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 68.50
Split: 02, Run: 02
None time:  1.603975169127807
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.40
Split: 02, Run: 03
None time:  1.5701386460568756
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.061980824917555
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 90.00
   Final Test: 65.10
Split: 03, Run: 02
None time:  1.5928586451336741
None Run 08:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.40
Split: 03, Run: 03
None time:  1.4811024800874293
None Run 09:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.756702712038532
None Run 10:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 96.67
   Final Test: 58.80
Split: 04, Run: 02
None time:  1.6306494201999158
None Run 11:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 65.30
Split: 04, Run: 03
None time:  1.543553147930652
None Run 12:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 66.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1916819571051747
None Run 13:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 62.60
Split: 05, Run: 02
None time:  1.5434954820666462
None Run 14:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.00
Split: 05, Run: 03
None time:  1.8983919059392065
None Run 15:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.30
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.2109976501669735
None Run 16:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 63.60
Split: 06, Run: 02
None time:  1.4117130909580737
None Run 17:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.50
Split: 06, Run: 03
None time:  1.5515034380368888
None Run 18:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 68.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.7199983140453696
None Run 19:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 76.67
   Final Test: 59.70
Split: 07, Run: 02
None time:  1.6203052739147097
None Run 20:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 86.67
   Final Test: 59.20
Split: 07, Run: 03
None time:  1.581078913062811
None Run 21:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 83.33
   Final Test: 59.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8371074500028044
None Run 22:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 93.33
   Final Test: 59.90
Split: 08, Run: 02
None time:  1.6318280471023172
None Run 23:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 67.40
Split: 08, Run: 03
None time:  1.545781766064465
None Run 24:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 69.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.606503308052197
None Run 25:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 80.00
   Final Test: 60.80
Split: 09, Run: 02
None time:  1.5276500240433961
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 68.50
Split: 09, Run: 03
None time:  1.5643151949625462
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9684593100100756
None Run 28:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 96.67
   Final Test: 64.20
Split: 10, Run: 02
None time:  1.5810340538155288
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.50
Split: 10, Run: 03
None time:  1.4764196940232068
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 5.085134267807007
total time:  60.09721653792076
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.51 ± 3.82
  Final Train: 93.11 ± 6.78
   Final Test: 65.62 ± 3.63
best run test_acc: 67.38999938964844
[I 2023-06-12 00:46:32,097] Trial 138 finished with value: 66.51333618164062 and parameters: {'Fwd': 0.021798156864612808, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 2.442710498270137, 'loop': 2, 'loss': 'CE', 'lr': 0.0005983097836338228, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.423696929767439e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0006015057877340611
weight_decay:  2.346727300735033e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9502902028616518
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 86.67
   Final Test: 62.90
Split: 01, Run: 02
None time:  2.5538537250831723
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 63.33
   Final Test: 63.80
Split: 01, Run: 03
None time:  1.8134047579951584
None Run 03:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 60.00
   Final Test: 63.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9399736251216382
None Run 04:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 69.10
Split: 02, Run: 02
None time:  1.2727927500382066
None Run 05:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
Split: 02, Run: 03
None time:  1.250338242156431
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.6407042399514467
None Run 07:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 93.33
   Final Test: 63.40
Split: 03, Run: 02
None time:  1.2404903550632298
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.90
Split: 03, Run: 03
None time:  1.250552082899958
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.281405827961862
None Run 10:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 63.50
Split: 04, Run: 02
None time:  1.262320966925472
None Run 11:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 96.67
   Final Test: 67.60
Split: 04, Run: 03
None time:  1.2494232908356935
None Run 12:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.9797206041403115
None Run 13:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.60
Split: 05, Run: 02
None time:  1.1861160842236131
None Run 14:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 70.00
Split: 05, Run: 03
None time:  1.2701273318380117
None Run 15:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 69.50
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5581650489475578
None Run 16:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 96.67
   Final Test: 66.00
Split: 06, Run: 02
None time:  1.3127231739927083
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.60
Split: 06, Run: 03
None time:  1.1819756729528308
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  4.645158450119197
None Run 19:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 63.33
   Final Test: 57.50
Split: 07, Run: 02
None time:  1.2882900040131062
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 76.67
   Final Test: 58.80
Split: 07, Run: 03
None time:  1.1881959929596633
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 76.67
   Final Test: 58.70
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.0341357190627605
None Run 22:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 80.00
   Final Test: 53.80
Split: 08, Run: 02
None time:  1.3933152209501714
None Run 23:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.00
   Final Test: 66.20
Split: 08, Run: 03
None time:  1.2534487459342927
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 90.00
   Final Test: 67.00
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.16841655690223
None Run 25:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 83.33
   Final Test: 59.50
Split: 09, Run: 02
None time:  1.3208371310029179
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 66.90
Split: 09, Run: 03
None time:  1.262979180086404
None Run 27:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.10
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.900890899123624
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 93.33
   Final Test: 66.30
Split: 10, Run: 02
None time:  1.1965523730032146
None Run 29:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 10, Run: 03
None time:  1.0545352709013969
None Run 30:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 4.209850072860718
total time:  52.21985426405445
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.08 ± 4.37
  Final Train: 90.44 ± 11.67
   Final Test: 65.62 ± 4.27
best run test_acc: 67.00999450683594
[I 2023-06-12 00:47:24,859] Trial 139 finished with value: 66.08000183105469 and parameters: {'Fwd': 0.0095937388924489, 'K': 10, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 1.810200016147146, 'loop': 2, 'loss': 'CE', 'lr': 0.0006015057877340611, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.346727300735033e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0005938203641880055
weight_decay:  2.1577107353480242e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.862111708149314
None Run 01:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 93.33
   Final Test: 43.40
Split: 01, Run: 02
None time:  1.3726514040026814
None Run 02:
Highest Train: 100.00
Highest Valid: 40.20
  Final Train: 100.00
   Final Test: 43.60
Split: 01, Run: 03
None time:  1.4074677019380033
None Run 03:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 43.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.890647092135623
None Run 04:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.30
Split: 02, Run: 02
None time:  1.2304999900516123
None Run 05:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 57.30
Split: 02, Run: 03
None time:  1.2491845008917153
None Run 06:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 56.90
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8926741741597652
None Run 07:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.60
Split: 03, Run: 02
None time:  1.2487445739097893
None Run 08:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 53.00
Split: 03, Run: 03
None time:  1.2700389029923826
None Run 09:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 52.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2123076538555324
None Run 10:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 41.10
Split: 04, Run: 02
None time:  2.011337438831106
None Run 11:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 86.67
   Final Test: 47.80
Split: 04, Run: 03
None time:  1.1216280669905245
None Run 12:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 48.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.9532318541314453
None Run 13:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 96.67
   Final Test: 49.20
Split: 05, Run: 02
None time:  1.256304580019787
None Run 14:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 48.80
Split: 05, Run: 03
None time:  1.3529095551930368
None Run 15:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 48.80
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.2850698691327125
None Run 16:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 61.20
Split: 06, Run: 02
None time:  1.3895019060000777
None Run 17:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 61.90
Split: 06, Run: 03
None time:  1.6350559720303863
None Run 18:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 96.67
   Final Test: 61.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7672838910948485
None Run 19:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 86.67
   Final Test: 51.00
Split: 07, Run: 02
None time:  2.2586266139987856
None Run 20:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 86.67
   Final Test: 50.80
Split: 07, Run: 03
None time:  1.6515975559595972
None Run 21:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 90.00
   Final Test: 49.80
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8682281461078674
None Run 22:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.30
Split: 08, Run: 02
None time:  1.3163484539836645
None Run 23:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.10
Split: 08, Run: 03
None time:  1.2766043769661337
None Run 24:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7880185171961784
None Run 25:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 45.50
Split: 09, Run: 02
None time:  2.0719864438287914
None Run 26:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 90.00
   Final Test: 45.50
Split: 09, Run: 03
None time:  1.5341634710785002
None Run 27:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 96.67
   Final Test: 45.50
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.124347447184846
None Run 28:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 53.90
Split: 10, Run: 02
None time:  1.46000681607984
None Run 29:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 54.60
Split: 10, Run: 03
None time:  1.2575614610686898
None Run 30:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 54.00
run time now: 4.902072906494141
total time:  50.483437112066895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.72 ± 8.59
  Final Train: 97.33 ± 4.58
   Final Test: 51.97 ± 6.14
best run test_acc: 52.46000289916992
[I 2023-06-12 00:48:15,797] Trial 140 finished with value: 51.71999740600586 and parameters: {'Fwd': 0.017868837518280535, 'K': 10, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 2.416579666138509, 'loop': 2, 'loss': 'CE', 'lr': 0.0005938203641880055, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1577107353480242e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0007087819074331491
weight_decay:  3.415731524403623e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7329553680028766
None Run 01:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 76.67
   Final Test: 56.60
Split: 01, Run: 02
None time:  1.2613844249863178
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 93.33
   Final Test: 60.90
Split: 01, Run: 03
None time:  1.299794940976426
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 90.00
   Final Test: 60.40
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9072144210804254
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 67.60
Split: 02, Run: 02
None time:  1.2006755729671568
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.50
Split: 02, Run: 03
None time:  1.163418454816565
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.2080421110149473
None Run 07:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 93.33
   Final Test: 62.40
Split: 03, Run: 02
None time:  1.0106440449599177
None Run 08:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 63.30
Split: 03, Run: 03
None time:  1.1746335341595113
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.10
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.4103280811104923
None Run 10:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 96.67
   Final Test: 60.90
Split: 04, Run: 02
None time:  1.3106837999075651
None Run 11:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 65.20
Split: 04, Run: 03
None time:  1.3386689820326865
None Run 12:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.4556638849899173
None Run 13:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 96.67
   Final Test: 71.20
Split: 05, Run: 02
None time:  1.2265276268590242
None Run 14:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 96.67
   Final Test: 69.80
Split: 05, Run: 03
None time:  1.2876590329688042
None Run 15:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.83134057209827
None Run 16:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 96.67
   Final Test: 63.70
Split: 06, Run: 02
None time:  1.2658342849463224
None Run 17:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.30
Split: 06, Run: 03
None time:  1.3011373088229448
None Run 18:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.801045071100816
None Run 19:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 80.00
   Final Test: 57.30
Split: 07, Run: 02
None time:  1.308475481113419
None Run 20:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 59.50
Split: 07, Run: 03
None time:  1.3074966231361032
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 90.00
   Final Test: 58.90
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.2719166059978306
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 66.80
Split: 08, Run: 02
None time:  1.3010405839886516
None Run 23:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
Split: 08, Run: 03
None time:  1.2300546648912132
None Run 24:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 69.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7087997018825263
None Run 25:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.00
Split: 09, Run: 02
None time:  1.2174311901908368
None Run 26:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.40
Split: 09, Run: 03
None time:  1.2394293979741633
None Run 27:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.7769525910262018
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 66.40
Split: 10, Run: 02
None time:  1.2416506891604513
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
Split: 10, Run: 03
None time:  1.2511017210781574
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.323381423950195
total time:  49.72131226793863
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.20 ± 5.42
  Final Train: 95.89 ± 5.72
   Final Test: 65.42 ± 4.53
best run test_acc: 66.8499984741211
[I 2023-06-12 00:49:06,085] Trial 141 finished with value: 66.19999694824219 and parameters: {'Fwd': 0.02356619833773141, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 2.9525005002162223, 'loop': 2, 'loss': 'CE', 'lr': 0.0007087819074331491, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.415731524403623e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0007002084287515227
weight_decay:  3.645443474380882e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.318012890871614
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 63.33
   Final Test: 63.70
Split: 01, Run: 02
None time:  1.844354324042797
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 63.33
   Final Test: 65.70
Split: 01, Run: 03
None time:  1.2410199290607125
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.5618051008787006
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 86.67
   Final Test: 70.60
Split: 02, Run: 02
None time:  1.2369236869271845
None Run 05:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 71.00
Split: 02, Run: 03
None time:  1.3064880869351327
None Run 06:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 70.80
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.7788415290415287
None Run 07:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 86.67
   Final Test: 62.60
Split: 03, Run: 02
None time:  1.2749576370697469
None Run 08:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.70
Split: 03, Run: 03
None time:  1.2142112760338932
None Run 09:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.60
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.3050146468449384
None Run 10:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 86.67
   Final Test: 61.10
Split: 04, Run: 02
None time:  1.2364684960339218
None Run 11:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 67.30
Split: 04, Run: 03
None time:  1.250436524860561
None Run 12:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 96.67
   Final Test: 67.20
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.737978387158364
None Run 13:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.80
Split: 05, Run: 02
None time:  1.3501106221228838
None Run 14:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.70
Split: 05, Run: 03
None time:  1.8741828030906618
None Run 15:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 65.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5609048011247069
None Run 16:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 61.00
Split: 06, Run: 02
None time:  1.3307084129191935
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 66.40
Split: 06, Run: 03
None time:  1.232735593104735
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7111036381684244
None Run 19:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 93.33
   Final Test: 57.50
Split: 07, Run: 02
None time:  1.4366377349942923
None Run 20:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 56.80
Split: 07, Run: 03
None time:  1.3489859879482538
None Run 21:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 58.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6022749010007828
None Run 22:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 62.30
Split: 08, Run: 02
None time:  1.4369474609848112
None Run 23:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.10
Split: 08, Run: 03
None time:  1.26674444694072
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 93.33
   Final Test: 69.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.5003509738016874
None Run 25:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 80.00
   Final Test: 52.00
Split: 09, Run: 02
None time:  1.2847490070853382
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 65.40
Split: 09, Run: 03
None time:  1.314869707915932
None Run 27:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 65.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.536567658185959
None Run 28:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 83.33
   Final Test: 65.30
Split: 10, Run: 02
None time:  1.2263027639128268
None Run 29:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 68.80
Split: 10, Run: 03
None time:  1.2751412140205503
None Run 30:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 68.30
run time now: 5.0911431312561035
total time:  49.93001281004399
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.00 ± 5.06
  Final Train: 92.56 ± 9.42
   Final Test: 64.66 ± 4.40
best run test_acc: 66.4000015258789
[I 2023-06-12 00:49:56,502] Trial 142 finished with value: 65.00000762939453 and parameters: {'Fwd': 0.01981552817817497, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 1.8639648201954153, 'loop': 2, 'loss': 'CE', 'lr': 0.0007002084287515227, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.645443474380882e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0008413243117658211
weight_decay:  2.5205810466631673e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.64480674918741
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 66.67
   Final Test: 64.70
Split: 01, Run: 02
None time:  1.6074608908966184
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 60.00
   Final Test: 66.30
Split: 01, Run: 03
None time:  1.231910727918148
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 96.67
   Final Test: 66.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8313437020406127
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.70
Split: 02, Run: 02
None time:  1.3445132148917764
None Run 05:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 70.70
Split: 02, Run: 03
None time:  1.1664331059437245
None Run 06:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 72.00
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.3126308310311288
None Run 07:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 83.33
   Final Test: 55.90
Split: 03, Run: 02
None time:  1.1973842210136354
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.80
Split: 03, Run: 03
None time:  1.2138115409761667
None Run 09:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.90
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.8807344320230186
None Run 10:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 96.67
   Final Test: 52.30
Split: 04, Run: 02
None time:  1.3163184160366654
None Run 11:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 96.67
   Final Test: 65.10
Split: 04, Run: 03
None time:  1.2205570279620588
None Run 12:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 66.10
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.168130898848176
None Run 13:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 96.67
   Final Test: 57.50
Split: 05, Run: 02
None time:  1.341082216007635
None Run 14:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 68.50
Split: 05, Run: 03
None time:  1.4258847460150719
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 68.20
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6026763371191919
None Run 16:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 65.40
Split: 06, Run: 02
None time:  1.1278794310055673
None Run 17:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 67.70
Split: 06, Run: 03
None time:  1.3166973320767283
None Run 18:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0222909941803664
None Run 19:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 86.67
   Final Test: 57.20
Split: 07, Run: 02
None time:  1.3007828320842236
None Run 20:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.80
Split: 07, Run: 03
None time:  1.2468735668808222
None Run 21:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 96.67
   Final Test: 59.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7191053598653525
None Run 22:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 90.00
   Final Test: 59.20
Split: 08, Run: 02
None time:  1.3303293189965189
None Run 23:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 68.00
Split: 08, Run: 03
None time:  1.3071114008780569
None Run 24:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 90.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.242548373993486
None Run 25:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 76.67
   Final Test: 54.00
Split: 09, Run: 02
None time:  1.3050519118551165
None Run 26:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 96.67
   Final Test: 68.40
Split: 09, Run: 03
None time:  1.3179020727984607
None Run 27:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.773462309036404
None Run 28:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 96.67
   Final Test: 57.60
Split: 10, Run: 02
None time:  1.2045966719742864
None Run 29:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 10, Run: 03
None time:  1.2557045700959861
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 4.287440299987793
total time:  47.21283818408847
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.29 ± 5.69
  Final Train: 93.00 ± 9.60
   Final Test: 64.28 ± 5.39
best run test_acc: 66.97999572753906
[I 2023-06-12 00:50:44,212] Trial 143 finished with value: 65.2933349609375 and parameters: {'Fwd': 0.010454876362216365, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 3.016733534833674, 'loop': 2, 'loss': 'CE', 'lr': 0.0008413243117658211, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.5205810466631673e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.000760605106346114
weight_decay:  3.2581141401289134e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.970221698982641
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 73.33
   Final Test: 61.30
Split: 01, Run: 02
None time:  1.844113882863894
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 66.67
   Final Test: 63.50
Split: 01, Run: 03
None time:  1.354917178163305
None Run 03:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 96.67
   Final Test: 65.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4666943000629544
None Run 04:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 90.00
   Final Test: 68.90
Split: 02, Run: 02
None time:  1.3268614308908582
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 67.90
Split: 02, Run: 03
None time:  1.3657072728965431
None Run 06:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 67.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.191719815135002
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 64.50
Split: 03, Run: 02
None time:  1.362424778053537
None Run 08:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.60
Split: 03, Run: 03
None time:  1.3103119439911097
None Run 09:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.70
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.409173984080553
None Run 10:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 86.67
   Final Test: 63.80
Split: 04, Run: 02
None time:  1.343668557005003
None Run 11:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 66.50
Split: 04, Run: 03
None time:  1.354344782885164
None Run 12:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 96.67
   Final Test: 65.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.665527543053031
None Run 13:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 96.67
   Final Test: 52.40
Split: 05, Run: 02
None time:  1.3912859251722693
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 60.70
Split: 05, Run: 03
None time:  1.3477935679256916
None Run 15:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 59.60
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7433486110530794
None Run 16:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 93.33
   Final Test: 61.80
Split: 06, Run: 02
None time:  1.3783694070298225
None Run 17:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.80
Split: 06, Run: 03
None time:  1.2858687820844352
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 68.50
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.794187146006152
None Run 19:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 76.67
   Final Test: 58.70
Split: 07, Run: 02
None time:  1.1355367510113865
None Run 20:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 86.67
   Final Test: 59.80
Split: 07, Run: 03
None time:  1.324268194846809
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 86.67
   Final Test: 60.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.3110055590514094
None Run 22:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 83.33
   Final Test: 56.80
Split: 08, Run: 02
None time:  1.3690864180680364
None Run 23:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 70.30
Split: 08, Run: 03
None time:  1.35231390921399
None Run 24:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 69.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.4181352430023253
None Run 25:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 73.33
   Final Test: 56.80
Split: 09, Run: 02
None time:  1.4042589347809553
None Run 26:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 68.40
Split: 09, Run: 03
None time:  1.3555575751233846
None Run 27:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.4744494389742613
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 83.33
   Final Test: 66.50
Split: 10, Run: 02
None time:  1.2555025229230523
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 69.70
Split: 10, Run: 03
None time:  1.2800256919581443
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 70.10
run time now: 5.064423084259033
total time:  53.858345738146454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.22 ± 4.93
  Final Train: 91.11 ± 8.77
   Final Test: 64.60 ± 4.76
best run test_acc: 66.75999450683594
[I 2023-06-12 00:51:38,655] Trial 144 finished with value: 65.2199935913086 and parameters: {'Fwd': 0.014489504171912483, 'K': 10, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 2.6365673243113252, 'loop': 2, 'loss': 'CE', 'lr': 0.000760605106346114, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.2581141401289134e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0006328647237560591
weight_decay:  2.3258922356607602e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1426315740682185
None Run 01:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 86.67
   Final Test: 61.00
Split: 01, Run: 02
None time:  1.8030030629597604
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 73.33
   Final Test: 61.90
Split: 01, Run: 03
None time:  1.3857606400270015
None Run 03:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 76.67
   Final Test: 63.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.4651729341130704
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 90.00
   Final Test: 68.90
Split: 02, Run: 02
None time:  1.1767196250148118
None Run 05:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 03
None time:  1.17421173886396
None Run 06:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0148083369713277
None Run 07:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 93.33
   Final Test: 58.70
Split: 03, Run: 02
None time:  1.1637909801211208
None Run 08:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.50
Split: 03, Run: 03
None time:  1.1400074588600546
None Run 09:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.138286623172462
None Run 10:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 41.20
Split: 04, Run: 02
None time:  1.2030436489731073
None Run 11:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 61.90
Split: 04, Run: 03
None time:  1.1774831828661263
None Run 12:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 62.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.6283901068381965
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.60
Split: 05, Run: 02
None time:  2.3709149349015206
None Run 14:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 68.20
Split: 05, Run: 03
None time:  1.1936033309902996
None Run 15:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.052871006075293
None Run 16:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 80.00
   Final Test: 58.80
Split: 06, Run: 02
None time:  1.2189291771501303
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.10
Split: 06, Run: 03
None time:  1.1618239800445735
None Run 18:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8445325319189578
None Run 19:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 86.67
   Final Test: 56.20
Split: 07, Run: 02
None time:  1.1391769349575043
None Run 20:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 56.60
Split: 07, Run: 03
None time:  1.1040948629379272
None Run 21:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 56.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2355624330230057
None Run 22:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 53.50
Split: 08, Run: 02
None time:  1.2059660621453077
None Run 23:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.60
Split: 08, Run: 03
None time:  1.3109962320886552
None Run 24:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 65.90
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.2554170140065253
None Run 25:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 86.67
   Final Test: 54.60
Split: 09, Run: 02
None time:  1.1186772459186614
None Run 26:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.00
Split: 09, Run: 03
None time:  1.1578019398730248
None Run 27:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.30
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.4824008650612086
None Run 28:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 86.67
   Final Test: 65.20
Split: 10, Run: 02
None time:  1.1448888038285077
None Run 29:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.80
Split: 10, Run: 03
None time:  1.1184170769993216
None Run 30:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.80
run time now: 4.80157732963562
total time:  46.96501691103913
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.77 ± 7.66
  Final Train: 94.44 ± 7.65
   Final Test: 63.08 ± 6.50
best run test_acc: 65.76000213623047
[I 2023-06-12 00:52:26,085] Trial 145 finished with value: 63.77333068847656 and parameters: {'Fwd': 0.008383684705919447, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 1.8176374652138731, 'loop': 1, 'loss': 'CE', 'lr': 0.0006328647237560591, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.3258922356607602e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0005625661549675461
weight_decay:  1.6759295309246847e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.112647170899436
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 86.67
   Final Test: 62.00
Split: 01, Run: 02
None time:  1.285298208007589
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 93.33
   Final Test: 64.20
Split: 01, Run: 03
None time:  1.2975399380084127
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 96.67
   Final Test: 62.90
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.025967658031732
None Run 04:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 86.67
   Final Test: 67.30
Split: 02, Run: 02
None time:  1.146559308981523
None Run 05:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.20
Split: 02, Run: 03
None time:  1.221929064951837
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.1358969272114336
None Run 07:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.10
Split: 03, Run: 02
None time:  1.1860097360331565
None Run 08:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.00
Split: 03, Run: 03
None time:  1.1327749849297106
None Run 09:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.050016156863421
None Run 10:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 60.40
Split: 04, Run: 02
None time:  1.1471908478997648
None Run 11:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 66.70
Split: 04, Run: 03
None time:  1.1646359891165048
None Run 12:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 66.40
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.2878977230284363
None Run 13:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 96.67
   Final Test: 65.10
Split: 05, Run: 02
None time:  1.5505998749285936
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 64.80
Split: 05, Run: 03
None time:  1.427342918002978
None Run 15:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 64.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3943328019231558
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 58.40
Split: 06, Run: 02
None time:  1.2077907300554216
None Run 17:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.20
Split: 06, Run: 03
None time:  1.279847312020138
None Run 18:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 66.80
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.469823906198144
None Run 19:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 83.33
   Final Test: 57.00
Split: 07, Run: 02
None time:  1.1650705381762236
None Run 20:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 59.80
Split: 07, Run: 03
None time:  1.1109583349898458
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 93.33
   Final Test: 60.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.404333976097405
None Run 22:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 80.00
   Final Test: 61.50
Split: 08, Run: 02
None time:  1.1803650960791856
None Run 23:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 68.70
Split: 08, Run: 03
None time:  1.1958348990883678
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 96.67
   Final Test: 68.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.8427984619047493
None Run 25:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 80.00
   Final Test: 59.90
Split: 09, Run: 02
None time:  1.218906378839165
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.20
Split: 09, Run: 03
None time:  1.1634630369953811
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.1157364267855883
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 83.33
   Final Test: 65.20
Split: 10, Run: 02
None time:  1.1795369570609182
None Run 29:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.60
Split: 10, Run: 03
None time:  1.2385015219915658
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 68.80
run time now: 5.588642835617065
total time:  49.535018916008994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.61 ± 4.43
  Final Train: 94.33 ± 5.95
   Final Test: 64.51 ± 3.47
best run test_acc: 66.08000183105469
[I 2023-06-12 00:53:16,176] Trial 146 finished with value: 65.61332702636719 and parameters: {'Fwd': 0.026159875036788342, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 2.2963506184833444, 'loop': 2, 'loss': 'CE', 'lr': 0.0005625661549675461, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.6759295309246847e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0007038457712297494
weight_decay:  1.0173753159113425e-05
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.814943031873554
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 80.00
   Final Test: 63.90
Split: 01, Run: 02
None time:  2.1995942569337785
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 83.33
   Final Test: 64.10
Split: 01, Run: 03
None time:  1.3430151408538222
None Run 03:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 93.33
   Final Test: 63.60
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.283330423058942
None Run 04:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 67.60
Split: 02, Run: 02
None time:  1.299182162154466
None Run 05:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 69.40
Split: 02, Run: 03
None time:  1.3307374340947717
None Run 06:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.70
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.866778227034956
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 86.67
   Final Test: 64.10
Split: 03, Run: 02
None time:  1.3722897230181843
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.00
Split: 03, Run: 03
None time:  1.318222732981667
None Run 09:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.6926025168504566
None Run 10:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 93.33
   Final Test: 59.00
Split: 04, Run: 02
None time:  1.270479773869738
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 96.67
   Final Test: 65.60
Split: 04, Run: 03
None time:  1.3531072789337486
None Run 12:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 96.67
   Final Test: 64.90
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.8531883200630546
None Run 13:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 67.50
Split: 05, Run: 02
None time:  1.530530781019479
None Run 14:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 67.10
Split: 05, Run: 03
None time:  1.3574459971860051
None Run 15:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9777417599689215
None Run 16:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 96.67
   Final Test: 62.50
Split: 06, Run: 02
None time:  1.4475512218195945
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.00
Split: 06, Run: 03
None time:  1.3173345408868045
None Run 18:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 66.00
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.819694645004347
None Run 19:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 83.33
   Final Test: 59.00
Split: 07, Run: 02
None time:  1.423440002836287
None Run 20:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 90.00
   Final Test: 60.50
Split: 07, Run: 03
None time:  1.3012879178859293
None Run 21:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 90.00
   Final Test: 61.00
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.045859500998631
None Run 22:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 63.70
Split: 08, Run: 02
None time:  1.4648717509116977
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 90.00
   Final Test: 66.50
Split: 08, Run: 03
None time:  1.3937641989905387
None Run 24:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 64.70
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.9034202150069177
None Run 25:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 90.00
   Final Test: 64.30
Split: 09, Run: 02
None time:  1.327920001000166
None Run 26:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 66.40
Split: 09, Run: 03
None time:  1.376742660999298
None Run 27:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 90.00
   Final Test: 65.70
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.185926489997655
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 65.70
Split: 10, Run: 02
None time:  1.4020742198918015
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 68.80
Split: 10, Run: 03
None time:  1.3728925469331443
None Run 30:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.40
run time now: 5.010408163070679
total time:  55.06581297703087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.32 ± 3.82
  Final Train: 93.11 ± 5.10
   Final Test: 65.05 ± 2.62
best run test_acc: 66.12999725341797
[I 2023-06-12 00:54:11,787] Trial 147 finished with value: 65.31999206542969 and parameters: {'Fwd': 0.044642525579644245, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 1.6364550272887688, 'loop': 2, 'loss': 'CE', 'lr': 0.0007038457712297494, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.0173753159113425e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0005226830635145413
weight_decay:  3.8041477859469724e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9548094780184329
None Run 01:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 35.30
Split: 01, Run: 02
None time:  3.220450774068013
None Run 02:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 44.70
Split: 01, Run: 03
None time:  2.98715244513005
None Run 03:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 49.00
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  6.0558313459623605
None Run 04:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 50.10
Split: 02, Run: 02, Epoch: 100, Loss: 0.0129, Train: 100.00%, Valid: 55.80% Test: 53.40%
Split: 02, Run: 02
None time:  7.612677383935079
None Run 05:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 52.90
Split: 02, Run: 03, Epoch: 100, Loss: 0.0135, Train: 100.00%, Valid: 49.00% Test: 46.00%
Split: 02, Run: 03
None time:  7.585548389004543
None Run 06:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 45.40
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.3084935459773988
None Run 07:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 44.80
Split: 03, Run: 02
None time:  1.9958674351219088
None Run 08:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 40.10
Split: 03, Run: 03
None time:  2.9822493891697377
None Run 09:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 55.00
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  7.23192799789831
None Run 10:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 48.00
Split: 04, Run: 02
None time:  2.9134025191888213
None Run 11:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 50.20
Split: 04, Run: 03
None time:  2.0015485279727727
None Run 12:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 45.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  6.593673912808299
None Run 13:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 52.60
Split: 05, Run: 02
None time:  7.426555851940066
None Run 14:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 47.80
Split: 05, Run: 03, Epoch: 100, Loss: 0.0119, Train: 100.00%, Valid: 51.20% Test: 50.00%
Split: 05, Run: 03
None time:  7.624018094036728
None Run 15:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 49.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9449663900304586
None Run 16:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.20
Split: 06, Run: 02
None time:  6.050932566868141
None Run 17:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 45.80
Split: 06, Run: 03
None time:  1.9753347041551024
None Run 18:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 41.20
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.7600669539533556
None Run 19:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 49.20
Split: 07, Run: 02, Epoch: 100, Loss: 0.0113, Train: 100.00%, Valid: 46.40% Test: 50.60%
Split: 07, Run: 02
None time:  7.496465218951926
None Run 20:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 50.40
Split: 07, Run: 03
None time:  2.477444560965523
None Run 21:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 54.30
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0138, Train: 100.00%, Valid: 56.20% Test: 57.20%
Split: 08, Run: 01
None time:  7.487274043960497
None Run 22:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 57.30
Split: 08, Run: 02
None time:  3.812799307052046
None Run 23:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.70
Split: 08, Run: 03
None time:  3.822733686072752
None Run 24:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 54.30
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.007674168795347
None Run 25:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 36.80
Split: 09, Run: 02
None time:  1.9586297229398042
None Run 26:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 36.80
Split: 09, Run: 03
None time:  1.933528820052743
None Run 27:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 36.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  4.67369316983968
None Run 28:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 39.50
Split: 10, Run: 02
None time:  5.049438305897638
None Run 29:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.50
Split: 10, Run: 03
None time:  3.4991297179367393
None Run 30:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 47.30
run time now: 13.276343822479248
total time:  129.77011029305868
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 47.52 ± 6.41
  Final Train: 100.00 ± 0.00
   Final Test: 47.17 ± 6.60
best run test_acc: 50.97999954223633
[I 2023-06-12 00:56:22,030] Trial 148 finished with value: 47.52000045776367 and parameters: {'Fwd': 0.02057370504386603, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 2.576744795910434, 'loop': 2, 'loss': 'MSE', 'lr': 0.0005226830635145413, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.8041477859469724e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0009011260231187406
weight_decay:  2.0080552775300133e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9793847489636391
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 70.00
   Final Test: 54.70
Split: 01, Run: 02
None time:  1.2987557989545166
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 96.67
   Final Test: 62.30
Split: 01, Run: 03
None time:  1.292315848870203
None Run 03:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 96.67
   Final Test: 62.50
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1043969460297376
None Run 04:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 80.00
   Final Test: 67.90
Split: 02, Run: 02
None time:  1.2285032230429351
None Run 05:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 70.00
Split: 02, Run: 03
None time:  1.2375504409428686
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.10
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.584864880889654
None Run 07:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 80.00
   Final Test: 56.30
Split: 03, Run: 02
None time:  1.3137533150147647
None Run 08:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 90.00
   Final Test: 62.50
Split: 03, Run: 03
None time:  1.2723880980629474
None Run 09:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.50
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1640812889672816
None Run 10:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 80.00
   Final Test: 53.30
Split: 04, Run: 02
None time:  1.1953822409268469
None Run 11:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 66.80
Split: 04, Run: 03
None time:  1.022354976972565
None Run 12:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 66.60
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.2092878699768335
None Run 13:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 96.67
   Final Test: 64.90
Split: 05, Run: 02
None time:  1.1614062010776252
None Run 14:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 69.00
Split: 05, Run: 03
None time:  1.1778550879098475
None Run 15:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 69.10
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6755094858817756
None Run 16:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 66.90
Split: 06, Run: 02
None time:  1.2617754128295928
None Run 17:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 68.30
Split: 06, Run: 03
None time:  1.188509285915643
None Run 18:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.10
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6113391739781946
None Run 19:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 96.67
   Final Test: 55.80
Split: 07, Run: 02
None time:  1.1201159399934113
None Run 20:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 58.50
Split: 07, Run: 03
None time:  1.2788579540792853
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 96.67
   Final Test: 59.20
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.4133285689167678
None Run 22:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 80.00
   Final Test: 58.40
Split: 08, Run: 02
None time:  1.2272933421190828
None Run 23:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 90.00
   Final Test: 67.80
Split: 08, Run: 03
None time:  1.2274841768667102
None Run 24:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 90.00
   Final Test: 68.40
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6731667900457978
None Run 25:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 90.00
   Final Test: 60.00
Split: 09, Run: 02
None time:  1.250460911076516
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 67.80
Split: 09, Run: 03
None time:  1.2650544880889356
None Run 27:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 69.00
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6780416469555348
None Run 28:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 93.33
   Final Test: 63.90
Split: 10, Run: 02
None time:  1.1798270628787577
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
Split: 10, Run: 03
None time:  1.1523977909237146
None Run 30:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 70.20
run time now: 4.063137531280518
total time:  45.951531142927706
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.51 ± 6.04
  Final Train: 92.78 ± 7.43
   Final Test: 64.38 ± 5.17
best run test_acc: 66.71000671386719
[I 2023-06-12 00:57:08,461] Trial 149 finished with value: 64.51333618164062 and parameters: {'Fwd': 0.005714338680492727, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 1.8509211053629775, 'loop': 2, 'loss': 'CE', 'lr': 0.0009011260231187406, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.0080552775300133e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0006201408113218197
weight_decay:  3.020299748670907e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.29443217208609
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 73.33
   Final Test: 61.90
Split: 01, Run: 02
None time:  1.4086444720160216
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 76.67
   Final Test: 62.50
Split: 01, Run: 03
None time:  1.0608892708551139
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 62.20
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1645385259762406
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 90.00
   Final Test: 65.50
Split: 02, Run: 02
None time:  0.9625521369744092
None Run 05:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 70.50
Split: 02, Run: 03
None time:  1.0676920688711107
None Run 06:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 70.30
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.3802568591199815
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 83.33
   Final Test: 61.50
Split: 03, Run: 02
None time:  1.0758038989733905
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.10
Split: 03, Run: 03
None time:  1.0693532500881702
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.20
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.9942910610698164
None Run 10:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 41.40
Split: 04, Run: 02
None time:  1.0790976779535413
None Run 11:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 62.90
Split: 04, Run: 03
None time:  1.0677970950491726
None Run 12:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 64.30
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.0857430279720575
None Run 13:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 68.30
Split: 05, Run: 02
None time:  1.92115453700535
None Run 14:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 68.40
Split: 05, Run: 03
None time:  1.667173762107268
None Run 15:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 67.40
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.3532335970085114
None Run 16:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.20
Split: 06, Run: 02
None time:  1.2429771751631051
None Run 17:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 66.50
Split: 06, Run: 03
None time:  1.0436966340057552
None Run 18:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.30
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5620580411050469
None Run 19:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 93.33
   Final Test: 56.60
Split: 07, Run: 02
None time:  1.0574913381133229
None Run 20:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 59.10
Split: 07, Run: 03
None time:  1.0644865669310093
None Run 21:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 96.67
   Final Test: 59.60
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.8405908858403563
None Run 22:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 63.33
   Final Test: 61.30
Split: 08, Run: 02
None time:  1.0429508909583092
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 93.33
   Final Test: 68.10
Split: 08, Run: 03
None time:  0.8732764660380781
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 67.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.515246521914378
None Run 25:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 70.00
   Final Test: 59.90
Split: 09, Run: 02
None time:  1.1755164479836822
None Run 26:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 67.80
Split: 09, Run: 03
None time:  1.0588923369068652
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 68.40
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0512269120663404
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 86.67
   Final Test: 67.50
Split: 10, Run: 02
None time:  1.0440879301168025
None Run 29:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.00
Split: 10, Run: 03
None time:  1.0618000300601125
None Run 30:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.2090559005737305
total time:  44.94527033995837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.23 ± 7.27
  Final Train: 92.78 ± 9.79
   Final Test: 64.43 ± 5.75
best run test_acc: 66.56999206542969
[I 2023-06-12 00:57:53,907] Trial 150 finished with value: 65.23332977294922 and parameters: {'Fwd': 0.011076930978140189, 'K': 9, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 1.4681103856977025, 'loop': 2, 'loss': 'CE', 'lr': 0.0006201408113218197, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.020299748670907e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0004985661828168905
weight_decay:  7.139372453815952e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.033744792919606
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  2.3416047480423003
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 83.33
   Final Test: 67.50
Split: 01, Run: 03
None time:  2.192568690981716
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 76.67
   Final Test: 66.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.66136806900613
None Run 04:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 70.50
Split: 02, Run: 02
None time:  1.6330293219070882
None Run 05:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 69.70
Split: 02, Run: 03
None time:  1.6895944071002305
None Run 06:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.60
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.134580889949575
None Run 07:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.80
Split: 03, Run: 02
None time:  1.5904425010085106
None Run 08:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.50
Split: 03, Run: 03
None time:  1.571411349112168
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.80
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.830769750988111
None Run 10:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 96.67
   Final Test: 60.90
Split: 04, Run: 02
None time:  1.661899436963722
None Run 11:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 96.67
   Final Test: 63.20
Split: 04, Run: 03
None time:  1.657230829121545
None Run 12:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.80
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.0396448138635606
None Run 13:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.00
Split: 05, Run: 02
None time:  1.8063723531085998
None Run 14:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.80
Split: 05, Run: 03
None time:  1.6001455879304558
None Run 15:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.00
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7291552999522537
None Run 16:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 02
None time:  1.5880532651208341
None Run 17:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.80
Split: 06, Run: 03
None time:  1.7015929559711367
None Run 18:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.90
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.5376150130759925
None Run 19:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 86.67
   Final Test: 57.30
Split: 07, Run: 02
None time:  1.6030148367863148
None Run 20:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.70
Split: 07, Run: 03
None time:  1.492346272803843
None Run 21:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.40
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.408598273061216
None Run 22:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 90.00
   Final Test: 60.10
Split: 08, Run: 02
None time:  1.6169286139775068
None Run 23:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
Split: 08, Run: 03
None time:  1.6216950879897922
None Run 24:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.10
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.724582798080519
None Run 25:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 62.80
Split: 09, Run: 02
None time:  1.8272645559627563
None Run 26:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 67.30
Split: 09, Run: 03
None time:  1.652674132026732
None Run 27:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 93.33
   Final Test: 67.80
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.39076330489479
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 66.80
Split: 10, Run: 02
None time:  1.6842844130005687
None Run 29:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.40
Split: 10, Run: 03
None time:  1.6669364850968122
None Run 30:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 5.801475286483765
total time:  60.044037411920726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.25 ± 3.95
  Final Train: 96.22 ± 5.85
   Final Test: 65.43 ± 3.75
best run test_acc: 66.88999938964844
[I 2023-06-12 00:58:54,533] Trial 151 finished with value: 66.25333404541016 and parameters: {'Fwd': 0.02372133464976469, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 2.9338537293115357, 'loop': 2, 'loss': 'CE', 'lr': 0.0004985661828168905, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.139372453815952e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0005198320111448516
weight_decay:  7.772327380970801e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0100023788399994
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 83.33
   Final Test: 66.80
Split: 01, Run: 02
None time:  1.8681956499349326
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 90.00
   Final Test: 67.00
Split: 01, Run: 03
None time:  1.9653938519768417
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 80.00
   Final Test: 67.70
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1824475459288806
None Run 04:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.40
Split: 02, Run: 02
None time:  1.7090121910441667
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 02, Run: 03
None time:  1.7943562041036785
None Run 06:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.50
len(train) 30
random split CiteSeer split 2
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.567206925014034
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 93.33
   Final Test: 65.80
Split: 03, Run: 02
None time:  1.6238035650458187
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.70
Split: 03, Run: 03
None time:  1.6792009361088276
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.40
len(train) 30
random split CiteSeer split 3
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.0464839909691364
None Run 10:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 96.67
   Final Test: 61.70
Split: 04, Run: 02
None time:  1.7314916769973934
None Run 11:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 64.40
Split: 04, Run: 03
None time:  1.5506639960221946
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 65.50
len(train) 30
random split CiteSeer split 4
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.9548277978319675
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.20
Split: 05, Run: 02
None time:  2.1045254659838974
None Run 14:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 96.67
   Final Test: 67.50
Split: 05, Run: 03
None time:  1.8817340899258852
None Run 15:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 96.67
   Final Test: 65.70
len(train) 30
random split CiteSeer split 5
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.491286211879924
None Run 16:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 96.67
   Final Test: 64.20
Split: 06, Run: 02
None time:  1.6769654888194054
None Run 17:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 96.67
   Final Test: 67.60
Split: 06, Run: 03
None time:  1.611628991086036
None Run 18:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 96.67
   Final Test: 67.60
len(train) 30
random split CiteSeer split 6
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.38502142787911
None Run 19:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 86.67
   Final Test: 56.90
Split: 07, Run: 02
None time:  1.6046854709275067
None Run 20:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 58.50
Split: 07, Run: 03
None time:  1.6366840149275959
None Run 21:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 59.50
len(train) 30
random split CiteSeer split 7
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7999206900130957
None Run 22:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.40
Split: 08, Run: 02
None time:  1.7382619369309396
None Run 23:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.20
Split: 08, Run: 03
None time:  1.5917022870853543
None Run 24:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
len(train) 30
random split CiteSeer split 8
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.8557518240995705
None Run 25:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 93.33
   Final Test: 60.20
Split: 09, Run: 02
None time:  1.7458004439249635
None Run 26:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 67.00
Split: 09, Run: 03
None time:  1.6966418491210788
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 96.67
   Final Test: 67.90
len(train) 30
random split CiteSeer split 9
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.4579585320316255
None Run 28:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 68.50
Split: 10, Run: 02
None time:  1.664806097978726
None Run 29:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 10, Run: 03
None time:  1.6754418269265443
None Run 30:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 5.855085134506226
total time:  62.578543949872255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.27 ± 4.44
  Final Train: 96.00 ± 5.13
   Final Test: 65.86 ± 3.48
best run test_acc: 67.38999938964844
[I 2023-06-12 00:59:57,590] Trial 152 finished with value: 66.26667022705078 and parameters: {'Fwd': 0.03137264022001165, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 3.1939317083118213, 'loop': 2, 'loss': 'CE', 'lr': 0.0005198320111448516, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.772327380970801e-05, 'weightedloss': False}. Best is trial 132 with value: 66.56000518798828.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0005650425208750259
weight_decay:  7.986808409993713e-05
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 30
random split CiteSeer split 0
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9369483611080796
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 90.00
   Final Test: 64.60
Split: 01, Run: 02
None time:  1.9694542549550533
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 86.67
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.7789082638919353
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 90.00
   Final Test: 65.80
len(train) 30
random split CiteSeer split 1
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(30, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3183060300070792
None Run 04:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
Split: 02, Run: 02
None time:  1.6328803019132465
None Run 05:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.20
